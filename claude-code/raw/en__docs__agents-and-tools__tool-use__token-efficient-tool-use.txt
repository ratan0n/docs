URL: https://docs.anthropic.com/en/docs/agents-and-tools/tool-use/token-efficient-tool-use
TITLE: Token-efficient tool use - Anthropic
SCRAPED: 2025-06-23T15:07:42.244256
WORD_COUNT: 606
LINKS_FOUND: 36
================================================================================

Anthropic
home page
English
Search...
Search...
Navigation
Tools
Token-efficient tool use
Welcome
Developer Guide
API Guide
Claude Code
Model Context Protocol (MCP)
Resources
Release Notes
Documentation
Developer Discord
Support
First steps
Intro to Claude
Get started
Models & pricing
Models overview
Choosing a model
Migrating to Claude 4
Model deprecations
Pricing
Learn about Claude
Building with Claude
Features overview
Context windows
Glossary
Capabilities
Prompt caching
Extended thinking
Streaming Messages
Batch processing
Citations
Multilingual support
Token counting
Embeddings
Vision
PDF support
Files API
Google Sheets add-on
Tools
Overview
How to implement tool use
Token-efficient tool use
Fine-grained tool streaming
Bash tool
Code execution tool
Computer use tool
Text editor tool
Web search tool
Model Context Protocol (MCP)
MCP connector
Remote MCP servers
Use cases
Overview
Ticket routing
Customer support agent
Content moderation
Legal summarization
Prompt engineering
Overview
Claude 4 best practices
Prompt generator
Use prompt templates
Prompt improver
Be clear and direct
Use examples (multishot prompting)
Let Claude think (CoT)
Use XML tags
Give Claude a role (system prompts)
Prefill Claude's response
Chain complex prompts
Long context tips
Extended thinking tips
Test & evaluate
Define success criteria
Develop test cases
Using the Evaluation Tool
Reducing latency
Strengthen guardrails
Reduce hallucinations
Increase output consistency
Mitigate jailbreaks
Streaming refusals
Reduce prompt leak
Keep Claude in character
Legal center
Anthropic Privacy Policy
Security and compliance
Claude Sonnet 3.7 is capable of calling tools in a token-efficient manner. Requests save an average of 14% in output tokens, up to 70%, which also reduces latency. Exact token reduction and latency improvements depend on the overall response shape and size.
Token-efficient tool use is a beta feature. Please make sure to evaluate your responses before using it in production.
Please use
this form
to provide feedback on the quality of the model responses, the API itself, or the quality of the documentation—we cannot wait to hear from you!
If you choose to experiment with this feature, we recommend using the
Prompt Improver
in the
Console
to improve your prompt.
Token-efficient tool use does not currently work with
disable_parallel_tool_use
.
Claude 4 models (Opus and Sonnet) do not support this feature. The beta header
token-efficient-tools-2025-02-19
will not break an API request, but it will result in a no-op.
To use this beta feature, simply add the beta header
token-efficient-tools-2025-02-19
to a tool use request. If you are using the SDK, ensure that you are using the beta SDK with
anthropic.beta.messages
.
Here’s an example of how to use token-efficient tools with the API:
Shell
Python
TypeScript
Java
curl
https://api.anthropic.com/v1/messages
\
-H
"content-type: application/json"
\
-H
"x-api-key:
$ANTHROPIC_API_KEY
"
\
-H
"anthropic-version: 2023-06-01"
\
-H
"anthropic-beta: token-efficient-tools-2025-02-19"
\
-d
'
{
"model"
:
"claude-3-7-sonnet-20250219"
,
"max_tokens"
:
1024
,
"tools"
:
[
{
"name"
:
"get_weather"
,
"description"
:
"Get the current weather in a given location"
,
"input_schema"
:
{
"type"
:
"object"
,
"properties"
:
{
"location"
:
{
"type"
:
"string"
,
"description"
:
"The city and state, e.g. San Francisco, CA"
}
}
,
"required"
:
[
"location"
]
}
}
]
,
"messages"
:
[
{
"role"
:
"user"
,
"content"
:
"Tell me the weather in San Francisco."
}
]
}
' | jq '
.usage'
The above request should, on average, use fewer input and output tokens than a normal request. To confirm this, try making the same request but remove
token-efficient-tools-2025-02-19
from the beta headers list.
To keep the benefits of prompt caching, use the beta header consistently for requests you’d like to cache. If you selectively use it, prompt caching will fail.
Was this page helpful?
Yes
No
How to implement tool use
Fine-grained tool streaming