URL: https://docs.anthropic.com/en/docs/build-with-claude/prompt-engineering/prefill-claudes-response
TITLE: Prefill Claude's response for greater output control - Anthropic
SCRAPED: 2025-06-23T15:07:49.959205
WORD_COUNT: 1168
LINKS_FOUND: 12
================================================================================

Anthropic
home page
English
Search...
Search...
Navigation
Prompt engineering
Prefill Claude's response for greater output control
Welcome
Developer Guide
API Guide
Claude Code
Model Context Protocol (MCP)
Resources
Release Notes
Documentation
Developer Discord
Support
First steps
Intro to Claude
Get started
Models & pricing
Models overview
Choosing a model
Migrating to Claude 4
Model deprecations
Pricing
Learn about Claude
Building with Claude
Features overview
Context windows
Glossary
Capabilities
Prompt caching
Extended thinking
Streaming Messages
Batch processing
Citations
Multilingual support
Token counting
Embeddings
Vision
PDF support
Files API
Google Sheets add-on
Tools
Overview
How to implement tool use
Token-efficient tool use
Fine-grained tool streaming
Bash tool
Code execution tool
Computer use tool
Text editor tool
Web search tool
Model Context Protocol (MCP)
MCP connector
Remote MCP servers
Use cases
Overview
Ticket routing
Customer support agent
Content moderation
Legal summarization
Prompt engineering
Overview
Claude 4 best practices
Prompt generator
Use prompt templates
Prompt improver
Be clear and direct
Use examples (multishot prompting)
Let Claude think (CoT)
Use XML tags
Give Claude a role (system prompts)
Prefill Claude's response
Chain complex prompts
Long context tips
Extended thinking tips
Test & evaluate
Define success criteria
Develop test cases
Using the Evaluation Tool
Reducing latency
Strengthen guardrails
Reduce hallucinations
Increase output consistency
Mitigate jailbreaks
Streaming refusals
Reduce prompt leak
Keep Claude in character
Legal center
Anthropic Privacy Policy
Security and compliance
While these tips apply broadly to all Claude models, you can find prompting tips specific to extended thinking models
here
.
Prefilling is only available for non-extended thinking modes. It’s not currently supported with extended thinking.
When using Claude, you have the unique ability to guide its responses by prefilling the
Assistant
message. This powerful technique allows you to direct Claude’s actions, skip preambles, enforce specific formats like JSON or XML, and even help Claude maintain character consistency in role-play scenarios.
In some cases where Claude is not performing as expected, a few prefilled sentences can vastly improve Claude’s performance. A little prefilling goes a long way!
​
How to prefill Claude’s response
To prefill, include the desired initial text in the
Assistant
message (Claude’s response will continue from where the
Assistant
message leaves off):
import
anthropic
client
=
anthropic
.
Anthropic
(
)
response
=
client
.
messages
.
create
(
model
=
"claude-opus-4-20250514"
,
max_tokens
=
1024
,
messages
=
[
{
"role"
:
"user"
,
"content"
:
"What is your favorite color?"
}
,
{
"role"
:
"assistant"
,
"content"
:
"As an AI assistant, I don't have a favorite color, But if I had to pick, it would be green because"
}
# Prefill here
]
)
The prefill content cannot end with trailing whitespace. A prefill like
"As an AI assistant, I "
(with a space at the end) will result in an error.
​
Examples
​
Example 1: Controlling output formatting and skipping the preamble
Power user tip
: Prefilling
{
forces Claude to skip the preamble and directly output the JSON object. This is cleaner, more concise, and easier for programs to parse without additional processing.
Example: Structured data extraction without prefilling
Role
Content
User
Extract the name, size, price, and color from this product description as a JSON object:
<description>
The SmartHome Mini is a compact smart home assistant available in black or white for only $49.99. At just 5 inches wide, it lets you control lights, thermostats, and other connected devices via voice or app—no matter where you place it in your home. This affordable little hub brings convenient hands-free control to your smart devices.
</description>
Assistant
Here’s the extracted information in JSON format:
```json
{
“name”: “SmartHome Mini”,
“size”: “5 inches wide”,
“price”: “$49.99”,
“colors”: [“black”, “white”]
}
```
I’ve extracted the following details from the product description:
-
Name
: SmartHome Mini
-
Size
: 5 inches wide
-
Price
: $49.99
-
Colors
: Available in black and white
The JSON object provides a structured format that’s easy for programs to parse and use. Let me know if you need any modifications or have any other questions!
Example: Structured data extraction with prefilling
Role
Content
User
Extract the name, size, price, and color from this product description as a JSON object:
<description>
The SmartHome Mini is a compact smart home assistant available in black or white for only $49.99. At just 5 inches wide, it lets you control lights, thermostats, and other connected devices via voice or app—no matter where you place it in your home. This affordable little hub brings convenient hands-free control to your smart devices.
</description>
Assistant (prefill)
{
Assistant (Claude’s response)
“name”: “SmartHome Mini”,
“size”: “5 inches wide”,
“price”: “$49.99”,
“colors”: [
“black”,
“white”
]
}
​
Example 2: Maintaining character in roleplay scenarios
Role-play tip
: Prefilling a bracketed
[ROLE_NAME]
can remind Claude stay in character, even for longer and more complex conversations. This is especially powerful when combined with role prompting in the
system
parameter.
Example: Maintaining character without role prompting
Role
Content
User (50 conversation turns in with “Sherlock Holmes” Claude)
What do you deduce about the owner of this shoe? <image>muddy_shoe.jpg</image>
Assistant
As an AI assistant, I would be happy to analyze the image of a muddy shoe as if you had provided it. Here’s my deduction…
Example: Maintaining character with role prompting
Role
Content
User (50 conversation turns in with “Sherlock Holmes” Claude)
What do you deduce about the owner of this shoe?
<image>muddy_shoe.jpg</image>
Assistant (prefill)
[Sherlock Holmes]
Assistant (Claude’s response)
Ah, what have we here? A most curious specimen, Watson! Let us examine this shoe with a discerning eye. The mud, you see, is not your common London clay, but rather the distinctive reddish hue of the iron-rich soil found only in the environs of Hampstead Heath. And yet, the wear on the sole suggests a gait more suited to the cobblestones of Whitechapel than the gentle slopes of the Heath.
Now, observe the laces! They are tied with a particular knot favored by those in the medical profession—doubtless a habit acquired during years of tying surgical gowns. But the scuff marks on the toe box tell a different tale: they are consistent with the kicking motion one might employ in the martial arts, specifically Baritsu.
We may conclude, then, that our absent shoe owner is a doctor, possibly a surgeon, who resides in Whitechapel but frequents Hampstead Heath—perhaps for a secret Baritsu practice, away from prying eyes. A most intriguing case, Watson! We must make haste; the game is afoot!
Prompt library
Get inspired by a curated selection of prompts for various tasks and use cases.
GitHub prompting tutorial
An example-filled tutorial that covers the prompt engineering concepts found in our docs.
Google Sheets prompting tutorial
A lighter weight version of our prompt engineering tutorial via an interactive spreadsheet.
Was this page helpful?
Yes
No
Give Claude a role (system prompts)
Chain complex prompts
On this page
How to prefill Claude’s response
Examples
Example 1: Controlling output formatting and skipping the preamble
Example 2: Maintaining character in roleplay scenarios