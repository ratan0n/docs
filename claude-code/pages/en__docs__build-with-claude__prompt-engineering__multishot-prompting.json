{
  "url": "https://docs.anthropic.com/en/docs/build-with-claude/prompt-engineering/multishot-prompting",
  "title": "Use examples (multishot prompting) to guide Claude's behavior - Anthropic",
  "text": "Anthropic\nhome page\nEnglish\nSearch...\nSearch...\nNavigation\nPrompt engineering\nUse examples (multishot prompting) to guide Claude's behavior\nWelcome\nDeveloper Guide\nAPI Guide\nClaude Code\nModel Context Protocol (MCP)\nResources\nRelease Notes\nDocumentation\nDeveloper Discord\nSupport\nFirst steps\nIntro to Claude\nGet started\nModels & pricing\nModels overview\nChoosing a model\nMigrating to Claude 4\nModel deprecations\nPricing\nLearn about Claude\nBuilding with Claude\nFeatures overview\nContext windows\nGlossary\nCapabilities\nPrompt caching\nExtended thinking\nStreaming Messages\nBatch processing\nCitations\nMultilingual support\nToken counting\nEmbeddings\nVision\nPDF support\nFiles API\nGoogle Sheets add-on\nTools\nOverview\nHow to implement tool use\nToken-efficient tool use\nFine-grained tool streaming\nBash tool\nCode execution tool\nComputer use tool\nText editor tool\nWeb search tool\nModel Context Protocol (MCP)\nMCP connector\nRemote MCP servers\nUse cases\nOverview\nTicket routing\nCustomer support agent\nContent moderation\nLegal summarization\nPrompt engineering\nOverview\nClaude 4 best practices\nPrompt generator\nUse prompt templates\nPrompt improver\nBe clear and direct\nUse examples (multishot prompting)\nLet Claude think (CoT)\nUse XML tags\nGive Claude a role (system prompts)\nPrefill Claude's response\nChain complex prompts\nLong context tips\nExtended thinking tips\nTest & evaluate\nDefine success criteria\nDevelop test cases\nUsing the Evaluation Tool\nReducing latency\nStrengthen guardrails\nReduce hallucinations\nIncrease output consistency\nMitigate jailbreaks\nStreaming refusals\nReduce prompt leak\nKeep Claude in character\nLegal center\nAnthropic Privacy Policy\nSecurity and compliance\nWhile these tips apply broadly to all Claude models, you can find prompting tips specific to extended thinking models\nhere\n.\nExamples are your secret weapon shortcut for getting Claude to generate exactly what you need. By providing a few well-crafted examples in your prompt, you can dramatically improve the accuracy, consistency, and quality of Claude’s outputs.\nThis technique, known as few-shot or multishot prompting, is particularly effective for tasks that require structured outputs or adherence to specific formats.\nPower up your prompts\n: Include 3-5 diverse, relevant examples to show Claude exactly what you want. More examples = better performance, especially for complex tasks.\n​\nWhy use examples?\nAccuracy\n: Examples reduce misinterpretation of instructions.\nConsistency\n: Examples enforce uniform structure and style.\nPerformance\n: Well-chosen examples boost Claude’s ability to handle complex tasks.\n​\nCrafting effective examples\nFor maximum effectiveness, make sure that your examples are:\nRelevant\n: Your examples mirror your actual use case.\nDiverse\n: Your examples cover edge cases and potential challenges, and vary enough that Claude doesn’t inadvertently pick up on unintended patterns.\nClear\n: Your examples are wrapped in\n<example>\ntags (if multiple, nested within\n<examples>\ntags) for structure.\nAsk Claude to evaluate your examples for relevance, diversity, or clarity. Or have Claude generate more examples based on your initial set.\nExample: Analyzing customer feedback\nNotice that in the “no examples” version, Claude does not list multiple options for each category, despite its written analysis indicating that there are multiple categories for certain feedback. It also includes a long explanation when we may not want it to.\nRole\nNo Examples\nWith Examples\nUser\nAnalyze this customer feedback and categorize the issues. Use these categories: UI/UX, Performance, Feature Request, Integration, Pricing, and Other. Also rate the sentiment (Positive/Neutral/Negative) and priority (High/Medium/Low).\nHere is the feedback: {{FEEDBACK}}\nOur CS team is overwhelmed with unstructured feedback. Your task is to analyze feedback and categorize issues for our product and engineering teams. Use these categories: UI/UX, Performance, Feature Request, Integration, Pricing, and Other. Also rate the sentiment (Positive/Neutral/Negative) and priority (High/Medium/Low). Here is an example:\n<example>\nInput: The new dashboard is a mess! It takes forever to load, and I can’t find the export button. Fix this ASAP!\nCategory: UI/UX, Performance\nSentiment: Negative\nPriority: High</example>\nNow, analyze this feedback: {{FEEDBACK}}\nAssistant (Claude’s response)\nHere’s the analysis of the customer feedback:\nIssue: UI/UX\nSentiment: Negative\nPriority: High\nThe customer is frustrated with the new dashboard design, which they find cluttered and slow to load. They specifically call out the missing “export” button, which is likely a critical feature. This issue needs to be addressed as a high priority.\nIssue: Integration\nSentiment: Positive\nPriority: Medium\nThe customer is pleased with the existing Salesforce integration but would like to see support for Hubspot as well. This is a feature request that could be considered for a future product update.\nIssue: Pricing\nSentiment: Negative\nPriority: High\nThe customer finds the pricing to be unreasonable, especially for the basic features. They are threatening to switch to a competitor, so this is a high-priority issue that needs to be reviewed.\nIssue: Performance\nSentiment Negative\nPriority: High\nThe customer is experiencing critical issues with the mobile app, where large file uploads consistently result in crashes. This is a significant problem that impacts the customer’s ability to use the product effectively and should be addressed as a high priority.\nIssue: UI/UX\nSentiment: Positive\nPriority: Low\nThe customer is overall satisfied with the product, specifically calling out the intuitive UI and excellent customer support. This is a positive piece of feedback that does not require any immediate action.\nHere’s the analysis of the customer feedback:\n1. The new dashboard is a mess! It takes forever to load, and I can’t find the export button. Fix this ASAP!\nCategory: UI/UX, Performance\nSentiment: Negative\nPriority: High\n2. Love the Salesforce integration! But it’d be great if you could add Hubspot too.\nCategory: Integration, Feature Request\nSentiment: Positive\nPriority: Medium\n3. Your pricing is ridiculous! $99/mo for basic features? I’m switching to Competitor X.\nCategory: Pricing\nSentiment: Negative\nPriority: High\n4. The mobile app keeps crashing when I try to upload large files (>50MB). This is critical for our field agents.\nCategory: Performance\nSentiment: Negative\nPriority: High\n5. Overall, I’m happy with the product. The UI is intuitive, and the customer support is top-notch. Keep it up!\nCategory: UI/UX, Other (Customer Support)\nSentiment: Positive\nPriority: Low\nPrompt library\nGet inspired by a curated selection of prompts for various tasks and use cases.\nGitHub prompting tutorial\nAn example-filled tutorial that covers the prompt engineering concepts found in our docs.\nGoogle Sheets prompting tutorial\nA lighter weight version of our prompt engineering tutorial via an interactive spreadsheet.\nWas this page helpful?\nYes\nNo\nBe clear and direct\nLet Claude think (CoT)\nOn this page\nWhy use examples?\nCrafting effective examples",
  "links": [
    {
      "url": "https://docs.anthropic.com/en/docs/build-with-claude/prompt-engineering/chain-of-thought",
      "text": "Let Claude think (CoT)"
    },
    {
      "url": "https://docs.anthropic.com/en/docs/build-with-claude/prompt-engineering/use-xml-tags",
      "text": "Use XML tags"
    },
    {
      "url": "https://docs.anthropic.com/en/docs/build-with-claude/prompt-engineering/system-prompts",
      "text": "Give Claude a role (system prompts)"
    },
    {
      "url": "https://docs.anthropic.com/en/docs/build-with-claude/prompt-engineering/prefill-claudes-response",
      "text": "Prefill Claude's response"
    },
    {
      "url": "https://docs.anthropic.com/en/docs/build-with-claude/prompt-engineering/chain-prompts",
      "text": "Chain complex prompts"
    },
    {
      "url": "https://docs.anthropic.com/en/docs/build-with-claude/prompt-engineering/long-context-tips",
      "text": "Long context tips"
    },
    {
      "url": "https://docs.anthropic.com/en/docs/build-with-claude/prompt-engineering/extended-thinking-tips",
      "text": "Extended thinking tips"
    },
    {
      "url": "https://docs.anthropic.com/en/docs/test-and-evaluate/define-success",
      "text": "Define success criteria"
    },
    {
      "url": "https://docs.anthropic.com/en/docs/test-and-evaluate/develop-tests",
      "text": "Develop test cases"
    },
    {
      "url": "https://docs.anthropic.com/en/docs/test-and-evaluate/eval-tool",
      "text": "Using the Evaluation Tool"
    },
    {
      "url": "https://docs.anthropic.com/en/docs/test-and-evaluate/strengthen-guardrails/reduce-latency",
      "text": "Reducing latency"
    },
    {
      "url": "https://docs.anthropic.com/en/docs/test-and-evaluate/strengthen-guardrails/reduce-hallucinations",
      "text": "Reduce hallucinations"
    },
    {
      "url": "https://docs.anthropic.com/en/docs/test-and-evaluate/strengthen-guardrails/increase-consistency",
      "text": "Increase output consistency"
    },
    {
      "url": "https://docs.anthropic.com/en/docs/test-and-evaluate/strengthen-guardrails/mitigate-jailbreaks",
      "text": "Mitigate jailbreaks"
    },
    {
      "url": "https://docs.anthropic.com/en/docs/test-and-evaluate/strengthen-guardrails/handle-streaming-refusals",
      "text": "Streaming refusals"
    },
    {
      "url": "https://docs.anthropic.com/en/docs/test-and-evaluate/strengthen-guardrails/reduce-prompt-leak",
      "text": "Reduce prompt leak"
    },
    {
      "url": "https://docs.anthropic.com/en/docs/test-and-evaluate/strengthen-guardrails/keep-claude-in-character",
      "text": "Keep Claude in character"
    },
    {
      "url": "https://docs.anthropic.com/en/resources/prompt-library/library",
      "text": "Prompt libraryGet inspired by a curated selection of prompts for various tasks and use cases."
    }
  ],
  "metadata": {
    "scraped_at": "2025-06-23T15:07:48.600307",
    "word_count": 1036,
    "link_count": 18,
    "content_length": 7098
  }
}