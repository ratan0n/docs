{
  "url": "https://docs.anthropic.com/en/docs/build-with-claude/context-windows",
  "title": "Context windows - Anthropic",
  "text": "Anthropic\nhome page\nEnglish\nSearch...\nSearch...\nNavigation\nLearn about Claude\nContext windows\nWelcome\nDeveloper Guide\nAPI Guide\nClaude Code\nModel Context Protocol (MCP)\nResources\nRelease Notes\nDocumentation\nDeveloper Discord\nSupport\nFirst steps\nIntro to Claude\nGet started\nModels & pricing\nModels overview\nChoosing a model\nMigrating to Claude 4\nModel deprecations\nPricing\nLearn about Claude\nBuilding with Claude\nFeatures overview\nContext windows\nGlossary\nCapabilities\nPrompt caching\nExtended thinking\nStreaming Messages\nBatch processing\nCitations\nMultilingual support\nToken counting\nEmbeddings\nVision\nPDF support\nFiles API\nGoogle Sheets add-on\nTools\nOverview\nHow to implement tool use\nToken-efficient tool use\nFine-grained tool streaming\nBash tool\nCode execution tool\nComputer use tool\nText editor tool\nWeb search tool\nModel Context Protocol (MCP)\nMCP connector\nRemote MCP servers\nUse cases\nOverview\nTicket routing\nCustomer support agent\nContent moderation\nLegal summarization\nPrompt engineering\nOverview\nClaude 4 best practices\nPrompt generator\nUse prompt templates\nPrompt improver\nBe clear and direct\nUse examples (multishot prompting)\nLet Claude think (CoT)\nUse XML tags\nGive Claude a role (system prompts)\nPrefill Claude's response\nChain complex prompts\nLong context tips\nExtended thinking tips\nTest & evaluate\nDefine success criteria\nDevelop test cases\nUsing the Evaluation Tool\nReducing latency\nStrengthen guardrails\nReduce hallucinations\nIncrease output consistency\nMitigate jailbreaks\nStreaming refusals\nReduce prompt leak\nKeep Claude in character\nLegal center\nAnthropic Privacy Policy\nSecurity and compliance\n​\nUnderstanding the context window\nThe “context window” refers to the entirety of the amount of text a language model can look back on and reference when generating new text plus the new text it generates. This is different from the large corpus of data the language model was trained on, and instead represents a “working memory” for the model. A larger context window allows the model to understand and respond to more complex and lengthy prompts, while a smaller context window may limit the model’s ability to handle longer prompts or maintain coherence over extended conversations.\nThe diagram below illustrates the standard context window behavior for API requests\n1\n:\n1\nFor chat interfaces, such as for\nclaude.ai\n, context windows can also be set up on a rolling “first in, first out” system.\nProgressive token accumulation:\nAs the conversation advances through turns, each user message and assistant response accumulates within the context window. Previous turns are preserved completely.\nLinear growth pattern:\nThe context usage grows linearly with each turn, with previous turns preserved completely.\n200K token capacity:\nThe total available context window (200,000 tokens) represents the maximum capacity for storing conversation history and generating new output from Claude.\nInput-output flow:\nEach turn consists of:\nInput phase:\nContains all previous conversation history plus the current user message\nOutput phase:\nGenerates a text response that becomes part of a future input\n​\nThe context window with extended thinking\nWhen using\nextended thinking\n, all input and output tokens, including the tokens used for thinking, count toward the context window limit, with a few nuances in multi-turn situations.\nThe thinking budget tokens are a subset of your\nmax_tokens\nparameter, are billed as output tokens, and count towards rate limits.\nHowever, previous thinking blocks are automatically stripped from the context window calculation by the Anthropic API and are not part of the conversation history that the model “sees” for subsequent turns, preserving token capacity for actual conversation content.\nThe diagram below demonstrates the specialized token management when extended thinking is enabled:\nStripping extended thinking:\nExtended thinking blocks (shown in dark gray) are generated during each turn’s output phase,\nbut are not carried forward as input tokens for subsequent turns\n. You do not need to strip the thinking blocks yourself. The Anthropic API automatically does this for you if you pass them back.\nTechnical implementation details:\nThe API automatically excludes thinking blocks from previous turns when you pass them back as part of the conversation history.\nExtended thinking tokens are billed as output tokens only once, during their generation.\nThe effective context window calculation becomes:\ncontext_window = (input_tokens - previous_thinking_tokens) + current_turn_tokens\n.\nThinking tokens include both\nthinking\nblocks and\nredacted_thinking\nblocks.\nThis architecture is token efficient and allows for extensive reasoning without token waste, as thinking blocks can be substantial in length.\nYou can read more about the context window and extended thinking in our\nextended thinking guide\n.\n​\nThe context window with extended thinking and tool use\nThe diagram below illustrates the context window token management when combining extended thinking with tool use:\n1\nFirst turn architecture\nInput components:\nTools configuration and user message\nOutput components:\nExtended thinking + text response + tool use request\nToken calculation:\nAll input and output components count toward the context window, and all output components are billed as output tokens.\n2\nTool result handling (turn 2)\nInput components:\nEvery block in the first turn as well as the\ntool_result\n. The extended thinking block\nmust\nbe returned with the corresponding tool results. This is the only case wherein you\nhave to\nreturn thinking blocks.\nOutput components:\nAfter tool results have been passed back to Claude, Claude will respond with only text (no additional extended thinking until the next\nuser\nmessage).\nToken calculation:\nAll input and output components count toward the context window, and all output components are billed as output tokens.\n3\nThird Step\nInput components:\nAll inputs and the output from the previous turn is carried forward with the exception of the thinking block, which can be dropped now that Claude has completed the entire tool use cycle. The API will automatically strip the thinking block for you if you pass it back, or you can feel free to strip it yourself at this stage. This is also where you would add the next\nUser\nturn.\nOutput components:\nSince there is a new\nUser\nturn outside of the tool use cycle, Claude will generate a new extended thinking block and continue from there.\nToken calculation:\nPrevious thinking tokens are automatically stripped from context window calculations. All other previous blocks still count as part of the token window, and the thinking block in the current\nAssistant\nturn counts as part of the context window.\nConsiderations for tool use with extended thinking:\nWhen posting tool results, the entire unmodified thinking block that accompanies that specific tool request (including signature/redacted portions) must be included.\nThe effective context window calculation for extended thinking with tool use becomes:\ncontext_window = input_tokens + current_turn_tokens\n.\nThe system uses cryptographic signatures to verify thinking block authenticity. Failing to preserve thinking blocks during tool use can break Claude’s reasoning continuity. Thus, if you modify thinking blocks, the API will return an error.\nClaude 4 models support\ninterleaved thinking\n, which enables Claude to think between tool calls and make more sophisticated reasoning after receiving tool results.\nClaude Sonnet 3.7 does not support interleaved thinking, so there is no interleaving of extended thinking and tool calls without a non-\ntool_result\nuser turn in between.\nFor more information about using tools with extended thinking, see our\nextended thinking guide\n.\n​\nContext window management with newer Claude models\nIn newer Claude models (starting with Claude Sonnet 3.7), if the sum of prompt tokens and output tokens exceeds the model’s context window, the system will return a validation error rather than silently truncating the context. This change provides more predictable behavior but requires more careful token management.\nTo plan your token usage and ensure you stay within context window limits, you can use the\ntoken counting API\nto estimate how many tokens your messages will use before sending them to Claude.\nSee our\nmodel comparison\ntable for a list of context window sizes by model.\n​\nNext steps\nModel comparison table\nSee our model comparison table for a list of context window sizes and input / output token pricing by model.\nExtended thinking overview\nLearn more about how extended thinking works and how to implement it alongside other features such as tool use and prompt caching.\nWas this page helpful?\nYes\nNo\nFeatures overview\nGlossary\nOn this page\nUnderstanding the context window\nThe context window with extended thinking\nThe context window with extended thinking and tool use\nContext window management with newer Claude models\nNext steps",
  "links": [
    {
      "url": "https://docs.anthropic.com/en/docs/about-claude/glossary",
      "text": "Glossary"
    },
    {
      "url": "https://docs.anthropic.com/en/docs/build-with-claude/prompt-caching",
      "text": "Prompt caching"
    },
    {
      "url": "https://docs.anthropic.com/en/docs/build-with-claude/extended-thinking",
      "text": "Extended thinking"
    },
    {
      "url": "https://docs.anthropic.com/en/docs/build-with-claude/streaming",
      "text": "Streaming Messages"
    },
    {
      "url": "https://docs.anthropic.com/en/docs/build-with-claude/batch-processing",
      "text": "Batch processing"
    },
    {
      "url": "https://docs.anthropic.com/en/docs/build-with-claude/citations",
      "text": "Citations"
    },
    {
      "url": "https://docs.anthropic.com/en/docs/build-with-claude/multilingual-support",
      "text": "Multilingual support"
    },
    {
      "url": "https://docs.anthropic.com/en/docs/build-with-claude/token-counting",
      "text": "Token counting"
    },
    {
      "url": "https://docs.anthropic.com/en/docs/build-with-claude/embeddings",
      "text": "Embeddings"
    },
    {
      "url": "https://docs.anthropic.com/en/docs/build-with-claude/vision",
      "text": "Vision"
    },
    {
      "url": "https://docs.anthropic.com/en/docs/build-with-claude/pdf-support",
      "text": "PDF support"
    },
    {
      "url": "https://docs.anthropic.com/en/docs/build-with-claude/files",
      "text": "Files API"
    },
    {
      "url": "https://docs.anthropic.com/en/docs/agents-and-tools/claude-for-sheets",
      "text": "Google Sheets add-on"
    },
    {
      "url": "https://docs.anthropic.com/en/docs/agents-and-tools/tool-use/overview",
      "text": "Overview"
    },
    {
      "url": "https://docs.anthropic.com/en/docs/agents-and-tools/tool-use/implement-tool-use",
      "text": "How to implement tool use"
    },
    {
      "url": "https://docs.anthropic.com/en/docs/agents-and-tools/tool-use/token-efficient-tool-use",
      "text": "Token-efficient tool use"
    },
    {
      "url": "https://docs.anthropic.com/en/docs/agents-and-tools/tool-use/fine-grained-tool-streaming",
      "text": "Fine-grained tool streaming"
    },
    {
      "url": "https://docs.anthropic.com/en/docs/agents-and-tools/tool-use/bash-tool",
      "text": "Bash tool"
    },
    {
      "url": "https://docs.anthropic.com/en/docs/agents-and-tools/tool-use/code-execution-tool",
      "text": "Code execution tool"
    },
    {
      "url": "https://docs.anthropic.com/en/docs/agents-and-tools/tool-use/computer-use-tool",
      "text": "Computer use tool"
    },
    {
      "url": "https://docs.anthropic.com/en/docs/agents-and-tools/tool-use/text-editor-tool",
      "text": "Text editor tool"
    },
    {
      "url": "https://docs.anthropic.com/en/docs/agents-and-tools/tool-use/web-search-tool",
      "text": "Web search tool"
    },
    {
      "url": "https://docs.anthropic.com/en/docs/agents-and-tools/mcp-connector",
      "text": "MCP connector"
    },
    {
      "url": "https://docs.anthropic.com/en/docs/agents-and-tools/remote-mcp-servers",
      "text": "Remote MCP servers"
    },
    {
      "url": "https://docs.anthropic.com/en/docs/about-claude/use-case-guides/overview",
      "text": "Overview"
    },
    {
      "url": "https://docs.anthropic.com/en/docs/about-claude/use-case-guides/ticket-routing",
      "text": "Ticket routing"
    },
    {
      "url": "https://docs.anthropic.com/en/docs/about-claude/use-case-guides/customer-support-chat",
      "text": "Customer support agent"
    },
    {
      "url": "https://docs.anthropic.com/en/docs/about-claude/use-case-guides/content-moderation",
      "text": "Content moderation"
    },
    {
      "url": "https://docs.anthropic.com/en/docs/about-claude/use-case-guides/legal-summarization",
      "text": "Legal summarization"
    },
    {
      "url": "https://docs.anthropic.com/en/docs/build-with-claude/prompt-engineering/overview",
      "text": "Overview"
    },
    {
      "url": "https://docs.anthropic.com/en/docs/build-with-claude/prompt-engineering/claude-4-best-practices",
      "text": "Claude 4 best practices"
    },
    {
      "url": "https://docs.anthropic.com/en/docs/build-with-claude/prompt-engineering/prompt-generator",
      "text": "Prompt generator"
    },
    {
      "url": "https://docs.anthropic.com/en/docs/build-with-claude/prompt-engineering/prompt-templates-and-variables",
      "text": "Use prompt templates"
    },
    {
      "url": "https://docs.anthropic.com/en/docs/build-with-claude/prompt-engineering/prompt-improver",
      "text": "Prompt improver"
    },
    {
      "url": "https://docs.anthropic.com/en/docs/build-with-claude/prompt-engineering/be-clear-and-direct",
      "text": "Be clear and direct"
    },
    {
      "url": "https://docs.anthropic.com/en/docs/build-with-claude/prompt-engineering/multishot-prompting",
      "text": "Use examples (multishot prompting)"
    },
    {
      "url": "https://docs.anthropic.com/en/docs/build-with-claude/prompt-engineering/chain-of-thought",
      "text": "Let Claude think (CoT)"
    },
    {
      "url": "https://docs.anthropic.com/en/docs/build-with-claude/prompt-engineering/use-xml-tags",
      "text": "Use XML tags"
    },
    {
      "url": "https://docs.anthropic.com/en/docs/build-with-claude/prompt-engineering/system-prompts",
      "text": "Give Claude a role (system prompts)"
    },
    {
      "url": "https://docs.anthropic.com/en/docs/build-with-claude/prompt-engineering/prefill-claudes-response",
      "text": "Prefill Claude's response"
    },
    {
      "url": "https://docs.anthropic.com/en/docs/build-with-claude/prompt-engineering/chain-prompts",
      "text": "Chain complex prompts"
    },
    {
      "url": "https://docs.anthropic.com/en/docs/build-with-claude/prompt-engineering/long-context-tips",
      "text": "Long context tips"
    },
    {
      "url": "https://docs.anthropic.com/en/docs/build-with-claude/prompt-engineering/extended-thinking-tips",
      "text": "Extended thinking tips"
    },
    {
      "url": "https://docs.anthropic.com/en/docs/test-and-evaluate/define-success",
      "text": "Define success criteria"
    },
    {
      "url": "https://docs.anthropic.com/en/docs/test-and-evaluate/develop-tests",
      "text": "Develop test cases"
    },
    {
      "url": "https://docs.anthropic.com/en/docs/test-and-evaluate/eval-tool",
      "text": "Using the Evaluation Tool"
    },
    {
      "url": "https://docs.anthropic.com/en/docs/test-and-evaluate/strengthen-guardrails/reduce-latency",
      "text": "Reducing latency"
    },
    {
      "url": "https://docs.anthropic.com/en/docs/test-and-evaluate/strengthen-guardrails/reduce-hallucinations",
      "text": "Reduce hallucinations"
    },
    {
      "url": "https://docs.anthropic.com/en/docs/test-and-evaluate/strengthen-guardrails/increase-consistency",
      "text": "Increase output consistency"
    },
    {
      "url": "https://docs.anthropic.com/en/docs/test-and-evaluate/strengthen-guardrails/mitigate-jailbreaks",
      "text": "Mitigate jailbreaks"
    },
    {
      "url": "https://docs.anthropic.com/en/docs/test-and-evaluate/strengthen-guardrails/handle-streaming-refusals",
      "text": "Streaming refusals"
    },
    {
      "url": "https://docs.anthropic.com/en/docs/test-and-evaluate/strengthen-guardrails/reduce-prompt-leak",
      "text": "Reduce prompt leak"
    },
    {
      "url": "https://docs.anthropic.com/en/docs/test-and-evaluate/strengthen-guardrails/keep-claude-in-character",
      "text": "Keep Claude in character"
    }
  ],
  "metadata": {
    "scraped_at": "2025-06-23T15:07:35.700938",
    "word_count": 1355,
    "link_count": 53,
    "content_length": 8939
  }
}