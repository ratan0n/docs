{
  "url": "https://docs.anthropic.com/en/docs/about-claude/use-case-guides/legal-summarization",
  "title": "Legal summarization - Anthropic",
  "text": "Anthropic\nhome page\nEnglish\nSearch...\nSearch...\nNavigation\nUse cases\nLegal summarization\nWelcome\nDeveloper Guide\nAPI Guide\nClaude Code\nModel Context Protocol (MCP)\nResources\nRelease Notes\nDocumentation\nDeveloper Discord\nSupport\nFirst steps\nIntro to Claude\nGet started\nModels & pricing\nModels overview\nChoosing a model\nMigrating to Claude 4\nModel deprecations\nPricing\nLearn about Claude\nBuilding with Claude\nFeatures overview\nContext windows\nGlossary\nCapabilities\nPrompt caching\nExtended thinking\nStreaming Messages\nBatch processing\nCitations\nMultilingual support\nToken counting\nEmbeddings\nVision\nPDF support\nFiles API\nGoogle Sheets add-on\nTools\nOverview\nHow to implement tool use\nToken-efficient tool use\nFine-grained tool streaming\nBash tool\nCode execution tool\nComputer use tool\nText editor tool\nWeb search tool\nModel Context Protocol (MCP)\nMCP connector\nRemote MCP servers\nUse cases\nOverview\nTicket routing\nCustomer support agent\nContent moderation\nLegal summarization\nPrompt engineering\nOverview\nClaude 4 best practices\nPrompt generator\nUse prompt templates\nPrompt improver\nBe clear and direct\nUse examples (multishot prompting)\nLet Claude think (CoT)\nUse XML tags\nGive Claude a role (system prompts)\nPrefill Claude's response\nChain complex prompts\nLong context tips\nExtended thinking tips\nTest & evaluate\nDefine success criteria\nDevelop test cases\nUsing the Evaluation Tool\nReducing latency\nStrengthen guardrails\nReduce hallucinations\nIncrease output consistency\nMitigate jailbreaks\nStreaming refusals\nReduce prompt leak\nKeep Claude in character\nLegal center\nAnthropic Privacy Policy\nSecurity and compliance\nVisit our\nsummarization cookbook\nto see an example legal summarization implementation using Claude.\n​\nBefore building with Claude\n​\nDecide whether to use Claude for legal summarization\nHere are some key indicators that you should employ an LLM like Claude to summarize legal documents:\nYou want to review a high volume of documents efficiently and affordably\nLarge-scale document review can be time-consuming and expensive when done manually. Claude can process and summarize vast amounts of legal documents rapidly, significantly reducing the time and cost associated with document review. This capability is particularly valuable for tasks like due diligence, contract analysis, or litigation discovery, where efficiency is crucial.\nYou require automated extraction of key metadata\nClaude can efficiently extract and categorize important metadata from legal documents, such as parties involved, dates, contract terms, or specific clauses. This automated extraction can help organize information, making it easier to search, analyze, and manage large document sets. It’s especially useful for contract management, compliance checks, or creating searchable databases of legal information.\nYou want to generate clear, concise, and standardized summaries\nClaude can generate structured summaries that follow predetermined formats, making it easier for legal professionals to quickly grasp the key points of various documents. These standardized summaries can improve readability, facilitate comparison between documents, and enhance overall comprehension, especially when dealing with complex legal language or technical jargon.\nYou need precise citations for your summaries\nWhen creating legal summaries, proper attribution and citation are crucial to ensure credibility and compliance with legal standards. Claude can be prompted to include accurate citations for all referenced legal points, making it easier for legal professionals to review and verify the summarized information.\nYou want to streamline and expedite your legal research process\nClaude can assist in legal research by quickly analyzing large volumes of case law, statutes, and legal commentary. It can identify relevant precedents, extract key legal principles, and summarize complex legal arguments. This capability can significantly speed up the research process, allowing legal professionals to focus on higher-level analysis and strategy development.\n​\nDetermine the details you want the summarization to extract\nThere is no single correct summary for any given document. Without clear direction, it can be difficult for Claude to determine which details to include. To achieve optimal results, identify the specific information you want to include in the summary.\nFor instance, when summarizing a sublease agreement, you might wish to extract the following key points:\ndetails_to_extract\n=\n[\n'Parties involved (sublessor, sublessee, and original lessor)'\n,\n'Property details (address, description, and permitted use)'\n,\n'Term and rent (start date, end date, monthly rent, and security deposit)'\n,\n'Responsibilities (utilities, maintenance, and repairs)'\n,\n'Consent and notices (landlord\\'s consent, and notice requirements)'\n,\n'Special provisions (furniture, parking, and subletting restrictions)'\n]\n​\nEstablish success criteria\nEvaluating the quality of summaries is a notoriously challenging task. Unlike many other natural language processing tasks, evaluation of summaries often lacks clear-cut, objective metrics. The process can be highly subjective, with different readers valuing different aspects of a summary. Here are criteria you may wish to consider when assessing how well Claude performs legal summarization.\nFactual correctness\nThe summary should accurately represent the facts, legal concepts, and key points in the document.\nLegal precision\nTerminology and references to statutes, case law, or regulations must be correct and aligned with legal standards.\nConciseness\nThe summary should condense the legal document to its essential points without losing important details.\nConsistency\nIf summarizing multiple documents, the LLM should maintain a consistent structure and approach to each summary.\nReadability\nThe text should be clear and easy to understand. If the audience is not legal experts, the summarization should not include legal jargon that could confuse the audience.\nBias and fairness\nThe summary should present an unbiased and fair depiction of the legal arguments and positions.\nSee our guide on\nestablishing success criteria\nfor more information.\n​\nHow to summarize legal documents using Claude\n​\nSelect the right Claude model\nModel accuracy is extremely important when summarizing legal documents. Claude Sonnet 3.5 is an excellent choice for use cases such as this where high accuracy is required. If the size and quantity of your documents is large such that costs start to become a concern, you can also try using a smaller model like Claude Haiku 3.\nTo help estimate these costs, below is a comparison of the cost to summarize 1,000 sublease agreements using both Sonnet and Haiku:\nContent size\nNumber of agreements: 1,000\nCharacters per agreement: 300,000\nTotal characters: 300M\nEstimated tokens\nInput tokens: 86M (assuming 1 token per 3.5 characters)\nOutput tokens per summary: 350\nTotal output tokens: 350,000\nClaude Sonnet 4 estimated cost\nInput token cost: 86 MTok * $3.00/MTok = $258\nOutput token cost: 0.35 MTok * $15.00/MTok = $5.25\nTotal cost: $258.00 + $5.25 = $263.25\nClaude Haiku 3 estimated cost\nInput token cost: 86 MTok * $0.25/MTok = $21.50\nOutput token cost: 0.35 MTok * $1.25/MTok = $0.44\nTotal cost: $21.50 + $0.44 = $21.96\nActual costs may differ from these estimates. These estimates are based on the example highlighted in the section on\nprompting\n.\n​\nTransform documents into a format that Claude can process\nBefore you begin summarizing documents, you need to prepare your data. This involves extracting text from PDFs, cleaning the text, and ensuring it’s ready to be processed by Claude.\nHere is a demonstration of this process on a sample pdf:\nfrom\nio\nimport\nBytesIO\nimport\nre\nimport\npypdf\nimport\nrequests\ndef\nget_llm_text\n(\npdf_file\n)\n:\nreader\n=\npypdf\n.\nPdfReader\n(\npdf_file\n)\ntext\n=\n\"\\n\"\n.\njoin\n(\n[\npage\n.\nextract_text\n(\n)\nfor\npage\nin\nreader\n.\npages\n]\n)\n# Remove extra whitespace\ntext\n=\nre\n.\nsub\n(\nr'\\s+'\n,\n' '\n,\ntext\n)\n# Remove page numbers\ntext\n=\nre\n.\nsub\n(\nr'\\n\\s*\\d+\\s*\\n'\n,\n'\\n'\n,\ntext\n)\nreturn\ntext\n# Create the full URL from the GitHub repository\nurl\n=\n\"https://raw.githubusercontent.com/anthropics/anthropic-cookbook/main/skills/summarization/data/Sample Sublease Agreement.pdf\"\nurl\n=\nurl\n.\nreplace\n(\n\" \"\n,\n\"%20\"\n)\n# Download the PDF file into memory\nresponse\n=\nrequests\n.\nget\n(\nurl\n)\n# Load the PDF from memory\npdf_file\n=\nBytesIO\n(\nresponse\n.\ncontent\n)\ndocument_text\n=\nget_llm_text\n(\npdf_file\n)\nprint\n(\ndocument_text\n[\n:\n50000\n]\n)\nIn this example, we first download a pdf of a sample sublease agreement used in the\nsummarization cookbook\n. This agreement was sourced from a publicly available sublease agreement from the\nsec.gov website\n.\nWe use the pypdf library to extract the contents of the pdf and convert it to text. The text data is then cleaned by removing extra whitespace and page numbers.\n​\nBuild a strong prompt\nClaude can adapt to various summarization styles. You can change the details of the prompt to guide Claude to be more or less verbose, include more or less technical terminology, or provide a higher or lower level summary of the context at hand.\nHere’s an example of how to create a prompt that ensures the generated summaries follow a consistent structure when analyzing sublease agreements:\nimport\nanthropic\n# Initialize the Anthropic client\nclient\n=\nanthropic\n.\nAnthropic\n(\n)\ndef\nsummarize_document\n(\ntext\n,\ndetails_to_extract\n,\nmodel\n=\n\"claude-opus-4-20250514\"\n,\nmax_tokens\n=\n1000\n)\n:\n# Format the details to extract to be placed within the prompt's context\ndetails_to_extract_str\n=\n'\\n'\n.\njoin\n(\ndetails_to_extract\n)\n# Prompt the model to summarize the sublease agreement\nprompt\n=\nf\"\"\n\"Summarize the following sublease agreement\n.\nFocus on these key aspects\n:\n{\ndetails_to_extract_str\n}\nProvide the summary\nin\nbullet points nested within the XML header\nfor\neach section\n.\nFor example\n:\n<\nparties involved\n>\n-\nSublessor\n:\n[\nName\n]\n//\nAdd more details\nas\nneeded\n<\n/\nparties involved\n>\nIf\nany\ninformation\nis\nnot\nexplicitly stated\nin\nthe document\n,\nnote it\nas\n\"Not specified\"\n.\nDo\nnot\npreamble\n.\nSublease agreement text\n:\n{\ntext\n}\n\"\"\n\"\nresponse\n=\nclient\n.\nmessages\n.\ncreate\n(\nmodel\n=\nmodel\n,\nmax_tokens\n=\nmax_tokens\n,\nsystem\n=\n\"You are a legal analyst specializing in real estate law, known for highly accurate and detailed summaries of sublease agreements.\"\n,\nmessages\n=\n[\n{\n\"role\"\n:\n\"user\"\n,\n\"content\"\n:\nprompt\n}\n,\n{\n\"role\"\n:\n\"assistant\"\n,\n\"content\"\n:\n\"Here is the summary of the sublease agreement: <summary>\"\n}\n]\n,\nstop_sequences\n=\n[\n\"</summary>\"\n]\n)\nreturn\nresponse\n.\ncontent\n[\n0\n]\n.\ntext\nsublease_summary\n=\nsummarize_document\n(\ndocument_text\n,\ndetails_to_extract\n)\nprint\n(\nsublease_summary\n)\nThis code implements a\nsummarize_document\nfunction that uses Claude to summarize the contents of a sublease agreement. The function accepts a text string and a list of details to extract as inputs. In this example, we call the function with the\ndocument_text\nand\ndetails_to_extract\nvariables that were defined in the previous code snippets.\nWithin the function, a prompt is generated for Claude, including the document to be summarized, the details to extract, and specific instructions for summarizing the document. The prompt instructs Claude to respond with a summary of each detail to extract nested within XML headers.\nBecause we decided to output each section of the summary within tags, each section can easily be parsed out as a post-processing step. This approach enables structured summaries that can be adapted for your use case, so that each summary follows the same pattern.\n​\nEvaluate your prompt\nPrompting often requires testing and optimization for it to be production ready. To determine the readiness of your solution, evaluate the quality of your summaries using a systematic process combining quantitative and qualitative methods. Creating a\nstrong empirical evaluation\nbased on your defined success criteria will allow you to optimize your prompts. Here are some metrics you may wish to include within your empirical evaluation:\nROUGE scores\nThis measures the overlap between the generated summary and an expert-created reference summary. This metric primarily focuses on recall and is useful for evaluating content coverage.\nBLEU scores\nWhile originally developed for machine translation, this metric can be adapted for summarization tasks. BLEU scores measure the precision of n-gram matches between the generated summary and reference summaries. A higher score indicates that the generated summary contains similar phrases and terminology to the reference summary.\nContextual embedding similarity\nThis metric involves creating vector representations (embeddings) of both the generated and reference summaries. The similarity between these embeddings is then calculated, often using cosine similarity. Higher similarity scores indicate that the generated summary captures the semantic meaning and context of the reference summary, even if the exact wording differs.\nLLM-based grading\nThis method involves using an LLM such as Claude to evaluate the quality of generated summaries against a scoring rubric. The rubric can be tailored to your specific needs, assessing key factors like accuracy, completeness, and coherence. For guidance on implementing LLM-based grading, view these\ntips\n.\nHuman evaluation\nIn addition to creating the reference summaries, legal experts can also evaluate the quality of the generated summaries. While this is expensive and time-consuming at scale, this is often done on a few summaries as a sanity check before deploying to production.\n​\nDeploy your prompt\nHere are some additional considerations to keep in mind as you deploy your solution to production.\nEnsure no liability:\nUnderstand the legal implications of errors in the summaries, which could lead to legal liability for your organization or clients. Provide disclaimers or legal notices clarifying that the summaries are generated by AI and should be reviewed by legal professionals.\nHandle diverse document types:\nIn this guide, we’ve discussed how to extract text from PDFs. In the real-world, documents may come in a variety of formats (PDFs, Word documents, text files, etc.). Ensure your data extraction pipeline can convert all of the file formats you expect to receive.\nParallelize API calls to Claude:\nLong documents with a large number of tokens may require up to a minute for Claude to generate a summary. For large document collections, you may want to send API calls to Claude in parallel so that the summaries can be completed in a reasonable timeframe. Refer to Anthropic’s\nrate limits\nto determine the maximum amount of API calls that can be performed in parallel.\n​\nImprove performance\nIn complex scenarios, it may be helpful to consider additional strategies to improve performance beyond standard\nprompt engineering techniques\n. Here are some advanced strategies:\n​\nPerform meta-summarization to summarize long documents\nLegal summarization often involves handling long documents or many related documents at once, such that you surpass Claude’s context window. You can use a chunking method known as meta-summarization in order to handle this use case. This technique involves breaking down documents into smaller, manageable chunks and then processing each chunk separately. You can then combine the summaries of each chunk to create a meta-summary of the entire document.\nHere’s an example of how to perform meta-summarization:\nimport\nanthropic\n# Initialize the Anthropic client\nclient\n=\nanthropic\n.\nAnthropic\n(\n)\ndef\nchunk_text\n(\ntext\n,\nchunk_size\n=\n20000\n)\n:\nreturn\n[\ntext\n[\ni\n:\ni\n+\nchunk_size\n]\nfor\ni\nin\nrange\n(\n0\n,\nlen\n(\ntext\n)\n,\nchunk_size\n)\n]\ndef\nsummarize_long_document\n(\ntext\n,\ndetails_to_extract\n,\nmodel\n=\n\"claude-opus-4-20250514\"\n,\nmax_tokens\n=\n1000\n)\n:\n# Format the details to extract to be placed within the prompt's context\ndetails_to_extract_str\n=\n'\\n'\n.\njoin\n(\ndetails_to_extract\n)\n# Iterate over chunks and summarize each one\nchunk_summaries\n=\n[\nsummarize_document\n(\nchunk\n,\ndetails_to_extract\n,\nmodel\n=\nmodel\n,\nmax_tokens\n=\nmax_tokens\n)\nfor\nchunk\nin\nchunk_text\n(\ntext\n)\n]\nfinal_summary_prompt\n=\nf\"\"\n\"\nYou are looking at the chunked summaries of multiple documents that are\nall\nrelated\n.\nCombine the following summaries of the document\nfrom\ndifferent truthful sources into a coherent overall summary\n:\n<\nchunked_summaries\n>\n{\n\"\"\n.\njoin\n(\nchunk_summaries\n)\n}\n<\n/\nchunked_summaries\n>\nFocus on these key aspects\n:\n{\ndetails_to_extract_str\n}\n)\nProvide the summary\nin\nbullet points nested within the XML header\nfor\neach section\n.\nFor example\n:\n<\nparties involved\n>\n-\nSublessor\n:\n[\nName\n]\n//\nAdd more details\nas\nneeded\n<\n/\nparties involved\n>\nIf\nany\ninformation\nis\nnot\nexplicitly stated\nin\nthe document\n,\nnote it\nas\n\"Not specified\"\n.\nDo\nnot\npreamble\n.\n\"\"\n\"\nresponse\n=\nclient\n.\nmessages\n.\ncreate\n(\nmodel\n=\nmodel\n,\nmax_tokens\n=\nmax_tokens\n,\nsystem\n=\n\"You are a legal expert that summarizes notes on one document.\"\n,\nmessages\n=\n[\n{\n\"role\"\n:\n\"user\"\n,\n\"content\"\n:\nfinal_summary_prompt\n}\n,\n{\n\"role\"\n:\n\"assistant\"\n,\n\"content\"\n:\n\"Here is the summary of the sublease agreement: <summary>\"\n}\n]\n,\nstop_sequences\n=\n[\n\"</summary>\"\n]\n)\nreturn\nresponse\n.\ncontent\n[\n0\n]\n.\ntext\nlong_summary\n=\nsummarize_long_document\n(\ndocument_text\n,\ndetails_to_extract\n)\nprint\n(\nlong_summary\n)\nThe\nsummarize_long_document\nfunction builds upon the earlier\nsummarize_document\nfunction by splitting the document into smaller chunks and summarizing each chunk individually.\nThe code achieves this by applying the\nsummarize_document\nfunction to each chunk of 20,000 characters within the original document. The individual summaries are then combined, and a final summary is created from these chunk summaries.\nNote that the\nsummarize_long_document\nfunction isn’t strictly necessary for our example pdf, as the entire document fits within Claude’s context window. However, it becomes essential for documents exceeding Claude’s context window or when summarizing multiple related documents together. Regardless, this meta-summarization technique often captures additional important details in the final summary that were missed in the earlier single-summary approach.\n​\nUse summary indexed documents to explore a large collection of documents\nSearching a collection of documents with an LLM usually involves retrieval-augmented generation (RAG). However, in scenarios involving large documents or when precise information retrieval is crucial, a basic RAG approach may be insufficient. Summary indexed documents is an advanced RAG approach that provides a more efficient way of ranking documents for retrieval, using less context than traditional RAG methods. In this approach, you first use Claude to generate a concise summary for each document in your corpus, and then use Clade to rank the relevance of each summary to the query being asked. For further details on this approach, including a code-based example, check out the summary indexed documents section in the\nsummarization cookbook\n.\n​\nFine-tune Claude to learn from your dataset\nAnother advanced technique to improve Claude’s ability to generate summaries is fine-tuning. Fine-tuning involves training Claude on a custom dataset that specifically aligns with your legal summarization needs, ensuring that Claude adapts to your use case. Here’s an overview on how to perform fine-tuning:\nIdentify errors:\nStart by collecting instances where Claude’s summaries fall short - this could include missing critical legal details, misunderstanding context, or using inappropriate legal terminology.\nCurate a dataset:\nOnce you’ve identified these issues, compile a dataset of these problematic examples. This dataset should include the original legal documents alongside your corrected summaries, ensuring that Claude learns the desired behavior.\nPerform fine-tuning:\nFine-tuning involves retraining the model on your curated dataset to adjust its weights and parameters. This retraining helps Claude better understand the specific requirements of your legal domain, improving its ability to summarize documents according to your standards.\nIterative improvement:\nFine-tuning is not a one-time process. As Claude continues to generate summaries, you can iteratively add new examples where it has underperformed, further refining its capabilities. Over time, this continuous feedback loop will result in a model that is highly specialized for your legal summarization tasks.\nFine-tuning is currently only available via Amazon Bedrock. Additional details are available in the\nAWS launch blog\n.\nSummarization cookbook\nView a fully implemented code-based example of how to use Claude to summarize contracts.\nCitations cookbook\nExplore our Citations cookbook recipe for guidance on how to ensure accuracy and explainability of information.\nWas this page helpful?\nYes\nNo\nContent moderation\nOverview\nOn this page\nBefore building with Claude\nDecide whether to use Claude for legal summarization\nDetermine the details you want the summarization to extract\nEstablish success criteria\nHow to summarize legal documents using Claude\nSelect the right Claude model\nTransform documents into a format that Claude can process\nBuild a strong prompt\nEvaluate your prompt\nDeploy your prompt\nImprove performance\nPerform meta-summarization to summarize long documents\nUse summary indexed documents to explore a large collection of documents\nFine-tune Claude to learn from your dataset",
  "links": [
    {
      "url": "https://docs.anthropic.com/en/docs/build-with-claude/prompt-engineering/claude-4-best-practices",
      "text": "Claude 4 best practices"
    },
    {
      "url": "https://docs.anthropic.com/en/docs/build-with-claude/prompt-engineering/prompt-generator",
      "text": "Prompt generator"
    },
    {
      "url": "https://docs.anthropic.com/en/docs/build-with-claude/prompt-engineering/prompt-templates-and-variables",
      "text": "Use prompt templates"
    },
    {
      "url": "https://docs.anthropic.com/en/docs/build-with-claude/prompt-engineering/prompt-improver",
      "text": "Prompt improver"
    },
    {
      "url": "https://docs.anthropic.com/en/docs/build-with-claude/prompt-engineering/be-clear-and-direct",
      "text": "Be clear and direct"
    },
    {
      "url": "https://docs.anthropic.com/en/docs/build-with-claude/prompt-engineering/multishot-prompting",
      "text": "Use examples (multishot prompting)"
    },
    {
      "url": "https://docs.anthropic.com/en/docs/build-with-claude/prompt-engineering/chain-of-thought",
      "text": "Let Claude think (CoT)"
    },
    {
      "url": "https://docs.anthropic.com/en/docs/build-with-claude/prompt-engineering/use-xml-tags",
      "text": "Use XML tags"
    },
    {
      "url": "https://docs.anthropic.com/en/docs/build-with-claude/prompt-engineering/system-prompts",
      "text": "Give Claude a role (system prompts)"
    },
    {
      "url": "https://docs.anthropic.com/en/docs/build-with-claude/prompt-engineering/prefill-claudes-response",
      "text": "Prefill Claude's response"
    },
    {
      "url": "https://docs.anthropic.com/en/docs/build-with-claude/prompt-engineering/chain-prompts",
      "text": "Chain complex prompts"
    },
    {
      "url": "https://docs.anthropic.com/en/docs/build-with-claude/prompt-engineering/long-context-tips",
      "text": "Long context tips"
    },
    {
      "url": "https://docs.anthropic.com/en/docs/build-with-claude/prompt-engineering/extended-thinking-tips",
      "text": "Extended thinking tips"
    },
    {
      "url": "https://docs.anthropic.com/en/docs/test-and-evaluate/define-success",
      "text": "Define success criteria"
    },
    {
      "url": "https://docs.anthropic.com/en/docs/test-and-evaluate/develop-tests",
      "text": "Develop test cases"
    },
    {
      "url": "https://docs.anthropic.com/en/docs/test-and-evaluate/eval-tool",
      "text": "Using the Evaluation Tool"
    },
    {
      "url": "https://docs.anthropic.com/en/docs/test-and-evaluate/strengthen-guardrails/reduce-latency",
      "text": "Reducing latency"
    },
    {
      "url": "https://docs.anthropic.com/en/docs/test-and-evaluate/strengthen-guardrails/reduce-hallucinations",
      "text": "Reduce hallucinations"
    },
    {
      "url": "https://docs.anthropic.com/en/docs/test-and-evaluate/strengthen-guardrails/increase-consistency",
      "text": "Increase output consistency"
    },
    {
      "url": "https://docs.anthropic.com/en/docs/test-and-evaluate/strengthen-guardrails/mitigate-jailbreaks",
      "text": "Mitigate jailbreaks"
    },
    {
      "url": "https://docs.anthropic.com/en/docs/test-and-evaluate/strengthen-guardrails/handle-streaming-refusals",
      "text": "Streaming refusals"
    },
    {
      "url": "https://docs.anthropic.com/en/docs/test-and-evaluate/strengthen-guardrails/reduce-prompt-leak",
      "text": "Reduce prompt leak"
    },
    {
      "url": "https://docs.anthropic.com/en/docs/test-and-evaluate/strengthen-guardrails/keep-claude-in-character",
      "text": "Keep Claude in character"
    },
    {
      "url": "https://docs.anthropic.com/_sites/docs.anthropic.com/en/docs/about-claude/use-case-guides/legal-summarization",
      "text": "prompting"
    },
    {
      "url": "https://docs.anthropic.com/en/docs/build-with-claude/develop-tests",
      "text": "strong empirical evaluation"
    }
  ],
  "metadata": {
    "scraped_at": "2025-06-23T15:07:46.923637",
    "word_count": 3292,
    "link_count": 25,
    "content_length": 21405
  }
}