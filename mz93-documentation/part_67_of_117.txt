# RATANON/MZ93-DOCUMENTATION - Part 67/112

---
**Dataset:** ratanon/mz93-documentation
**Part:** 67 of 112
**GitHub:** https://github.com/ratan0n/docs/tree/main/mz93-documentation
**Size:** ~68.4 KB
---

Input/Output Data The Input/Output data is the type of data an agent expects and delivers. The agent produces bytearray types. MIM For information about the MIM and a list of the general MIM parameters, see Administration and Management in Legacy Desktop . Publishes MIM Value Description File Modified Timestamp This MIM parameter contains a timestamp, indicating when the file is stored in the collection directory. File Modified Timestamp is of the date type and is defined as a header MIM context type. File Retrieval Timestamp This MIM parameter contains a timestamp, indicating when the file processing starts. File Retrieval Timestamp is of the date type and is defined as a header MIM context type. Source File Size This MIM parameter contains the file size, in bytes, of the source file. Source File Size is of the long type and is defined as a header MIM context type. Source Filename This MIM parameter contains the name of the currently processed file, as defined at the source. Source Filename is of the string type and is defined as a header MIM context type. Source Filenames This MIM parameter contains a list of file names of the files that are about to be collected from the current collection directory. Note! When the agent collects from multiple directories, the MIM value is cleared after the collection of each directory. Then, the MIM value is updated with the listing of the next directory. Source Filenames is of the list<any> type and is defined as a Header MIM context type. Source File Count This MIM parameter contains the number of files, available to this instance for collection at startup. The value is constant throughout the execution of the workflow, even if more files arrive during the execution. The new files will not be collected until the next execution. Source File Count is of the long type and is defined as a global MIM context type. Source Pathname This MIM parameter contains the path to the directory where the file currently under processing is located. Source Pathname is of the string type and is defined as a global MIM context type. The path is defined in the Disk tab. Note! Even if a relative path was defined when configuring the Disk Collection agent (see Disk Tab in Disk Collection Agent Configuration - Batch ), for example, input , the value of this parameter will include the whole absolute path; /$MZHOME/input . Source Files Left This parameter contains the number of source files that are yet to be collected. This is the number that appears in the Execution Manager backlog. Source Files Left is of the long type and is defined as a header MIM context type. Accesses The agent does not access any MIM resources.

---

# Document 1573: Installing Cloudera Manager and Cloudera Data Platform - MediationZone Documentation 9.3 - InfoZone

**Source:** ratanon/mz93-documentation
**URL:** https://infozone.atlassian.net/wiki/spaces/MD93/pages/204610795/Installing+Cloudera+Manager+and+Cloudera+Data+Platform
**Categories:** chunks_index.json

Prerequisites Cloudera Manager Cloudera Data Platform (CDP) 7.1.6 or 7.7.7 Info! For installation instructions, see the Cloudera documentation that is provided with the download link. Requirements and Recommendations for Installation The following are listed as the installation requirements and recommendations for Data Hub: Data Hub has been tested with CDP 7.1.6 or 7.1.7 The Enterprise Edition must be used in production environments. Select the parcels installation method for CDP. Installing additional parcels is optional and these are not required by Data Hub. When you are prompted to specify CDP services to install, select Core with Impala. Single-user mode is recommended for production environments.

---

# Document 1574: SAP CC UDRs - MediationZone Documentation 9.3 - InfoZone

**Source:** ratanon/mz93-documentation
**URL:** https://infozone.atlassian.net/wiki/spaces/MD93/pages/204609134
**Categories:** chunks_index.json

The SAP CC UDR types are designed to formalize the exchange between workflows and the SAP Convergent Charging Core Server. There are 4 classifications of SAP CC UDRs for MediationZone and these are divided into the SAP CC Online agents, SAP CC Batch agents, SAP CC Notification agents, and common SAP CC UDRs that are used by the SA P CC agents. The section contains the following subsections: SAP CC Batch UDRs SAP CC Online UDRs Notification UDRs Common SAP CC UDRs

---

# Document 1575: mzsh - MediationZone Documentation 9.3 - InfoZone

**Source:** ratanon/mz93-documentation
**URL:** https://infozone.atlassian.net/wiki/spaces/MD93/pages/205656966/mzsh
**Categories:** chunks_index.json

This section describes the Command Line Tool mzsh. The Command Line Tool is a standard user interface for the Platform. The Command Line Tool mzsh is a shell that can be used both as a system administration tool and as a Platform client tool. Depending on whether the Platform is running or not, or if you are logged in or not, mzsh enables you to access different parts of the system. Note! To start an application, or to activate a workflow, you must have Execute permissions for the application and configuration, see https://infozone.atlassian.net/wiki/x/hRwzD for more information. Some commands require that the user is the MZ_HOME owner. This information will be found together with the respective commands presented in this user guide. Caution! Ensure that the firewall is correctly configured as some commands require communication between the Execution Contexts and the Platform. For information about communication through firewalls, see the System Administrator's Guide . This section contains the following subsections: Starting mzsh mzsh Commands Exit Codes Textual Pattern Matches Executing Shell Commands When OS Level Access Is not Available

---

# Document 1576: Managing a Workflow Group - MediationZone Documentation 9.3 - InfoZone

**Source:** ratanon/mz93-documentation
**URL:** https://infozone.atlassian.net/wiki/spaces/MD93/pages/204604969/Managing+a+Workflow+Group
**Categories:** chunks_index.json

This section includes the following topics: Opening a new or saved workflow group Creating a workflow group Removing members Execution: Manual or Scheduled Configuration Opening a Workflow Group Configuration You create a new workflow group configuration from the Build view of the Desktop User Interface. To open the workflow group configuration, click Build  New Configuration . Select Workflow Group from the Configurations dialog. To open an existing workflow group configuration, click Build and select the workflow group configuration in the Configuration Browser, or right-click a workflow configuration and then select View Configuration . Creating a Workflow Group You create a workflow group by adding a workflow or a workflow group, as a member to the group. To create a workflow group: In the Available To Add pane, select a workflow or a workflow group. Note! An invalid workflow member will not affect the validity of the workflow group. Click the button. The member is added in the Group Members list. Note! Batch, task and system task workflow members can be combined in a workflow group, but real-time workflow members can only be combined with other real-time workflow members. However, for real-time workflows, we recommend that only one workflow is included in each workflow group, unless you have selected the Continuous Workflow Execution checkbox in the Execution tab, which will allow you to have multiple real-time workflows in the same group. Click the Save As button and give the new workflow group a name. Removing a Member from a Workflow Group When you remove a member from a workflow group, the member does not cease to exist: A workflow member may still be running according to its configuration, or as a member of a workflow group in the system. A workflow group member may still run as a member of another workflow group in the system. To remove a member from a workflow group: Select the member that you want to remove in the in the Group Members list in the Members tab in workflow group configuration. Click the Remove button. You will get a question if you are sure you want to remove the member. Click Yes if you are sure. The member is removed from the group. Executing a Workflow Group Execute the Workflow group either manually, from the Execution Manager - see Execution Manager - or, schedule an automatic execution - see the section below, Scheduling. Configuring a Workflow Group Configuring a workflow group includes: Planning members' execution order Setting the workflow group execution parameters Setting the workflow group scheduling parameters Members' Execution Order When planning the execution order of the members in your workflow group, use the Prerequisites column in the Group Members table. By doing so you ensure: A linear execution A certain execution order That every member is fully executed before the next member starts running Note! If you use the Continuous Workflow Execution setting, you can override this behavior by allowing scheduled workflows to execute even though all workflow members are not finished. See the section below, Execution, for further information. To configure members' execution order: Select a member in the Group Members pane in the Members tab. Click the Edit button. The Prerequisites dialog box opens. Open The Prerequisites dialog box Select the checkboxes for the members that the current member should follow. Click OK . See the image below for an example of how it may look. Open Workflow Group members' execution prerequisites You can rearrange the members' order of appearance in the Group Members list, by using the Up and Down buttons. When rearranging a list, that is already configured with Prerequisites you notice that the Prerequisites parameter is removed and a yellow warning icon appears instead. Note that this does not affect the workflow group validity. To remove the notification sign, either open the Prerequisites dialog box and click OK , or - to remove all the notification signs - save the workflow group configuration, and reopen it. Execution Click the Execution tab in the workflow group configuration. Open The Workflow Group Execution tab Entry Description Entry Description Max Simultaneous Running Workflows Enter the maximum number of workflows you want to be able to run concurrently. Note! If you do not specify a limit, your specific work environment and equipment will determine the maximum number of workflows that can run simultaneously. This value applies only to the workflow group that you are defining and does not affect members that are workflow groups. Startup Delay If Max Simultaneous Running Workflows is set to a value larger than 1, enter the delay (in seconds) of the execution start for each of the workflows that may run simultaneously. Note! If you do not enter any value, a very short delay will be applied by the system, by default. You can assign a Startup Delay regardless of the members' status. Once the delay is up, if the member in turn is disabled, the Workflow group attempts to execute the next member. Continuous Workflow Execution Select this checkbox if you want to allow members in scheduled workflow groups to execute on schedule even though all workflow members in the group have not finished execution. This may be useful in case one member is delayed for some reason. In that case remaining workflow members will not be prevented from executing on schedule. Note! This feature is not supported for nested group members, only workflow members. For a workflow group with a member that is delayed over the next scheduled time, this setting makes the member execute immediately when it is finished, and the group will be in a continuous Running state, not switching to Idle in between executions as is the default behavior. This needs to be considered when making configurations based on workflow group states. Continue This option activates the default behavior on member abort, which means that the workflow group will run until all its members are fully executed and/or all are aborted. Note! This means that groups with real-time workflow members continue to run until all the members are aborted or stopped manually. Stop Select this option to have the workflow group stop when a member aborts. A batch Workflow will finish the current batch and then stop. Stop Immediately Select this option to have the workflow group stop immediately when a member aborts. A batch workflow will stop even in the middle of processing a batch. Enable Select this checkbox to enable the workflow group execution settings. Note! Execution settings that you configure here, only apply to workflow members for which execution settings have not been enabled in the configurations that they are part of. Workflow groups cannot run as stand-alones, and will be executed on the Platform. For further information about stand-alone, see Execution Context in the Desktop User's Guide . Distribution A workflow executes on an EC group. You can specify these EC groups, or the system can select them automatically. The Distribution rules are applied to all included group members, such as workflows and workflow group configurations. When there are conflicting settings, the members that are lowest in the workflow group hierarchy have precedence. When the Distribution rules of the workflow group configurations are set on the same level in the hierarchy, they do not conflict with each other. Note! If you configure the distribution using EC groups, the selected distribution type is also applied to the ECs within the groups. The following options exist: Sequential - Starts the workflow on the first EC group in the list. If this EC group is not available, it proceeds with the next in line. Workflow Count - Starts the workflow on the EC group running the fewest number of workflows. If the Execution Contexts list contains at least one entry, only this/these EC groups will be considered. Machine Load - Starts the workflow on the EC group with the lowest machine load. If the Execution Contexts list contains at least one entry, only this/these EC groups will be considered. Which EC group to select is based on information from the System Statistics sub-system. Round Robin - Starts the workflow on the available EC groups in turn, but not necessarily in a sequential order. If ecg1, ecg2, and ecg3 are defined, the workflow may first attempt to start on ecg2. The next time it may start on ecg3 and then finally on ecg1. This order is then repeated. If an EC group is not available, the workflow will be started on any other available EC groups. Scheduling The cause of execution for a workflow group can either be a planned time scheme or a specific event. You can configure the cause of execution in the Scheduling tab. Note! Changes to a running workflow group will not apply until the group has finished running, which means that a real-time workflow will have to be stopped manually for changes to apply. Info! The times stated in Scheduling follows the timezone of the server hosting the MediationZone Platform. Open The Workflow Group Scheduling tab Entry Description Entry Description Day Plans Use this table to plan timed triggers that will execute your Workflow group. Note that you can define a list of various plans. The system picks the plan that meets the top priority according to the section below, Day Plans Priority Rule. Event Trigger Use this table to define an event execution trigger for the Workflow group, see the section below, Event Triggers. Day Plans Priority Rule The Day Plans table lets you create a list of different execution schemes of the Workflow group. You configure each Day Plan to any interval between executions. Note! Two Day Plans should not contradict each another. An example of an invalid configuration: Day Plan A is set to Tuesdays Off, while Day Plan B is set to Every 5 minutes between 15:00:00 and 15:05:00 on Tuesdays. The system applies the following priority rule for picking a Day Plan out of the list: Last day of month Day of month (1-31) Weekday (Monday-Sunday) Every day To Configure a Day Plan Schedule: Click the Add button below the Day Plan table in the Scheduling tab. The Add Day Plan dialog opens. Open The Add Day Plan dialog Entry Description Entry Description Day Select the target day. Valid options are: Every day A specific weekday A specific day of the month (1-31) The last day of the month Day Off Select this checkbox to avoid execution on the day specified in the Day list. Start At Enter a start time for the first execution. Stop At Enter the time for when execution should stop. Note! If these fields are left empty, the default stop time, which is 23:59, is applied. Repeat Every Enter the interval between execution start time in seconds, minutes, or hours. Note! If this field is left empty, only one execution session is run at the specified start time. Note! If a member in a group is delayed for some reason, and not finished at the time the execution is set to be repeated, all members in the group have to wait until the next repeat time. To override this behavior, you can use the Continuous Workflow Execution setting in the Execution tab. See the Execution section above. Event Triggers To trigger the execution of a Workflow group you add a row to the Event Trigger table. A row can be either a certain event, or a chain of events, that must occur in order for the Workflow group execution to set off. Note! An Event Trigger that is comprised of a chain of events will take effect only when all the events that it includes have occurred. The events that have occurred are stored in memory. When MediationZone is restarted this information is lost and none of the events on the event chain are considered to have occurred. To Configure an Event Trigger: Click the Add button beneath the Event Triggers table. The Add Event Chain Trigger dialog opens. Open The Add Event Chain Trigger Dialog Click the Add button. The Add Event Selection dialog opens. Open The Add Event Selection dialog Select an Event Type from the drop-down list. See Event Fields in Event Notifications Configuration . Double-click an entry in the Event Filter table. The Edit Match Value dialog opens. Click the Add button. The Add Match Value dialog opens. If you want to filter all the events based on specific values of the selected type, enter the values in the Match Value(s) column. Otherwise, if you leave the default value, all events of the selected event type will trigger the execution of the Workflow group. Click Add/OK/Close to close each of the four dialog boxes, confirming that your entry is included. Note! There are no referential constraints for Event Triggers nor any way to track relations between workflows that are triggered by one another. For example: Workflow A is defined to be activated when Workflow B is activated. Workflow B may be deleted without any warnings, leaving Workflow A, still a valid workflow, without a trigger. This can happen since value matching is based on a regular expression of the workflow name, and not on a precise link match.

---

# Document 1577: Form UDR - MediationZone Documentation 9.3 - InfoZone

**Source:** ratanon/mz93-documentation
**URL:** https://infozone.atlassian.net/wiki/spaces/MD93/pages/204643632/Form+UDR
**Categories:** chunks_index.json

The Form UDR is used to create a form that includes other components where you can enter data to be sent to workflow. Open Example of a simple form with one TextField and one Button You can use the following APL code to create a form as shown above: //Create the Form UDR Form searchform = udrCreate(Form); searchform.method = searchform.METHOD_POST; //Create the textfield to be included in the form. TextField searchText = udrCreate(TextField); searchText.id = "search"; //Must include name otherwise the data can not be sent to workflow searchText.name = "search"; searchText.placeholder = "Filter Results"; //Create the send button Button searchButton = udrCreate(Button); searchButton.buttonType = searchButton.SUBMIT; searchButton.text = "Search"; //Add the components to the form searchform.components = listCreate(ComponentUDR, searchText, searchButton); Another example of a form that uses a grid to place the components. Open Example of a form using grid The APL code to produce the above example is this: Example of APL code // Helper functions for column and row GridColumn getColumn(ComponentUDR comp, int width){ GridColumn col = udrCreate(GridColumn); if(width > 0){ col.width = width; } col.components = listCreate(ComponentUDR, comp); return col; } GridRow getRow(list<GridColumn> columns){ GridRow row = udrCreate(GridRow); row.columns = listCreate(GridColumn); for (GridColumn column: columns) { listAdd(row.columns, column); } return row; } The following fields are included in the Form UDR : Field Description Field Description action (string) This field may contain a string that specifies where to send the form data when a form is submitted. Possible values: An absolute URL - points to another web site (like " http://www.example.com/example.htm ") A relative URL - points to a url within the web site (like "example") attributes (map<string,string>) This field may contain extra attributes to be added. components (list<ComponentUDR>) This field may contain a list of child components, the components that will produce the form data. They can be added direct in the list or inside a Grid UDR and then the Grid UDR is added here. cssClasses (list<string>) This field may contain a list of extra values added to class attribute. This is typically used to style the component. Please read more on Bootstrap . encoding (string) This field may contain may a string for encoding. Some constants is added to help: URL_ENCODED , TEXT_PLAIN , MULTIPART Default is URL_ENCODED. id (string) This field may contain the id of the component method (int) This field may contain method used to submit the form. Possible values are: METHOD_GET , METHOD_POST . Default is METHOD_GET. name (string) This field may contain the name of the component

---

# Document 1578: KPI Management UDR Types - MediationZone Documentation 9.3 - InfoZone

**Source:** ratanon/mz93-documentation
**URL:** https://infozone.atlassian.net/wiki/spaces/MD93/pages/204677192
**Categories:** chunks_index.json

This section describes the UDR types that are used for KPI Management. This section includes the following subsections: KDR KPIAggregatedOutput KPIOutput

---

# Document 1579: Collection Agents - MediationZone Documentation 9.3 - InfoZone

**Source:** ratanon/mz93-documentation
**URL:** https://infozone.atlassian.net/wiki/spaces/MD93/pages/205881802/Collection+Agents
**Categories:** chunks_index.json

A collection agent is responsible for gathering data into the workflow from external systems or devices. An example of a simple collection agent could be one that reads a file from disk and sends the file contents into the workflow.

---

# Document 1580: UI Builder UDRs - MediationZone Documentation 9.3 - InfoZone

**Source:** ratanon/mz93-documentation
**URL:** https://infozone.atlassian.net/wiki/spaces/MD93/pages/205002396/UI+Builder+UDRs
**Categories:** chunks_index.json

The UI Builder agent contains a number of UDRs. In the UDR Internal Format Browser , a detailed view of the available UDRs and respective fields is displayed. To open the browser, click the Configuration menu and select the option APL Code , and then right-click in the editing area and select the option UDR Assistance... . This section contains the following subsections: General UI Builder UDRs UI Builder Component UDRs

---

# Document 1581: CloseConnection UDR - MediationZone Documentation 9.3 - InfoZone

**Source:** ratanon/mz93-documentation
**URL:** https://infozone.atlassian.net/wiki/spaces/MD93/pages/204675399/CloseConnection+UDR
**Categories:** chunks_index.json

The CloseConnection UDR is used for closing an existing connection. Either the Websocket server agent receives a closing handshake request and routes a CloseConnection UDR into the workflow, or the workflow sends a CloseConnection UDR to the Websocket server agent, which in turn sends a closing handshake request to the peer. A CloseConnection UDR can also be sent to the Websocket client agent for closing a connection. The following field is included in the CloseConnection UDR: Field Description Field Description URI (string) This field contains the Uniform Resource Identifier of the server or client to which connection will be closed, in string format. securityInformation (TLSInformation (webs oc ket)) This field contains information about the certificate chain and also which protocol and cipher suite are used .

---

# Document 1582: Configuring Searchable Fields in the ECS - MediationZone Documentation 9.3 - InfoZone

**Source:** ratanon/mz93-documentation
**URL:** https://infozone.atlassian.net/wiki/spaces/MD93/pages/205000024/Configuring+Searchable+Fields+in+the+ECS
**Categories:** chunks_index.json

If you want to search for UDRs with specific values in certain fields, you can configure such fields in the ECS Searchable Fields dialog (ECS Inspector  Searchable Fields button). Open Searchable Fields dialog Note! These configurations must be made before UDRs are sent to the ECS by the ECS forwarding agent. To configure searchable fields: In the ECS Searchable Fields dialog, Labels tab, click the Add button at the bottom of the dialog. The Add Label dialog opens. Open Add Label dialog Enter a name in the Label field. Click the Add button to add the label into the Defined Field Labels list. Repeat the previous step for all the labels you want to add, and then click the Close button. Click the Mappings tab to map UDR fields to the different labels. Click the Add button to open the UDR Internal Format Browser. Select the UDR type you want and click OK (to add and close the browser) or Apply (to add more UDR types without having to reopen the browser). The UDR type(s) are added in the UDR Types list. Select a UDR type in the UDR Types list, and double click on the UDR Field row to select a UDR Field to associate to the chosen label. The Select UDR Field dialog opens. Select a UDR Field and click OK. The selected UDR Field is listed in the UDR Field row for the label. Repeat the previous step for all the UDR Types where you want to map UDR Fields. Click the Save button when you are finished. The configuration is saved, and the next time the ECS receives UDRs from an ECS forwarding agent, the configured UDR Fields are added as meta data and can later be used for making searches, see Searching the ECS .

---

# Document 1583: Backup Routines for [CZ] and [EZ] - MediationZone Documentation 9.3 - InfoZone

**Source:** ratanon/mz93-documentation
**URL:** https://infozone.atlassian.net/wiki/spaces/MD93/pages/205816252/Backup+Routines+for+CZ+and+EZ
**Categories:** chunks_index.json

Refer to the System Administrator's Guide for information about backup routines and maintenance for [CZ] and [EZ].

---

# Document 1584: Audit Profile - MediationZone Documentation 9.3 - InfoZone

**Source:** ratanon/mz93-documentation
**URL:** https://infozone.atlassian.net/wiki/spaces/MD93/pages/204605649/Audit+Profile
**Categories:** chunks_index.json

There is the possibility to output information to user-defined database tables. This means that several workflows may output information about the same batch to the same table, which makes it possible to trace batches/UDRs between workflows. To increase this traceability, it is highly recommended to add fields to the UDRs, to make it possible to identify their origin. Useful values may be: Name of the switch Name of the original file name Time stamp of the original file The audit table column types are defined in an Audit profile configuration. The Audit profile is loaded when you start a workflow that depends on it. Changes to the profile become effective when you restart the workflow. The Audit profile is used by the Audit tab in the workflow properties, Analysis, and Aggregation agents for Batch workflows. Audit profile is not used in Real-Time workflows. Note! Modifying the existing Audit profile will invalidate the workflow. To ensure the workflow functions correctly, review and update the Audit tab in the workflow properties. Configuration To create a new Audit profile configuration, click the New Configuration button in the Build View , and then sele ct Audit Profile from the selection screen. Open The Audit profile configuration The contents of the buttons in the button bar may change depending on which configuration type has been opened. The Audit Profile uses the standard menu items and buttons that are visible for all configurations, and these are described in Common Configuration Buttons . The profile uses the standard menu items and buttons that are visible for all configurations. The Audit profile configuration contains the following settings: Setting Description Setting Description Database This is the database that the agent will connect and send data to. Click the Browse... button to get a list of all the database profiles that are available. For further information see Database Profile . Note! For performance reasons, Audit information is logged directly from an EC to the database. If an external EC is unable to connect to the database, a "Workflow performance warning" is logged in System Log. If this warning appears, the firewall might need to be reconfigured to allow the EC to communicate directly with the database. The Audit functionality is supported for use with the following databases: Oracle TimesTen Derby SQL Server PostgreSQL SAP HANA Refresh Open Select Refresh to reload the metadata for the tables residing in the selected database. Use Default Database Schema Check this to use the default database schema that was added in the Username field of the Default Connection Setup in the Database profile configuration. When using the default database schema the names of the audit tables listed in Table will appear without schema prefix. For more details on how to add a default database schema, see Database Profile . Note! This is not applicable for all database types. Use Default Database Schema is only available for selection when accessing Oracle or TimesTen databases. Table A list of selected audit tables. For further information about adding and editing tables, see the section below, Adding and Editing a Table Mapping. Adding and Editing a Table Mapping From the Add and Edit Audit Table Attributes dialogs, the existing table columns are mapped to valid types. Open Add Audit Table Attributes Setting Description Setting Description Table A list from which the audit table is selected. Note! Tables in the System schema will not be available for selection when accessing the Oracle database Column Name The name of the columns in the selected table. Type Clicking the cell, displays a list of valid types. Each column must be mapped against a type. Valid types are: Counter - A built-in sequence which is incremented with the value passed on with the auditAdd APL function. Key - Used to differ between several audit inserts. It is possible to use several keys, where a unique combination of keys will result in one new row in the database. If the same key combination is used several times within a batch, the existing row will be overwritten with new audit data. However, if a later batch uses the same key combination, a new row will be created. If using more than one key, the Key Sequence must be entered in the same order when calling the auditAdd or auditSet APL functions. The Audit functions are further described in the APL Reference Guide . Note that this is not a database key and it must be kept as small as possible. A value that is static during the whole batch must never be used as a key value. Value - A column holding any type of value to be set, except for Counter values. This is used in combination with the auditSet APL function. Another use is mapping against existing MIM values in the Workflow Properties dialog. Transaction Id - To make sure entries are transaction safe, each table must contain a column of type NUMBER and at least have the length twelve (or have no size declared at all). Do not enter or alter any values in this column, it is handled automatically by the system. The value -1 indicates that the entry is committed and safe. Unused - Used in case a column must not be populated, that is, set to null . Key Sequence A key sequence is a defined way to assign a Key value, to identify in which order you need to send along key values when you use the auditAdd or auditSet APL functions. Each key in a table must have a sequence number in order to be identified when passed on as parameters to the APL audit functions. The first key is identified as 1, the second as 2, and so on. The key sequence will uniquely identify all audit log entries to be inserted per batch. Audit Profile Example To illustrate how Audit may be used, consider a workflow with an Analysis agent, validating and routing UDRs. Most of the UDRs will be sent on the "COMPLETE" route. The rest of the incomplete UDRs will be sent on the "PARTIALS" route. If there are a considerable amount UDRs that are routed to the latter, the batch is can celled. Open A workflow example The output on each route is to be logged in an audit table, including information on cancelled batches. An entry in the table is made for each batch and for each route. Hence two entries per batch. Open Example audit information In this example, only the destination key is needed, which uniquely identifies all the rows to be inserted per batch. The name of the destination agent is therefore selected. Note that it is not possible to update an existing row in the table, only to add new rows. This is to ensure the traceability of data. To output information other than MIM values (which may be mapped in the Workflow Properties dialog), the workflow must contain an Analysis or Aggregation agent. Setting up an Audit profile involves the following steps: Design the tables: One column (of type NUMBER) must be reserved for transaction handling. This column should be indexed in order to achieve the best performance. The contents will be of low cardinality and could therefore be compressed if supported. Consider which column/columns contain tag information, that is, the key. A key may consist of one or several columns. Create an Audit profile. For further information, see the section below, Adding the Table Mapping. Map parameters in the Workflow Preferences Audit tab to the Audit profile. For further information, see the section below, Workflow Properties - Audit Tab. Design APL code to populate the tables. For further information, see the section below, Populating Audit Tables. Audit Profile In the Audit profile configuration, the column types are configured. To create a new Audit profile configuration, click New Configuration and select Audit Profile from the menu. Click Browse to select the database in which the table(s) reside, then click OK . Adding the Table Mapping Click Add or Edit to open the Add Audit Table Attributes and Edit Audit Table Attributes dialogs, respectively. This is where the existing table columns are mapped to valid types. Open The Audit profile Add Audit Table Attributes dialog or Edit Audit Table Attributes dialog The data to insert, is put in the UDRs column. Setting it to type Counter , makes it possible to use the auditAdd function to increment the corresponding column value. If Value is used, the auditSet function can be used to assign a value. Workflow Properties - Audit Tab The Audit tab in the Workflow Properties dialog defines the type of data entered in the table by the workflow, such as MIM types or anything sent on with the APL audit functions. Open Workflow Properties - The Audit tab The complete , invalid and partial Column Names in the the Audit table are populated by using the APL audit functions, while collection_date and filename are populated by the workflow MIM values. The cancelled Column Name can be mapped directly to an existing MIM value or populated by the APL audit functions using the Analysis Agent. Populating Audit Tables There are two ways of populating audit tables; either by using the auditAdd function, which automatically increments the value of Counter columns, or by setting fixed values to columns of type Value with the auditSet function. Note that Counter columns are automatically set to 0 (zero) when a batch is cancelled. This is not the case for Value columns. Note! In terms of performance, it does not matter how many times an audit function is called. Each call is saved in memory and a summary for each key is committed at End Batch. Counter Increment By using the auditAdd function, the user does not have to keep track of the number to increment a counter column with. At Cancel Batch, the value is set to 0 (zero). Fixed Values Using the auditSet function for the same example as discussed in the previous section, means the user has to keep track of the number of records in the APL code. Note that the profile must be updated; the Counter column must be redefined to Value. Value columns are not reset when a batch is canceled. Hence there are entries made in the table for the UDRs column for all batches. Example - Use of auditAdd and auditSet In this example code, each UDR is validated with respect to the contents of the causeForOutput field. The audit table is updated to hold information on the numbers of complete, partial , and invalid UDRs sent on the routes. // Define counters int complete = 0; int partials = 0; int invalid = 0; //Publish a new MIM mimPublish(trailer, "My Trailer",string); consume { // Check if the UDR is of type complete if(input.causeForOutput == 0){ // Increment complete counter complete = complete + 1; // Increment value of column COMPLETE auditAdd( "Default.PRF_AUDIT","MZADMIN.MZ_AUDIT","COMPLETE",1 ); // Route UDR on outgoing route "COMPLETE" udrRoute(input, "COMPLETE"); } // Check if the UDR is of type partial else if(input.causeForOutput == 1 ||input.causeForOutput == 2){ // Increment partial counter partials = partials + 1; // Increment value of column PARTIAL auditAdd( "Default.PRF_AUDIT","MZADMIN.MZ_AUDIT","PARTIAL",1 ); // Route UDR on outgoing route "PARTIALS" udrRoute(input, "PARTIALS"); } else{ // Increment invalid counter invalid = invalid + 1; // Set the value of column INVALID auditSet( "Default.PRF_AUDIT","MZADMIN.MZ_AUDIT","INVALID",invalid ); } }

---

# Document 1585: KPI Management Overview - MediationZone Documentation 9.3 - InfoZone

**Source:** ratanon/mz93-documentation
**URL:** https://infozone.atlassian.net/wiki/spaces/MD93/pages/205655902/KPI+Management+Overview
**Categories:** chunks_index.json

UDRs from network assets and IT systems contain raw data that may represent various aspects of business and operations performance. KPI Management allows you to create metrics based on this data, and to calculate KPIs for each of these metrics in different dimensions. This can be used to retrieve valuable information such as the quality of service that a specific customer segment is perceiving, or the status of network assets in a crowded geographical area. Examples of metrics: Average duration Total volume Maximum quantity Quality of service Failure rate Examples of dimensions: Assets type Location User segment Product category Vendor All calculations are based on configurable service models in which the relations between the various entities are defined, e g metrics, dimensions, and KPIs. For instance, assume that a set of raw data contains fields that indicate the result of business transactions and a quantitative measurement such as sales amount. These types of fields are suitable to calculate metrics. Furthermore, also assume that the data set contains information about the geographical location and vendor involved in the transactions. You may use these types of fields to create dimensions in your data. Dimensions can be arranged in tree hierarchies that describe on which level the KPI output should be calculated. By combining the metrics and dimensions in your service model, you may create KPI definitions. Optionally, you may associate these with thresholds for alarm generation. To process the data in KPI Management, you must first convert the decoded input into KDR UDRs. To do this, you will copy the values of the fields in the decoded UDR to a map of key-values in the KDR, which can then be referenced in the service model. The type field in the KDR makes it possible to distinguish between different input types, e g the original UDR type. Open Data flow with example When you run data through your service model, the output will be generated in periods of configurable length. The start- and end time of each period does not depend on system-time but on a timestamp that you can either generate or extract from the input. The output for each defined KPI is delivered in KPIOutput UDRs. These UDRs contain the "instance path", the name of the KPI, and the calculated value. The instance represents the tree structure in the figure above, but with actual values from the KDR. Open Representation of calculated KPIs in KPIOutput UDRs

---

# Document 1586: MediationZone 9.3 Release - MediationZone Documentation 9.3 - InfoZone

**Source:** ratanon/mz93-documentation
**URL:** https://infozone.atlassian.net/wiki/spaces/MD93/pages/204678755/MediationZone+9.3+Release
**Categories:** chunks_index.json

Open The release information for MediationZone 9.3 contains the following: Executive Summary New Features and Enhancements Important Information Known Issues Bug Fixes

---

# Document 1587: REST Server_Deprecated Agent UDR Types - MediationZone Documentation 9.3 - InfoZone

**Source:** ratanon/mz93-documentation
**URL:** https://infozone.atlassian.net/wiki/spaces/MD93/pages/204740335
**Categories:** chunks_index.json

The REST type is used to pass data between the workflow and REST Server_Deprecated agent. Field Description Field Description error (Error(REST)) This field contains information related to internal processing errors. request (Request(REST)) This field contains the request from the client application to the REST Server_Deprecated agent. response(Response(REST)) This field contains the response from the REST Server_Deprecated agent to the client application. In the event of an internal error scenario, this field may contain the suggested response from the REST Server_Deprecated agent to the client application. The nested UDR types of REST are described below. Request Field Description Field Description authentication (Authentication (REST)) This field contains the OAuth 2.0 access token details and the basic authentication credentials. Includes the accessToken (AccessToken(REST)) and basicAuth (BasicAuth(REST)) udrs. body (bytearray) This field contains the HTTP message body. clientHost (string) This field contains the client IP. clientPort (int) This field contains the client port. contextID (long) This field contains the context ID headerFields (map<string,list<string>>) This field may contain an HTTP header. The header fields are stored as key-value pairs. httpMethod (string) This field must contain the HTTP method. pathParams (list<string>) This field may contain HTTP path parameters. Example Example URI: /registered/endpoint/foo/bar?k1=v1&k1=v11&k2=v2 Registered endpoint URI in the REST Server_Deprecated Profile is: /registered/endpoint It will appear in pathParams as: List[0]: foo and List[1]: bar Note! If there is a trailing slash at the end of the URI there will be no empty string segment in pathParams representing the string after slash (e.g. URI /test/ contains only one segment: "test"). This is how it appears: pathParams: List of 1 element [0]: test requestedUri: /test/ queryParams (map<string,list<string>>) This field may contain HTTP query parameters. requestedUri (string) This field contains a requested URI. Response Field Description Field Description body (bytearray) This field contains the HTTP message body. headerFields (map<string,list<string>>) This field may contain an HTTP header. The header is stored as key-value pairs. httpResponseCode (int) This field contains the response code from the server. Hint! When the body field contains a JSON formatted string, you can use the APL function jsonDecode to decode the contents. For further information about this function, see 21. JSON Functions in the APL Reference Guide . When the body field contains XML data, you can use the XML schema support in Ultra to decode the contents. For further information about XML and Ultra, see 18. XML Schema Support in the Ultra Reference Guide . AccessToken Field Description Field Description clientname (string) This field contains the name of the client provisioned for the access token by the authentication server. expirationTime (long) This field contains the expiration time of the access token. jwtRawData (string) This field contains the raw data, including the access token. scope (list<string>) This field contains a list of scopes authorized for the client to use. username (string) This field contains the username of the client. BasicAuth Field Description Field Description password (string) This field contains the password of the client. username (string) This field contains the username of the client. Error Field Description Field Description code (int) This field contains an internal error code. 200 - Ok 400 - Bad Request 401 - Unauthorised 404 - Not Found 408 - Request Timeout 500 - Internal Server Error description (string) This field contains the description of the error code.

---

# Document 1588: mzcli - wflist - MediationZone Documentation 9.3 - InfoZone

**Source:** ratanon/mz93-documentation
**URL:** https://infozone.atlassian.net/wiki/spaces/MD93/pages/547980212/mzcli+-+wflist
**Categories:** chunks_index.json

Usage usage: wflist <pattern matching expression for workflow names> ... [ -invalid ] [ -valid ] [ -active ] [ -inactive ] [ -not-member-of-wfgroup ] [ -long [ -activationMode ] ] [ -loop [ N ] ] This command lists workflows. If you use the command without any options, all workflows will be listed. Options Option Description Option Description [-invalid] Lists all invalid workflows. [-valid] Lists all valid workflows. [-active] Lists all active workflows. [-inactive] Lists all inactive workflows. [ -not-member-of-wfgroup ] Lists all the workflows that are not included in a workflow group. [-long] Lists the workflow state and information about the latest start (aborted or not started). If the workflow is running long reveals how long it has been running. long will also display the current throughput. [-long [ -activationMode]] Lists the workflow state and information about the latest start as well as the workflow's activation mode. If the workflow is enabled it will be shown as ENABLED. [-loop [ N ]] Sets a loop mode that runs the wflist command forever every N seconds (N is by default set to 10) To terminate loop use Ctrl-C. Note! When combining [-active] and [-long], the Execution Context and the execution time for the workflow will be listed. Return Codes Listed below are the different return codes for the wflist command: Code Description Code Description 0 Will be returned if the command was successful. 1 Will be returned if the number of arguments is incorrect.

---

# Document 1589: Pico Management - MediationZone Documentation 9.3 - InfoZone

**Source:** ratanon/mz93-documentation
**URL:** https://infozone.atlassian.net/wiki/spaces/MD93/pages/205030732/Pico+Management
**Categories:** chunks_index.json

The Pico Management interface provides a comprehensive view of the various pico instances that are currently deployed as well as allow you to create and manage the pico instances. Open Pico Management dashboard view The dashboard displays a list of all pico instances in the system. You can search and filter them for easy viewing. Columns and Buttons Description Columns and Buttons Description Name Name of the pico instances. Type The pico instance type of the JVM will be displayed here. These types will be labeled as platform , ec , sc , and ui Status The status of the JVM will be shown here. If the pico instance is up and can be pinged, it will be shown as running . If it cannot be pinged, it will be shown as unreachable . If the pico instance is shut down it will show as not-started . Memory Use The amount of memory being used by the pico instance will be shown here. Response Time The response time of the pico instance will be shown here. Up Time The amount of time that the pico instance has been running will be shown here. EC Groups If the pico instance belongs to any EC Groups, these will be shown here. Actions These are buttons that allow you to make changes to the selected pico. Edit - Allows you to make changes to the properties related to that particular pico instance. See Editing a Pico Instance for more details. Details - Allows to check more details about the pico instance from the Pico Management dashboard. Restart - Restarts the pico instance from the Pico Management dashboard. Stop - Stops the pico instance from the Pico Management dashboard. Start - Starts the pico instance from the Pico Management dashboard. Delete - Removes the pico instance from the Pico Management dashboard. Managing the Pico Instances You can start, stop or restart pico instances in the Pico Management dashboard. Selecting one or more of the pico instances will allow you to perform any of the highlighted actions shown at the top of the pico list. The available actions depend on the type of pico instance. Open Selecting multiple pico instances to start. Adding a Pico Instance You can add an EC or SC pico instance using the New Pico button on the Pico Management dashboard. The following are properties found in the Create New Pico dialog: Property Description Property Description Pico Container Choose between all available containers in your installation to list the pico instance under. This is a mandatory field. Name Provide a unique identifier for your pico instance. The name cannot be shared across other pico instances and has to be unique. This is a mandatory field. Template Choose between the standard-ec template or the standard-sc template for your pico instance. You can then make changes to the JSON template in the text field below, such as add on properties in Execution Context for EC's and Service Context Properties for SC's. Open Create New Pico dialog window with the standard-ec option selected. Editing a Pico Instance You can add or modify properties pertaining to the particular pico instance as well as their values. The Edit Pico dialog consists of a JSON template text field where you can add new properties, edit the values and View Resolved Config . The View Resolved Config lets you view the current valid configuration for that particular pico instance. You cannot make changes to the text field while viewing the resolved config. For more details to the properties you can add, refer to: Platform Properties for the Platform pico. Execution Context for Execution Context pico. Service Context Properties for Service Context pico. Open Edit Pico dialog window for an ec container. Details of a Pico Instance The user can learn more about each pico instance by clicking Details in the Actions buttons, where its possible to see information separated by the following tabs: Details - Overview Tab Details - Application Tab Details - Virtual Machine Tab Details - Operating System Please note that the information presented in the tabs comes directly from JMX MBeans and is primarily intended for troubleshooting activities.

---

# Document 1590: HTTPD_Deprecated Agent UDR Type - MediationZone Documentation 9.3 - InfoZone

**Source:** ratanon/mz93-documentation
**URL:** https://infozone.atlassian.net/wiki/spaces/MD93/pages/205685878
**Categories:** chunks_index.json

The UDR type created in the HTTPD_Deprecated agent can be viewed in the UDR Internal Format Browser. Format The built-in HTTP format definition must be extended prior to usage of the HTTPD format. To extend the HTTP format: Open the Ultra Format Editor by clicking the New Configuration button in the upper left part of the Desktop window, and then selecting Ultra Format from the menu. Enter: internal MYHTTPD: extends_class ("com.digitalroute.wfc.http.HttpdUDR") { // Additional fields (if required). }; The following fields are included in the built-in HTTPD format: Additional fields may be entered. This is useful mainly for transportation of variable values to subsequent agents. Save your Ultra by clicking on the Save button and entering the name of the Ultra.

---

# Document 1591: Diameter Routing Profile - MediationZone Documentation 9.3 - InfoZone

**Source:** ratanon/mz93-documentation
**URL:** https://infozone.atlassian.net/wiki/spaces/MD93/pages/204607031
**Categories:** chunks_index.json

The Diameter Routing profile enables you to define the Peer Table and the Realm Routing Table properties for the Diameter Stack agent. You can also enable throttling, which allows you to prevent more than the specified number of UDRs per second to be forwarded. The throttling functionality uses the token bucket algorithm. The Diameter Routing profile is loaded when you start a workflow that depends on it. Changes to the profile become effective when you restart the workflow. It is also possible to make changes effectively while a workflow is running. For more information about this, see the section below, To Dynamically Update the Diameter Routing Profile. To define a Diameter Routing profile, click on the New Configuration button and then select Di ameter Routing profile in the menu. Routing Tab The Diameter Routing profile configuration - Routing tab Peer Table A Diameter Stack agent that uses the Diameter Routing profile maintains transport connections with all the hosts that are defined in the Peer table list. Connections and handshakes of hosts that are not in this list are rejected with the appropriate protocol errors. Note that the system will actively try to establish connections to any hosts that are included in this list, unless the Do Not Create Outgoing Connections option is checked in the Diameter Stack agent. Item Description Item Description Hostname The hostname (case sensitive) or IP address of a Diameter Identity. For example, ggsn01.vendor.com Note! The content of the Origin-Host AVP in the answer commands from the specified peer should be identical to this value. If the values do not match, the MIM values published by the Diameter Stack agent that contain counters are not updated correctly. This may occur, for instance, if you have specified a hostname in this text box but the Origin-Host AVP contains an IP address. It is recommended that you consistently use either IP addresses or hostnames when configuring the Diameter profiles and agents. Port The port to connect to when initiating transport connections with a peer. For example, 3868 . Protocol The transport protocol to use when initiating a peer connection. The following settings are available: TCP TCP/TLS SCTP When TCP/TLS is selected, the Diameter Stack requires a secure connection from this host. You configure this feature by setting the Keystore Path and the Keystore Password in the Diameter Stack agent. For further information, see the section, Advanced Tab, in Diameter Stack Agent Configuration . Note! SCTP must be installed on every EC host that uses the SCTP protocol. For installation instructions, see your operating system documentation. Throughput Threshold If throttling has been enabled for the peer, this field will show the configured threshold for when transmissions of request UDRs should be throttled. Throttled UDRs will be routed back into the workflow. For example 1.000 (which means a maximum of 1.000 UDRs/second will be transmitted). Note! Throttling will determine if and how the workflow will limit the number of requests and UDRs sent out from the workflow. For information regarding how to configure the Diameter agent to reject incoming requests or UDRs to the workflow, see the section, Diameter Too Busy in Diameter Stack Agent Configuration . On Connection from Unknown Peer When unknown peers try to connect to the Diameter Stack, you can configure how such connection attempts are to be handled. You can choose from three options from the drop box: Reject - Select this option to reject all connection attempts from unknown peers. This is the default option. Accept Secure Connection - Select this option to accept connection attempts from unknown peers with TLS authentication. Accept All - Select this option to accept all connection attempts from unknown peers. To Add a Host In the Diameter Routing Profile , click on the Add button beneath the Peer Table . The Add Host dialog o pens . Open The Diameter Routing Profile - Adding a Host Enter the host name and port for the host in the Hostname and Port fields. Select protocol in the Protocol drop-down-list. If you want to enable throttling for the peer, select the Enable Throttling check box, and then enter the maximum number of request UDRs per second you want the Diameter Stack agent to transmit to the peer in the Throughput Threshold (UDR/s) field. Click on the Add button and the host will be added in the Peer Table , and then click on the Close button to close the dialog when you are finished adding hosts. Realm Routing Table Realm-based routing is performed when the Destination-Host AVP is not set in a Diameter message. All realm-based routing is performed based on lookups in the Realm Routing Table. When the lookup matches more than one set of keys, the first result from the lookup will be used for routing. For this reason, the order of the rows in the Realm Routing Table must be considered. You can control the order of the rows by using the arrow buttons. Clicking on the table columns to change the displayed sort order does not have any effect on the actual order of the rows in the Realm Routing Table . Item Description Item Description Realm Routing Strategy Diameter requests are routed to peers in the realms in accordance with the selected Realm Routing Strategy. The following settings are available: Failover : For each realm, Diameter requests are routed to the first specified peer (primary) in the Hostnames cell, or the first host resolved by a DNS query. If the connection to the first peer fails, requests to this realm are routed to the next peer (secondary) in the cell, or the next host resolved by a DNS query. Failback to the first peer (primary) is performed when possible. Round Robin : Diameter requests are evenly distributed to all the specified peers in the Hostnames cell, or peers resolved by DNS queries. If the connection to a peer fails, the requests are distributed to the remaining hosts. This also applies when UDRs are throttled due to the settings in the Peer Table . The table below contains examples of how Diameter requests are routed to the peers of a realm, with the Round Robin strategy, depending on the peer connection state: Peer 1 Status Peer 2 Status Peer 3 Status Route Distribution OKAY OKAY OKAY Peer 1, Peer 2, or Peer 3 OKAY OKAY SUSPECT Peer 1 or Peer 2 REOPEN SUSPECT OKAY Peer 3 DOWN DOWN SUSPECT Peer 3 DOWN REOPEN DOWN Peer 2 DOWN DOWN DOWN None Diameter request are not routed to peers that are specified in the ExcludePeers field of a RequestCycle UDR. For more information about the RequestCycle UDR, see the section, RequestCycleUDR in The Diameter Base Protocol . Enable Dynamic Peer Discovery Select this check box when you want to use DNS queries (dynamic peer discovery) to find peer hosts in realms. The queried peer host information is buffered by the Diameter Stack agent according to the TTL (time to live) parameter in the DNS records. When the TTL has expired, the agent will attempt to refresh the information. If the refresh fails, the buffered information will be deleted. When Enable Dynamic Peer Discovery is selected, DNS queries are performed at: Workflow start After TTL Expiration Dynamic update of Diameter routing profile Note! To make changes to this setting effective, you must restart the workflow(s). If the DNS service is unavailable (server available but service down) when starting the workflow(s), the system log entry will indicate errors in realm lookups. In order to resume lookups in DNS, you need to dynamically update the routing table in the Diameter Stack agent when the DNS is available again. For information about how to dynamically update the routing table, see the section below, To Dynamically Update the Diameter routing profile. For information about how to select DNS servers, see the section below, DNS tab. Realm The realm name (case sensitive). Realm is used as the primary key in the routing table lookup. If left empty, all the destination realms are valid for this route. For example, address.com Applications The applications that this route serves. This entry is used as a secondary key field in the routing table lookup. If left empty all the applications are valid for this route. For example, 3,4 . Hostnames A list of all the peer hosts in the realm. The hostnames must be selected from the Peer Table . When Node Discovery is set to Dynamic, you should leave this field empty. Node Discovery The method of finding the peer hosts in the realm: Static - The peer hosts are specified in the Hostnames field of the Realm Routing Table. Dynamic - The Diameter Stack agent uses DNS queries (dynamic peer discovery) to find the peer hosts. These queries may resolve to multiple IP addresses or hostnames. In order to use this setting, you may need to add DNS servers to the network interfaces of your system. Note! Entries in the Realm Routing Table that have the Dynamic setting are ignored (not matched), unless Enable Dynamic Peer Discovery is selected. When a DNS server resolves a realm to peer hosts, it may return fully-qualified DNS domain names with a dot at the end. These trailing dots are removed by the Diameter Stack agent. To Add a Realm In the Diameter Routing Profile , click on the Add button beneath the Realm Routing Table. The Add Route dialog opens. Open The Diameter Routing Profile - Adding a Realm Enter the realm name in the Realm text box. If the realm serves specific applications, click on the Add button beneath the Applications list box and specify the Application Id. Repeat this step for each application. You should only perform this step if Peer Discovery is set to Static and the peer hosts are to be specified in the Realm Routing Table. Click on the Add button beneath the Hostname list box and select a host from the drop-down list. Repeat this step for each host in the realm. If you specified the peer hosts of the realm in the previous step, select Static from Peer Discovery . If you want to use dynamic peer discovery instead, select Dynamic from this drop-down list. Click on the Add button and the realm will be added to the Realm Routing Table , and then click on the Close button to close the dialog when you are finished a ddin g realms. DNS Tab Open The Diameter Routing profile - DNS tab You can use the DNS tab to configure the DNS settings used for looking up peer hosts of realms. For information about how to configure your DNS for dynamic peer discovery, see the Diameter Base Protocol (RFC 6733). Note! To make changes to this tab effective, you must restart the workflow(s). Avoid configuring the same peer host in both DNS and the Peer Table , this may cause duplicate instances of Diameter peers. The host- and realm names in the Diameter Stack agent are case-sensitive. Retry Interval Time (ms) Enter the time (in milliseconds) that the Diameter Stack agent must wait before retrying a failed DNS connection. Max Number Of Retries Enter the maximum number of times that the Diameter Stack agent should retry to connect to the servers in the DNS Servers list before it gives up. When the agent has attempted to connect to all servers (after an initial failed attempt), it counts as a retry. DNS Servers Enter the hostname or IP address of the DNS servers that can be queried. The topmost available server will be used. If the DNS Servers list is empty, the Diameter Stack agent will use the file /etc/resolv.conf on the Execution Context host to select the DNS server. For information about how to configure resolv.conf, see your operating system documentation. To Dynamically Update the Diameter Routing Profile You can refresh the routing table of a Diameter Stack agent while a workflow is running. When the agent refreshes the routing table, it reads the updated Peer Table , Realm Routing Table and Realm Routing Strategy from the selected Diameter Routing Profile. The setting Enable Dynamic Peer Discovery in the Routing tab and the settings in the DNS tab is not read from the Diameter Routing table at refresh. To make changes to these settings effective, you must restart the workflow(s). The routing table can be refreshed from the Workflow Monitor or from the Command Line Tool. In the Workflow Monitor, double-click the Diameter Stack agent to open the Workflow Status Agent configuration. In the Command tab, select the Update Routing Table button to refresh the routing table. Command Line Tool Run the following command: mzsh mzadmin/<password> wfcommand <workflow name> <Diameter Stack agent name> Example - Update Routing Table mzsh mzadmin/<password> wfcommand Default.my_workflow Stack1 When Round Robin is the selected Realm Routing Strategy , you can reset the selection cycle by running the following command: mzsh mzadmin/<password> wfcommand <workflow name> <Diameter Stack agent name> clearstrategystate Example - Reset Round Robin Selection mzsh mzadmin/<password> wfcommand Default.my_workflow Stack1 clearstrategystate To Read the Realm Routing Table in APL You can use the Diameter Stack MIM value Realm Routing Table to read the realm routing table of a Diameter Stack Agent from APL. The MIM value is of the map<string,map<string, list<string>>> type and is defined as a global MIM context type. The string values in the outer map contain the realm names (primary key). The string values of the inner map contain the applications (secondary key). The lists in the map contain the hostnames of the peers in the realm. The string values in the outer map contain the realm names (primary key). The string values of the inner map contain the applications (secondary key). The lists in the map contain the hostnames of the peers in the realm. Open Asterisks (*) are used in the strings to denote unspecified realm name or unspecified applications. The values in the inner and outer maps are sorted exactly as the Realm Routing Table of the selected Diameter routing profile. Example Realm Routing Table MIM Assume that the following realm routing table is defined for a Diameter Stack agent: Realm Applications Peers dr peer1, peer2 100,200 peer3, peer4 peer5, peer6 The following APL code can be used to read the table: initialize { //Note the space between the angle brackets! map<string, map<string, list<string> > > realmTable = (map<string, map<string, list<string> > >) mimGet("Stack1", "Realm Routing Table"); //Check the size of the table if (mapSize(realmTable) != 2) abort("Realm table incorrect size"); //Check that realms are included if (mapKeys(realmTable) != listCreate(string, "dr", "*")) abort("Wrong realms"); //Get the inner map for realm name "dr" map<string, list<string> > drMap = mapGet(realmTable, "dr"); //Get the inner map for realm name "*" (unspecified realm) map<string, list<string> > starMap = mapGet(realmTable, "*"); //Any Application Id debug(mapGet(drMap, "*")); //Application Id 100 debug(mapGet(starMap, "100")); //Any Application Id debug(mapGet(starMap, "*")); } Example debug output: 12:11:40: [peer1, peer2] 12:11:40: [peer3, peer4] 12:11:40: [peer5, peer6] For more information about MIM values published by the Diameter Stack agent, see Diameter Stack Agent Input/Output Data and MIM .

---

# Document 1592: REST Server Profile Deprecated - MediationZone Documentation 9.3 - InfoZone

**Source:** ratanon/mz93-documentation
**URL:** https://infozone.atlassian.net/wiki/spaces/MD93/pages/204671802
**Categories:** chunks_index.json

The REST Server Profile Deprecated is used to define the endpoint URI for any particular REST Server_Deprecated agent in MediationZone. There can be one or many endpoints for a REST server and the URIs defined by this profile will determine the endpoints where the client application will be able to connect via the REST Server_Deprecated agent. If no endpoint URIs are defined in the profile, the REST Server_Deprecated agent will accept all client requests as valid. Configuration To create a new REST Server Profile Deprecated, click the New Configuration button from the Configuration dialog available from Build View , and then select REST Server Profile Deprecation from the selection screen. The contents of the menus in the menu bar may change depending on which configuration type has been opened in the currently active tab. The REST Server Profile Deprecated uses the standard menu items and buttons that are visible for all configurations, and these are described in Common Configuration Buttons . REST Server Profile Deprecated The following settings are available in the REST Server Profile Deprecated: Setting Description Setting Description Endpoint URI This table will display the endpoint URIs defined for a particular REST server.

---

# Document 1593: GCP Profile - MediationZone Documentation 9.3 - InfoZone

**Source:** ratanon/mz93-documentation
**URL:** https://infozone.atlassian.net/wiki/spaces/MD93/pages/204673280
**Categories:** chunks_index.json



---
**End of Part 67** - Continue to next part for more content.
