# RATANON/MZ93-DOCUMENTATION - Part 45/112

---
**Dataset:** ratanon/mz93-documentation
**Part:** 45 of 112
**GitHub:** https://github.com/ratan0n/docs/tree/main/mz93-documentation
**Size:** ~69.5 KB
---

**URL:** https://infozone.atlassian.net/wiki/spaces/MD93/pages/204645370/Overview+External+Version+Control
**Categories:** chunks_index.json

The external version control functionality facilitates means for user groups with different functions and different tasks to use and perform changes to the same configurations, and keep them stored in a Version Control System. Upgrades and changes in configurations will thus be easier to keep track of. Open Concept You can, for example, have different teams working on developing new configurations which can be checked into the Version Control System, to keep track of changes made during development. When releasing a finished configuration, the users that are working on the implementation of the new configuration can simply check out the released configurations from the Version Control System. The format of the exported data also allows for easy comparison between different versions of configurations using external diff utilities. Minor differences in the schema files should not cause any problems as long as you have both the XML files and the schema files for the configurations.

---

# Document 1012: APL - PCC Runtime Support - Buckets - MediationZone Documentation 9.3 - InfoZone

**Source:** ratanon/mz93-documentation
**URL:** https://infozone.atlassian.net/wiki/spaces/MD93/pages/204677417/APL+-+PCC+Runtime+Support+-+Buckets
**Categories:** chunks_index.json

The runtime support is used for looking up the actual products based on the references received with the mapper support. The runtime support functions include: pccCreate pccGetUdr pccGetUdrList pccCreate This function creates a data set object that can be used with the pccGetUdr and pccGetUdrList functions described below. any pccCreate( string area ) Parameters Parameter Description Parameter Description area The name of the area which the function is operating against. Returns: A data set object that can be used with the pccGetUdr or pccGetUdrList functions. Example pccCreate("PROD"); will create a data set object that can be used with the pccGetUdr and pccGetUdrList functions against the PROD area. pccGetUdr Retrieves a specific UDR based on the stated UDR type and key. drudr pccGetUdr( string typename, any key [, any dataset] ) Parameters Parameter Description Parameter Description typename The fully qualified typename of the requested UDR. key The reference to the requested UDR dataset The data set object that you want to use for retrieving the UDR. This field is optional, and if it is not used, the data set that was used last will be used for the retrieval. Returns: The matching UDR or null if no matching UDR was found. Example pccGetUdr ("PCC.Products.Provisioning.Notification", 50); will retrieve a UDR of the type PCC.Products.Provisioning.Notification with the key 50 . pccGetUdrList Retrieves a list with all the UDRs with the stated UDR type. list<drudr> pccGetUdrList( string typename [, any dataset] ) Parameters Parameter Description Parameter Description typename The fully qualified UDR typename of the requested UDRs. dataset The data set object that you want to use for retrieving the UDRs. This field is optional, and if it is not used, the data set that was used last will be used for the retrieval. Returns: A list containing all the UDRs of the requested type. Example list<drudr> notificationsList = pccListData ("PCC.Products.Provisioning.Notification"); will return a list named notificationsList with all the UDRs that have the type PCC.Products.Provisioning.Notification .

---

# Document 1013: SOX Monitoring - MediationZone Documentation 9.3 - InfoZone

**Source:** ratanon/mz93-documentation
**URL:** https://infozone.atlassian.net/wiki/spaces/MD93/pages/205849426/SOX+Monitoring
**Categories:** chunks_index.json

MediationZone has been used to facilitate compliance with Sarbanes-Oxley Act (SOX) with regards to the SOX Control Environment process. DigitalRoute customers have had their IT department as well as other departments use reports and GUIs for operational "SOX-CONTROL ENVIRONMENT PROCESS", including: Configuration and Change Management Separate Development, Test and Production Environments Segregation of duties Identification and Authentication Clearly defined roles & responsibilities ("Access Controller") Audit & Control With the counters and their reconciliation we assure that there are no records lost By monitoring the processing chain we assure that no files get lost, that all are processed The error counters where checked manually on at least a monthly basis by the RA department, in case of abnormalities an explanation was requested Daily Reports Error Correction System statistics (which error codes and the number of occurrences) Automated Checks Number of input files and records in a normal range Percentage of erroneous records in a normal range

---

# Document 1014: Setting Up a Certificate Authority - MediationZone Documentation 9.3 - InfoZone

**Source:** ratanon/mz93-documentation
**URL:** https://infozone.atlassian.net/wiki/spaces/MD93/pages/204643870/Setting+Up+a+Certificate+Authority
**Categories:** chunks_index.json

This page explains how to set up a CA. In the following example it is called Test CA. To start Test CA, we need a private key. This is the top secret of the CA. If this is compromised then the CA is doomed! All certificates issued by this CA will be revoked. This is why the root private key is so important and often kept off-line necessitating a multi-tier hierarchy. For our Test CA, we need to create the key-pair and create a Certificate Signing Request (CSR) for the root CA's public key. This CSR i s f or the CA itself. These two steps can be done in a single command using SSL as follows: $ openssl req -new -keyout cakey.pem -out careq.pem When prompted for Common Name , the hostname where the certificate is valid should be entered, for example localhost. Other values can be anything. Now we need to generate a certificate out of Test CA's CSR. Obviously this would be self signed. The following OpenSSL command is used to generate a self signed certificate form the CSR. openssl x509 -signkey cakey.pem -req -days 3650 -in careq.pem -out caroot.cer -extensions v3_ca At this point you have self signed root certificate of our Test CA. This certificate, caroot.cer , along with the private key, cakey.pem , will be used to sign others certificates. This root public certificate should be publicly available and must be trusted by programs. Test CA is ready, you need to note that when a CA issues a new certificate, it will put a unique serial number into that certificate. So you need to tell OpenSSL what is the next serial number to use. To do that, create a serial.txt file containing a serial number in the same directory as cakey.pem and caroot.cer . $ echo 1234 > serial.txt

---

# Document 1015: Conditional Trace - MediationZone Documentation 9.3 - InfoZone

**Source:** ratanon/mz93-documentation
**URL:** https://infozone.atlassian.net/wiki/spaces/MD93/pages/204737262/Conditional+Trace
**Categories:** chunks_index.json

Conditional Trace is a trouble-shooting function that allows you to trace data in real-time workflows. Conditional Trace templates, defining what you want to trace, are created in the Legacy Desktop, and these templates can then be used in the regular Desktop. The Conditional Trace templates can be configured to match certain workflows, certain UDR types and fields, as well as using matches for specific parameters, using either specific values or regular expressions. Conditional Trace makes it possible to download and examine selected records from running workflows, making it a very powerful tool for troubleshooting in production environments. For more information on this, see Conditional Trace (CT) . You can also refer to the Conditional Trace User's Guide for a detailed walkthrough.

---

# Document 1016: Installation - MediationZone Documentation 9.3 - InfoZone

**Source:** ratanon/mz93-documentation
**URL:** https://infozone.atlassian.net/wiki/spaces/MD93/pages/205029520/Installation
**Categories:** chunks_index.json

This section contains a general installation overview as well as separate instructions for installing a Platform Container and optional Execution Container, and for installing an Execution Container only. Installation Overview Platform Container Installation Execution Container Installation

---

# Document 1017: DRBatchAgent - MediationZone Documentation 9.3 - InfoZone

**Source:** ratanon/mz93-documentation
**URL:** https://infozone.atlassian.net/wiki/spaces/MD93/pages/204676578/DRBatchAgent
**Categories:** chunks_index.json

The batch agent adds transaction points to a DRAgent . It is the super class for all batch agents. The following methods are defined: initialize The initialize ( DRStorable , DRInputStream ) method is called during startup to give the agent its configuration and optionally a stream, where the state is read from. The config argument is the agent configuration class, populated with the configuration saved in the user interface. The state argument is an input stream that, if not null , must be read in the same order as written in the writeState method. beginBatch This method is called at the beginning of a batch and it is fed the transaction id. Agents must prepare themselves to be fed with data at this point. endBatch This method is called when all data for the current batch has been processed by the workflow. Agents must be prepared for a commit of the current transaction at this point. writeState This method is invoked after endBatch and allows the agent to persist transaction specific information. In case of a crash during commit/rollback, the state will be used at startup to apply the correct logic for commit/rollback of the transaction. rollback Called if the current transaction should be rolled back, that is, removed. This method is only called after initialization in case of a previous crash. commit Called when the current transaction should be committed. The transaction is closed at this point and the produced data is considered safe. cancelBatch Invoked when a batch is being canceled. A Collection agent should route the incoming file to the error service. Other agents should make sure temporary data that has been persisted in interfaced systems is removed. getTransactionResources If the agent depends on resources that must take an active part of the workflow transaction in terms of prepare/rollback/commit, it must return a reference to these resources in this method. These resources must be defined in the initialize method. For example, return the DRECSBatchServiceExec if it is dependent on the transaction. Transaction Order An important feature of a mediation system is transaction safety. The system provides a two-phase commit transaction model, with the possibility to save a transaction state with the current transaction. The Collection agent controls a transaction, since it feeds the incoming batches. The DTK defines a method that can be called to hint the Collection agent to close a transaction. This method is called hintEndBatch and is defined in DRBatchServerEnv . The collector may choose to ignore this call. The following examples shows possible method invocation orders for Processor agents. Example A batch is successfully processed. The Collector agent begins the batch, feeds the data into the workflow, and then ends the batch. Invocation order: Open The flag isRecover to commit will be false . * The consume method can be called several times. Example A batch is committed at startup. The commit invocation started the last time the workflow was running. Before the commit was finished, the workflow aborted. Invocation order: Open The state passed to initialize is the state written in writeState just before the workflow aborted. Since one or more agents may already have received commit before the crash, an agent must always be prepared to receive more than one invocation to this method. The flag isRecover to commit will be true . This indicates that the method may have been invoked earlier with the same transactionID. Example A batch is rolled back at startup. The commit invocation never started the last time the workflow was running. Before reaching commit, the workflow aborted. Invocation order: Open The state passed to initialize is the state written in writeState during the last successfully committed batch. The flag isRecover to rollback will be true . This indicates that the method may have been invoked earlier with the same transactionID. Example A batch is canceled. It can happen at any time after beginBatch and before endBatch . Invocation order: Open A canceled batch is still treated as a processed batch and therefore the transaction will be committed. Any Processor agent may call cancelBatch in the environment during an invocation of consume . The thread will eventually be unwound and call execute on the Collector agent again. An agent calling DRObjectRouter.consume must ensure that its internal state is not corrupted when the thread is unwound. Note that cancelBatch , writeState , and commit may be called before the thread is unwound. Any Processor agent may also call cancelBatch in the environment during an invocation of drain . * The consume method can be called several times.

---

# Document 1018: XML Schema Limitations - MediationZone Documentation 9.3 - InfoZone

**Source:** ratanon/mz93-documentation
**URL:** https://infozone.atlassian.net/wiki/spaces/MD93/pages/204744361/XML+Schema+Limitations
**Categories:** chunks_index.json

XML Schema Constructs not Supported The following XML schema constructs are not supported in UFDL: list type complexType defined as an extension of a simpleType group nillable declarations include redefine substitutionGroup Validation against XML Schema Definition XML input data is not fully validated against the XML Schema Definition, so you must ensure that your data is correct. For example, if maxOccurs is set to 1 (one) you must ensure that the element does not occur more than once. Support Limitations for Union and Restrictions Range restrictions are added to the following predefined types: byte , short , unsignedByte , unsignedShort , nonPositiveInteger , nonNegativeInteger , positiveInteger , and negativeInteger . Range restrictions for the types that exceed the integer range, such as long , are not supported when using union type and restrictions . Only string and integer types can be used as base in restrictions, for example integer , byte , short , positiveInt . A union can only be referred to via a ref to an element, not via a type . The following restrictions are not supported: fractionDigits , totalDigits , and whiteSpace .

---

# Document 1019: System Requirements PCC - MediationZone Documentation 9.3 - InfoZone

**Source:** ratanon/mz93-documentation
**URL:** https://infozone.atlassian.net/wiki/spaces/MD93/pages/204638075/System+Requirements+PCC
**Categories:** chunks_index.json

The following system requirements need to be met in order to install the Policy and Charging Control. Network It is recommended that you have at least 1 GB of Ethernet. Additional switches and network cards are required for a High Availability configuration. See High Availability in PCC for further information. Storage The Policy and Charging Control solution has been designed to run with local disk storage. Other Requirements Two machines assigned to [CZ]. Two machines assigned to the [EZ]. For Couchbase - three machines assigned to [DR]. For MySQL Cluster - two machines assigned to [DR]. All machines running the same OS. SSHdeamon installed and running on all machines. Note! Sharing is only supported for the software installed when used for application failover. No runtime data, e.g. data provided in the Data Repository, should use shared storage, e.g. NFS.

---

# Document 1020: HTTPD_Deprecated Agent Configuration - MediationZone Documentation 9.3 - InfoZone

**Source:** ratanon/mz93-documentation
**URL:** https://infozone.atlassian.net/wiki/spaces/MD93/pages/205033465/HTTPD_Deprecated+Agent+Configuration
**Categories:** chunks_index.json

To open the HTTPD_Deprecated agent configuration dialog from a workflow configuration, you can do one of the following: right-click the agent icon and select Configuration... double-click the agent icon Open HTTPD_Deprecated collection agent configuration dialog Settings Description Settings Description Settings Use SSL If enabled, the communication channels will be encrypted. You must select this option for the Enable 2-way Authentication option to be made available. Security Profile Note! In MediationZone 8, Keystore-related fields in agent configuration can be configured in the Workflow Table. However, in MediationZone 9, these settings are moved to the Security Profile configuration and the Workflow Table does not support configuring the Security Profile fields directly. Enable 2-way Authentication If enabled, two-way authentication is enabled for the communication channels. To use the default Java truststore, select this option, but leave the Truststore and Password fields empty. Local Address The local address that the server will bind to. If the field is left empty, the server will bind to the default address. Port The port the server will listen to. Default port for non-encrypted communication is 80 and for encrypted 443. Transport Select the transport protocol that you prefer for the best performance. Request Handling Content Type The UDR Type, extended HttpdUDR, the collector will emit. For an example, see HTTPD_Deprecated Agent UDR Type . Timeout Client Timeout (sec) Number of seconds a client can be idle while sending the request, before the connection is closed. If the timeout is set to 0 (zero) no timeout will occur. This is not recommended. Default value is 10. Server Timeout (sec) The number of seconds before the server closes a request and a 500 Server Error is sent back to the client. If the timeout is set to 0 (zero) no timeout will occur. Default value is 0. Responses Character Encoding List of encoding options to use for handling of responses. GZIP Compression Level Regulates compression data size. Valid levels are from 1-9, where 9 is slowest but provides optimal compression. Note! If the keystore or truststore that you selected is updated (i e, certificates are removed or added), you must restart the agent for the changes to take effect.

---

# Document 1021: Data Hub Forwarding Agent Configuration - MediationZone Documentation 9.3 - InfoZone

**Source:** ratanon/mz93-documentation
**URL:** https://infozone.atlassian.net/wiki/spaces/MD93/pages/204644952/Data+Hub+Forwarding+Agent+Configuration
**Categories:** chunks_index.json

Configuration Open Data Hub agent configuration Field Description Field Description Profile Click Browse to select a predefined Data Hub profile. The profile contains the settings required to connect to the database. Table Select the target database table from the drop-down list. If a table does not appear in the list, make sure that it has been mapped to a UDR type in the selected Data Hub profile.

---

# Document 1022: Amazon S3 Forwarding MultiForwardingUDR Input - MediationZone Documentation 9.3 - InfoZone

**Source:** ratanon/mz93-documentation
**URL:** https://infozone.atlassian.net/wiki/spaces/MD93/pages/204999009
**Categories:** chunks_index.json

When the agent is set to use MultiForwardingUDR input, it accepts input of the UDR type MultiForwardingUDR declared in the package FNT. The declaration follows: internal MultiForwardingUDR { // Entire file content byte[] content; // Target filename and directory FNTUDR fntSpecification; }; The content of the MultiForwardingUDR will be stored at the path that you have set in the fntSpecification field. Use the APL functions fntAddString and fntAddDirDelimiter to set the value of this field. For further information about these functions, see FNTUDR Functions in APL Reference Guide . When the files are received they are written to temp files in the DR_TMP_DIR directory situated in the root output folder. The files are moved to their final destination when an end batch message is received. A runtime error will occur if any of the fields have a null value or if the path is invalid on the target file system. A UDR of the type MultiForwardingUDR which has a target filename that is not identical to its precedent and is saved in a new output file. Note! After a target filename that is not identical to its precedent is saved, you cannot use the first filename again. For example: Saving filename B after saving filename A, prevents you from using A again. Instead, you should first save all the A filenames, then all the B filenames, and so forth. Non-existing directories will be created if the Create Non-Existing Directories check box under the Filename Template tab is checked. If not checked, a runtime error will occur if a previously unknown directory exists in the FNTUDR of an incoming MultiForwardingUDR . Every configuration option referring to bytearray input is ignored when MultiForwardingUDR s are expected. Example - APL code to send MultiForwardingUDRs This example shows the APL code used in an Analysis agent connected to a forwarding agent expecting input of type MultiForwardingUDR s. import ultra.FNT; MultiForwardingUDR createMultiForwardingUDR (string dir, string file, bytearray fileContent){ //Create the FNTUDR FNTUDR fntudr = udrCreate(FNTUDR); fntAddString(fntudr, dir); fntAddDirDelimiter(fntudr);//Add a directory fntAddString(fntudr, file);//Add a file MultiForwardingUDR multiForwardingUDR = udrCreate(MultiForwardingUDR); multiForwardingUDR.fntSpecification = fntudr; multiForwardingUDR.content = fileContent; return multiForwardingUDR; } consume { bytearray file1Content; strToBA (file1Content, "file nr 1 content"); bytearray file2Content; strToBA (file2Content, "file nr 2 content"); //Send MultiForwardingUDRs to the forwarding agent udrRoute(createMultiForwardingUDR ("dir1", "file1", file1Content)); udrRoute(createMultiForwardingUDR ("dir2", "file2", file2Content)); } The Analysis agent mentioned previous in the example will send two MultiForwardingUDR s to the forwarding agent. Two files with different contents will be placed in two separate subfolders in the root directory. The Create Non-Existing Directories check box under the Filename Template tab in the configuration of the forwarding agent must be checked if the directories do not previously exist.

---

# Document 1023: Provisioning PCC Rules in Desktop - MediationZone Documentation 9.3 - InfoZone

**Source:** ratanon/mz93-documentation
**URL:** https://infozone.atlassian.net/wiki/spaces/MD93/pages/204677268/Provisioning+PCC+Rules+in+Desktop
**Categories:** chunks_index.json

Rules can be provisioned in the PCC Policy Control screen on the Desktop. To open the PCC Policy Control screen, click on the Manage screen option in Desktop and then click on the PCC Policy Control button. Open The PCC Policy Control screen In the PCC Policy Control screen you can view, add, edit, and remove populated definitions for: Rules Mappings PCC Rules Charging Rules Static Rules Dynamic Rules Flow Informations Final Indication Rules Periods QoS Information Allocation Retention Policies See Rules Data Model for information about the different definitions and their respective fields. Hint! Whenever configurations are viewed, added, edited, copied, or deleted, this is logged for the EC log with log-level INFO. The system is by default configured to only register log entries with log level WARNING and higher, so if you want the log entries from the PCC Web UI to be registered, change the log level to INFO instead. See System Properties for further information. Creating Rules Definitions The different definitions need to be configured in the following order: Period Flow Information Dynamic Rule Final Indication Rule Static Rule Charging Rule Allocation Retention Policy QoS Information PCC Rules Rules Mappings The reason for the order stated above is that some definitions are selectable in other definitions as follows: In the Dynamic Rule you select among the Flow Information definitions. In the Charging Rule you select among the Dynamic Rule , Final Indication Rule , and Static Rule definitions. In the QoS Information you select among the Allocation Retention Policy definitions. In the PCC Rules you can select among the Charging Rules , Periods , and QoS Information definitions. In the Rules Mapping you select among the PCC Rules definitions. See Rules Data Model and Periods Data Model Rules , for more information about these dependencies. To create the different definitions: In the PCC Policy Control screen, click on the definition type you want to create definitions for. A new screen will be displayed where you can see the definitions that have already been created for the selected type. Click on the New button, fill in the mandatory information, and click Save . The definition will be saved and listed in the view, and will now be selectable when creating other definition types that depend on it. Open The Create PCC Rule dialog Open The Rules Mapping screen shows the Rules Mapping definitions Editing a Rules Definition To edit the different definitions: In the PCC Policy Control screen, click on the definition type you want to definitions for. A new screen will be displayed where you can see the existing definitions. Select the check box for the definition you want to edit and click on Details in the Actions column. A dialog opens up displaying the configuration for the definition. Make your changes and click on the Save button. The definition will be saved and listed in the view, and will now be selectable when creating other definition types that depend on it. Copying Rules Definitions To copy definitions: In the PCC Policy Control screen, click on the definition type you want to copy definitions for. A new screen will be displayed where you can see the existing definitions. Select the check box(es) for the definition(s) you want to copy and click on the Copy button. The selected definition(s) will be copied with new ID(s) and you can then edit the definition(s) as described above. Deleting Rules Definitions To delete definitions: In the PCC Policy Control screen, click on the definition type you want to delete definitions for. A new screen will be displayed where you can see the existing definitions. Select the check box(es) for the definition(s) you want to copy and click on the Delete button. You will get a question if you are sure you want to delete the definition(s). Click OK if you are sure. The selected definition(s) will be deleted.

---

# Document 1024: TextField UDR - MediationZone Documentation 9.3 - InfoZone

**Source:** ratanon/mz93-documentation
**URL:** https://infozone.atlassian.net/wiki/spaces/MD93/pages/204675182/TextField+UDR
**Categories:** chunks_index.json

The TextField UDR is used to create an input text field. You can use the following APL code to create a text field that is required and has a placeholder text to assist you with a syntax: TextField username = udrCreate(TextField); username.name = "username"; username.label = "Username"; username.required = true; username.placeholder = "user@email.com"; The following fields are included in the TextField UDR : Field Description attributes (map<string,string>) This field may contain extra attributes to be added. cssClasses (list<string>) This field may contain a list of extra values added to class attribute. This is typically used to style the component. Please read more on Bootstrap . disabled (boolean) This field may contain a boolean if the component should be disabled or enabled. id (string) This field may contain the id of the component label (string) This field may contain the label for the text field. labelCssClasses (list<string>) This field may contain a list of extra values added to class attribute of the label. This is typically used to style the component. Please read more on Bootstrap . name (string) This field may contain the name of the component. If the component is present in a Form UDR , the name will be submitted with the form as the key in the Params Map in Request UDR . placeholder (string) This field may contain a placeholder can be used as a help text. readonly (boolean) This field may contain a boolean if the field is readonly. required (boolean) This field may contain a boolean if the component is required. Typically used inside a Form UDR. value (int) This field may contain a value.

---

# Document 1025: Managing Service Configurations (Removed from User Doc for XE-15203) - MediationZone Documentation 9.3 - InfoZone

**Source:** ratanon/mz93-documentation
**URL:** https://infozone.atlassian.net/wiki/spaces/MD93/pages/204678559
**Categories:** chunks_index.json

The Platform, ECs and SCs can host services that workflows, running in ECs, can share. The system default values for standard services are specified in standard.conf . Standard Service Description Standard Service Description storage-dispatcher This service runs on the Platform and is required for database handling. aeron-media This service may run on an EC or an SC and is required for aeron message transport. By default, no SC is specified and the service will be started on the EC where it is invoked. Services that are frequently configured to meet the requirements of specific use cases are referred to as custom services. You can configure these services in the file custom.conf . You can also use this file to override the values of properties in standard.conf . If you set the property install.str.config-script to scripts/str-templates/basic.sh in install.xml during the installation, the following custom services will be available in custom.conf : Custom Service Description Custom Service Description kafka Required by Kafka agents and KPI Management zookeeper Required by Kafka agents and KPI Management Each service has a unique set of properties. For instance, the method of specifying the required SCs are different for the services kafka and zookeeper . Example - Specifying required SCs The kafka service directly references a number of SCs, which are assigned a unique broker id. { kafka { kafka1 { template: "1/standard/basic" config: { zookeeper-instance: "zookeeper1" deployment-info: [{ sc:"sc1",brokerid:1},{ sc:"sc2",brokerid:2},{ sc:"sc3",brokerid:3}] } } } } Similar to the kafka service, the zookeeper service directly references the required SCs. { zookeeper { zookeeper1 { template: "1/standard/basic" config: { sc-list: [zk1, zk2, zk3] } } } } For further information about properties that are available for each respective service, see the relevant sections in the user documentation. This chapter includes the following sections:

---

# Document 1026: mzcli - generate_pcc_classes - MediationZone Documentation 9.3 - InfoZone

**Source:** ratanon/mz93-documentation
**URL:** https://infozone.atlassian.net/wiki/spaces/MD93/pages/547980298/mzcli+-+generate_pcc_classes
**Categories:** chunks_index.json

Usage usage: generate_pcc_classes <Output dir> <XML data model dir> [ <XML data reference dir> ] [ -resource <resource dir> ] After defining your own PCC data model, use this command to generate the PCC classes for the extension. Return Codes Listed below are the different return codes for the generate_pcc_classes command: Code Description Code Description 0 Will be returned if the command was successful. 1 Will be returned if the syntax is incorrect. 2 Will be returned if any of the stated directories are missing.

---

# Document 1027: Audit Profile - MediationZone Documentation 9.3 - InfoZone

**Source:** ratanon/mz93-documentation
**URL:** https://infozone.atlassian.net/wiki/spaces/MD93/pages/204605649
**Categories:** chunks_index.json

There is the possibility to output information to user-defined database tables. This means that several workflows may output information about the same batch to the same table, which makes it possible to trace batches/UDRs between workflows. To increase this traceability, it is highly recommended to add fields to the UDRs, to make it possible to identify their origin. Useful values may be: Name of the switch Name of the original file name Time stamp of the original file The audit table column types are defined in an Audit profile configuration. The Audit profile is loaded when you start a workflow that depends on it. Changes to the profile become effective when you restart the workflow. The Audit profile is used by the Audit tab in the workflow properties, Analysis, and Aggregation agents for Batch workflows. Audit profile is not used in Real-Time workflows. Note! Modifying the existing Audit profile will invalidate the workflow. To ensure the workflow functions correctly, review and update the Audit tab in the workflow properties. Configuration To create a new Audit profile configuration, click the New Configuration button in the Build View , and then sele ct Audit Profile from the selection screen. Open The Audit profile configuration The contents of the buttons in the button bar may change depending on which configuration type has been opened. The Audit Profile uses the standard menu items and buttons that are visible for all configurations, and these are described in Common Configuration Buttons . The profile uses the standard menu items and buttons that are visible for all configurations. The Audit profile configuration contains the following settings: Setting Description Setting Description Database This is the database that the agent will connect and send data to. Click the Browse... button to get a list of all the database profiles that are available. For further information see Database Profile . Note! For performance reasons, Audit information is logged directly from an EC to the database. If an external EC is unable to connect to the database, a "Workflow performance warning" is logged in System Log. If this warning appears, the firewall might need to be reconfigured to allow the EC to communicate directly with the database. The Audit functionality is supported for use with the following databases: Oracle TimesTen Derby SQL Server PostgreSQL SAP HANA Refresh Open Select Refresh to reload the metadata for the tables residing in the selected database. Use Default Database Schema Check this to use the default database schema that was added in the Username field of the Default Connection Setup in the Database profile configuration. When using the default database schema the names of the audit tables listed in Table will appear without schema prefix. For more details on how to add a default database schema, see Database Profile . Note! This is not applicable for all database types. Use Default Database Schema is only available for selection when accessing Oracle or TimesTen databases. Table A list of selected audit tables. For further information about adding and editing tables, see the section below, Adding and Editing a Table Mapping. Adding and Editing a Table Mapping From the Add and Edit Audit Table Attributes dialogs, the existing table columns are mapped to valid types. Open Add Audit Table Attributes Setting Description Setting Description Table A list from which the audit table is selected. Note! Tables in the System schema will not be available for selection when accessing the Oracle database Column Name The name of the columns in the selected table. Type Clicking the cell, displays a list of valid types. Each column must be mapped against a type. Valid types are: Counter - A built-in sequence which is incremented with the value passed on with the auditAdd APL function. Key - Used to differ between several audit inserts. It is possible to use several keys, where a unique combination of keys will result in one new row in the database. If the same key combination is used several times within a batch, the existing row will be overwritten with new audit data. However, if a later batch uses the same key combination, a new row will be created. If using more than one key, the Key Sequence must be entered in the same order when calling the auditAdd or auditSet APL functions. The Audit functions are further described in the APL Reference Guide . Note that this is not a database key and it must be kept as small as possible. A value that is static during the whole batch must never be used as a key value. Value - A column holding any type of value to be set, except for Counter values. This is used in combination with the auditSet APL function. Another use is mapping against existing MIM values in the Workflow Properties dialog. Transaction Id - To make sure entries are transaction safe, each table must contain a column of type NUMBER and at least have the length twelve (or have no size declared at all). Do not enter or alter any values in this column, it is handled automatically by the system. The value -1 indicates that the entry is committed and safe. Unused - Used in case a column must not be populated, that is, set to null . Key Sequence A key sequence is a defined way to assign a Key value, to identify in which order you need to send along key values when you use the auditAdd or auditSet APL functions. Each key in a table must have a sequence number in order to be identified when passed on as parameters to the APL audit functions. The first key is identified as 1, the second as 2, and so on. The key sequence will uniquely identify all audit log entries to be inserted per batch. Audit Profile Example To illustrate how Audit may be used, consider a workflow with an Analysis agent, validating and routing UDRs. Most of the UDRs will be sent on the "COMPLETE" route. The rest of the incomplete UDRs will be sent on the "PARTIALS" route. If there are a considerable amount UDRs that are routed to the latter, the batch is can celled. Open A workflow example The output on each route is to be logged in an audit table, including information on cancelled batches. An entry in the table is made for each batch and for each route. Hence two entries per batch. Open Example audit information In this example, only the destination key is needed, which uniquely identifies all the rows to be inserted per batch. The name of the destination agent is therefore selected. Note that it is not possible to update an existing row in the table, only to add new rows. This is to ensure the traceability of data. To output information other than MIM values (which may be mapped in the Workflow Properties dialog), the workflow must contain an Analysis or Aggregation agent. Setting up an Audit profile involves the following steps: Design the tables: One column (of type NUMBER) must be reserved for transaction handling. This column should be indexed in order to achieve the best performance. The contents will be of low cardinality and could therefore be compressed if supported. Consider which column/columns contain tag information, that is, the key. A key may consist of one or several columns. Create an Audit profile. For further information, see the section below, Adding the Table Mapping. Map parameters in the Workflow Preferences Audit tab to the Audit profile. For further information, see the section below, Workflow Properties - Audit Tab. Design APL code to populate the tables. For further information, see the section below, Populating Audit Tables. Audit Profile In the Audit profile configuration, the column types are configured. To create a new Audit profile configuration, click New Configuration and select Audit Profile from the menu. Click Browse to select the database in which the table(s) reside, then click OK . Adding the Table Mapping Click Add or Edit to open the Add Audit Table Attributes and Edit Audit Table Attributes dialogs, respectively. This is where the existing table columns are mapped to valid types. Open The Audit profile Add Audit Table Attributes dialog or Edit Audit Table Attributes dialog The data to insert, is put in the UDRs column. Setting it to type Counter , makes it possible to use the auditAdd function to increment the corresponding column value. If Value is used, the auditSet function can be used to assign a value. Workflow Properties - Audit Tab The Audit tab in the Workflow Properties dialog defines the type of data entered in the table by the workflow, such as MIM types or anything sent on with the APL audit functions. Open Workflow Properties - The Audit tab The complete , invalid and partial Column Names in the the Audit table are populated by using the APL audit functions, while collection_date and filename are populated by the workflow MIM values. The cancelled Column Name can be mapped directly to an existing MIM value or populated by the APL audit functions using the Analysis Agent. Populating Audit Tables There are two ways of populating audit tables; either by using the auditAdd function, which automatically increments the value of Counter columns, or by setting fixed values to columns of type Value with the auditSet function. Note that Counter columns are automatically set to 0 (zero) when a batch is cancelled. This is not the case for Value columns. Note! In terms of performance, it does not matter how many times an audit function is called. Each call is saved in memory and a summary for each key is committed at End Batch. Counter Increment By using the auditAdd function, the user does not have to keep track of the number to increment a counter column with. At Cancel Batch, the value is set to 0 (zero). Fixed Values Using the auditSet function for the same example as discussed in the previous section, means the user has to keep track of the number of records in the APL code. Note that the profile must be updated; the Counter column must be redefined to Value. Value columns are not reset when a batch is canceled. Hence there are entries made in the table for the UDRs column for all batches. Example - Use of auditAdd and auditSet In this example code, each UDR is validated with respect to the contents of the causeForOutput field. The audit table is updated to hold information on the numbers of complete, partial , and invalid UDRs sent on the routes. // Define counters int complete = 0; int partials = 0; int invalid = 0; //Publish a new MIM mimPublish(trailer, "My Trailer",string); consume { // Check if the UDR is of type complete if(input.causeForOutput == 0){ // Increment complete counter complete = complete + 1; // Increment value of column COMPLETE auditAdd( "Default.PRF_AUDIT","MZADMIN.MZ_AUDIT","COMPLETE",1 ); // Route UDR on outgoing route "COMPLETE" udrRoute(input, "COMPLETE"); } // Check if the UDR is of type partial else if(input.causeForOutput == 1 ||input.causeForOutput == 2){ // Increment partial counter partials = partials + 1; // Increment value of column PARTIAL auditAdd( "Default.PRF_AUDIT","MZADMIN.MZ_AUDIT","PARTIAL",1 ); // Route UDR on outgoing route "PARTIALS" udrRoute(input, "PARTIALS"); } else{ // Increment invalid counter invalid = invalid + 1; // Set the value of column INVALID auditSet( "Default.PRF_AUDIT","MZADMIN.MZ_AUDIT","INVALID",invalid ); } }

---

# Document 1028: Couchbase - MediationZone Documentation 9.3 - InfoZone

**Source:** ratanon/mz93-documentation
**URL:** https://infozone.atlassian.net/wiki/spaces/MD93/pages/204613265/Couchbase
**Categories:** chunks_index.json

For information about basic administration of Couchbase, see the official Couchbase documentation: https://docs.couchbase.com/home/index.html .

---

# Document 1029: FTPS Forwarding Agent Input/Output Data and MIM - MediationZone Documentation 9.3 - InfoZone

**Source:** ratanon/mz93-documentation
**URL:** https://infozone.atlassian.net/wiki/spaces/MD93/pages/205000290/FTPS+Forwarding+Agent+Input+Output+Data+and+MIM
**Categories:** chunks_index.json

Input/Output Data The agent consumes bytearray or MultiForwardingUDR types. MIM For information about the MIM and a list of the general MIM parameters, see Administration and Management in Legacy Desktop . Publishes MIM Parameter Description MultiForwardingUDR's FNTUDR This MIM parameter is only set when the agent expects input of MultiForwardingUDR type. The MIM value is a string representing the sub-path from the output root directory on the target file system. The path is specified by the fntSpecification field of the last received MultiForwardingUDR . For further information on using input of MultiForwardingUDR type, refer to FTPS Forwarding Agent MultiForwardingUDR Input . This parameter is of string type and is defined as a batch MIM context type. File Transfer Timestamp This MIM parameter contains a timestamp, indicating when the target file is created in the temporary directory. File Transfer Timestamp is of date type and is defined as a trailer MIM context type. Target Filename This MIM parameter contains the target filename, as defined in the Filename Template tab. Target Filename is of string type and is defined as a trailer MIM context type. Target File Size This MIM parameter provides the size of the file that has been written. The file is located on the server. Target File Size is of long type and is defined as a trailer MIM context type. Target Hostname This MIM parameter contains the name of the target host, as defined in the Target or Advanced tab of the agent. Target Hostname is of string type and is defined as a global MIM context type. Target Pathname This MIM parameter contains the path to the target file, as defined in the FTPS tab of the agent. Target Pathname is of string type and is defined as a global MIM context type. Target Username This MIM parameter contains the login name of the user connecting to the remote host, as defined in the FTPS tab of the agent. Target Username is of string type and is defined as a global MIM context type. Accesses Various resources from the Filename Template configuration to construct the target filename.

---

# Document 1030: Data Hub Forwarding Agent Events - MediationZone Documentation 9.3 - InfoZone

**Source:** ratanon/mz93-documentation
**URL:** https://infozone.atlassian.net/wiki/spaces/MD93/pages/204644973/Data+Hub+Forwarding+Agent+Events
**Categories:** chunks_index.json

Agent Message Events An information message from the agent, generated according to the configuration in the Event Notification Editor. For further information about the agent message event type, see Agent Event . ...Done The agent has completed uploading the file. Create batch file <filename> The agent is creating a local temporary file. Remove batch file <filename> The agent is removing the local temporary file. Load batch file into data hub... The agent is uploading the temporary file to Impala. Debug Events Debug messages are dispatched in debug mode. During execution, the messages are displayed in the Workflow Monitor. You can configure Event Notifications that are triggered when a debug message is dispatched. For further information about the debug event type, see Debug Event . initialize The agent has entered the initialize state. Write state The agent is writing to the temporary file Committing batch <transaction id> recovery <true|false> The agent has completed writing to the local temporary file and will commit the batch. deinitialize The agent has entered the deinitialize state.

---

# Document 1031: IBM MQ Input/Output Data - MediationZone Documentation 9.3 - InfoZone

**Source:** ratanon/mz93-documentation
**URL:** https://infozone.atlassian.net/wiki/spaces/MD93/pages/204608080/IBM+MQ+Input+Output+Data
**Categories:** chunks_index.json

If the IBM MQ collection agent is configured to read connection parameters dynamically, it will deliver and expect a connection UDR during initialization. Depending on the configuration, the connection UDR can be of the following types: MQConnectionInfo if Queues has been selected as Connection Mode MQConnectionInfoTopic if Topics has been selected as Connection Mode MQConnectionInfoDurableTopic if Durable Subscriptions has been selected as Connection Mode If the IBM MQ agent is configured for Queues, messages are delivered as MQMessage UDRs, while Topics and Durable Subscriptions will deliver messages as MQMessageTopic and the agent expects the same UDR type back. All UDRs are described in IBM MQ UDRs .

---

# Document 1032: UI Builder - customize responsive web UIs - MediationZone Documentation 9.3 - InfoZone

**Source:** ratanon/mz93-documentation
**URL:** https://infozone.atlassian.net/wiki/spaces/MD93/pages/205658133/UI+Builder+-+customize+responsive+web+UIs
**Categories:** chunks_index.json

The UI Builder Agent enables users to create customized responsive web UIs, by using regular workflow configuration. Communication is handled with HTTP request/response cycles, and the UI is constructed using HTML. These UIs add huge flexibility; they give external users access to customized information without the need of using the regular product Desktop. Also, UIs can be tailor-made to complement deployment specifics. Currently, there are several ways of adding UIs to a deployment, where the UI Builder Agent offers most flexibility: Development Toolkit (DTK) plug-ins; these are java extensions that require JDK and Java knowledge. Workflows containing Analysis agents using HTTP functions in combination with HTML syntax. This requires HTML knowledge, and lots of APL code. Workflows containing the UI Builder Agent; the HTTP communication and the UI components are built-in. Examples of tailor-made UIs can be to view status of use case processing details, feed a deployment with parameters, perform tasks, etc. Below is an example of a UI that shows the contents of $MZHOME, with the possibility to view and download files. Open The web UIs are restricted to users registered in the Usage Engine Access Controller with UI Builder Agent permissions.

---

# Document 1033: Amazon Profile - MediationZone Documentation 9.3 - InfoZone

**Source:** ratanon/mz93-documentation
**URL:** https://infozone.atlassian.net/wiki/spaces/MD93/pages/204998951
**Categories:** chunks_index.json

The Amazon Profile is a generic profile used for setting up Amazon S3 credentials and properties that can be used by various other profiles or agents. Currently, the profile can be used with the File System Profile, with Notifications of SNS Topic type, and supports External References. Configuration When selecting Amazon S3 as a file system, you will see two tabs; General and S3 . Open General Tab The following settings are available in the General tab in the File System profile (see screenshot above): Setting Description Setting Description Access Key Enter the access key for the user who owns the Amazon S3 account in this field. Secret Key Enter the secret key for the stated access key in this field. Region Enter the name of the Amazon S3 region in this field. IAM Role Selection Select how you want IAM role to be selected; Without role , Role from environment , Enter role name manually , Enter role ARN manually , or Inherit from AWS EC2 . Role from environment - If you select this option, run either: export AWS_IAM_ROLE=<role name> or export AWS_IAM_ROLE=<role ARN> in the environment, and then restart the EC. Enter role name manually - If you select this option, enter the name in the IAM Role field, and ensure to have "Action": "iam:GetRole", defined in your AWS console. Enter role ARN - If you select this option, enter the name in the IAM Role field. Inherit from AWS EC2 - If you select this option, no further actions are required. S3 Tab In the S3 tab, you can configure the S3 bucket and properties for the Amazon S3 client. Open Setting Description Setting Description Bucket Enter the name of the Amazon S3 bucket in this field. Advanced Properties Configure what property to use. For information on how to configure the properties for the Amazon S3 File System client, please refer to https://docs.aws.amazon.com/AmazonS3/latest/dev/acl-overview.html#canned-acl . The contents of the buttons in the button bar may change depending on which configuration type has been opened. The Amazon Profile uses the standard menu items and buttons that are visible for all configurations, and these are described in Common Configuration Buttons . The Amazon Profile profile uses the standard menu items and buttons that are visible for all configurations. The Edit button is specific to the Amazon profile configurations. Item Description Item Description External References Select this menu item to enable the use of External References in the Amazon profile. This can be used to configure the following fields: Access Key Secret Key Region IAM Role IAM Role Selection Bucket Advanced Properties For further information, see Using External Reference in Agent Profile Fields and External Reference Profile .

---

# Document 1034: Importing Code - MediationZone Documentation 9.3 - InfoZone

**Source:** ratanon/mz93-documentation
**URL:** https://infozone.atlassian.net/wiki/spaces/MD93/pages/205653576
**Categories:** chunks_index.json

When importing code, use the following prefixes: python. : to import Python Module configurations. ultra. : to import built-in UDR types or Ultra Format configurations. apl. : to import functions and/or constants from APL Code configurations. . : to import something relative to any of the items listed above if located in the same folder. <nothing> : to import any standard or third party Python module. A good practice is to strive to organize the code in modules for maximum reuse. Note! Always import your Python Module configurations, Ultra Format configurations, and APL Code configurations from the global scope, i.e. not from within a function. Example - Importing Code to the Python Agent # Absolute imports from python.Analytics.PYM_Algorithms import findclu from ultra.Analytics.UFL_Types import InputData from apl.Analytics.APL_Helpers import logger # Relative imports from .PYM_Algorithms import findclu from .UFL_Types import InputData from .APL_Helpers import logger # Other imports import numpy as np

---

# Document 1035: Workflow Packages for Routing Control - MediationZone Documentation 9.3 - InfoZone

**Source:** ratanon/mz93-documentation
**URL:** https://infozone.atlassian.net/wiki/spaces/MD93/pages/205656369/Workflow+Packages+for+Routing+Control
**Categories:** chunks_index.json

Workflow Configurations This section describes the purpose of the default batch and real-time workflow configurations that are available in Routing Control. The workflow configurations are intended as a baseline for implementation projects and can be adapted to meet specific customer requirements. For this reason, the description of the workflow configurations described in this document may deviate from your implementation. The default workflow configurations are designed for routing of Diameter messages but can be configured to handle other protocols, for example, Radius. Front-End Workflow and Back-End Windows The Front-End Workflow configuration, named RC_WFL_FrontEnd , handles the decoding and validation of UDRs from the network. Various lookups are performed based on session- and subscriber attributes to determine the correct route and destination for each UDR. It forwards the UDR and responds to the source network element. Depending on the use case, the Front-End Workflow may forward UDRs to a Back-End Workflow, named RC_WFL_BackEnd for further processing. The rationale behind separating the processing into two different workflow configurations is that it may enhance performance. When all use cases are executed in the front end, rare but complex use cases may have a significant negative impact on the throughput. By offloading these use cases to the back end, the overall throughput can be optimized. It is also possible to perform internal load balancing by executing multiple Back-End Workflows. Error Handling Workflows In case of errors when processing UDRs, a log UDR is stored before a response to the source network element. The location and content of the stored Error Log UDR are implementation specific. The default log UDRs contain the following fields: Field Description Field Description timestamp The time when the error was generated. subsKey The subscriber id, IMSI or E164, if available. errorMessage An error message defined in RC_APL_Constants . This is an APL code file imported by workflow configurations. There are two workflow configurations for handling Error Log UDRs. The configuration, named RC_WFL_IWF_Error , collects Error Log UDRs from the Front-End Workflow in real-time. The UDRs are encoded and forwarded, via an Inter Workflow agent to a batch workflow named RC_WFL_Error_To_Disk that will send the UDRs to a local disk. KPI Collection Window The Front-End Workflow and the Back-End Workflow configurations calculate a number of KPIs and store these in UDRs on disk. The location and content of the stored KPI UDRs are implementation specific. There are two workflow configurations that enable SLA Monitoring. The configuration, named RC_WFL_IWF_KPI , collects KPI UDRs from the Front-End Workflow in real-time. The UDRs are encoded and forwarded, via an Inter Workflow agent to a batch workflow named RC_WFL_KPI_To_Disk that will send the UDRs to a local disk. The default KPI UDRs contain the following fields: Field Description Field Description key The subscriber id, IMSI or E164, if available. resultcode An error code defined in RC_APL_Constants . This is an APL code file imported by workflow configurations. latency The response time to the source. time The timestamp of the incoming UDR. Batch Provisioning Workflows The workflow RC_WFL_Provisioning_Import reads UDRs from files and provisions the data using APL functions. The reverse process is performed by running RC_WFL_Provisioning_Export which exports Routing Control configuration data to files. Workflow Functionality This section describes the default preconfigured functions and uses cases that are included in the default workflow configurations and which enable users to control routing of Diameter messages, through the Web GUI. Changes in the workflow configurations are typically required in order to introduce new use cases or when adding or changing communication endpoints, data formats, and protocols. Routing Types Session-Based Routing Session-Based Routing provides routing of UDRs based on the session attributes of the incoming UDRs. The UDRs for any given session are always routed to the same destination, also when the function is combined with Weight-Based Routing. Subscriber-Based Routing Subscriber-Based Routing provides routing of UDRs based on the subscription attributes of the incoming UDRs. The UDRs for a specific subscriber are always routed to the same destination, also when the function is combined with Weight-Based Routing. Weight-Based Routing Weight-Based Routing provides load balancing of UDRs towards routing destinations. Weight-Based Routing is always combined with either Subscriber-Based Routing or Session-Based Routing. Workflow Bridge Routing Workflow Bridge Routing forwards UDRs to the Back-End Workflow for further processing.

---

# Document 1036: Managing Data Veracity Access Permission - MediationZone Documentation 9.3 - InfoZone

**Source:** ratanon/mz93-documentation
**URL:** https://infozone.atlassian.net/wiki/spaces/MD93/pages/204672668/Managing+Data+Veracity+Access+Permission
**Categories:** chunks_index.json

In order to grant permission to users to have different level of Data Veracity access privilege, you can configure the Data Veracity and Data Veracity Data Masking application permissions in Access Controller. For more information on configuring user access group permission, refer to Access Controller . Data Veracity Application Permission The following table lists the actions allowed for each Data Veracity interface in Data Management based on the selected permission, Execute and Write . The permissions are selected for Data Veracity application in Access Controller. Data Veracity actions in Data Management Execute Permission Only Write Permission Data Veracity actions in Data Management Execute Permission Only Write Permission Search & Repair Allows users to: Search View UDRs Export CSV Load Filters All masked fields are viewed as **** Note! Users are allowed to select the Data Veracity profile if the Data Veracity profile is given the Read & Execute permission. Users are allowed to search if the Database profile in the selected Data Veracity profile is given the Read & Execute permission. Allows users to: Search View UDRs Export CSV Load Filters Save/Update Filters Mark Delete Set State Execute Repair UDRs Save/Update Repair Rules Delete records When adding a Repair Rule, the Restricted Field is disabled Users are able to view the original data for masked fields Approve Delete Allows users to: Search for PRE_DELETE records Review View UDRs Export CSV Note! Users are allowed to select the Data Veracity profile if the Data Veracity profile is given the Read & Execute permission. Users are allowed to search if the Database profile in the selected Data Veracity profile is given the Read & Execute permission. Allows users to: Search for PRE_DELETE records Review View UDRs Export CSV Approve records Reject records Repair Jobs Allows users to view the repair jobs records Allows users to view the repair jobs records Error Codes Allows users to view the Error Codes Allows users to: View Error Codes Create Error Codes Edit Error Codes Delete Error Codes Filters Allows users to view the Filters Allows users to: Search Filters View Filters Create Filters Edit Filters Delete Filters Restricted Fields Allows users to view the Restricted Fields Allows users to: View Restricted Fields Create Restricted Fields Edit Restricted Fields Delete Restricted Fields Repair Rules Allows users to view the Repair Rules Allows users to: View Repair Rules Create Repair Rules Edit Repair Rules Delete Repair Rules Data Masking All masked fields are viewed as **** All masked fields are viewed as raw data without masking Data Veracity Data Masking Application Permission The Data Veracity Data Masking permission is required to configure masked fields or view masked data. The following lists the actions are allowed based on the selected permission: Execute Only - All masked fields are viewed as **** Write - Users are able to view the original data for masked fields

---

# Document 1037: Functionality - MediationZone Documentation 9.3 - InfoZone

**Source:** ratanon/mz93-documentation
**URL:** https://infozone.atlassian.net/wiki/spaces/MD93/pages/205816388/Functionality
**Categories:** chunks_index.json

MediationZone provides a comprehensive set of supporting functions to ensure effective management and operation of the system, enabling it to process very large volumes of data in a safe and consistent manner. Functionality Description Functionality Description Access Control Access to the system is controlled with user profiles, which are used to control access rights to all parts of the system. Alarm Detection Manager MediationZone can be configured to proactively monitor any execution characteristics of the system state. If a deviation is detected, an alarm is generated and can trigger a number of different events such as an SNMP trap, or email. Archiving The archiving system provides on-line storage on disk for file archiving. Automatic swap of disk partitions is included, as well as regular cleanup of old data. Auditing Audit and statistical information is generated and stored in user-defined database tables, from which reports can be generated. Data Veracity Data Veracity provides a repository of erroneous records and allows users to search, view, modify and reprocess the data. Error Correction System (ECS) ECS is a repository for usage data records (UDR) and batches failing a predefined set of processing rules. The system has full support for automatic grouping of data, purging, and automatic reprocessing. Event Notification Configuration An event notification configuration acts as a receiver/distributor of all messages generated within the MediationZone system. This makes it possible to output customized information and alarms to any target, such as a mail server, SNMP trap, or database table. Execution Manager The Execution Manager is used to control and monitor all workflows. Workflows are activated and deactivated, and user-defined views can be created to view runtime information presented in real-time. External Version Control MediationZone provides a special XML export and import format for storing configurations in an external version control system. Using external version control systems to store configuration artifacts allows for efficient collaboration, and control, during the complete lifetime of the solution. Pico Management Processes and threads are controlled through the Pico Manager, which can restrict access to certain hosts and monitor the memory and availability status. Pico management also ensures a single point of administration from a distributed architecture perspective, where the Pico manages software updates to all distributed execution environments. Reference Data Management Functions Reference Data Management deliver the capability to query and edit specific table sets in relational databases while schema permissions remain unaltered. System Export and Import The system export and import enables backup of configuration data  full or partial. The configurations are stored in XML files, which can also be exported into a ZIP archive. The export and import functionality is also very useful for migrating mediation configuration in between two different installations of MediationZone, such as production and test. System Statistics MediationZone automatically records a wide range of internal as well as external system statistics. This information can be used to monitor the performance of workflows or the utilization of hardware. System Topology Registry A data structure that holds configurations, service configurations, and attributes that control the behavior of MediationZone. The data in STR can be edited manually in a web GUI, editor, or via the command line. UDR File Configuration A UDR file configuration is used to examine and update data files, for example, when creating test data. It includes filtering capabilities, making it possible to list a selection of UDR fields. Usage Management Meters usage against a product definition, in order to provide balance management and support for complex, hierarchal aggregation structures Web Interface and Dashboard monitoring through Traffic Lights Monitoring the execution of all parts of MediationZone is performed using a web based operation and maintenance GUI. Any deviation to expected execution characteristics, such as an alarm, is immediately visible. Workflow Configuration A workflow configuration is created to design and configure Workflows and Tasks. Tools are also provided to debug and profile workflows. Workflow Group Configuration By creating a workflow group configuration, workflows can be grouped conceptually to any level of complexity. Common configuration and execution characteristics, such as scheduling and distribution criteria can then be applied collectively to all elements of a group.

---

# Document 1038: FTP Forwarding Agent MultiForwardingUDR Input - MediationZone Documentation 9.3 - InfoZone

**Source:** ratanon/mz93-documentation
**URL:** https://infozone.atlassian.net/wiki/spaces/MD93/pages/205000194/FTP+Forwarding+Agent+MultiForwardingUDR+Input
**Categories:** chunks_index.json

When the agent is set to use MultiForwardingUDR input, it accepts input of the UDR type MultiForwardingUDR declared in the package FNT. The declaration follows: internal MultiForwardingUDR { // Entire file content byte[] content; // Target filename and directory FNTUDR fntSpecification; }; The content of the MultiForwardingUDR will be stored at the path that you have set in the fntSpecification field. Use the APL functions fntAddString and fntAddDirDelimiter to set the value of this field. For further information about these functions, see FNTUDR Functions in APL Reference Guide . When the files are received they are written to temp files in the DR_TMP_DIR directory situated in the root output folder. The files are moved to their final destination when an end batch message is received. A runtime error will occur if any of the fields have a null value or if the path is invalid on the target file system. A UDR of the type MultiForwardingUDR which has a target filename that is not identical to its precedent is saved in a new output file. Note! After a target filename that is not identical to its precedent is saved, you cannot use the first filename again. For example: Saving filename B after saving filename A, prevents you from using A again. Instead, you should first save all the A filenames, then all the B filenames, and so forth. Non-existing directories will be created if the Create Non-Existing Directories check box on the Filename Template tab is checked. If not checked a runtime error will occur if a previously unknown directory exists in the FNTUDR of an incoming MultiForwardingUDR . Every configuration option referring to bytearray input is ignored when MultiForwardingUDR s are expected. For further information about Filename Template, see Workflow Template . Example - APL code to send MultiForwardingUDRs This example shows the APL code used in an Analysis agent connected to a forwarding agent expecting input of type MultiForwardingUDR s. import ultra.FNT; MultiForwardingUDR createMultiForwardingUDR (string dir, string file, bytearray fileContent){ //Create the FNTUDR FNTUDR fntudr = udrCreate(FNTUDR); fntAddString(fntudr, dir); fntAddDirDelimiter(fntudr);//Add a directory fntAddString(fntudr, file);//Add a file MultiForwardingUDR multiForwardingUDR = udrCreate(MultiForwardingUDR); multiForwardingUDR.fntSpecification = fntudr; multiForwardingUDR.content = fileContent; return multiForwardingUDR; } consume { bytearray file1Content; strToBA (file1Content, "file nr 1 content"); bytearray file2Content; strToBA (file2Content, "file nr 2 content"); //Send MultiForwardingUDRs to the forwarding agent udrRoute(createMultiForwardingUDR ("dir1", "file1", file1Content)); udrRoute(createMultiForwardingUDR ("dir2", "file2", file2Content)); } The Analysis agent mentioned previous in the example will send two MultiForwardingUDR s to the forwarding agent. Two files with different contents will be placed in two separate sub folders in the root directory. The Create Non-Existing Directories check box under the Filename Template tab in the configuration of the forwarding agent must be checked if the directories do not previously exist.

---

# Document 1039: Prometheus UDR Type - MediationZone Documentation 9.3 - InfoZone

**Source:** ratanon/mz93-documentation
**URL:** https://infozone.atlassian.net/wiki/spaces/MD93/pages/204608609
**Categories:** chunks_index.json



---
**End of Part 45** - Continue to next part for more content.
