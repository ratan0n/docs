# RATANON/MZ93-DOCUMENTATION - Part 41/112

---
**Dataset:** ratanon/mz93-documentation
**Part:** 41 of 112
**GitHub:** https://github.com/ratan0n/docs/tree/main/mz93-documentation
**Size:** ~66.6 KB
---

To open the Build screen , click the Build button on the top menu bar. This is the interface where you create and manage configurations. Open Build screen This view has two sections: Display List  The left side of the Build screen shows the Main option that displays all available configurations in the system, and the existing, committed workflow packages in the Workflow Packages section. If you select a workflow package, the Browser displays the content of the selected package and if you want to display all configurations regardless of workflow package, click the Main menu item. At the bottom of this section you can click the Create package button to create workflow packages. For more information, see Workflow Packages . Configurations Navigator  In the Configuration Browser you can create, manage, delete, and rename the configurations in the system if you have selected Main in the Display List . Configuration Browser The configurations can be either profiles that belong to specific agents, common profiles, or other types such as Event Notification or APL Collection Strategies. For more information, see Configuration Types . Option/Value Description Option/Value Description Open Selection Checkbox Select the checkbox for those configurations that you want to perform actions for. See section Table Action Bar with Configuration(s) Selected below for more information. Name Displays the name of the configuration. Valid Displays the validity of the configurations. Fields are automatically validated in agents and other core functionality. Encrypted Displays the encryption status of the configuration. Locked Shows if the configuration is locked or not. Permission Displays the permissions granted to the current user of the configuration. Permissions are shown as R (Read), W (Write), and X (eXecute). If the configuration is encrypted, an E is also added. Owner Displays the username of the user that created the configuration. The owner can: Read, modify (write), and execute the configuration Modify the permissions of user groups to read, modify, and execute the configuration. Modified date Displays the date when the configuration was last modified. Subfolders in the Configuration Browser Note! Subfolders in this context are visual representations of areas that you have partitioned to keep your configurations. They are meant to make your configuration browser look neat and tidy. They do not represent actual subfolders. You can enable subfolders to allow you to sort your configurations within your folders, making it easier to maintain larger implementations. To enable subfolders, you must set the property mz.subfolder.enabled to true in the platform.conf file . Refer to Platform (in the System Properties section) for more information on how to set the property. To create subfolders, you must use the valid separators in the folder name when creating a new folder, like the folder names "sftp_coll" and "cipher_sftp_coll shown on the image above. When subfolders are created, configurations are sorted into subfolders determined by the separator used in the folder name. The only valid separators in a folder name are "_" or "-". If any other character is used as a separator the folder will not appear with subfolders. Table Action Bar The table action bar is located on top of the Browser . The actions available change depending on if you have selected the checkbox for any configuration(s) or not. Open Table Action Bar with no configurations selected Open Table Action Bar with configuration(s) selected Table Actions with No Configurations Selected When no configurations are selected, the table action bar contains the following actions: Action Description Action Description Filter Click this button to open the Filter dialog where you can select which configuration types you want to view. Search This is a free text search box that you can use to search for specific workflow configurations that match the entered text. New Configuration Click this button to open the Configurations dialog where you can select which type of configuration you want to create. The configurations have a common set of buttons, see Common Configuration Buttons , and some have specific buttons that are described in the documentation for each configuration. New Folder Click this button to create a new folder to save your configurations in. Open The New Folder dialog Note! The maximum allowed length for a folders name is 40 characters. Refresh Click this button to refresh the list of configurations. Table Actions with Configuration(s) Selected When selecting the checkbox for one or more configurations, the table action bar is populated with different actions you can do for the configuration(s). The available actions are: Action Description Action Description Clear selection(s) Click this button to clear the selection of configurations. The table action bar shows the default actions. Delete Click this button to delete the selected configuration(s). You will be asked if you are sure you want to delete before deletion is done. Rename Click this button to open the Rename configuration or Rename folder dialog where a new name for the configuration can be entered. Open Encrypt Click this button to open the Encrypt configurations dialog where a password can be provided thus securing the configuration from unauthorized access. This button is disabled if you have selected a checkbox for a folder. Open Decrypt Click this button to open the Decrypt configurations dialog where the encryption password can be provided giving access to the configuration. This button is disabled if the selected configuration is not encrypted. Open Open Properties Click this button and select the option Properties to open the Properties dialog where you can configure the properties for the selected configuration. This button is disabled if you have selected a folder or multiple configurations. See the section Configuration Properties below for more information. Open Keyboard shortcuts Click this button to open the Configurations - Keyboard shortcuts dialog. Click anywhere outside the dialog to close it. Open Configuration Properties To open the Configuration Properties dialog, select the checkbox for the configuration you want to set properties for and click on the button with three dots in the table action bar and select Properties . This dialog has four different tabs; Basic , Permission , Reference , and History . The Basic Tab The Basic tab is the default tab in the Properties dialog. Open The Basic tab It contains the following information: Configuration Information Description Configuration Information Description Name Displays the name of the configuration. Type Displays the type of configuration. Key Displays the internal key used to identify the configuration. Folder Displays the name of the folder in which the configuration is located. Version Displays the version number of the configuration, see the History tab for further information about the different versions. Permissions Displays the permissions granted to the current user of the configuration. Permissions are shown as R (Read), W (Write), and X (eXecute). If the configuration is encrypted, an E is also added. For further information about permissions, see the Permissions Tab section. Owner Displays the username of the user that created the configuration. The owner can: Read, modify (write), and execute the configuration Modify the permissions of user groups to read, modify, and execute the configuration. Modified by Displays the user name of the user that made the last modifications to the configuration. Modified Displays the date when the configuration was last modified. If you want to use the information somewhere else you can highlight the information and press CTRL-C to copy the information to the clipboard. The Permission Tab The Permission tab contains settings for what different user groups are allowed to do with the configuration. Open The Permission tab As access permissions are assigned to user groups, and not individual users, it is important to make sure that the users are included in the correct user groups to allow access to different configurations. R W X E Permission Description R W X E Permission Description R - - - Allowed only to view the Configuration, given that the user is granted access to the application. - W - - Allowed to edit and delete the Configuration. - - X - Allowed only to execute the Configuration. R W - - Allowed to view, edit, and delete the Configuration, given that the user is granted access to the application. - W X - Allowed to edit, delete, and execute the Configuration. R - X - Allowed to view and execute the Configuration, given that the user is granted access to the application. R W X - Full access. - - - E Encrypted. The Reference Tab The Reference tab contains information about which other configurations that the current configuration refers to, and which other configurations that the current configuration is referenced by. Open The Reference tab The Reference tab contains two sub-tabs: Used By , which displays all the configurations that use the current configuration, and Uses , which displays all the configurations that the current configuration uses. If you want to edit any of the configurations, you can double-click the configuration to open it for editing. The History Tab The History tab contains version information for the configuration. Open The History tab In the table, the following columns are included: Column Description Column Description Version Displays the version number. Modified Date Displays the date and time when the version was saved. Modified By Displays the user name of the user that saved the version. Comment Displays any comments for the version. If you want to clear the configurations history, click the Clear Configuration History button. The version number is not affected by this.

---

# Document 917: Processing Agents - MediationZone Documentation 9.3 - InfoZone

**Source:** ratanon/mz93-documentation
**URL:** https://infozone.atlassian.net/wiki/spaces/MD93/pages/204613545/Processing+Agents
**Categories:** chunks_index.json

A processing agent expects to be fed data and is expected to deliver data on one or several outgoing routes. A processing agent could be as simple as a counter that counts the throughput. It could also be more complex in that it aggregates, correlates and consolidates the data and depending on the result, delivers it on different routes. Amongst the processing agents so called transformer agents can be identified. A transformer agent is responsible for translating an incoming byte stream into a UDR object or the opposite. For file distribution the Encoder Agent can be used to create header/trailer records containing metadata of the file, e.g. record counter, check sum etc. This is commonly referred to as Decoding and Encoding, which the MediationZone Ultra format system will handle.

---

# Document 918: IPv6 - MediationZone Documentation 9.3 - InfoZone

**Source:** ratanon/mz93-documentation
**URL:** https://infozone.atlassian.net/wiki/spaces/MD93/pages/204678495/IPv6
**Categories:** chunks_index.json

MediationZone includes support for IPv6 addresses for communication between pico processes over RCP (system internal protocol), i e EC-Platform, Desktop-Platform, and EC-EC. IPv6 addresses with both long and short notation are supported, and the system will then display the addresses with long notation. However, currently there are a few limitations: Picos binding on link-local addresses are not supported. Configuration of addresses with zone id is not supported. IPv6 addresses are not supported in high availability installations. For information about IPv6 support in specific agents, see the Desktop User's Guide .

---

# Document 919: vcimport - MediationZone Documentation 9.3 - InfoZone

**Source:** ratanon/mz93-documentation
**URL:** https://infozone.atlassian.net/wiki/spaces/MD93/pages/204612611/vcimport
**Categories:** chunks_index.json

usage: vcimport [options] This command imports exports made with the vcexport command. Option Description [-d, --directory] This option is mandatory and is used to state from which directory you want to import data. [-y, --dryrun] Use this option to parse import files without importing them. [-f, --folders] Use this option to specify which folders you want to include in the import. For example, mzsh <user name>/<password> vcimport -d MyDirectory/ -f Default ECS will import the configurations in the folders Default and ECS . If this option is not used, configurations in all folders will be included. [-m, --message] Use this option to add a message to identify the import. Return Codes Note! If a key or name conflict occur, the imported data will not overwrite existing configurations. Listed below are the different return codes for the vcimport command: Code Description Code Description 0 Will be returned if the import was successful. 1 Will be returned if the command could not be interpreted, e g if a option that does not exist has been entered. 2 Will be returned if the import failed. 3 Will be returned if the folder you want to import from, stated with the -d, --directory option, does not exist. 5 Will be returned if the folder(s) stated, when using the -f, --folders option, does not exist.

---

# Document 920: Workflow Configuration - MediationZone Documentation 9.3 - InfoZone

**Source:** ratanon/mz93-documentation
**URL:** https://infozone.atlassian.net/wiki/spaces/MD93/pages/204647603/Workflow+Configuration
**Categories:** chunks_index.json

The workflow configuration is a central part of the MediationZone Desktop. This is where all workflows are designed and configured by adding agents and connecting them to each other to form a data flow. The workflow configuration operates in three modes: Design mode  where workflows are created and configured Monitor mode  where workflows are started or stopped and the status of its individual agents is monitored Profiling mode  same as monitor mode but with graphical information on where most of the time is spent in the workflow A workflow that is fully configured will have access to all modes. This is determined when a workflow is opened and saved. If the workflow is not fully configured or deleted, the Monitor and Profiling modes are disabled. Workflow Group Configuration The Workflow Group configuration enables management of workflows. A workflow group can consist of one or several workflows, each with a diverse setup of scheduling, load balancing, and event notifications. Workflow groups enable you to configure these as a single entity. Groups are either of type batch or real-time, which means that batch and real-time workflows cannot be mixed in the same group. The example below shows a workflow group consisting of two batch workflows with a dependency (the first one must finish before the second can start). Open A workflow group configuration with three batch workflows Grouping of workflows can be useful in the following scenarios: There are dependencies between workflows within one line of business (e.g. collection, processing and forwarding) which can be managed through prerequisites, and the workflows need to be executed in a certain order. To limit the resource usage when executing groups with multiple workflows in parallel, you can control the maximum number of simultaneously running workflows. If there is a need to complete all collection before beginning the processing step, this can be achieved by creating a collection group and a processing group that belong to a super group. To simplify the monitoring as the groups show their status in the Execution Manager. Runtime Modification of the Workflow Configuration MediationZone includes two mechanisms by which an operator can modify a workflow that is already running. While a workflow is executing, it is possible to change the configuration of certain agents in their respective Configuration tabs which is available in the Monitor mode of the Workflow Designer. These changes will be automatically sent to the running workflow and provisioned into the agent that is being reconfigured. In this case, the changes are applied without affecting the execution of the workflow. The example below shows how this is performed for the TCP/IP Agent of an active Workflow. In this scenario, the IP address used for listening on incoming requests is changed. Open Example of runtime update of a TCP/IP agent configuration Runtime Modification of Workflow State MediationZone includes a mechanism through which it is possible  while the workflow is running  to send a signal to an agent to instruct it to perform some action without affecting the active workflow. The example below shows how this capability is used to instruct an Aggregation agent to execute the instructions within the command block for all sessions that have a timeout condition configured. This can be used, for example, to implement the capability to force a hard-flush of sessions in a Charging Gateway deployment. Executing command block from monitor mode in the graphical user interface: Open Example of runtime modification of a workflow state through the Aggregation agent A command block can also be executed from the command line interface, by using the wfcommand . This enables the workflow logic to be executed based on input from the Command Line Interface. Configuration Import and Export All, or part, of the configuration related to a MediationZone installation can be managed using the System Export/Import feature. Exporting configuration objects with this mechanism will create a compressed XML file that contains selected configuration. Exported information can also be protected through a one-way encrypted password. Using the export and import feature, it is possible to develop and test all functionality on one system, then export it and later import it into another environment. This feature can be combined with the external references feature that allows definition of all configuration parameters in a text file which gives the possibility to use one configuration export file across all environments which all have their individual parameter file. The following example shows the system import/export sub-system, creating a full configuration export: Open Example of full configuration export In addition to configuration data, the export/import function includes the capability to export runtime data from, for example, ECS and Archive systems. Parameters are available to the system import command in order to specify system behavior during the import. It is now possible to suppress all workflow scheduling until the import has finished in order, as well as a synchronized restart of all workflows. Profiles in Workflow Table The Workflow Table can be configured with: Manually entered values, e.g. directories, regular expressions, hosts, ports External References, pointing to values in property files Configuration profiles selected through the GUI, such as Database, Dup UDR, Aggregation and Inter Workflow profiles, as illustrated below: Open Workflow table including selected configuration profiles Import and Export of Workflow Table When managing multiple environments (e.g. test, pre-production and production) it can be beneficial to export the different workflow tables to CSV-format. This allows one configuration export to be valid across several environments in combination with importing the appropriate CSV-file containing the specific configuration. Also, when managing many rows in the table, it can be a good idea to import/export the table to a CSV-format (for easy editing in Excel). External References External References enable loading MediationZone with configuration values that originate from a properties file that is external to the workflow configuration. This allows MediationZone system administrators to have specific files on test and production servers, and when an export is made from the test deployment, no changes are necessary when deploying the configuration to the production installation. The example below shows a properties file containing mapping of values and variables used in MediationZone profiles, APL code and the workflow table. Open Properties file containing mapping of values and variables used in MediationZone The image below depicts the External References Profile where properties files are selected and the variable names from the file are mapped to internal variable names. Open An External References profile example The local key variables can then be mapped in the workflow instance table by activating External References in the relevant cells. Open Workflow table showing External References files usage

---

# Document 921: Provisioning PCF Session Management Policy in Desktop Online - MediationZone Documentation 9.3 - InfoZone

**Source:** ratanon/mz93-documentation
**URL:** https://infozone.atlassian.net/wiki/spaces/MD93/pages/204677601/Provisioning+PCF+Session+Management+Policy+in+Desktop+Online
**Categories:** chunks_index.json

PCFRules can be provisioned in the PCC Extensions screen in the Desktop after having inserted the data model into your system as described in https://infozone.atlassian.net/wiki/spaces/MD93/pages/204677512/PCC+Extensions?atl_f=content-tree . To open the PCC Extensions screen, click on the Manage screen option in Desktop and then click on the PCC Extensions button. Open The PCC Extensions screen In the PCC Extensions screen you can view, add, edit, and remove populated definitions for: RulesMapping UDR Target UDR SessionRule UDR Ambr UDR AuthorizedDefaultQos UDR Arp UDR PCCRule UDR FlowInformation UDR EthFlowDescription UDR TscaiInputContainer UDR DownlinkDataNotificationControl UDR QosData UDR ChargingData UDR TrafficControlData UDR RedirectInformation UDR UpPathChgEvent UDR SteeringMode UDR UsageMonitoringData UDR QosCharacteristics UDR QosMonitoringData UDR ConditionData UDR in the https://infozone.atlassian.net/wiki/spaces/MD93/pages/204645975/SMPolicy+Data+Model?atl_f=content-tree and: Period RouteToLocation RouteInformation in the Common Data Model Creating Rules Definitions The different definitions need to be configured in the following order: Period RouteInformation RouteToLocation RedirectInformation UsageMonitoringData QosCharacteristics QosMonitoringData ConditionData Arp AuthorizedDefaultQos Ambr SessionRule EthFlowDescription FlowInformation TscaiInputContainer DownlinkDataNotificationControl PCCRule QosData ChargingData Target RulesMapping The reason for the order stated above is that some definitions are selectable in other definitions, see the SMPolicy Data Model (3.2) for more information about these dependencies. To create the different definitions: In the PCC Extension screen, click on the definition type you want to create definitions for. A new screen will be displayed where you can see the definitions that have already been created for the selected type. Click on the New button, fill in the mandatory information, and click Save . The definition will be saved and listed in the view, and will now be selectable when creating other definition types that depend on it. Open The Create Period dialog Editing a Rules Definition To edit the different definitions: In the PCC Extensions screen, click on the definition type you want to edit definitions for. A new screen will be displayed where you can see the existing definitions. Select the check box for the definition you want to edit and click on Details in the Actions column. A dialog opens up displaying the configuration for the definition. Make your changes and click on the Save button. The definition will be saved. Copying Rules Definitions To copy definitions: In the PCC Extensions screen, click on the definition type you want to copy definitions for. A new screen will be displayed where you can see the existing definitions. Select the check box(es) for the definition(s) you want to copy and click on the Copy button. The selected definition(s) will be copied with new ID(s) and you can then edit the definition(s) as described above. Deleting Rules Definitions To delete definitions: In the PCC Extensions screen, click on the definition type you want to delete definitions for. A new screen will be displayed where you can see the existing definitions. Select the check box(es) for the definition(s) you want to copy and click on the Delete button. You will get a question if you are sure you want to delete the definition(s). Click OK if you are sure. The selected definition(s) will be deleted.

---

# Document 922: Function Blocks for Agents in Batch Workflows - MediationZone Documentation 9.3 - InfoZone

**Source:** ratanon/mz93-documentation
**URL:** https://infozone.atlassian.net/wiki/spaces/MD93/pages/204608666/Function+Blocks+for+Agents+in+Batch+Workflows
**Categories:** chunks_index.json

The function blocks described in this section can only be used in Python agents in batch workflows. The available function blocks are: beginBatch drain endBatch endBatchHinted cancelBatch splittingBatch commit rollback beginBatch Note! This function block only applies for the Python processing agent. This function block is executed at the beginning of each batch. def beginBatch() Example - beginBatch function block def beginBatch(): debug('beginBatch called') drain Note! This function block only applies for the Python processing agent. This function block is called before the current batch ends. The agent must flush all internal buffers to make sure all pending data has been processed before the transaction is ended. This method is the last point in the batch processing where the agent is permitted to route data. def drain() Example - drain function block def drain(): debug('drain called') udrRoute(myLastUDR) endBatch Note! This function block only applies for the Python processing agent. This function block is executed at the end of each batch. def endBatch() example - endBatch function block def endBatch(): debug('endBatch called') endBatchHinted Note! This function block only applies for the Python collection agent. This function block is called when another agent has called hintEndBatch . The collection agent may choose to ignore this method, that is, not to implement it if it cannot be supported. def endBatchHinted() Example - endBatchHinted function block def endBatchHinted(): debug('endBatchHinted called') cancelBatch This function block is executed if a Cancel Batch is emitted anywhere in the workflow. def cancelBatch() Exampel - cancelBatch function block def cancelBatch(): debug('cancelBatch called') splittingBatch Note! This function block only applies for the Python processing agent. This function block is called when the collection agent has split the input batch. If the agent keeps internal buffers to be flushed differently depending on the nature of the transaction, this method serves as a hint to the drain call. def splittingBatch() Example - splittingBatch function block def splittingBatch(): debug('splittingBatch called') commit This function block is executed for each batch when the transaction is successful. If the commit block fails with an exception, it will be executed again until it succeeds. def commit() Example - commit function block isRecoveryCommit = True def initialize(): debug('initialize called') def beginBatch(): global isRecoveryCommit isRecoveryCommit = False def commit(): if isRecoveryCommit: debug('this is a recovery commit, it is executed immediately after initialize') else: debug('this is a normal commit') rollback This function block is executed for a batch if it fails. def rollback() Example - rollback function block def rollback(): debug('rollback called')

---

# Document 923: Azure KeyVault Profile - MediationZone Documentation 9.3 - InfoZone

**Source:** ratanon/mz93-documentation
**URL:** https://infozone.atlassian.net/wiki/spaces/MD93/pages/204639329/Azure+KeyVault+Profile
**Categories:** chunks_index.json

The Azure KeyVault Profile is used for setting up the access credentials and properties to be used to connect to an Azure KeyVault environment. Currently, the profile can be used in the following Profiles: Secrets Profile Security Profile Buttons The contents of the buttons in the button bar may change depending on which configuration type has been opened. The Azure Keyvault Profile uses the standard menu items and buttons that are visible for all configurations, and these are described in Common Configuration Buttons . The profile uses the standard menu items and buttons that are visible for all configurations. Setting Description Setting Description External References Select this menu item to enable the use of External References in the Azure KeyVault profile configuration. This can be used to configure the following fields: Secret Key Key Vault Name Client ID Tenant ID Client Secret Certificate Key Vault Name Client ID Tenant ID Certificate Path Certificate Password For further information, see Using External Reference in Agent Profile Fields and External Reference Profile . General Tab Authentication Method - Secret Key The following settings are available in the Secret Key authentication method. Open Azure KeyVault profile - Secret Key configuration Setting Description Setting Description Authentication Method Choose the authentication method used for this profile. The supported options are Secret Key and Certificate . Choosing one of the options will display the appropriate configuration menu for the chosen authentication method. Key Vault Name Enter the name of the Azure Key Vault. Client ID Enter the client ID (application ID) used to create the application for the Azure Active Directory that will allow the profile to access the Azure KeyVault. The ID entered here should correlate with the client ID that is used when registering the application on the Azure Active Directory. Tenant ID Enter the tenant ID (directory ID) linked to the Azure AD application that will be used by the profile to access the Azure KeyVault. Client Secret Enter the client secret provided when creating the application for the Azure Active Directory with the client ID above. The client's secret will only be visible when registering the client ID. Test Connection Test the connectivity to the selected Azure service using the authentication credentials provided. Authentication Method - Certificate The following settings are available in the Certificate authentication method. Open Azure profile - Certificate configuration Setting Description Setting Description Authentication Method Choose the authentication method used for this profile. The supported options are Secret Key and Certificate . Choosing one of the options will display the appropriate configuration menu for the chosen authentication method. Key Vault Name Enter the name of the Azure Key Vault. Client ID Enter the client ID (application ID) used to create the application for the Azure Active Directory that will allow the profile to access the Azure KeyVault. The ID entered here should correlate with the client ID that is used when registering the application on the Azure Active Directory. Tenant ID Enter the tenant ID (directory ID) linked to the Azure AD application that will be used by the profile to access the Azure KeyVault. Certificate Type Set the certificate format that is used by the Azure AD application. You can set it to either a PEM or PFX formatted certificate. Certificate Path Define the full local path of the certificate. The certificate must be stored in the same location as the EC that will be running the workflows. The certificate must be the same one used by the Azure AD application. Certificate Password Enter the password for the PFX certificate, where the password value can also be an empty string. Password-locked PEM certificates are not supported. Test Connection Test the connectivity to the selected Azure service using the authentication credentials provided. Note! For the Test Connection button to work while using certificate authentication, the certificate path must point to a certificate located in the Platform. However, when running workflows, the certificate path must point to a certificate located in the EC. Advanced Tab Open Advanced tab In the Advanced tab, you specify settings that correspond to the Azure Keyvault environment connection. The two optional fields are the Authority Host and API Endpoint . If left empty, the following default values will be used: Field Default Values Field Default Values Authority Host Enter the URL to the directory the Microsoft Authentication Library will request tokens. If left empty, the following default values will be used accordingly: Azure Key Vault - https://login.microsoftonline.com API Endpoint Enter the API endpoint in Azure to be used for accessing and managing the services. If left empty, the following default values will be used accordingly: Azure Key Vault - vault.azure.net For Additional Information To find out more about the configuration for both authority and endpoints, refer to https://docs.microsoft.com/en-us/azure/active-directory/develop/authentication-national-cloud#azure-ad-authentication-endpoints and https://docs.microsoft.com/en-us/azure/azure-government/compare-azure-government-global-azure .

---

# Document 924: SAP RFC Profile - MediationZone Documentation 9.3 - InfoZone

**Source:** ratanon/mz93-documentation
**URL:** https://infozone.atlassian.net/wiki/spaces/MD93/pages/204642964/SAP+RFC+Profile
**Categories:** chunks_index.json

You use the SAP RFC profile to dynamically generate UDRs based on selected SAP RFC functions that are part of an SAP system. To open the SAP RFC profile configuration, click Build  New Configuration . Select SAP RFC Profile in the Configurations dialog. The profile contains the standard configuration buttons as described in Common Configuration Buttons and one additional button: Open SAP RFC profile configuration dialog The profile contains the standard configuration buttons as described in Common Configuration Buttons and one additional button: Button Description Button Description Open Click on this button to Enable External References in an agent profile field. Refer to Enabling External References in an Agent Profile Field in External Reference Profile for further information. The following settings are available in the SAP RFC profile: Setting Description Setting Description Connection Details Username Enter the SAP user ID Password Enter the SAP user password Use Secrets Profile Select this check box if you want to use a Secrets profile instead of entering the SAP password in the SAP RFC profile. If you select this option, click on the Browse... button to select the Secrets profiles you want to use. Host Enter the IP address of the SAP System Enable Load Balancing Select this check box to enable load balancing for SAP Jco. System ID Enter the 3 character code for the SAP System Message Server Host Enter the hostname/IP of the SAP Message Server Message Server Port Enter the port of the SAP Message Server. Group Name Enter the group name associated with the SAP System Advanced SAP System Number Enter the SAP System number SAP Client Number Enter the SAP Client number Secure Connection Enable SNC Mode Select this check box to allow the SAP RFC agent to apply a Secure Network Communications (SNC) to the connection between the agent and the SAP RFC system. This option is enabled by default. You must generate a SNC Personal Security Environment (PSE) on the servers running the Platform, EC and also on the machine running the Desktop Client. The PSE's in all of these environment must have the same security certificate and SNC library path. For more information on setting up the SNC, refer to Setting Up the SNC . SNC Library Path Enter the full path of the SAP Cryptographic Library files ( SAPCRYPTOLIB sar files). The files are required for you to use the SAP SNC. You can download the files from the SAP Portal. SNC Name Enter the SNC PSE's distinguished name where the SAP RFC agent is hosted on with the 'p:' prefix. Example: p:CN=CnName, O=MyCompany, C=Country SNC Partner Name Enter the SNC PSE's distinguished name of the target, the SAP RFC system with the 'p:' prefix. Example: p:CN=CnName, O=MyCompany, C=Country SNC Level Protection Select the level of protection to apply to the connection. 1: Authentication only - The SNC verifies the identity of the communication partner. No data protection is applied for this level. 2: Integrity protection - The SNC detects any changes or manipulation of the data, which may have occurred between the two end points of a communication. It will also apply the Authentication only level of protection. 3: Privacy protection - The SNC encrypts the communication as well as apply all the previous levels of protection onto the data. 8: Apply the default level of protection. The default is set to Level 3. 9: Apply the maximum level of protection. Enable SNC SSO Enable this checkbox if the SAP RFC system uses Single Sign-On with its SNC. Test Connection Click this button to test the connection to the SAP RFC system. SAP RFC Functions Click the Add button to add the required RFC functions. Generate RFC UDR Click this button to generate the UDR for the selected SAP RFC function, according to the structure in SAP. When the UDR has has been generated, click Save to save the UDR to the profile.

---

# Document 925: Event Types - MediationZone Documentation 9.3 - InfoZone

**Source:** ratanon/mz93-documentation
**URL:** https://infozone.atlassian.net/wiki/spaces/MD93/pages/204736991/Event+Types
**Categories:** chunks_index.json

This section describes the event types and their fields and includes the following subsections: Azure Application Insight Event Base Event DB Ref Event Alarm Event Code Manager Event Diameter Dynamic Event Group State Event Suppressed Event Suspend Execution Event System Event Security Event System External Reference Event User Event SharedTables Event Workflow Event Agent Event Agent Failure Event Agent Message Event User Agent Message Event Agent State Event Diameter Peer State Changed Event ECS Insert Event ECS Statistics Event Debug Event Dynamic Update Event Workflow State Event Workflow External Reference Event Supervision Event CC Monitoring Event <User Defined> Event

---

# Document 926: Python Collection Agent Transaction Behavior  - Batch - MediationZone Documentation 9.3 - InfoZone

**Source:** ratanon/mz93-documentation
**URL:** https://infozone.atlassian.net/wiki/spaces/MD93/pages/205001563/Python+Collection+Agent+Transaction+Behavior+-+Batch
**Categories:** chunks_index.json

The transaction behavior for the Python collection agent is presented here. For more information about general transaction behavior please refer to the section Transactions in Workflow Monitor . Emits The agent emits commands that changes the state of the file currently processed. Command Description Begin Batch Emitted when the beginBatch function is called. End Batch Emitted when the endBatch function is called. Retrieves The agent retrieves commands from other agents and based on them, generates a state change of the data currently processed. Command Description Cancel Batch If a Cancel Batch message is received, the agent calls the cancelBatch function block. However, if you have not added the cancelBatch function block to the Python collection agent configuration, and the Cancel Batch command is called by another agent in the workflow, an exception is thrown informing you that the agent does not implement cancelBatch . See Function Blocks for Agents in Batch Workflows . Note! If the Cancel Batch behavior defined on workflow level is configured to abort the workflow, the agent will never receive the last Cancel Batch message. Hint End Batch If a Hint End Batch message is received, the collector may split the batch at an appropriate point. After a batch split, the collector emits an End Batch message, followed by a Begin Batch message (provided that there is more data to be processed). However, if you have not added the endBatchHinted function block to the Python collection agent configuration, and the Hint End Batch command is called by another agent in the workflow, an exception is thrown informing you that the agent does not implement endBatchHinted . See Function Blocks for Agents in Batch Workflows .

---

# Document 927: mzcli - disconnect - MediationZone Documentation 9.3 - InfoZone

**Source:** ratanon/mz93-documentation
**URL:** https://infozone.atlassian.net/wiki/spaces/MD93/pages/547979468/mzcli+-+disconnect
**Categories:** chunks_index.json

Usage usage: disconnect [ -q ] [ -verbose ] <running pico process> ... Switches: -q Quiet mode -verbose Verbose mode With this command you can let an EC and its workflows run in disconnected mode during Platform upgrade, in order to avoid downtime. Note! Since a batch workflow cannot run without contact with the Platform, this command should only be executed for ECs running real-time workflows. If an EC running a batch workflow is disconnected, the workflow will abort. When the EC has been disconnected, it will continue executing real-time workflows without interference from the Platform and there will be no risk that new software is downloaded to the EC during the Platform upgrade. When the upgrade is done, each EC has to be restarted in order to re-connect to the Platform. Options Option Description Option Description [-q] Quiet mode. Use this option to eliminate the display of any report during execution. [-verbose] Verbose mode. This option will print extended error information. By running the disconnect command from the Platform without any options, all running ECs, will be disconnected without the need to login to each machine and disconnect them one by one: MZ>> disconnect Return Codes Listed below are the different return codes for the disconnect command: Code Description Code Description 0 Will be returned if the command was successful. 1 Will be returned if an EC process is not running. 2 Will be returned if an EC cannot be reached due to a communication problem. 3 Will be returned if an EC does not exist. 10 Will be returned if the Platform cannot be reached due to communication problems. 11 Will be returned in case system configuration prevent the command from running. 1-3: Errors only effecting one or more EC. 10-11: Fatal error, no EC was disconnected.

---

# Document 928: APL Collection Strategy - MediationZone Documentation 9.3 - InfoZone

**Source:** ratanon/mz93-documentation
**URL:** https://infozone.atlassian.net/wiki/spaces/MD93/pages/205654949/APL+Collection+Strategy
**Categories:** chunks_index.json

APL Collection Strategy configurations are used on top of pre-defined collection strategies to customize how files are collected from the local file system. Prerequisites The reader of this document should be familiar with: Analysis Programming Language. For further information, see the APL Reference Guide . Configuration To open the configuration, go to Build  New Configuration and then select APL Collection Strategy from the menu. Open The APL Collection Strategy Configuration Setting Description Setting Description Base Collection Strategy From the drop-down list , select a pre-defined collection strategy. The Default Collection Strategy is the standard collection strategy that is used by default by the Disk and FTP agents. The available strategies are: Default Collection Strategy Control File Duplicate Filter Multi Directory TMO Full Collection Strategy Note! The Base Collection Strategy is the collection strategy that your APL Extension will be based on. When saving your new collection strategy, make sure to use a descriptive name since it will be added to the list of available strategies in the agent's configuration. The code that you see in the dialog is a default 'skeleton' set of function blocks that are already defined in the Base Collection Strategy . By adding APL code within these function blocks, you customize the way by which the collection is going to be handled by the workflow. initialize deinitialize prepareBaseDirList accept filterFiles preFileCollection postFileCollection begin commit rollback For more information about APL functions blocks and functions, see the APL Reference Guide . The FileInfo UDR Type The FileInfo UDR type includes the properties of the file to collect or a directory where files are stored. The FileInfo UDR type can be viewed in the UDR Internal Format Browser. To open the browser right-click in the editing area of an APL Editor and select UDR Assistance... . The browser opens. Open UDR Internal Format Browser - FileInfo UDR Type FileInfo UDR Fields The following fields are included in the FileInfo UDR: Field Description Field Description isDirectory(boolean) Set to True if FileInfo represents a directory. isFile(boolean) Set to True if FileInfo represents a file. name(string) The name of the file or directory. size(long) The size of the file or directory. timestamp(long) The timestamp for when the file or directory was last modified.

---

# Document 929: Amazon S3 Agents - MediationZone Documentation 9.3 - InfoZone

**Source:** ratanon/mz93-documentation
**URL:** https://infozone.atlassian.net/wiki/spaces/MD93/pages/204606217
**Categories:** chunks_index.json

This section describes the Amazon S3 collection and forwarding agents. These agents are available in batch and real-time workflow configurations. The Amazon S3 agents collect and forward batches of files from specified buckets and regions in Amazon. Open The section contains the following subsections: Amazon Profile Amazon S3 Collection Agent Amazon S3 Forwarding Agent

---

# Document 930: Provisioning Routing Control in Desktop - MediationZone Documentation 9.3 - InfoZone

**Source:** ratanon/mz93-documentation
**URL:** https://infozone.atlassian.net/wiki/spaces/MD93/pages/204677465/Provisioning+Routing+Control+in+Desktop
**Categories:** chunks_index.json

Rules can be provisioned in the PCC Routing Control screen on the Desktop. To open the PCC Routing Control screen, click on the Manage screen option in Desktop and then click on the PCC Routing Control button. Open The PCC Routing Control screen In the PCC Policy Control screen you can view, add, edit, and remove populated definitions for: Route Mappings Routing Details Routing Destination Use Case See Routing Control Data Model for information about the different definitions and their respective fields. Hint! Whenever configurations are viewed, added, edited, copied, or deleted, this is logged for the EC log with log-level INFO. The system is by default configured to only register log entries with log level WARNING and higher, so if you want the log entries from the PCC Web UI to be registered, change the log level to INFO instead. See System Properties for further information. Creating Routing Control Definitions The different definitions need to be configured in the following order: Use Case Routing Destination Routing Details Rules Mappings The reason for the order stated above is that some definitions are selectable in other definitions as follows: In the Routing Details you can select among the Routing Destination , and Use Case . In the Route Mapping you select among the Routing Details definitions. See Routing Control Data Model , for more information about these dependencies. To create the different definitions: In the PCC Routing Control screen, click on the definition type you want to create definitions for. A new screen will be displayed where you can see the definitions that have already been created for the selected type. Click on the New button, fill in the mandatory information, and click Save . The definition will be saved and listed in the view, and will now be selectable when creating other definition types that depend on it. The Create Routing Details dialog The Route Mappings screen shows the Rules Mapping definitions Editing a Routing Control Definition To edit the different definitions: In the PCC Routing Control screen, click on the definition type you want to definitions for. A new screen will be displayed where you can see the existing definitions. Select the check box for the definition you want to edit and click on Details in the Actions column. A dialog opens up displaying the configuration for the definition. Make your changes and click on the Save button. The definition will be saved and listed in the view, and will now be selectable when creating other definition types that depend on it. Copying Routing Control Definitions To copy definitions: In the PCC Routing Control screen, click on the definition type you want to copy definitions for. A new screen will be displayed where you can see the existing definitions. Select the check box(es) for the definition(s) you want to copy and click on the Copy button. The selected definition(s) will be copied with new ID(s) and you can then edit the definition(s) as described above. Deleting PCC Definitions To delete definitions: In the PCC Routing Control screen, click on the definition type you want to delete definitions for. A new screen will be displayed where you can see the existing definitions. Select the check box(es) for the definition(s) you want to copy and click on the Delete button. You will get a question if you are sure you want to delete the definition(s). Click OK if you are sure. The selected definition(s) will be deleted.

---

# Document 931: Submitting a Spark Application - MediationZone Documentation 9.3 - InfoZone

**Source:** ratanon/mz93-documentation
**URL:** https://infozone.atlassian.net/wiki/spaces/MD93/pages/205656068/Submitting+a+Spark+Application
**Categories:** chunks_index.json

This section describes how to submit a Spark application. Prerequisite The scripts must be prepared according to 5.2 Preparing and Creating Scripts for KPI Management . Submitting the Spark Cluster Use this script to submit a Spark application to the Spark workers: $ submit.sh <kpiapp name> Where the kpiapp name must match a name present in the script kpi_params.sh in the same folder. Default is: submit.sh kpiapp You can now confirm the status of the application. Open a browser and go to: http://<spark service master host>:8080 This opens the Spark Master Web UI. Open Spark UI Hint! The Application Detail UI contains useful tools for monitoring of the submitted applications. This UI can be opened from the Spark Master Web UI by clicking the Application Name of a running application. Click the top-level menus in the UI to monitor various aspects of the submitted applications. The Scheduling Delay and Processing Time graphs under the S treaming menu are particularly useful for monitoring the processing performance. The former displays the scheduling time of "Spark batches" and should be near 0. The latter display the processing time of these batches.

---

# Document 932: Workflow Types - MediationZone Documentation 9.3 - InfoZone

**Source:** ratanon/mz93-documentation
**URL:** https://infozone.atlassian.net/wiki/spaces/MD93/pages/204997393
**Categories:** chunks_index.json

There are four types of workflow configurations: Batch Real-Time Task System Task Batch Workflow A batch workflow processes input from a specific source, usually a file. The workflow creates batches from the data and processes them one by one. In a batch workflow data is collected by a single collecting agent in a transaction-safe manner. A single batch is collected (only once) and is fully processed by the workflow before the next batch is collected. A batch workflow: Processes batches, one at a time. Is started either manually or by a scheduled trigger. Stops either when it finishes processing the input, or when aborted. Note! If the workflow aborts, the current batch can be reprocessed. Real-Time Workflow Real-time workflows are used in systems where instant processing requests need to be addressed as they occur. In real-time workflows most of the collecting agents communicate in a two-way manner; they receive requests and provide replies. A real-time workflow: Can have more than one collecting agent Note! Multithreading operations differ from batch workflows in the following ways: The order of UDR processing cannot be guaranteed. Only global MIMs are used. They can process several UDRs simultaneously. See Multithreading . Once started, the real-time workflows remain active. A real-time workflow is started either manually or by a scheduled trigger and stops either manually or due to an error. Processes reside in memory. Transaction safety must be handled prior to collection and after distribution. Errors are registered in the System Log and the workflow continues to run. Real-time workflow error handling rarely leads to workflow aborts. Note! Real-time workflows may use the Inter Workflow or Kafka agents to forward data to a batch workflow. Task Workflows Task workflows are single-agent workflows that execute user-defined SQL, shell scripts, or unit tests. System Task Workflows MediationZone comes with built-in System Task workflows. System Task workflows and groups let you perform activities such as log and run-time data cleanup. System Task workflows include the following types: Archive Cleaner Configuration Cleaner Data Veracity Maintenance ECS Maintenance Statistics Cleaner System Backup System Log Cleaner User Cleanup This section includes information about: Opening a System Task Workflow Modifying a System Task Workflow Configuration Opening a System Task Workflow You open a System Task Workflow from the workflow configurations list ( Build menu). To open a System Task, double-click a System Task workflow or workflow group in the Configurations pane. Open System Task Workflows list Modifying a System Task Workflow Configuration You modify all the System Task Workflow configurations at the template level. The workflow properties are all set to Final and cannot be modified. You can modify a System Task configuration, including its scheduling criteria, but you cannot create or remove a System Task configuration. The Archive Cleaner Workflow lets you modify only its scheduling criteria. For further information see Scheduling in Managing a Workflow Group . To Modify a System Task Workflow: Open the System Task Workflow that you want to modify by double-clicking on it or right-clicking and selecting View Configuration . Double-click the agent icon. The agent's configuration dialog opens. Perform the changes and click OK . Save the workflow. Archive Cleaner The Archive Cleaner System Task lets you remove old archived files from the file system. Archive Cleaner operates according to data that it receives from the Archive profiles. Note! You can only modify the scheduling criteria of the Archive Cleaner. See Archive Profile . Since schedules can only be applied to workflow groups, you modify the Archive Cleaner scheduling from the workflow group configuration. Configuration Cleaner The Configuration Cleaner lets you specify the maximum age of an old configuration before it is removed. Note! You cannot remove the most recent configuration with the Configuration Cleaner, only the previous ones. To configure the Configuration Cleaner: Select a configuration type from the table and click the entry in the Keep column. A drop-down list appears. Select one of the following options: Always , Days , or Versions . The Configuration Cleaner System Task Item Description Item Description Type The icon represents the configuration type. Name The name of the configuration type. Keep Specify how long to keep old configurations in the system. Always : Always keep configurations. Days : Keep configurations for a specified number of days. Versions : Keep only a certain amount of versions of the configurations. Value Specify the number of days or versions that represent the period during which configurations are kept. Data Veracity Maintenance The Data Veracity Maintenance system task removes outdated Data Veracity data, provided that the state is REPROCESSED or DELETE_APPROVED. For more information see Data Veracity Maintenance System Task . Open The Data Veracity Maintenance Task ECS Maintenance ECS Maintenance lets you remove old ECS data from the file system, provided that the state is REPROCESSED . For more information see ECS Maintenance System Task . Open The ECS Maintenance Task Statistics Cleaner The Statistics Cleaner lets you remove old statistics data that has been collected by the Statistics server and stored in the database. Open The Statistics Cleaner Task Item Description Item Description Minute Level Records Specifies the number of days during which a minute-level record should be kept in the database. Hour Level Records Specifies the number of days during which an hour-level record should be kept in the database. Day Level Records Specifies the number of days during which a day-level record should be kept in the database. System Backup System Backup enables you to create a backup of all the configurations in the system. A backup file is saved on the host machine where the Platform application is installed. The System Backup files are stored in $MZ_HOME/backup/yyyy_MM , where yyyy_MM is translated to the current year and month, and $MZ_HOME/backup is the default path . The system saves a backup file and names it according to the following format: backup_<date>.zip . In addition, System Backup lets you specify the maximum age of backup files before they are removed. You can change this location using the following command: <property name="mz.backup.path" value="${mz.home}/backup"/> The System Backup configuration dialog contains two tabs: System Backup : To enable the option. Cleanup : To configure the option. The System Backup System Task - the System Backup tab Item Description Item Description Enable System Backup Select this checkbox to enable the system backup. This setting is selected by default. Use Encryption Select this checkbox to enable encryption of the backup. Password Enter a password. Open The System Backup System Task - the Cleanup tab Item Description Item Description Imported Files Every time the System Importer imports a configuration, the system saves it as a backup on the Platform. Enter the period, in days, during which the imported files should remain on disk. System Backup Files Defines the maximum age of system backup files before they are removed from the host disk. System Log Cleaner The System Log Cleaner deletes the System Log periodically. You specify how long to keep different message types in the System Log Cleaner configuration. Open The System Log Cleaner Task Item Description Item Description Error/Disaster Enter the number of days to keep Error and Disaster messages before they are removed from the database. Max value: 999 days Default value: 30 days Warning Enter the number of days to keep Warning messages in the database. Max value: 999 days Default value: 20 days Information Enter the number of days to keep Information messages in the database. Max value: 999 days Default value: 10 days User Cleanup Task The User Cleanup Task automatically deletes inactive users. When either a SSO or LDAP user is logged in, the user is added into the system. However, the user is not removed when it is deleted from the external server. The User Cleanup Task is used to delete users that have not logged in for a configurable number of days. Open The User Cleanup Task Item Description Item Description Apply to the following user types Checkbox options to determine which User Type to apply the cleanup task on. Multiple options may be selected. Local users - apply the clean up on local system users SSO users - apply the clean up on SSO users LDAP users - apply the clean up on LDAP users Retention Period The default value is 0 (zero). This setting specifies the number of days to wait before a user is deleted after their last login session. A value of 0 (zero) disables the cleanup function. Default Successor If a certain user is deleted from the platform, a successor needs to be designated. This user will take ownership of all previously owned configurations.

---

# Document 933: Control Zone - MediationZone Documentation 9.3 - InfoZone

**Source:** ratanon/mz93-documentation
**URL:** https://infozone.atlassian.net/wiki/spaces/MD93/pages/204744432/Control+Zone
**Categories:** chunks_index.json

The Control Zone contains the MediationZone Platform and one or more databases. Platform The Platform provides a range of services to other pico processes: Server Description Activation Manager The Activation Manager handles all activations of workflow groups. Workflow groups can automatically be activated in one of two ways: At a specified time Day Plans As a result of another activity taking place within the system, Event Triggers Alarm Manager The Alarm Manager manages Alarm Raisers and their alarms. Audit Log The Audit Log is a server that receives audit log information from workflows that are running, and feeds this information to the corresponding audit tables for different databases. Code Server The Code Server is required all by all pico-started applications. It is the first server started on the Platform, and it is responsible for maintaining the code repository of MediationZone. The system groups all software code into packages that are inserted into the Code Server repository via the Code Server by using the installation scripts, or the mzsh command line tool. When receiving requests from pico-started clients, the Code Server will hand over the latest version of all the code needed for execution. Event Server The Event Server handles logging and triggering of entries of informative and error type, which are referred to as Events , within the system. The Event Server receives all events, and hands them out upon requests from various applications. Group Server The Group Server activates and manages the workflow groups by: Activating workflow group members Coordinating the workflow group members' timing and load Management Utilities Management Utilities handles miscellaneous database related operations, such as framework persistence configuration management and caching of database meta data. Notification Server Events in the system may be forwarded to any notifier. The mapping is made in the Event Notifications Configuration , and is stored and handled by the Notification Server. Reference Manager Different configurations may be related to each other. For example, an agent may depend on a format or a database profile. The Reference Manager keeps track of all such relations. Statistics Manager The Statistics Manager collects and manages statistics from the running system. This information is used for balancing workflow load, among other things, and may be viewed in the System Statistics Inspector that is opened by selecting the System Statistics option in the Tools menu in Desktop. System Log The System Log contains services for storing, browsing, and deleting entries in the system. The entries may be viewed in the System Log Inspector that is opened by selecting the System Log option in the Tools menu in Desktop. Workflow Server The Workflow Server loads all workflow data, both referential and configurational, upon workflow activation. It is also responsible for making sure that a workflow is up and running. Services that typically run on SCs can also be configured to run on the Platform. Pico-start Pico-start is a utility that automatically downloads new code from a repository maintained by the Code Server. A client that is pico-start compliant only needs the code for the pico-start utility. When initializing, it will establish contact with the Code Server and dynamically request the latest version of all code needed. To gain performance, the client will store all code that it downloads on the local file system (in the pico cache). The next time it initializes, it will compare the code version in the local cache with the code that is stored in the Code Server. If nothing is new, the code in the cache will be used. All the code is not transferred at once. Pico-start will send a request to the server each time the pico-started client detects a class that it does not have. For example, if a new agent package has been inserted into the system, the next time a Workflow Editor window is opened through the Desktop, this new code will be loaded. When an EC is started, a synchronization is made and the latest picostart.jar file will be automatically downloaded from the Platform if there is a new version available. For more information, please refer to the section MZ_HOME/lib . Software Packages MediationZone groups all software code into packages that are inserted into the Code Server repository via the Code Server by using the installation scripts, or the Command Line Tool . Each package is keyed by a name. The name and a version name are encapsulated in the package file together with code, images, property files etc. When a package is inserted, the package name is used to determine if the package already exists in the Code server or not. Note! If the package is already present, the existing code will be replaced completely with the code from the inserted package, regardless of the package version. The package vendor is free to use the version name in order to identify the package version. Preferably, the version should relate the official version of the code. The version name is a plain string. You can view the installed packages by clicking on the User menu in Desktop and selecting Installed packages . Open Installed packages Code Environment The code in the Code Server is stored on three different levels: Platform code This is code related to the core Platform, including some user interface plug-ins, for example the MediationZone Development Toolkit. Execution code This is code related to workflow agents, APL plug-ins, Tasks, and Events. Updates made to the code on execution level is propagated to clients on demand. Generation code This is code that is automatically generated by user configuration. This includes implementation code for Ultra formats and APL scripts. Databases Data that is persisted by the Platform is partially stored in the file system and partially in one or more databases. The supported database types are Derby, Oracle, PostgreSQL and SAP HANA. Derby is embedded in MediationZone while Oracle, PostgreSQL and SAP HANA are installed separately. The following is stored in the database(s): System log messages Duplicate Batch processing data Archiving data Error Correction System data User Access data (deprecated and configurable with Platform property) System Statistics Alarm data Group Server data License data Workflow transactions and workflow states When you install a Platform container, using Derby, the data listed above will be split across multiple databases. When you are using Oracle, PostgreSQL or SAP HANA the data will be stored in one database.

---

# Document 934: Agent Event - MediationZone Documentation 9.3 - InfoZone

**Source:** ratanon/mz93-documentation
**URL:** https://infozone.atlassian.net/wiki/spaces/MD93/pages/204737074/Agent+Event
**Categories:** chunks_index.json

The following fields are included: agentName - The name of the agent issuing the event. Fields inherited from the Base event The following fields are inherited from the Base event, and described in more detail in Base Event : category contents - Workflow: <Workflow name>, Agent: <Agent name> eventName origin receiveTimeStamp severity timeStamp Fields inherited from the Workflow event The following fields are inherited from the Workflow event, and described in more detail in Workflow Event : workflowKey workflowName workflowGroupName

---

# Document 935: Notifier Plugins - MediationZone Documentation 9.3 - InfoZone

**Source:** ratanon/mz93-documentation
**URL:** https://infozone.atlassian.net/wiki/spaces/MD93/pages/204645236/Notifier+Plugins
**Categories:** chunks_index.json



---
**End of Part 41** - Continue to next part for more content.
