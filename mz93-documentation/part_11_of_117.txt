# RATANON/MZ93-DOCUMENTATION - Part 11/112

---
**Dataset:** ratanon/mz93-documentation
**Part:** 11 of 112
**GitHub:** https://github.com/ratan0n/docs/tree/main/mz93-documentation
**Size:** ~69.0 KB
---

usage: topo <subcommand> <options> This command is used to register containers in STR and to create, update, remove, and view pico configurations. Note! This command is valid only for the MZ_HOME owner. When you make changes in pico configurations, using topo , these are automatically validated before they are copied to the active registry. If the command and its arguments can be parsed but fails the validation, you can update the configuration or use a reset command to undo the changes. An error message will appear if the validation fails. You can disable the validation by using the option --no-activation . Changes performed by the mzsh topo will then remain in the master registry until you submit a separate topo activate command. You can use the following subcommands with topo: activate container convert diff env get hash help migrate open rebase-configs register reset set setupremote show unset activate usage: activate [options] Options: -d, --allow-disconnected Allow the use of locally cached data (when platform unreachable) Default: false --dry-run Validates all changes to master, but stops before actually completing the activation Default: false --hash Perform activation, only if active registry hash matches the specified hash Default: <empty string> -v, --verbose Outputs information about the changes performed Default: false Use topo activate to move staged changes in the master registry to the active registry. Option Description Option Description [--dry-run] Use this option to validate the staged changes without performing the activation. [-d, --allow-disconnected] Use this option when the Platform is unreachable and you want to operate on cached data. [hash <hash value>] Compare the provided hash value with the actual hash that represents the current state of active registry. The activation fails if the values are not equal. For further information, see hash below, [-v, --verbose] Use this option for detailed information about the changes. Hint! The options --dry-run and --verbose are useful to learn the mzsh topo syntax. When you have edited the configuration manually, use the following command, to view the corresponding edits in a scripted syntax: mzsh topo activate --dry-run --verbose Example - Output from activate with verbose Option mzsh topo activate -v --dry-run mzsh topo set topo://container:main1/pico:ec1/val:config.properties.ec.httpd.port 9096 # (was: 9092) Dry-run: Validation successful Dry-run: Stopping without performing activation Dry-run: Active registry not changed You can then restore the master registry with the command mzsh topo reset . Example - Restart the Picos to Apply the Changes Changes to the STR are not applied on running pico instances or services. If you, for example, have updated the properties of the Platform and an EC, both must be restarted after activation. Example, after an mzsh topo activate of ec5, mzsh shutdown and startup needs to be done to apply the changes. mzsh shutdown ec5 mzsh startup ec5 container Outputs the current MZ_CONTAINER usage: container [options] Options: -d, --allow-disconnected Allow the use of locally cached data (when platform unreachable) Default: true Use topo container to display the name of the current container. Option Description Option Description [-d, --allow-disconnected] Use this option when the Platform is unreachable and you want to operate on cached data. convert Converts specified file of pico definitions from ("XML" -> STR) usage: convert [options] Options: -d, --allow-disconnected Allow the use of locally cached data (when platform unreachable) Default: false -c, --container -g, --container-group --dry-run Output the command that will do the conversion, but do not execut it Default: false * -f, --file Migrate picos from specified file Use topo convert to move the configuration of a specific XML file to STR. Option Description Option Description [-c, --container <container>] Use this option to specify a target container. [-d, --allow-disconnected] Use this option when the Platform is unreachable and you want to operate on cached data. [-g, --container-group <container group>] Use this option to specify a target container group. [--dry-run] Use this option to validate that the conversion and display the result of the conversion without updating the STR. [-f, --file <filename> Use this option to specify the source XML file. Example - Converting an XML File mzsh topo convert --container main1 diff Compare active registry with master or backup usage: diff [options] Options: -d, --allow-disconnected Allow the use of locally cached data (when platform unreachable) Default: false -q, --brief Output only whether files differ Default: false -f, --from Name of the registry to compare to the active registry Default: master -e, --show-entries Show a diff of all updated entries in the files Default: false Use topo diff to view differences between the master repository and the active repository in the STR. Option Description Option Description [-d, --allow-disconnected] Use this option when the Platform is unreachable and you want to operate on cached data. [-e, --show-entries] Use this option for viewing differences in an easy-to-read format. By default, the output from the command displays topo set commands that correspond to the staged changes. Example - Output from diff Command With -e option: UPDATE (containers/main1/picos/ec1.conf) config.properties.aaa:"2" # (was: "1") Without -e option: mzsh topo set topo://container:main1/pico:ec1/val:config.properties.aaa "2" # (was: "1") [ -f, --from <registry>] Use this option when you want to compare the active registry with the backup registry [-q, --brief] Use this option to only view the names of the updated registry files. The default value is false. Example - Comparing Registry Files Run the following command to view the differences between the active registry and the master registry. $ mzsh topo diff or $ mzsh topo diff --from master Run the following command to view the differences between the active registry and the backup registry. $ mzsh topo diff --from backup env Print (or update) the MZ environment values in a format that can be "sourced" in bash: "export NAME=VALUE" usage: env [options] Options: -d, --allow-disconnected Allow the use of locally cached data (when platform unreachable) Default: false -e, --effective Read the environment parameters from within the MZ process runtime, i.e. "effective values", accounting for overrides. The default behaviour is to read the values as they are defineds in the mzsh script, not accounting for the possibility to override these values with environment variables. Default: false --update-java-home Update the mzsh script value of JAVA_HOME --update-mz-container Update the mzsh script value of MZ_CONTAINER --update-mz-home Update the mzsh script value of MZ_HOME --update-mz-platform Update the mzsh script value of MZ_PLATFORM --update-mz-platform-token Update the mzsh script value of MZ_PLATFORM_TOKEN Use topo env to display or set environment variables that are used by the mzsh command. These variables are written to the script file $MZ_HOME/bin/mzsh . The three variables MZ_PLATFORM , MZ_CONTAINER and MZ_CONTAINER_TYPE are handled differently than the rest. In order to update the value in the script file you use the parameters starting with --update-<value> as per below table. In order to both update the value in the script file and use the value immediately you will have to combine the --update-<value> parameter with the -e parameter. Option Description Option Description [-d, --allow-disconnected] Use this option when the Platform is unreachable and you want to operate on cached data. [-e, --effective] Use this option to read the environment parameters in runtime, i e the "effective values" after accounting for overrides. The default behaviour is to read the values as they are defineds in the mzsh script file, not accounting for the possibility to override these values with environment variables. [--update-java-home <value>] Use this option to update the value of JAVA_HOME [ --update-mz-container <value>] Use this option to update the value of MZ_CONTAINER. [--update-mz-home <value> ] Use this option to update the value of MZ_HOME. [--update-mz-platform <value> ] Use this option to update the mzsh value of MZ_PLATFORM. Example - Reading the Environment Variables $ mzsh topo env export JAVA_HOME="/opt/jdk/jdk-17.0.2/jdk-17.0.2.jdk" export MZ_CONTAINER="main1" export MZ_CONTAINER_TYPE="platform" export MZ_PLATFORM="http://192.168.0.1:9000" export MZ_HOME="/opt/mz" Example - Setting the Environment Variable JAVA_HOME $ mzsh topo env --update-java-home /opt/jdk/jdk-17.0.2.jdk get Return the information specified by target-path from the System Topology Registry usage: get [options] target-path Options: -d, --allow-disconnected Allow the use of locally cached data (when platform unreachable) Default: false --default-val Value to output in place of a missing value for a target-path --exclude-dynamic Exclude dynamic information, such as _status { .... } from the output Default: false --format Format of returned data (full|data-only) Default: full -l, --local Implicitly use the local MZ_CONTAINER, unless specified in path Default: false -p, --perspective View of the returned path (default|resolved) Default: default -s, --strict-json Produce/Require strict JSON Default: false --timeout-seconds Maximum time to allow for gathering dynamic information (e.g. _status) Default: 10 Use topo get to retrieve pico configurations in the target path from STR. Paths in STR are structured as follows: topo://container:<container>/pico:<pico>/val:<attribute> Option Description Option Description [-d, --allow-disconnected] Use this option when the Platform is unreachable and you want to operate on cached data. [--default-val <value>] Use this option to replace a missing value in the target path with a default value. Example - Using default-val If the property aaa, is not defined for ec1, 123 is returned instead. $ mzsh topo get -l --default-val 123 topo://pico:ec1/val:config.properties.aaa [ --exclude-dynamic] Use this option to exclude non-static data in the output e g _status in a pico configuration. This is useful in case of errors that blocks the topo command. [--format <full|data-only>] Use this option to exclude metadata from the command output. full - Include meta data data-only - exclude meta data Default: full [-l, --local] Use this option to select the local container, unless another container is specified in the target path. Default: false [-p, --perspective <resolve | default>] Use this option to retrieve the attributes of templates instead of the template names. resolve - attributes default - template names Default: default [-s, --strict-json] Produce/Require strict JSON Default: false [--timeout-seconds] Maximum time to allow for gathering dynamic information (e.g. _status) Default: 10 Example - Viewing Pico Configurations Run the following command to view one or more pico configurations. $ mzsh topo get topo://container:main1/pico:ec2 You can view multiple pico configurations by replacing the full path with a regular expression. $ mzsh topo get topo://container:main1/pico:.* Example - Viewing Pico Attributes Run the following command to view a specific attribute in a pico configuration. $ mzsh topo get topo://container:main1/pico:ec2/val:_name You can retrieve the attributes of multiple pico processes by replacing the full path with a regular expression. $ mzsh topo get --format data-only topo://container:main1/pico:.*/val:_name hash Outputs a hash representing the current state of 'active' usage: hash [options] Options: -d, --allow-disconnected Allow the use of locally cached data (when platform unreachable) Default: false Use topo hash to retrieve a value that represents the current state of the active registry. This is useful when you need to handle concurrent changes of the STR. For instance, an application may need to retrieve a pico configuration to evaluate the required changes. In the meantime, a second application or a user may update the same configuration. Option Description Option Description [-d, --allow-disconnected] Use this option when the Platform is unreachable and you want to operate on cached data. Example - Using Hash Values Application 1 retrieves a new hash value. $ mzsh topo hash "3a2e373fa1653c7f0e757e2682c70317-2028777631" Application 1 retrieves the properties of ec1. $ mzsh topo get -l pico:ec1/obj:config.properties Application 1 updates a property but does not call topo activate . The hash is specified to ensure that changes by other users are not activated inadvertently later on. $ mzsh topo set -l --no-activation --hash 3a2e373fa1653c7f0e757e2682c70317-2028777631  topo://pico:ec1/val:config.properties.ec.httpd.port 9090 Application 2 updates the properties of ec1. The hash value is updated. $ mzsh topo set -l topo://pico:ec1/val:config.properties.ec.httpd.port 9090 Application 1 calls topo activate with hash value retrieved in step 1. $ mzsh topo activate --hash 3a2e373fa1653c7f0e757e2682c70317-2028777631 The activation fails since the hash values do not match. Specified hash does not match transaction id: d9cd38f3793647028bd7e5d64c354ad5-2055434210 != 3a2e373fa1653c7f0e757e2682c70317-2028777631) This may indicate concurrent modification of registry: Operation aborted! Application 1 resets the master registry, retrieves a new hash and starts over. $ mzsh topo reset $ mzsh topo hash help Usage: topo help [<subcommand>] Use topo help to retrieve a description of a subcommand. Run the following command for an overview of the various topo subcomands $ mzsh topo help Run the following command for a description of a specific subcomand $ mzsh topo help <command> migrate Move pico process definitions in $MZ_HOME/etc/*.xml into System Topology Registry usage: migrate [options] Options: -d, --allow-disconnected Allow the use of locally cached data (when platform unreachable) Default: false -a, --no-archive Do not archive the existing xml configs (will create duplicates) Default: false Use topo migrate to move pico configurations from $MZ_HOME to STR. The upgrader runs this command during upgrade. Option Description Option Description [-d, --allow-disconnected] Use this option when the Platform is unreachable and you want to operate on cached data. open Opens an STR configuration file (in an editor) usage: open [options] target Options: -d, --allow-disconnected Allow the use of locally cached data (when platform unreachable) Default: false -n, --no-activation Write changes to master registry, but skip activation Default: false Use topo open to open a cell, container- or pico configuration file in a text editor. When you save and close the editor, the command will call topo activate to move the staged changes in the master registry to the active registry. Option Description Option Description [-d, --allow-disconnected] Use this option when the Platform is unreachable and you want to operate on cached data. [-n, --no-activation] Use this option to skip activation after changes in master registry. Run the following command to open a cell configuration: $ mzsh topo open cell:<cell> Example - Opening a Cell Configuration $ mzsh topo open cell:default Run the following command to open a container configuration: $ mzsh topo open <container> Example - Opening a Container Configuration $ mzsh topo open main1 Run the following command to open a pico configuration: $ mzsh topo open <pico> Example - Opening a Pico Configuration $ mzsh topo open ec1 or $ mzsh topo open container:main1/pico:ec1 If the pico name is not unique in the system, you will be prompted to specify the container. Example - Multiple Pico Configurations Sharing the Same Name $ mzsh topo open ec2 (/home/main1/common/config/cell/default/master/containers/main1/picos/ec2.conf,ec2,topo://container:main1/pico:ec2) (/home/main1/common/config/cell/default/master/containers/exec1/picos/ec2.conf,ec2,topo://container:exec1/pico:ec2) Multiple entries, select one: (1) topo://container:main1/pico:ec2 (2) topo://container:exec1/pico:ec2 [1] : To avoid ambiguous references, specify the name of the container and the pico configuration. Run the following command to open the custom or the standard services configuration: $ mzsh topo open services:<custom|standard> Example - Opening a Service Configuration $ mzsh topo open services:custom Hint! When you save the configuration, topo activate is called with the --verbose option and the saved changes are displayed in a scripted syntax. By default, the command opens the vi editor. To use a different editor set the environment variable EDITOR . Example - Setting nano as the Default Editor $ export EDITOR=nano rebase-configs Removes duplicate configuration entries from configuration files that exist in a template. usage: rebase-configs [options] [topology-ref] Options: -a, --activate Activate immediately Default: false -d, --allow-disconnected Allow the use of locally cached data (when platform unreachable) Default: false Use topo rebase to inset a standard template in a pico configuration and remove attributes that are identical to attributes in the template. The command automatically detects the pico configuration type and applies one of the following templates: mz.standard-platform.conf mz.standard-ec.conf mz.standard-sc This command is useful to reduce the size of the pico configurations and thereby facilitate maintenance. The changes are written to the master registry. To validate and activate the changes you can either use the --activate option or run topo activate after the topo rebase-configs command. For further information about templates, see STR File Structure . Option Description Option Description [-a, --activate] Use this option to immediately activate after changes in master registry. [-d, --allow-disconnected] Use this option when the Platform is unreachable and you want to operate on cached data. Example - Rebasing an EC Configuration $ mzsh topo rebase-configs topo://container:main1/pico:ec1$ mzsh topo active --verbose or mzsh topo rebase-configs --actoivate topo://container:main1/pico:ec1 register Usage: topo register [-a, --address] [-c, --container] [-d, --allow-disconnected] [-g, --container-group <container group>] [--mz-home <mz home>] [-u] When you install an execution container, and the Platform is running, it is automatically registered in the Platform Container. If the platform is not running during the installation, use topo register to register the Execution Container manually. Option Description Option Description [-a, --address <ip/host>] Use this when you need to set a different host address for the container than the one that is specified in the common property pico.rcp.server.host , which is the default value. This option is typically used together with the -u option. [-c, --container <container>] Use this option when you need to change the existing container name. This option is typically used together with the -u option. [-d, --allow-disconnected] Use this option when the Platform is unreachable and you want to operate on cached data. [-g, --container-group <container group>] Use this option when you need to change the existing container group. This option is typically used together with the -u option. [--mz-home <path>] Use this option when you need to set a different home directory for the container than the one that is specified in the environment variable MZ_HOME, which is the default value. [-u] Use this option to allow updates of an already registered container. By default, updates are not allowed and the command will attempt to register a new container. reset Usage: topo reset [-d, --allow-disconnected] [-f, --from <registry>] Use topo reset to remove any changes to the master registry in STR since the activation. Option Description Option Description [-d, --allow-disconnected] Use this option when the Platform is unreachable and you want to operate on cached data. [-f, --from <registry>] Use this option to state the name of the registry to reset from. Valid registries are: active, backup. set Usage: topo set [-d, --allow-disconnected] [-l, --local] [-n, --no-activation] [-s, --strict-json] <target path> <config> Use topo set to create and update pico configurations in the specified target-path of STR. Option Description Option Description [-d, --allow-disconnected] Use this option when the Platform is unreachable and you want to operate on cached data. [-l, --local ] Use this option to select the local container, unless another container is specified in the target path. [--no-activation, -n] Use this option to skip activation after changes in master registry. [-s, --strict-json] Use this option when you want to specify the configuration in JSON format instead of HOCON format. Run the following command to create a new pico configuration. $ mzsh topo set topo://container:<container>/pico:<pico> <config> The <config> argument may contain a key-value pair that specifies a template or a pico configuration in HOCON format. Example - Creating a New Pico Configuration Based on a Template $ mzsh topo set topo://container:main1/pico:ec2 template:mz.standard-ec Example - Creating Pico Configuration When you specify a pico configuration that consists of multiple attributes, it is recommended that you use multi-line strings. HOCON Format: $ mzsh topo set --local pico:ec2 ' { template:mz.standard-ec config { properties { ec.httpd.port : 9092 } classpath { jars=["lib/picostart.jar"] } } }' JSON Format: mzsh topo set -l --strict-json pico:ec2 ' { "template": "mz.standard-ec", "config": { "properties": { "ec": { "httpd": { "port": 9092 } } }, "classpath": { "jars": ["lib/picostart.jar"] } } }' Add the pico group setting by using the following topo command mzsh topo set topo://container:main1/pico:ec1/val:config.properties.pico.groups "ec1, ec2" This command makes the Execution context "EC1" a member of the "ec1" and "ec2" groups. This is the HOCON example format adding in ECs to a pico group. config { classpath {} jvmargs { args=[] } properties { mz.webserver.xframeoptions=DENY pico.groups="ec1, ec2" ec.backlog.dir="/opt/mz/tmp" ec.webserver.port=9137 } vendor-jvmargs { hp {} sun {} } } Run the following command to add or update an attribute of a pico configuration. mzsh topo set topo://container:<container>/pico:<pico>/val:<attribute> <attribute value> Example - Updating a Pico Attribute $ mzsh topo set topo://container:main1/pico:ec2/val:ec_type ec Run the following command to add or update an object that contains one or more attributes. $ mzsh topo set topo://container:<container>/pico:<pico>/obj:<object name> '<config>' The <config> argument may contain a pico configuration in HOCON format. Example - Updating a Pico Object This command adds the properties value1 and value2 : $ mzsh topo set topo://container:main1/pico:ec2/obj:config.properties.example_object '{ value1=1 value2=2 }' The following commands does not overwrite the properties value1 and value2 in example_object but adds value3 : $ mzsh topo set topo://container:main1/pico:ec2/obj:config.properties.example_object '{ value3=3 }' setupremote Usage: topo setupremote [-c, --container <container>] [-g, --container-group <container group>] [--host-key <path>] [--javahome <path>] [--no-authorized-key] [--no-host-key] [-- no-ssh-details] [--ssh-address <ip/host>] [--ssh-port <port>] [--ssh-username <username>] Use the command topo setupremote to enable remote access via SSH to an Execution Container, e g from the Platform container. Option Description Option Description [-c, --container <container>] Use this option to specify a different container than the local one, which is the default value. [-g, --container-group <container group>] Use this option to setup remote access to a container in specific container group. This is useful when you have multiple containers with identical names in different containers groups. [--host-key <path>] Use this option to use a pre-generated host key instead of the one that is generated when you run topo setupremote . [--java-home <path>] Use this option when the target container is located on a different host. The default value is specified by the environment variable JAVA_HOME in the current shell. [--no-authorized-key] By default, the topo setupremote command will obtain a public authorization key from the user home directory on the Platform Container host and store it in the STR, i e the file mz.conf . Use the option --no-authorized-key to skip this operation. [--no-host-key] By default, the topo setupremote command will store the public host key of the Execution Container in the STR, i e the file mz.conf . Use the option --no-host-key to skip this operation. [--no-ssh-details] Use this option to exclude ssh-username and ssh-address from STR. These attributes are required for remote access. If you use this option you will need to update the STR manually. [--ssh-address <ip/host>] Use this option when the target container is located on a different host or when you want to bind to a specific IP address or hostname. The default value is specified by the address attribute for container in mz.conf . [--ssh-port <port>] Use this option when you want to use a different port than 22 for SSH. [--ssh-username <username>] Use this option when the target container is located on a different host or when a specific username is required for SSH. The default SSH user is the OS user that runs the topo setupremote command. show Use topo show to retrieve various types of information about pico instances that are defined in the STR. Usage: topo show [-d, --allow-disconnected] [ --exclude-dynamic] [--format <format>] [-l, --local] [--timeout-seconds <time>] <view> Option Description Option Description [-d, --allow-disconnected] Use this option when the Platform is unreachable and you want to operate on cached data. [ --exclude-dynamic] Exclude non-static data in the output e g _status in a pico configuration. This is useful in case of errors that blocks the topo command. [ --format <format>] Set the format of the returned data: csv json table (default) [ -l, --local ] Use this option to view pico instances in the local container only. By default, all containers are included. [--timeout-seconds <time>] Use this option to limit the time for retrieving dynamic information, e g _status .The default value is 10 seconds. The following views are available: jvm-args - Displays the JVM arguments that are used by the pico instances in the system. JVM arguments that are set in templates are included. status - Displays the container name, pico name, pico type and running state. status-sc - Displays similar view as status but only includes SCs. status-ec - Displays similar view as status but only includes ECs. status-long - Displays similar view as status but also includes the status of replication between Platform Container and Execution Containers. pico-view - Displays similar view as status but also includes memory usage and the pico response time. pico-view2 - Displays similar view as pico-view but also includes uptime. ports - Displays the ports that are used by the pico instances in the system. Ports that are set in templates and on cell- and container level, are included. If both webserver and httpd ports are displayed, then webserver ports take precedence. Example - Views $ mzsh topo show jvm-args +------------------------------------------------------------- | container | name | config.jvmargs | +-----------+----------+-------------------------------------+ | main1 | platform | args=[ | | | | "-XX:MaxMetaspaceSize=256M", | | | | "-Xms192M", | | | | "-Xmx1024M" | | | | ] | +-----------+----------+-------------------------------------+ | main1 | ec1 | args=[ | | | | "-server" | | | | ] | | | | maxDirect=[ | | | | "-XX:MaxDirectMemorySize=4096M" | | | | ] | | | | maxMetaspace=[ | | | | "-XX:MaxMetaspaceSize=196M" | | | | ] | | | | xms=[ | | | | "-Xms64M" | | | | ] | | | | xmx=[ | | | | "-Xmx256M" | | | | ] | +-----------+----------+-------------------------------------+ | main1 | psc1 | args=[ | | | | "-server" | | | | ] | | | | maxDirect=[ | | | | "-XX:MaxDirectMemorySize=4096M" | | | | ] | | | | maxMetaspace=[ | | | | "-XX:MaxMetaspaceSize=196M" | | | | ] | | | | xms=[ | | | | "-Xms64M" | | | | ] | | | | xmx=[ | | | | "-Xmx256M" | | | | ] | +-----------+----------+-------------------------------------+ | exec1 | ec2 | args=[ | | | | "-server" | | | | ] | | | | maxDirect=[ | | | | "-XX:MaxDirectMemorySize=4096M" | | | | ] | | | | maxMetaspace=[ | | | | "-XX:MaxMetaspaceSize=196M" | | | | ] | | | | xms=[ | | | | "-Xms64M" | | | | ] | | | | xmx=[ | | | | "-Xmx256M" | | | | ] | +------------------------------------------------------------- $ mzsh topo show status +--------------------------------------------------------------- | container | name | type | state | config-state | +-----------+----------+----------+-------------+--------------+ | main1 | platform | platform | running | in-sync | | main1 | ec1 | ec. | not-started | | | main1 | psc1 | sc | not-started | | | exec1 | ec2 | ec | not-started | | +--------------------------------------------------------------- $ mzsh topo show ports +---------------------------------------------------------------------------- | container | name | type | ports | +-----------+----------+----------+-----------------------------------------+ | main1 | platform | platform | "mz.pcc.restful.port"="9090" | | | | | "mz.servicehost.port.range"="5451-5500" | | | | | "mz.wi.port"="9000" | | | | | "pico.rcp.platform.port"="6790" | | | | | "pico.synchronizer.port"="6791" | +-----------+----------+----------+-----------------------------------------+ | main1 | ec1 | ec | "ec.httpd.port"="9093" | | | | | "pico.rcp.platform.port"="6790" | | | | | "pico.synchronizer.port"="6791" | +-----------+----------+----------+-----------------------------------------+ | main1 | psc1 | sc | "mz.servicehost.port.range"="5801-5850" | | | | | "pico.rcp.platform.port"="6790" | | | | | "pico.synchronizer.port"="6791" | +-----------+----------+----------+-----------------------------------------+ | exec1 | ec2 | ec | "ec.httpd.port"="9090" | | | | | "pico.rcp.platform.port"="6790" | | | | | "pico.synchronizer.port"="6791" | +---------------------------------------------------------------------------- unset Usage: topo unset [-d, --allow-disconnected] [-l, --local] [-n, --no-activation] <target path> Use topo unset to remove pico configurations in the specified target-path of STR. Option Description Option Description [-d, --allow-disconnected] Use this option when the Platform is unreachable and you want to operate on cached data. [-l, --local] Use this option to select the local container, unless another container is specified in the target path. [-n, --no-activation] Use this option to skip activation after changes in master registry. Run the following command to remove a pico configuration. mzsh topo unset topo://container:<container>/pico:<pico> Example - Removing a Pico Configuration $ mzsh topo unset topo://container:main1/pico:ec2 Example - Removing a Pico Attribute $ mzsh topo unset topo://container:main1/pico:ec2/val:ec_type ec File Paths in Attributes When you enter a path that is relative to $MZ_HOME in the value of an attribute, it is recommend that you use ${mz.home} as a substitution. In the following example $MZ_HOME will be resolved to its current value e g /home/user/mz. Example - Resolved Path $ mzsh topo set topo://container:main1/val:common.pico.rcp.tls.keystore $MZ_HOME/keys/platform.keys The next example uses a path that is always relative to $MZ_HOME. Example - Substituted Path $ mzsh topo set topo://container:main1/obj:common.pico.rcp.tls.keystore '{ keystore=${mz.home}"/keys" }' When you are using ${mz.home} as a substitution, ensure to set attributes as part of an object, using the obj keyword. Conflicting Attributes The name of an attribute may contain the full name of another attribute. For instance, mz.httpd.security.keystore is a system property but its name is also a part of mz.httpd.security.keystore.password. In this case you must ensure that the name of both properties are surrounded by quotes, or one of the properties will be overwritten at activation. Example - Handling Conflicting Attributes, Manual Editing common : { "pico.rcp.tls.keystore" : "home/mz/keys", "pico.rcp.tls.keystore.password" : "..." } When there are conflicting properties and you are using the mzsh topo command, also add single quotes, surrounding the target path (topo://..). Example - Handling Conflicting Attributes, Scripted Editing $ mzsh topo set 'topo://container:<platform container>/val:common."pico.rcp.tls.keystore"' "home/mz/keys" $ mzsh topo set 'topo://container:<platform container>/val:common."pico.rcp.tls.keystore.password"' "..." Updating IP, Hostname, and Ports in JDBC URL You can update the IP address, hostname, and ports int he JDBC URL using the mzsh topo get and mzsh topo set commands as shown in the examples below. Example - Get Current Config $ mzsh topo get -s --format data-only topo://container:platform1/pico:platform/obj:config.properties.mz.jdbc { "password": "DR-4-48851644227183C2041D838568E117EC", "oracle": { "ons": "" }, "type": "oracle", "user": "mzadmin", "url": "jdbc:oracle:thin:@//127.0.0.1:1521/orcl" } Example - Update URL with set $ mzsh topo set topo://container:mz/pico:platform/val:config.properties.mz.jdbc.url "jdbc:oracle:thin:@//192.168.1.10:1522/orcl" [ set: topo://container:mz/pico:platform/val:config.properties.mz.jdbc.url => jdbc:oracle:thin:@//192.168.1.10:1522/orcl] Updating file: $MZ_HOME/common/config/cell/default/master/containers/mz/picos/platform.conf Topology activation completed (master->active) Caution! When you have set the new JDBC URL, run shutdown and startup on the platform to ensure that your changes take effect properly. If you added the incorrect config and the platform did not start, you can run your mzsh command again with the --allow-disconnected option Return Codes Listed below are the different return codes for the topo command: Code Description Code Description 0 Will be returned if the command is successful. 1 Will be returned if the argument count is incorrect or argument(s) are invalid. 3 Will be returned if the target path argument for the subcommand get does not exist.

---

# Document 240: Separators - MediationZone Documentation 9.3 - InfoZone

**Source:** ratanon/mz93-documentation
**URL:** https://infozone.atlassian.net/wiki/spaces/MD93/pages/205656666/Separators
**Categories:** chunks_index.json

The following separator characters are valid in the APL language. Separator Description Example Separator Description Example ( ) Used to enclose logical expressions and to overrule standard precedence NumFld = (NumFld2 + 2) * 3; { } Used to enclose blocks if ( ACode == "ABC" ) { // do_this // and_this } . Separates fields in UDR value accesses input.myField = 5;

---

# Document 241: Python Collection Agent - Batch - MediationZone Documentation 9.3 - InfoZone

**Source:** ratanon/mz93-documentation
**URL:** https://infozone.atlassian.net/wiki/spaces/MD93/pages/205686608/Python+Collection+Agent+-+Batch
**Categories:** chunks_index.json

The Python collection agent can collect data from any source supported by Python in batch by defining an execute block. It also uses an Interpreter profile that is used to configure the Python executable. If you have created several Interpreter profiles, you may also set which one you want to be the default one. If this is done, you will not have to select a profile in the agent configuration, as the default profile is used by default. Using the Python collection agent allows you to control the workflow execution from the execute block and to stop routing when requested, from the stop block. Open Example of a workflow including the Python collection agent for batch This section includes the following subsections: Python Collection Agent Configuration - Batch Function Blocks for the Python Collection Agent - Batch Python Collection Agent Transaction Behavior - Batch Python Collection Agent Input/Output Data and MIM - Batch Python Collection Agent Events - Batch

---

# Document 242: Salesforce Streaming API Agent Input/Output Data and MIM - MediationZone Documentation 9.3 - InfoZone

**Source:** ratanon/mz93-documentation
**URL:** https://infozone.atlassian.net/wiki/spaces/MD93/pages/205686841/Salesforce+Streaming+API+Agent+Input+Output+Data+and+MIM
**Categories:** chunks_index.json

Input/Output Data The Input/Output data is the type of data that an agent expects to receive and delivers. The agent expects UDRs of the type SalesForceSubscribeUDR , and it can deliver UDRs of the type SalesForceResponseUDR. See Salesforce Streaming API UDRs for further information. MIM The Salesforce Streaming API agent does not have any agent specific MIM parameters. For information about the MIM and a list of the general MIM parameters, see Administration and Management in Legacy Desktop .

---

# Document 243: Network - MediationZone Documentation 9.3 - InfoZone

**Source:** ratanon/mz93-documentation
**URL:** https://infozone.atlassian.net/wiki/spaces/MD93/pages/205657416/Network
**Categories:** chunks_index.json

In order to protect the system, it is recommended that the machines within the Control Zone and Execution Zone are placed behind firewalls. For further information how this setup is done, see Communications through Firewalls in Network Security . The internal protocol RCP and HTTP are used for communication between pico instances. It is recommended that both RCP and HTTP are encrypted with TLS, with or without authentication. For further information about how to set up encryption, see RCP Encryption and HTTP Encryption in Network Security . Users that have the relevant permissions can login to the Platform or ECs via the Web Interface using HTTP or HTTPS. The credential and permissions for the Platform Web Interface are configured in the Access Controller in the Desktop. The default user mzadmin , can login to Execution Context Web Interface and the password must be set in the Execution Context property ec.httpd.password . This property should be changed to the encrypted form. For more information about how to encrypt the password, see encryptpassword in Always Available in the Command Line Tool Reference Guide . Note! The cookies used by both web interfaces have the HttpOnly and Secure flags set. The HTTP TRACE command is not allowed by the web interfaces in MediationZone. Pico instances such as ECs and SCs can be started remotely from the Platform Container via SSH. Remote access is disabled by default but can be enabled via the mzsh commando topo . For further information about enabling remote access to Execution Containers, see Remote Access to Containers .

---

# Document 244: PCC Buckets - MediationZone Documentation 9.3 - InfoZone

**Source:** ratanon/mz93-documentation
**URL:** https://infozone.atlassian.net/wiki/spaces/MD93/pages/204611758/PCC+Buckets
**Categories:** chunks_index.json

Search this document: PCC Buckets delivers the capability to create and manage buckets based on subscriber information. With the PCC Buckets package, buckets can be created and used for usage counting. Depending on the subscribers' actions, consumed or exhausted buckets can either be deleted or reset. With PCC Buckets you can create and manage buckets based on subscriber information. PCC Buckets enable you to configure your Policy Control and Charging solution, either on the Desktop, by applying APL functions or using the REST HTTP Interface. Prerequisites The reader of this document should be familiar with: The HTTP protocol Terms and Acronyms This section contains glossaries for all terms and acronyms used throughout the PCC and MediationZone documentation. PCC Terms and Acronyms Term/Acronym Definition Term/Acronym Definition PCC Policy and Charging Control PCRF Policy and Charging Rules Function 3GPP 3rd Generation Partnership Project General Terms and Acronyms For information about general Terms and Abbreviations used in this document, see the Terminology document. Chapters The following chapters and sections are included: Data Model for PCC Buckets Provisioning of PCC Buckets Runtime APL Support for PCC Buckets

---

# Document 245: Inter Workflow Batch Collection Agent Input/Output Data and MIM - MediationZone Documentation 9.3 - InfoZone

**Source:** ratanon/mz93-documentation
**URL:** https://infozone.atlassian.net/wiki/spaces/MD93/pages/204673605/Inter+Workflow+Batch+Collection+Agent+Input+Output+Data+and+MIM
**Categories:** chunks_index.json

Input/Output Data The agent produces bytearray types. MIM For information about the MIM and a list of the general MIM parameters, see Meta Information Model in Administration and Management in Legacy Desktop . Publishes MIM Parameter Description Number of Source Batches This MIM parameter contains the number of incoming batches to merge in the current outgoing batch. If no merge is selected this MIM is static and set to 1 (one). Number of Source Batches is of the int type and is defined as a header MIM context type. Outgoing Batch Size This MIM parameter contains the size of the batch produced by the agent. Outgoing Batch Size is of the long type and is defined as a header MIM context type. Source Files Left This MIM parameter contains the number of source files still to be collected. This is the number presented in the Execution Manager backlog. Source Files Left is of the long type and is defined as a header MIM context type. <any> Any named MIM in the Inter Workflow Profile Editor . All imported MIMs are automatically converted to the type string, regardless of the original type. APL provides functions to convert strings to other data types. For further information about conversion functions, see the APL Reference Guide . Note! MIMs of list and map type cannot be imported. For information about how to add and map named MIMs, see the section Profile Configuration in Inter Workflow Profile . Accesses The agent does not itself access any MIM resources.

---

# Document 246: Querying A Table In Reference Data Management - MediationZone Documentation 9.3 - InfoZone

**Source:** ratanon/mz93-documentation
**URL:** https://infozone.atlassian.net/wiki/spaces/MD93/pages/204743433/Querying+A+Table+In+Reference+Data+Management
**Categories:** chunks_index.json

To query a table, you can do the following: click the Get Started button from the initial dashboard page click the Query button on the result view. A Query dialog will open where you will configure the criteria for your query. Note! If a query was done previously, last applied query settings will be reloaded. If it is unable to fully reload, a notification will prompt users to verify and update the values accordingly. Opening the Query dialog will discard any uncommitted changes and refresh the Reference Data Profiles if there are any changes to the profiles. Open Full Query dialog with Query Options and Query Expressions Setting Description Setting Description Saved filters Allows you to manage saved filters within the Query dialog. Update - Allows you to modify existing saved filter by updating the options. To update, select the desired filter, edit the options and click Update from the Acrion Select the desired filter, edit the options, click Action > Update to update the saved filter. Delete - Allows you to delete saved filter. Select desired filter, click Action > Delete to delete the saved filter. Save New - You are only able to save new filter once you have selected a profile and a table. Upon saving, the filter will be added to the list of saved filters for future use. Action Contains the following actions to manage the saved filters: Update - Allows you to modify existing saved filter by updating the options. To update, select the desired filter, edit the options and click Update from the Action dropdown. Delete - Allows you to delete saved filter. To delete, select the desired filter, click Delete from the Action dropdown. Save New - You are only able to save new filter once you have selected a profile and a table. Upon saving, the filter will be added to the list of saved filters for future use. Reference Data Profile Allows you to select a Reference Data Profile that contains the table you want to query from. For more on Reference Data profiles, you can refer to Reference Data Profile . Search Type There are two types of search that you can select as follows: Standard - Query the results from a table based on the Reference Data Management profiles in the system. This query supports the following operations on query result: Insert Row Edit Delete Export Import Join Table - Query the results from join tables based on the Reference Data Management profiles in the system, supports following operations on query result: Export Table This option appears once you have selected a profile and Standard Search Type . This is a dropdown list of tables configured in the selected Reference Data profile. You select from one table in the list to perform your query on. Main Table This option appears once you have selected a profile and Join Table Search Type . This is a dropdown list of tables configured in the selected Reference Data profile. You select from one table in the list to perform your query on. The alias of the selected main table will always be t1 which will be used for Join Constraints. Join Conditions This option appears once you have selected a profile and Join Table Search Type . Add join conditions to combine two or more tables by selecting Table Name, Join Type and configure Join Constraints. The alias of the selected table will be stated next to the Table Name label, for e.g: The screenshot below indicates that t2 will be the alias of the table. The following join types are supported: JOIN INNER JOIN LEFT JOIN RIGHT JOIN CROSS JOIN Open Reference Data Management - Join Condition Dialog Join Constraint is used to specify the conditions for joining tables, for e.g: t1.column_id=t2.column_id. Show Columns This option appears once you have selected a profile and a table. This displays all the column names available in the selected table. You can remove and add the columns at your choosing to be displayed in the query result. Clicking on the All button will select all the columns in the table. All columns are selected by default. Data Set Size This option appears once you have selected a profile and a table. The value in this field controls the maximum row count per data set. The queried data is fetched from the Platform in data sets of configurable size. A large size typically results in a faster query but it may take longer to display the first data set. Note! Data set is the scope in which query results are displayed and modifications are applied. When switching data set, any uncommitted changes will be discarded. Users switch between data sets with buttons on the footer bar in the query result view. Query Expressions This option appears once you have selected a profile and a table. Query Expressions allow you to filter the query results according to the criteria you configure in this option. Click on New Expression to add one to the query. Sort Expression This option appears once you have selected a profile and a table, defaulted to first column in ascending direction. Sort Expressions allow you to sort the query results according to the criteria you configure in this option. Click on New Sort Expression to add additional expression. Query Expressions Open Query Expressions configuration in the Query dialog Setting Description Setting Description Column This is a column in the selected database table. Note! Only columns with supported data types are available for selection. Operator This is a comparison operator that is applied to the values in the specified column and the value. The available operators are: equals not equals like not like greater than greater than or equals lesser than lesser than or equals between Value This field contains a value that is used in the expression. When between is the selected operator, two value fields are displayed. You can use SQL wildcards such % and _ with the operators like and not like. An underscore (_) in the pattern matches exactly one character (as opposed to one byte in a multibyte character set) in the value. A percent sign (%) in the pattern can match zero or more characters (as opposed to bytes in a multibyte character set) in the value. The pattern '%' cannot match a null. Sort Expressions Open Sort Expressions configuration in the Query dialog Setting Description Setting Description Column This is a column in the selected database table which data needs to be sorted. Note! Only columns with supported data types are available for selection. Direction You can select to view the query results in the following manner: Ascending - Query result is sorted from lowest to highest value Descending - Query result is sorted from highest to lowest value Querying a Result To query a result: On the Query dialog, choose a Reference Data Profile by clicking on the Browse button. Look for and select the profile that has the tables you want to search from using the Select Reference Data Profile dialog. Open Reference Data Profile selection dialog Select a Search Type and a table from the Table dropdown list. The tables configured in the Reference Data Profile will appear here. Open Selecting a table from the Query dialog. Select the columns to include or view in the query results and configure the maximum data set value should you require it to be set to a different number. Open Selecting columns You can also add query expressions to refine the result of the query by filtering out certain data. If you did not configure any expressions, the entire table will be retrieved and up to the number set in Data Set Size will be displayed at a time in the query result view. Add sort expressions to specify sort criteria for retrieving data in ascending or descending order. Open Selecting Sort Expression column Click on Apply and the result will be shown in a view. The status bar at the top and the footer bar displays information about the current query configuration. Click on the status bar to reveal the list of configured query expressions if any. From this view, you can then query again, filter with the Search Bar , switch to another data set, insert a new row, edit the fields in the view, delete rows, refresh the view, export the data set, export the entire table or import from data from a CSV file. Note! Drag and drop columns to change the order of the columns. The result of Export action will match the order of the columns. Column sorting is allowed one column at a time. String and number sorting is supported and uncommitted inserted rows are excluded. Open An example of the query result view JSON Viewer The JSON Viewer is available to assist you by displaying JSON data in a more readable form. This is only available for columns that contain valid JSON format. Follow the steps below to view the JSON data. In the Query Result View , click the View Value button. Open Query Result View - View Value If the column contains a valid JSON format, the Viewing Value dialog contains the following tabs: Grid - Displays the JSON data in a grid form. Open Viewing Value Dialog - Grid tab (for valid JSON data) Text - Displays the JSON data in a text form. Open Viewing Value Dialog - Text tab (for valid JSON data) For columns that do not contain valid JSON format, the Viewing Value dialog will display the Text tab only. Open Viewing Value - Text tab (for invalid JSON data)

---

# Document 247: Archive Inspector - MediationZone Documentation 9.3 - InfoZone

**Source:** ratanon/mz93-documentation
**URL:** https://infozone.atlassian.net/wiki/spaces/MD93/pages/204640167/Archive+Inspector
**Categories:** chunks_index.json

The Archive Inspector is used to locate files in an archive. The respective access group user can launch and purge files found in the archive. As soon as the target file is located, it is treated as a regular UNIX and standard commands can be used to interact with it. Note! It is not encouraged to alter or remove a file from the archive using UNIX commands. If altering is desired, make a copy of the file. If removal is desired, use the Archive Inspector. To open the Archive Inspector, click the Manage button from the top bar and select Archive Inspector from the list. Open The Archive Inspector Main Window Info Sensitive information is blurred on the screen. You will see the actual path of the file when using the Archive Inspector. Searching the Archive Initially, the dialog is empty and must be populated with data using the corresponding Search Archive dialog. When you click on the Search button, the Search Archive dialog appears where you can select the number of rows you want to view in the Archive Inspector . Each row represents information about a data batch (file). Open The Search Archive dialog Settings Description Settings Description Archive Profile Select the Archive profile that corresponds to the data of interest. If no profile is selected archive entries for all profiles will be shown. Workflow Option to narrow the search with respect to the workflow that archived the file. Agent Option to narrow the search with respect to the agent that archived the file. Period Option to search for data archived during a certain period. You can either select the User Defined option in the drop-down list and then enter date and time in the From and To fields, or you can select one of the predefined time intervals in the drop-down list; Last Hour, Today, Yesterday, This Week, Previous Week, Last 7 Days, This Month or Previous Month. Accessing the Inspector The Archive Inspector table shows the file(s) based on the search criteria specified in the Archive Inspector#Search Archive dialog. Open Archive Inspector Table - Selection Each file (row) in the table has a set of properties associated with it. Property Description Property Description ID Refers to the ID of the archived entry. Workflow Full name of the archiving workflow. The format is <folder>.<configuration>.<workflow name> Agent Name of the archiving agent. File path The full path of the file stored on disk. Timestamp The time when the entry was inserted in the archive. MIM Values Adherent MIM resources are defined as Logged MIM Data in the Archiving agent configuration dialog. Profile Name of the profile used to archive the file. Note! If the profile is not available, < Profile not found > message is displayed. An example screen: Open Table Toolbar The table toolbar for the Archive Inspector presents with more options to manipulate data within the table. Table Toolbar - Default View The following are the buttons found on the toolbar: Default options Option Description Search Displays the Search Archive dialog where search criteria may be defined to identify the files to be displayed, see Archive Inspector#Search Archive for more information. Refresh Refreshes the table. Delete All Deletes all shown items. With one file selected Clear Selection(s) Clears the currently selected item(s). View Raw Data Opens the Raw Data Viewer screen. An example of a Raw Data Viewer dialog : Open View MIM Values Shows the associated MIM values. For further information, see the figure below: MIM Values Dialog Note! The dialog also appears when you double-click on a row of the table. Delete Deletes the currently selected file. With multiple file(s) selected Clear Selection(s) Clears the current selection. Delete Delete selected files. Delete If Keep Files is disabled in the Archive profile, all selected files are removed from the archive, including their corresponding references in the database. If Keep Files is enabled or if the Archive profile that archived the entry is not available, only the references are removed while the files shown in Archive Inspector are still kept on disk. Refer to the documentation on the Keep Files option to know more.

---

# Document 248: Web Service Example - Defining the Web Service Profile - MediationZone Documentation 9.3 - InfoZone

**Source:** ratanon/mz93-documentation
**URL:** https://infozone.atlassian.net/wiki/spaces/MD93/pages/205002688/Web+Service+Example+-+Defining+the+Web+Service+Profile
**Categories:** chunks_index.json

Use the following instructions to create a WS profile: Click the New Configuration button in the upper left part of the Desktop window, and then select WS Profile from the menu. The WS profile configuration dialog opens. In the Configuration tab, click on the Import WSDL button, and select the WSDL file you want to import. You can now see the file contents on the View WSDL Contents tab. At the bottom of the Configuration tab, select the SOAP: Charger (Charger_SOAPBinding) in the Service Port Definition drop-down list. In the WS profile , click on the File menu and select the Save As... option. In the Save as dialog box select a folder and type Example in the Name text box. Click OK . Check the WS directory in the APL Code Editor and see the data structure that your WS profile just generated. The APL Code Editor is opened by clicking on the New Configuration button in Desktop, and then selecting WS Profile from the menu. Right-click on the text pad and select the UDR Assistance ... option. The UDR Internal Format Browser opens. Scroll down to the WS directory and expand it to see where data is stored once you save your WS profile. The WSDL File <?xml version="1.0" encoding="UTF-8"?> <wsdl:definitions xmlns:wsdl="http://schemas.xmlsoap.org/wsdl/" xmlns="http://schemas.xmlsoap.org/wsdl/" xmlns:soap="http://schemas.xmlsoap.org/wsdl/soap/" xmlns:tns="http://example.com/webservice/charger" xmlns:x1="http://example.com/webservice/charger/types" xmlns:xsd="http://www.w3.org/2001/XMLSchema" name="Charger" targetNamespace="http://example.com/webservice/charger"> <wsdl:types> <schema xmlns="http://www.w3.org/2001/XMLSchema" xmlns:tns="http://example.com/webservice/charger/types" elementFormDefault="qualified" targetNamespace="http://example.com/webservice/charger/types"> <complexType name="ChargingEvent"> <sequence> <element name="id" type="string"/> <element name="amount" type="float"/> </sequence> </complexType> <element name="Charge"> <complexType> <sequence> <element name="serviceType" type="string"/> <element name="chargingEvent" type="tns:ChargingEvent"/> </sequence> </complexType> </element> <element name="ChargeResult"> <complexType> <sequence> <element name="success" type="boolean"/> <element name="message" type="string"/> </sequence> </complexType> </element> <element name="FaultDetail"> <complexType> <sequence> <element name="reason" type="int"/> <element name="message" type="string"/> </sequence> </complexType> </element> </schema> </wsdl:types> <wsdl:message name="ChargingRequest"> <wsdl:part name="in" element="x1:Charge" /> </wsdl:message> <wsdl:message name="ChargingRespone"> <wsdl:part name="in" element="x1:ChargeResult" /> </wsdl:message> <wsdl:message name="chargeFault"> <wsdl:part name="faultDetail" element="x1:FaultDetail"/> </wsdl:message> <wsdl:portType name="Charger"> <wsdl:operation name="charge"> <wsdl:input name="chargingRequest" message="tns:ChargingRequest"/> <wsdl:output name="chargingResponse" message="tns:ChargingRespone"/> <wsdl:fault name="chargingFault" message="tns:chargeFault"/> </wsdl:operation> </wsdl:portType> <wsdl:binding name="Charger_SOAPBinding" type="tns:Charger"> <soap:binding style="document" transport="http://schemas.xmlsoap.org/soap/http"/> <wsdl:operation name="charge"> <soap:operation soapAction="" style="document"/> <wsdl:input name="chargingRequest"> <soap:body use="literal"/> </wsdl:input> <wsdl:output name="chargingResponse"> <soap:body use="literal"/> </wsdl:output> <wsdl:fault name="chargingFault"> <soap:fault name="chargingFault" use="literal"/> </wsdl:fault> </wsdl:operation> </wsdl:binding> <wsdl:service name="Charger_Service"> <wsdl:port binding="tns:Charger_SOAPBinding" name="Charger"> <soap:address location="http://localhost:8080/charge"/> </wsdl:port> </wsdl:service> </wsdl:definitions>

---

# Document 249: SAP CTS+ Integration User's Guide - MediationZone Documentation 9.3 - InfoZone

**Source:** ratanon/mz93-documentation
**URL:** https://infozone.atlassian.net/wiki/spaces/MD93/pages/261914788/SAP+CTS+Integration+User+s+Guide
**Categories:** chunks_index.json

The SAP CTS+ (Change and Transport System Plus) integration in MediationZone enables streamlined management of MediationZone configurations across different environments. SAP CTS+ uses SAP TMS (Transport Management System) as the engine to move changes. This integration allows for greater control, flexibility, and efficiency when moving changes between development, test, and production systems. You can find more information on SAP CTS+ in the SAP Help Portal - SAP Online Help . Note! Configuration exports in MediationZone are referred to as Changes in the SAP CTS+ Integration Users Guide. Key Features of the SAP CTS+ Integration in MediationZone Simplified Configuration Management : Manage regular system exports and workflow packages seamlessly through the SAP CTS+ interface. Please note that Development Toolkit bundles are excluded from this integration. Flexible Import Options : You can easily import configurations to any system in your landscape using CTS+. The source systems for imports can be customizedeither allowing all systems or limited to specific ones, as defined by the cts.source.systems property. For more information, see https://infozone.atlassian.net/wiki/x/8BVCD . Decoupled Export Process : With loose coupling between export and transport, exports are triggered separately from the CTS+ transport process. Use the System Export tool in Desktop, or the mzsh command line tool, to create export files, which you then upload to CTS+ for transport and deployment. Open The SAP CTS+ integration in MediationZone Subsections This section contains the following subsections: SAP CTS+ Export SAP CTS+ Import

---

# Document 250: Diameter Stack Agent Input/Output Data and MIM - MediationZone Documentation 9.3 - InfoZone

**Source:** ratanon/mz93-documentation
**URL:** https://infozone.atlassian.net/wiki/spaces/MD93/pages/204999675
**Categories:** chunks_index.json

Input/Output Data The input/output data is the type of data an agent expects and delivers. The agent emits and receives UDRs of the type RequestCycleUDR . When you have configured an error route, the agent also emits UDRs of the type DiameterErrorUDR . MIM For information about the MIM and a list of the general MIM parameters, see Administration and Management in Legacy Desktop . Publishes MIM Value Description Bytes Received This MIM parameter contains the number of received bytes from each peer in the selected Diameter Routing profile. Bytes Received is of the map<string>, long> type and is defined as a global MIM context type. The string values in the map contain the host-names of the peers. Bytes Transmitted This MIM parameter contains the number of transmitted bytes to each peer in the selected Diameter Routing profile. Bytes Transmitted is of the map<string, long> type and is defined as a global MIM context type. The string values in the map contain the host-names of the peers. CEA Count This MIM parameter contains the number of sent and received CEA (Capabilities-Exchange-Answer) commands for each peer in the selected Diameter Routing profile. CEA Count is of the map<string, long> type and is defined as a global MIM context type. The string values in the map contain the hostnames of the peers. CER Count This MIM parameter contains the number of sent and received CER (Capabilities-Exchange-Request) commands for each peer in the selected Diameter Routing profile. CER Count is of the map<string, long> type and is defined as a global MIM context type. The string values in the map contain the hostnames of the peers. Communication Failure Network Layer This MIM parameter contains the number of connection problems detected on network level. Communication Failure Network Layer is of the long type and is defined as a global MIM context type. Communication Failure Protocol Layer This MIM parameter contains the number of connection problems detected on protocol level. Communication Failure Protocol Layer is of the long type and is defined as a global MIM context type. Diameter Too Busy Count This MIM parameter contains the number of sent Diameter Too Busy responses. The MIM value is reset each time the MIM is read. Diameter Too Busy Count is of the long type and is defined as a global MIM context type. Diameter Too Busy Total Count This MIM parameter contains the number of Diameter Too Busy responses sent, since Workflow start. Diameter Too Busy Total Count is of the long type and is defined as a global MIM context type. DPA Count This MIM parameter contains the number of sent and received DPA (Disconnect-Peer-Answer) commands for each peer in the selected Diameter Routing profile. DPA Count is of the map<string, long> type and is defined as a global MIM context type. The string values in the map contain the hostnames of the peers. DPR Count This MIM parameter contains the number of sent and received DPR (Disconnect-Peer-Request) commands for each peer in the selected Diameter Routing profile. DPR Count is of the map<string, long> type and is defined as a global MIM context type. The string values in the map contain the hostnames of the peers. DWA Count This MIM parameter contains the number of sent and received DWA (Device-Watchdog-Answer) commands for each peer in the selected Diameter Routing profile. DWA Count is of the map<string, long> type and is defined as a global MIM context type. The string values in the map contain the hostnames of the peers. DWR Count This MIM parameter contains the number of sent and received DWR (Device-Watchdog-Request) commands for each peer in the selected Diameter Routing profile. DWR Count is of the map<string, long> type and is defined as a global MIM context type. The string values in the map contain the hostnames of the peers. Incoming Messages This MIM parameter contains the number of received messages. Incoming Messages is of the long type and is defined as a global MIM context type. Origin State Id This MIM parameter contains a value that is incremented in the initialize workflow execution state. It is used for populating the AVP Origin-State-Id. Origin State Id is of the int type and is defined as a global MIM context type. To amend this counter, see Diameter Functions in the APL Reference Guide . Outgoing Messages This MIM parameter contains the number of sent messages. Outgoing Messages is of the long type and is defined as a global MIM context type. Peer Status This MIM parameter contains the status of a Peer. The first string is the hostname and the second string is the status for that peer. Status can be any of the following: OKAY, SUSPECT, DOWN, REOPEN, or INITIAL. These are the watchdog states as de fi ned in RFC3539. The value of Peer Status is always INITIAL in the initialize work fl ow execution state. Peer Status is of the >map<string,string> type and is defined as a global MIM context type. Peer Round Trip Latency Avg This MIM parameter contains the average round trip latency to peer, calculated (in milliseconds) over the last 1000 received records. Workflow Round Trip Latency Avg is of the long type and is defined as a global MIM context type. Peer Round Trip Latency Max This MIM parameter contains the maximum round trip latency to peer since Workflow start. Workflow Round Trip Latency Max is of the long type and is defined as a global MIM context type. Peer Round Trip Latency Min This MIM parameter contains the minimum round trip latency to peer since Workflow start. Workflow Round Trip Latency Min is of the long type and is defined as a global MIM context type. Peer Status This MIM parameter contains the state of a peer connection. The first string is the hostname and the second string is the state. The state can be any of the following: OKAY, SUSPECT, DOWN, REOPEN, or INITIAL. These are described in RFC 3539. The value of Peer Status is always INITIAL in the initialize workflow execution state. Peer Status is of the map<string,string> type and is defined as a global MIM context type. Realm Routing Table This MIM parameter contains the realm routing table of the Diameter Stack agent. Realm Routing Table is of the map<string,map<string, list<string>>> type and is defined as a global MIM context type. The string values in the outer map contain the realm names (primary key). The string values of the inner map contain the applications (secondary key). The lists in the map contain the hostnames of the peers in the realm. Note! This MIM value only contains realms that have static peers, i e not dynamically discovered via DNS lookups. For an example of how to use this MIM value, see the section, To Read the Realm Routing Table in APL, in Diameter Routing Profile . Records in decoder queue This MIM parameter contains the current number of records in the queue for decoding. Records in decoder queue is of the long type and is defined as a global MIM context type. Rejected Messages This MIM parameter contains the number of rejected messages. Rejected Messages is of the long type and is defined as a global MIM context type. Workflow Round Trip Latency Avg This MIM parameter contains the average workflow processing latency, calculated (in milliseconds) over the last 1000 processed records. Workflow Round Trip Latency Avg is of the long type and is defined as a global MIM context type. Workflow Round Trip Latency Max This MIM parameter contains the minimum workflow processing latency, since Workflow start. Workflow Round Trip Latency Max is of the long type and is defined as a global MIM context type. Workflow Round Trip Latency Min This MIM parameter contains the maximum workflow processing latency, since Workflow start. Workflow Round Trip Latency Min is of the long type and is defined as a global MIM context type. Accesses The agent does not access any MIM parameters.

---

# Document 251: IPDR SP UDRs - MediationZone Documentation 9.3 - InfoZone

**Source:** ratanon/mz93-documentation
**URL:** https://infozone.atlassian.net/wiki/spaces/MD93/pages/205000779/IPDR+SP+UDRs
**Categories:** chunks_index.json



---
**End of Part 11** - Continue to next part for more content.
