# RATANON/MZ93-DOCUMENTATION - Part 58/112

---
**Dataset:** ratanon/mz93-documentation
**Part:** 58 of 112
**GitHub:** https://github.com/ratan0n/docs/tree/main/mz93-documentation
**Size:** ~69.9 KB
---

Were excited to announce the release and general availability of MediationZone 9.3! This release brings several updates designed to optimize productivity, enhance scalability and performance, and strengthen security and compliance, including features focused on refining usability. In MediationZone 9.3, we have further advanced the platform's ability to handle real-time and batch data processing, deepened integration with major cloud platforms, and strengthened security features to protect sensitive data. These updates allow you to scale operations more effectively, streamline processes, and maintain secure, compliant environments. Some of the key features are: Kafka Enhancements This feature encompasses a complete refactoring of the Kafka agents, introducing a new set of collector agents and a real-time forwarder agent with support for subscribing to multiple topics per agent, with wildcard functionality. Improved support for batch processes also enhances efficiency when handling large volumes of data. The new agents enable scale-out capabilities with automatic rebalancing, ensuring that multiple workflows can efficiently manage and process data in parallel. The new agents bring significant usability and efficiency improvements in configuration, management, and operation, and enable you to seamlessly integrate Kafka with MediationZone for optimized data processing and management, see Kafka Agents . Integration with Amazon SQS In this release we are introducing dedicated publisher and subscriber agents for integration with Amazon Simple Queue Service (Amazon SQS), enhancing compatibility with AWS cloud services for customers operating in hybrid environments. These agents facilitate bidirectional communication between MediationZone and Amazon SQS, ensuring smooth messaging and data exchange within the AWS ecosystem. The new agents provide control and flexibility in managing SQS message queues, enabling efficient data processing and seamless integration with AWS services. With these agents, you can optimize your workflows, improve operational efficiency, and ensure reliable data transfer in AWS cloud environments. See SQS Agents for more information. Support Google Cloud Secret Manager for Secrets and Security profiles Securing sensitive information, such as passwords, certificates, and keys, is a fundamental requirement in todays digital landscape. The integration with Google Cloud Secret Manager in this release provides centralized secret management, allowing users to securely store and retrieve secrets while associating them with specific environments. This granular level of control ensures that only authorized individuals and systems can access the necessary credentials, offering a robust enhancement to overall security measures. See Google Secret Manager Profile for more information. Amazon S3 Agents for real-time workflows This feature enables real-time collection, transformation, and enrichment of data using Amazon S3, supporting critical use cases such as real-time data processing, disaster recovery, and data backup. It also facilitates scalable data storage and seamless integration with analytics and machine learning platforms. Previously, the Amazon S3 agents were only available for batch workflows. The inclusion of Amazon S3 agents for both batch and real-time workflows mirrors the capabilities of existing SFTP/SCP/FTP/Disk agents, ensuring comprehensive and flexible data management across different environments. This unified approach not only optimizes costs but also provides you with the ability to handle large volumes of data, enabling quick access to actionable insights and supporting robust data operations See Amazon S3 Agents for more information. Logging Enhancements The Logging Enhancements in MediationZone 9.3 introduce a new 'Log Filter' function, enabling you to adjust logging settings in real-time for an individual or group of picos. With this feature you can swiftly modify logging levels and apply filters to specific packages as needed. When special logging configurations are no longer needed, logging can easily be reset to their default settings. The update also enhances overall logging quality and usability by ensuring accurate and consistent logging across all agents and components. A thorough review and cleanup of existing logs have been completed to maintain system-wide consistency. See Log Filter for more information. We encourage you to explore all the detailed features and enhancements below to gain a comprehensive understanding of the capabilities in MediationZone 9.3: New Features Usability Desktop Search Log Filter Support for wfexport and wfimport mzsh Commands MZSH Command For Shutting Down Desktop and Legacy Desktop New Connectors New Kafka Agents Amazon S3 Agents in Real-Time Workflows Amazon SQS Agents APN Processing Agent SAP CC REST Agent MariaDB Support Supported Agents for MariaDB Additional APL Functions and Event Notifications Support MariaDB Integration and Security User Security Improvements SAP CTS+ Integration Reference Data Management Supports SAP HANA Authentication and Monitoring Google Secret Manager System Statistics Enhancements followRedirects Field for RequestCycle UDR in HTTP/2 Agents HTTP/2 Client Agent Support Additional OAuth Settings All of these are explained in more detail in MediationZone 9.3 Release . Information about where the release can be accessed is available here: Release Information . Overall user documentation is available at: MediationZone Documentation 9.3 . Enjoy!

---

# Document 1368: Prometheus UDR Type - MediationZone Documentation 9.3 - InfoZone

**Source:** ratanon/mz93-documentation
**URL:** https://infozone.atlassian.net/wiki/spaces/MD93/pages/204608609/Prometheus+UDR+Type
**Categories:** chunks_index.json

Prometheus UDR You use PrometheusUDR s to create metrics. The PrometheusUDR has to be populated with a value and optional Prometheus labels. You can decide if you want to create a PrometheusUDR per each value, or aggregate them using the Aggregation agent and send a cumulative value after desired conditions are met. Labels should follow the Prometheus recommendation, for details see the official Prometheus documentation. The PrometheusUDR type can be viewed in the UDR Internal Format Browser . The PrometheusUDR contains data that can be sent to the endpoints running on each Execution Context. The following fields are included in the PrometheusUDR : Field/Option Description Name (string) This field is populated with the metric name, for example mim_realtime_processing_analysis_outbound_udrs . MetricType (string) This field is populated with one of the metric types supported by Prometheus. Supported types are: COUNTER GAUGE UNTYPED (default) Value (double) This field is populated with a numeric value and is what, in most cases, is displayed in your Grafana graph. For example, the field can be populated by 6.5 . Labels (map<string.string>) This field is populated with the labels applied to the metric, for example origin_country . Description (string) This field is populated with a description of a metric.

---

# Document 1369: Fail-Safe Operation - MediationZone Documentation 9.3 - InfoZone

**Source:** ratanon/mz93-documentation
**URL:** https://infozone.atlassian.net/wiki/spaces/MD93/pages/204613463/Fail-Safe+Operation
**Categories:** chunks_index.json

MediationZone is a workflow based mediation system that guarantees that all data will be secured in case of a system/network failure. During workflow execution, transaction data is exchanged between workflows and platform control servers in order to maintain transactional integrity (restart at failure point without data loss or duplication). MediationZone includes functionality for record/batch duplicate checking in order to avoid duplicated data due to network elements or human intervention. The duplicate control uses persistent storage so it will not lose track after a system failure. Configuration of checking an interval is easily configured from the user interface. Collected usage data can be secured in four different (optional) ways during Workflow execution: Stored on disk, locally or on networked disk. Stored in a relational database, locally or accessible over the network. Archived centrally in secure storage managed by platform control services. Vendor specific backup solutions should be applied for disks and databases. System Redundancy MediationZone includes the ability to have redundant workflow processing servers. If a specific server fails, workflows deployed on that server may automatically be re-directed to an available server. Full transactional integrity enables workflows to resume execution on the new server at the last recorded transaction point. System level High Availability is managed by third party high availability solutions.

---

# Document 1370: mzcli - wfenable - MediationZone Documentation 9.3 - InfoZone

**Source:** ratanon/mz93-documentation
**URL:** https://infozone.atlassian.net/wiki/spaces/MD93/pages/547979965/mzcli+-+wfenable
**Categories:** chunks_index.json

Usage usage: wfenable <pattern matching expression for workflow names> ... This command enables one or more workflows. Return Codes Listed below are the different return codes for the wfenable command: Code Description 0 Will be returned if the command was successful. 1 Will be returned if the argument count is incorrect. 2 Will be returned if the user is not found or not logged in. 3 Will be returned if no matching workflow was found.

---

# Document 1371: Diameter Dynamic Event - MediationZone Documentation 9.3 - InfoZone

**Source:** ratanon/mz93-documentation
**URL:** https://infozone.atlassian.net/wiki/spaces/MD93/pages/204997863/Diameter+Dynamic+Event
**Categories:** chunks_index.json

The Diameter Dynamic event is triggered by DNS lookups for Diameter peers. If dynamic peer discovery is enabled, these DNS lookups are performed when: A Diameter workflow is started. The routing table of a Diameter Stack agent is dynamically updated. The TTL (time to live) of a cached DNS record expires. For information about how to enable dynamic peer discovery, see the section Realm Routing Table in Diameter Routing Profile . Filtering In the Event Setup tab, the values for all the event fields are set by default to All in the Match Value(s) column, which will generate event notifications every time a Diameter dynamic event is generated. Double-click on the field to open the Match Values dialog where you can click on the Add button to add which values you want to filter on. If there are specific values available, these will appear in a drop-down list. Alternatively, you can enter a hard coded string or a regular expression. The following fields are available for filtering Diameter dynamic events in the Event Setup tab: Diameter dynamic event specific fields DynamicPeers - This field contains a comma separated list of dynamically discovered peers in a realm and their settings. The field is formatted as follows: [<host>,<port>,<protocol>],... realmName - This field contains the name of the realm for which the event is generated. Fields inherited from the Base event The following fields are inherited from the base event, and can also be used for filtering, and described in more detail in Base Event : category - If you have configured any Event Categories, you can select to only generate notifications for Diameter dynamic events with the selected categories. See Event Category for further information about Event Categories. contents - This field contains a string with event specific information. If you want to use this field for filtering you can enter a part of the contents as a hard coded string. eventName - This field can be used to specify which event types you want to generate notifications for. This may be useful if the selected event type is a parent to other event types. However, since the Diameter dynamic event is not a parent to any other event, this field will typically not be used for this event. origin - If you only want to generate notifications for events that are issued from certain Execution Contexts, you can specify the IP addresses of these Execution Contexts in this field. receiveTimeStamp - This field contains the date and time for when the event was inserted into the Platform database. If you want to use timeStamp for filtering, it may be a good idea to enter a regular expression, for example, "2014-06.*" for catching all Diameter dynamic events from 1st of June, 2014, to 30th of June, 2014. severity - With this field you can determine to only generate notifications for events with a certain severity; Information, Warning, Error or Disaster. timeStamp - This field contains the date and time for when the Execution Context generated the event. If you want to use timeStamp for filtering, it may be a good idea to enter a regular expression, for example, "2014-06-15 09:.*" for catching all Diameter dynamic events from 9:00 to 9:59 on the 15th of June, 2014. Note! The values of these fields may also be included in the notifications according to your configurations in the Notifier Setup tab.

---

# Document 1372: FTPS Forwarding Agent - MediationZone Documentation 9.3 - InfoZone

**Source:** ratanon/mz93-documentation
**URL:** https://infozone.atlassian.net/wiki/spaces/MD93/pages/204673250/FTPS+Forwarding+Agent
**Categories:** chunks_index.json

The FTPS forwarding agent sends files to a remote host by using the standard FTP (RFC 959) protocol. Files are created when a Begin Batch message is received and closed when an End Batch message is received. In addition, the agent offers the possibility to compress (gzip) the files. To ensure that downstream systems do not use the files until they are closed, they are maintained in a temporary directory on the remote host until the End Batch message is received. This behavior is also used for Cancel Batch messages. If a Cancel Batch is received, file creation is canceled. The FTPS forwarding agent supports IPv4 and IPv6 environments. The section contains the following subsections: FTPS Forwarding Agent Configuration FTPS Forwarding Agent Memory Management FTPS Forwarding Agent Events FTPS Forwarding Agent MultiForwardingUDR Input FTPS Forwarding Agent Transaction Behavior FTPS Forwarding Agent Input/Output Data and MIM

---

# Document 1373: GCP BigQuery Agent Configuration - MediationZone Documentation 9.3 - InfoZone

**Source:** ratanon/mz93-documentation
**URL:** https://infozone.atlassian.net/wiki/spaces/MD93/pages/204641484/GCP+BigQuery+Agent+Configuration
**Categories:** chunks_index.json

To configure the GCP BigQuery Agent, double-click on the agent or select the Edit agent button after left-clicking on the agent in the Workflow Editor. After opening the Agent Configuration , you can set a name for the agent using the Name field. Target The Target tab contains settings related to the UDR type to insert into the database and the specific table for the UDR to be inserted into by the agent. Open GCP BigQuery agent configuration - Target tab Field Description Field Description GCP Profile Click Browse to select a predefined GCP profile. The profile contains the credential information required to connect to BigQuery in the GCP Project. UDR Type Type of UDR to populate the target BigQuery table. Project ID Specify the reference ID of the project. This is a mandatory field as the workflow will be invalid if you try to save the configuration without specifying the Project ID. Dataset Select the target dataset. Data Table Select the target table name. Only the tables found within the selected dataset can be listed and chosen. Info! When creating the Data table, ensure that: The table must have a Transaction ID column , dedicated to the agent's internal use for transaction safety purposes. The column could be named according to your preference however it must be BigQuery INT64 data type (with alias INT , SMALLINT , INTEGER , BIGINT , TINYINT , BYTEINT ). It must also not allow NULL . Take note of the name as you will have to create a similar column with the same name for the Batch Status table. Info! Due to the restriction on modifying rows in Data table, the Data table is not modified during Commit and Rollback workflow stages. This Restriction is explained further in GCP BigQuery Agent Transaction Behavior . Batch Status Table A separate table to keep track of the transaction ID to allow the agent to better provide transaction safety in the event that the workflow aborts. A transaction ID is unique to each batch process, the agent will use the transaction ID to identify UDRs that belong to the batch when the data insertion into the table was interrupted. Info! When creating the Batch Status table, ensure that: The table must have a Transaction ID column , dedicated to the agent's internal use for transaction safety purposes. The column must be named the same as the Transaction ID column created in the Data table and it must be in INT64 . It must also not allow NULL . The table must also have a Status column for the agent to update the status of the transaction. This column must also be BigQuery INT64 data type (with alias INT , SMALLINT , INTEGER , BIGINT , TINYINT , BYTEINT ) and must be named status. See the example below on creating a Batch Status table: Example - Batch Status Table The following DDL query is used in the BigQuery Query Editor to create a table under the user_analytics Dataset with the table named batch_status . CREATE TABLE user_analytics.batch_status ( transactionID INT64 NOT NULL OPTIONS(description="The transaction ID field"), status INT64 OPTIONS(description="The status field"), ) Info! The Batch Status table is updated with status code during the Commit and Rollback workflow stages. The Batch Status, Status column may contain the following codes: Code Description 100 The UDR's are currently being inserted into the Data table. 0 The workflow successfully inserted all the UDRs into the Data table. 1 The workflow has aborted or has been manually stopped and the UDRs insertion has been cancelled. 2 The Workflow entered rollback stage, possibly due to errors in previous workflow run. -1 This status indicates an unknown issue and requires further investigation into the cause. Transaction ID Column Select the column that is designated for the transaction ID from the Batch Status Table and Data Table. The transaction ID has to be present in both Data and Batch Status table with the same name, for the transaction ID to be available for selection. Batch Size The amount of UDR to be inserted into the target data table for each batch process. This corresponds to the rows per insert request into the target Data table. The default value is 500 records per batch transaction. Note! If you need to increase the Batch Size, you will need to refer to the GCP documentation on the maximum limit of Bigquery streaming inserts. Concurrent Requests The amount of connections the agent will open to the target data table to insert the UDRs. The default value is 1 connection. Note! The order of insertion of the UDR data into the BigQuery table is done out of sequence and will appear as such in the target table. Sorting will have to be done from BigQuery itself. Assignment The Assignment tab contains the assignment of values to each column. Open GCP BigQuery agent configuration with the Assignment tab selected. If the Target tab is correctly configured with the Dataset , Data Table , Batch Status Table and Transaction ID Column filed, and the Assignment tab is selected, the Field Name and Field Type column in the table will automatically be populated. If assignments already exist in the Assignment tab, then Refresh must be manually selected, for the assignments to be updated with the configurations in the Target tab. Field Description Field Description Refresh Updates the table with all the columns from the selected table. Note! Potential changes in the database table will not be visible until the Dataset , Data Table , Batch Status Table and Transaction ID Column have been properly configured. If rows already exist in the table, the refresh operation preserves the configuration for all rows with a corresponding column. Thus, if a table has been extended with a new column, the old column configurations are left untouched and the new column appears when Refresh is selected. Field Name Displays a list of all columns for the selected Data table, except the Transaction ID column. Field Type Displays the BigQuery data type for each column as declared in the BigQuery table. Info! BigQuery data types that are currently supported are: BIGNUMERIC , BOOLEAN , DATE , DATETIME , TIME , TIMESTAMP , FLOAT64 , NUMERIC , GEOGRAPHY , STRING and INT64 . UDR Field Allows you to map the Field Name of the Data table with the UDR Field from the UDR Type configured from the Target tab. Only valid UDR Field types will be available for selection in the Column Assignment dialog based on the Field Type of the BigQuery Column. You can refer to the BigQuery to valid UDR data types mappings in the table below. BigQuery data types are automatically mapped to UDR data types as follows: BigQuery Data Types UDR Data Types BigQuery Data Types UDR Data Types BIGNUMERIC byte, int, short, long, float, double, bigint , bigdec BOOLEAN boolean DATE date DATETIME date TIME date TIMESTAMP date FLOAT64 byte, int, short, long, float, double NUMERIC byte, int, short, long, float, double GEOGRAPHY string STRING string INT64 byte, int, short, long

---

# Document 1374: Encryptor Agent Input/Output Data and MIM - MediationZone Documentation 9.3 - InfoZone

**Source:** ratanon/mz93-documentation
**URL:** https://infozone.atlassian.net/wiki/spaces/MD93/pages/204738675/Encryptor+Agent+Input+Output+Data+and+MIM
**Categories:** chunks_index.json

Input/Output Data The input/output data is the type of data that an agent expects to receive and delivers. The agent expects and delivers data in bytearray format. MIM The Encryptor agent does not have any agent specific MIM parameters. For information about the MIM and a list of the general MIM parameters, see Administration and Management .

---

# Document 1375: Standard Upgrade Procedure - MediationZone Documentation 9.3 - InfoZone

**Source:** ratanon/mz93-documentation
**URL:** https://infozone.atlassian.net/wiki/spaces/MD93/pages/204669969
**Categories:** chunks_index.json

This section describes the standard upgrade procedure that should be used when it is important to minimize downtime and ensure that persisted data is retained. The Standard upgrades must be performed stepwise to the next consecutive main or minor version. Note! Read the Documentation Ensure to read through all the documentation for the Standard Upgrade Procedure and check out the Release Notes for Important information and Known Issues before proceeding with the Upgrade. This section contains the following subsections: Disconnect ECs Shut Down Workflows and Desktops Upgrade Preparations Upgrade Platform Container Upgrade Execution Container Post Upgrade Resume Workflow Execution If you plan to upgrade several versions, repeat the steps on the next page and onwards for each version. Use the setup.sh script provided for each version during the upgrade. Note! There may be changes to certain agents and functions in the new version. Before upgrading, you should take note of any changes or updates that may have happened to your components, as you may have to modify your configuration before it can work with the newer version. See MediationZone Release Information for detailed information about changes in each release. Note! If you have a High Availability setup, you are advised to deactivate the failover functionality in the HA cluster daemon. You must ensure that no HA activities can impede the upgrade procedure. Note! If you have any of the following configurations in your system: Workflow Packages Containing Web Services PCC Extensions (the *.mzp file(s) containing your own custom data model(s) need to be recompiled following the instructions on this page) you will have to perform some additional steps, see the respective page describing the steps for more information.

---

# Document 1376: Batch-Based Real-Time Agents - MediationZone Documentation 9.3 - InfoZone

**Source:** ratanon/mz93-documentation
**URL:** https://infozone.atlassian.net/wiki/spaces/MD93/pages/205002942/Batch-Based+Real-Time+Agents
**Categories:** chunks_index.json

Collection and forwarding agents that are based on batch agents can be included in real-time workflows. This allows you to use various file-oriented protocols, and to access your batch data directly from a real-time workflow. The collection and forwarding agents that are available are: Amazon S3 Disk FTP SCP SFTP When you have selected to create a real-time workflow, you can select these agents from the lists of collection and forwarding agents in the agent pane. A real-time workflow with a batch-based agent: Can process several UDRs simultaneously, but the order of UDR processing is not guaranteed. The Begin and End Batch are signaled to the workflow. Decoder, error management, and scheduling are defined as part of the collection agent configuration. If the agent encounters an error that would cause a batch workflow to abort, instead behavior depends on how the agent is configured in the Execution tab. Note! You can choose to use these agents if you are not relying on transaction safety in your solution. If the workflow aborts, rollback or commit will not be called, and there is no recovery step when you start a workflow again. Note! When using the Disk agent in realtime workflows you cannot use the MultiForwardingUDR. The section contains the following subsections: Batch-Based Real-Time Agents - Agent Configuration Batch-Based Real-Time Agents - UDR Types Batch-Based Real-Time Agents - Transaction Behavior Batch-Based Real-Time Agents - Input/Output Data and MIM Batch-Based Real-Time Agents - Agent Events Batch-Based Real-Time Agents - Example Workflow

---

# Document 1377: Object Types - MediationZone Documentation 9.3 - InfoZone

**Source:** ratanon/mz93-documentation
**URL:** https://infozone.atlassian.net/wiki/spaces/MD93/pages/205655952/Object+Types
**Categories:** chunks_index.json

This section describes the JSON representation of the various object types that are used in the service model storage. In order to run KPI Management, you must first provision a service model that includes all the required objects that are listed in the schema below. The following JSON schema describes the data format of a complete service model: Loading Note! The aggregated-output object type is optional and contains a boolean value that determines if the KPI output for each dimension will be grouped in the same KPIAggregatedOutput UDR. When the value of this object is set to true , multiple KPIOutput UDRs are grouped by dimension in the same KPIAggregatedOutput UDR. When the value is false (default), each KPI AggregatedOutput will contain one KPIOutput UDR. Example - Aggregated output "aggregated-output": true, ... When the value of aggregated-output is true, all kpi objects in the model must have the same window size. Other object types in the JSON schema are described in the following subsections. Note! When a service model contains objects of the same type and with identical names, only one of them will be used. Duplicate object definitions are not detected automatically when you validate the KPI profile. Loading

---

# Document 1378: Decrypt Functions - MediationZone Documentation 9.3 - InfoZone

**Source:** ratanon/mz93-documentation
**URL:** https://infozone.atlassian.net/wiki/spaces/MD93/pages/204743670/Decrypt+Functions
**Categories:** chunks_index.json

decryptMZEncryptedString Decrypts a string that has been encrypted using mzsh encryptpassword , and returns the decrypted string. decryptMZEncryptedString (string encryptedString) Parameter Description Parameter Description encryptedString The string encrypted using mzsh encryptpassword Returns The decrypted string

---

# Document 1379: Hash - MediationZone Documentation 9.3 - InfoZone

**Source:** ratanon/mz93-documentation
**URL:** https://infozone.atlassian.net/wiki/spaces/MD93/pages/610697406/Hash
**Categories:** chunks_index.json

This tab is activated only when the Hash masking method is selected in the Fields tab. The following settings are available in the Hash masking method in the Data Masking profile. Setting Description Setting Description Salt Enter the key to be appended to the data or click the Random button to generate a random key.

---

# Document 1380: APL - PCC Runtime Support - Buckets - MediationZone Documentation 9.3 - InfoZone

**Source:** ratanon/mz93-documentation
**URL:** https://infozone.atlassian.net/wiki/spaces/MD93/pages/204677417
**Categories:** chunks_index.json

The runtime support is used for looking up the actual products based on the references received with the mapper support. The runtime support functions include: pccCreate pccGetUdr pccGetUdrList pccCreate This function creates a data set object that can be used with the pccGetUdr and pccGetUdrList functions described below. any pccCreate( string area ) Parameters Parameter Description Parameter Description area The name of the area which the function is operating against. Returns: A data set object that can be used with the pccGetUdr or pccGetUdrList functions. Example pccCreate("PROD"); will create a data set object that can be used with the pccGetUdr and pccGetUdrList functions against the PROD area. pccGetUdr Retrieves a specific UDR based on the stated UDR type and key. drudr pccGetUdr( string typename, any key [, any dataset] ) Parameters Parameter Description Parameter Description typename The fully qualified typename of the requested UDR. key The reference to the requested UDR dataset The data set object that you want to use for retrieving the UDR. This field is optional, and if it is not used, the data set that was used last will be used for the retrieval. Returns: The matching UDR or null if no matching UDR was found. Example pccGetUdr ("PCC.Products.Provisioning.Notification", 50); will retrieve a UDR of the type PCC.Products.Provisioning.Notification with the key 50 . pccGetUdrList Retrieves a list with all the UDRs with the stated UDR type. list<drudr> pccGetUdrList( string typename [, any dataset] ) Parameters Parameter Description Parameter Description typename The fully qualified UDR typename of the requested UDRs. dataset The data set object that you want to use for retrieving the UDRs. This field is optional, and if it is not used, the data set that was used last will be used for the retrieval. Returns: A list containing all the UDRs of the requested type. Example list<drudr> notificationsList = pccListData ("PCC.Products.Provisioning.Notification"); will return a list named notificationsList with all the UDRs that have the type PCC.Products.Provisioning.Notification .

---

# Document 1381: Python Processing Agent Transaction Behavior - Batch - MediationZone Documentation 9.3 - InfoZone

**Source:** ratanon/mz93-documentation
**URL:** https://infozone.atlassian.net/wiki/spaces/MD93/pages/205686671/Python+Processing+Agent+Transaction+Behavior+-+Batch
**Categories:** chunks_index.json

This section includes information about the Python processing agent transaction behavior. For information about the general transaction behavior, see Workflow Monitor . Emits The agent emits commands that changes the state of the file currently processed. Command Description End Batch The agent itself does not emit End Batch, however it can trigger the collector to do so by calling the hintEndBatch method. For further information, see Functions for Python . Cancel Batch The agent itself does not emit Cancel Batch however, it can trigger the collector to do so by calling the cancelBatch method. For further information, see Functions for Python . Hint End Batch If the code contains a call to the method hintEndBatch this will make the agent emit a Hint End Batch. Retrieves The agent retrieves commands from other agents and, based on them, generates a state change of the file currently processed. Command Description Begin Batch When a Begin Batch message is received, the agent calls the beginBatch function block, if present in the code. Cancel Batch When a Cancel Batch message is received, the agent calls the cancelBatch function block, if present in the code. End Batch When an End Batch message is received, the agent calls the drain and endBatch function blocks, if present in the code.

---

# Document 1382: SCP Agents Attributes and Authentication - MediationZone Documentation 9.3 - InfoZone

**Source:** ratanon/mz93-documentation
**URL:** https://infozone.atlassian.net/wiki/spaces/MD93/pages/204740493
**Categories:** chunks_index.json

Attributes The SCP collection agent and the SCP forwarding agent share a number of common attributes. They are both supported by a number of algorithms: 3des-cbc, 3des-ctr, blowfish-cbc, aes128-cbc, aes192-cbc, aes256-cbc, aes128-ctr, aes192-ctr, aes256-ctr, arcfour, arcfour128, arcfour256. Authentication The SCP agents support authentication through either username/password or private key. Private keys can optionally be protected by a Key password. Most commonly used private key files, can be imported into the system. Typical command line syntax (most systems): ssh-keygen -t <keyType> -f <directoryPath> Argument Description Argument Description keyType The type of key to be generated. Both RSA and DSA key types are supported. directoryPath Where to save the generated keys. Example The private key may be created using the following command line: > ssh-keygen -t rsa -f /tmp/keystore Enter passphrase: xxxxxx Enter same passphrase again: xxxxxx Then the following is stated: Your identification key has been saved in /tmp/keystore Your public key has been saved in /tmp/keystore.pub When the keys are created the private key may be imported to the SCP agent: Open Edit Private Key dialog Finally, on the SCP server host, append /tmp/keystore.pub to $HOME/.ssh/authorized_keys . If the $HOME/.ssh/authorized_keys is not there it must be created.

---

# Document 1383: Database Forwarding Agent - MediationZone Documentation 9.3 - InfoZone

**Source:** ratanon/mz93-documentation
**URL:** https://infozone.atlassian.net/wiki/spaces/MD93/pages/204999339/Database+Forwarding+Agent
**Categories:** chunks_index.json

The Database forwarding agent inserts UDR data into a database table, based on user-defined mappings between UDR fields and database table columns. Also, the agent offers the possibility of populating columns with other types of data. The data is inserted either using a plain SQL statement or through a call to a stored procedure that will be responsible for inserting the data. The agent does not only map and forward the data. A special column in the target table is also assigned a unique Transaction ID, generated for each batch. In relation to this, a pending transaction table is utilized to indicate that a batch is open. The Database collection agent also utilizes this table to prevent problems if collecting data from the target table. The section contains the following subsections: Database Forwarding Agent Configuration Database Forwarding Agent Input/Output Data and MIM Database Forwarding Agent Events Database Forwarding Agent Transaction Behavior

---

# Document 1384: GTP' Agent Preparations - MediationZone Documentation 9.3 - InfoZone

**Source:** ratanon/mz93-documentation
**URL:** https://infozone.atlassian.net/wiki/spaces/MD93/pages/205685759/GTP+Agent+Preparations
**Categories:** chunks_index.json

If you want to ensure that a specific IP address is used for the GTP' agent, you must set the property mz.gtp.server.host in the execution container: $ mzsh topo set topo://container:<container name>/pico:<ec name>/val:config.properties.mz.gtp.server.host '<host address or name>' For this change to take effect, you must restart the EC after setting this property. If this property is not set, the agent will listen on the host set in the property pico.rcp.server.host in the container.conf . If the property pico.rcp.server.host is not set in the container.conf , the agent listen on all interfaces.

---

# Document 1385: refreshdbmeta - MediationZone Documentation 9.3 - InfoZone

**Source:** ratanon/mz93-documentation
**URL:** https://infozone.atlassian.net/wiki/spaces/MD93/pages/205657080/refreshdbmeta
**Categories:** chunks_index.json

usage: refreshdbmeta [options] This command is used to refresh the metadata for existing Database profiles. Options: -p, --profile State a specific profile to be refreshed. The name should be entered in the following format: Folder.ProfileName If no profile is set, all existing profiles will be refreshed. Default: [] -v, --verbose More detailed output from the refreshdbmeta command. Default: [] Options Option Description Option Description [-p, --profile] This option can be used if you want to state a specific profile to be refreshed. If this option is not used, all profiles will be refreshed. [ -v --verbose ] Use this flag for detailed output from the refreshdbmeta command. Example - Using the -v flag $ mzsh <username>/<password> refreshdbmeta -v Output: Database profile <db_profile> metadata has been refreshed Added table: mzadmin.table1 Added procedure: mzadmin.procedure1 Removed table: mzadmin.table2 Removed procedure: mzadmin.procedure2 Execution has been completed Example - Using the -v flag $ mzsh <username>/<password> refreshdbmeta -v Output: Database profile <db_profile> metadata has been refreshed Added table: mzadmin.table1 Added procedure: mzadmin.procedure1 Removed table: mzadmin.table2 Removed procedure: mzadmin.procedure2 Execution has been completed Return codes Listed below are the different return codes for the refreshdbmeta command: Code Description Code Description 0 Will be returned if the metadata was successfully refreshed. 1 Will be returned if the stated profile is not valid or could not be found.

---

# Document 1386: CheckBox UDR - MediationZone Documentation 9.3 - InfoZone

**Source:** ratanon/mz93-documentation
**URL:** https://infozone.atlassian.net/wiki/spaces/MD93/pages/204609851/CheckBox+UDR
**Categories:** chunks_index.json

The CheckBox UDR is used to create a checkbox. Open Checkbox created by Checkbox UDR The following fields are included in the CheckBox UDR : Field Description Field Description attributes (map<string,string>) This field may contain extra attributes to be added. checked (boolean) This field may contain a boolean if the checkbox should be checked by default (when the page loads). Default is false. cssClasses (list<string>) This field may contain a list of extra values added to class attribute. This is typically used to style the component. Please read more on Bootstrap . disabled (boolean) This field may contain a boolean if the component should be disabled or enabled. id (string) This field may contain the id of the component label (string) This field must may contain the label for the checkbox. labelCssClasses (list<string>) This field may contain a list of extra values added to class attribute of the label. This is typically used to style the component. Please read more on Bootstrap . name (string) This field may contain the name of the component. If the component is present in a Form UDR , the name will be submitted with the form as the key in the Params Map in Request UDR . required (boolean) This field may contain a boolean if the component is required. Typically used inside a Form UDR. value (string) This field may contain a value that should be submitted when it is used inside a Form UDR. Default is on.

---

# Document 1387: Annotations - MediationZone Documentation 9.3 - InfoZone

**Source:** ratanon/mz93-documentation
**URL:** https://infozone.atlassian.net/wiki/spaces/MD93/pages/204645053/Annotations
**Categories:** chunks_index.json

Annotations are used to specify the needed attributes on type and field level attributes for the configuration objects. See Configuration Object Example for the full example used for illustration below. Class Level Annotations @DRStorableId("devkitexamples.DiskCollectionConfig") @DRConfigTypeInfo(version = 10f, section = "Disk Collection") public class DiskCollectionConfig extends DRAbstractConfigObject { Configuration objects handles serialization through the normal DRStorable data serialization interface (see ), but the actual implementation is handled automatically through reflection. Therefore a DRStorableId must be specified and also a version parameter in the DRConfigTypeInfo annotation. The section parameter is a field level parameter and is described below. Field Level Annotations @DRConfigFieldInfo(title = DIRECTORY, description = "The path to the source directory") public void setDirectory(String directory) { _directory = directory; } public String getDirectory() { return _directory; } Configuration fields are defined through normal Java beans semantics. This means that by defining a get and a set method a field is defined. In the example above a field named directory is defined. Configuration fields have a number of additional attributes that can be set through the DRConfigFieldInfo annotation Parameter Description title Short human readable title. This is what is used in the workflow table heading. If it is not set, field name is used as default. description Longer human readable description section Which section name should be used for the field in the workflow table. If the section parameter is defined in the DRConfigTypeInfo annotation, this is used as default if not specified on field level newLineAllowed Set as true for "large" text fields where newlines should be allowed in GUI interactions since To handle automatic upgrade from old versions of the configuration object, this should be specified whenever new fields are added for a new version level If it should be allowed to set this field on workflow level, then the level should be set to DRConfigFieldLevel.TEMPLATE . This should be done in cases where for example configuration controls the output type of the agent.

---

# Document 1388: FTP Agents - MediationZone Documentation 9.3 - InfoZone

**Source:** ratanon/mz93-documentation
**URL:** https://infozone.atlassian.net/wiki/spaces/MD93/pages/204641309/FTP+Agents
**Categories:** chunks_index.json

This section describes the FTP collection and FTP forwarding agents. The collection agent is available for batch and real-time workflows. The forwarding agent is available for batch workflows. Prerequisites The reader of this information should be familiar with the Stan da rd FTP (RFC 959, http://www.ietf.org/rfc/rfc0959.txt ) The section contains the following subsections: FTP Forwarding Agent FTP Collection Agent

---

# Document 1389: Version Management - MediationZone Documentation 9.3 - InfoZone

**Source:** ratanon/mz93-documentation
**URL:** https://infozone.atlassian.net/wiki/spaces/MD93/pages/204997468/Version+Management
**Categories:** chunks_index.json

The user may save new versions of a workflow while they are running or scheduled. However, it is not advisable to update or save a new version of the workflow that is scheduled to run or execute soon. In such a case, the workflow is reloaded to the most recent version upon activation or when it has finished the current execution. If the most recent workflow version is invalid, the workflow will abort when trying to load that version. A real-time workflow does not usually fall back to scheduled mode and therefore will not automatically pick up changes made to the workflow. Some real-time agents can be modified while they are running but will not be saved. See Dynamic Update in Administration and Management .

---

# Document 1390: REST HTTP Interface - Products - MediationZone Documentation 9.3 - InfoZone

**Source:** ratanon/mz93-documentation
**URL:** https://infozone.atlassian.net/wiki/spaces/MD93/pages/204677387/REST+HTTP+Interface+-+Products
**Categories:** chunks_index.json

Provisioning of Products is supported via a REST HTTP Interface which is implemented using the standard HTTP methods GET , PUT , POST and DELETE . The interface supports XML and JSON formats, and enables external systems to provision and update Products. The REST HTTP Interface runs on the EC Web Interface and is started when the EC process is started. Authentication is performed against the Platform, if possible. If the Platform is unreachable, the user is authenticated against the locally defined user (configured in EC web interface properties). The UDRs available in the Products REST Interface are: Capacity Enforcement Notification Product ProductMapping To retrieve one UDR: http://<host>:<port>/PCC/Products/<area>/<udr-type>/<udr-id> To retrieve all UDRs of a certain type: http://<host>:<port>/PCC/Products/<area>/<udr-type> Note! In the examples in this chapter, HTTP/1.0 have been used, but REST supports HTTP/1.1 as well. Creating a UDR A UDR can be created by sending data to the HTTP Interface using POST to the base URL for the resource. The response will be the created UDR. Default format for the response is XML if nothing is specified. The format of the response is determined by the Accept HTTP header. Example - Creating a ProductMapping UDR in area TEST using XML POST http://localhost:9090/PCC/Products/TEST/ProductMapping HTTP/1.0 Content-Type: application/xml The xml-data should be structured as follows: <ProductMapping> <Priority>1</Priority> <Arguments>Arg 1</Arguments> <Arguments>Arg 2</Arguments> <Targets>1000</Targets> <Targets>1001</Targets> </ProductMapping> Example Creating a ProductMapping UDR in area TEST using JSON POST http://localhost:9090/PCC/Products/TEST/ProductMapping HTTP/1.0 Content-Type: application/json The json-data should be structured as follows: { "Priority": 20, "Arguments": [ "21", "22" ], "Targets": [ 101, 200 ] } Retrieving a UDR The format of the response is determined by the Accept HTTP header. Retrieving all Capacity UDRs in area TEST as JSON GET http://localhost:9090/PCC/Products/TEST/Capacity/ HTTP/1.0 Accept: application/json Example output: { "Capacitys": [ { "Misc": { "entry": [ { "key": "qht", "type": "int", "value": "600" } ] }, "ID": 1001, "Name": "4GB Roaming",> "Capacity": 10240, "CapacityUnit": 1,> "CounterType": 2, "CounterUnit": 1, "QuotaDefault": 1024, "QuotaMinimum": 256 }, { "Misc": { "entry": [ { "key": "qht", "type": "int", "value": "1850" } ] }, "ID": 1002, "Name": "5GB national", "Capacity": 5120, "CapacityUnit": 1, "CounterType": 2, "CounterUnit": 1, "QuotaDefault": 4096, "QuotaMinimum": 2048 } ] } Retrieving a specific Capacity UDR in area TEST as JSON GET http://localhost:9090/PCC/Products/TEST/Capacity/1024 HTTP/1.0 Accept: application/json Example output: { "Misc": { "entry": [ { "key": "vqt", "type": "double", "value": "0.2" }, { "key": "qht", "type": "int", "value": "600" } ] }, "ID": 1024, "Name": "10GB Roaming", "Capacity": 10240, "CapacityUnit": 1, "CounterType": 2, "CounterUnit": 1, "QuotaDefault": 1024, "QuotaMinimum": 256 } Retrieving all Enforcement UDRs in area TEST as JSON GET http://localhost:9090/PCC/Products/TEST/Enforcement HTTP/1.0 Accept: application/json Example output: { "Enforcements": [ { "ID": 1001, "Name": "Enf100%", "CounterType": 2, "Level": 1 }, { "ID": 1002, "Name": "Enf0%", "CounterType": 2, "Level": 0 }, ] } Retrieving a specific Enforcement UDR in area TEST as JSON GET http://localhost:9090/PCC/Products/TEST/Enforcement/1001 HTTP/1.0 Accept: application/json Example output: { "ID": 1001, "Name": "Enf100%", "CounterType": 2, "Level": 1 } Retrieving all Notification UDRs in area TEST as JSON GET http://localhost:9090/PCC/Products/TEST/Notification HTTP/1.0 Accept: application/json Example output: { "Notifications": [ { "ID": 1001, "Name": "Surf Europe 4GB 80%", "Message": "TH_80", "CounterType": 2, "Level": 0.8, "Required": true, "Type": "0", "Address": "127.0.0.1" }, { "ID": 1002, "Name": "Surf Europe 4GB 100%", "Message": "TH_100_1", "CounterType": 2, "Level": 1.0, "Required": true, "Type": "0", "Address": "127.0.0.1" }, ] } Retrieving a specific Notification UDR in area TEST as JSON GET http://localhost:9090/PCC/Products/TEST/Notification/1001 HTTP/1.0 Accept: application/json Example output: { "ID": 1001, "Name": "Surf Europe 4GB 80%", "Message": "TH_80", "CounterType": 2, "Level": 0.8, "Required": true, "Type": "0", "Address": "127.0.0.1" } Retrieving all Product UDRs in area TEST as JSON GET http://localhost:9090/PCC/Products/TEST/Product HTTP/1.0 Accept: application/json Example output: { "Products": [ { "Misc": { "entry": [] }, "ID": 1001, "Name": "Surf Europe", "StartTime": "2010-05-08 00:00", "StopTime": "2020-12-12 00:00", "StopFallthrough": false, "Currency": "SEK", "Capacities": [ 3 ], "Duration": 24, "DurationUnit": 2, "ResetType": 1, "ResetInterval": 1, "ResetIntervalUnit": 1, "Price": 0, "Enforcements": [1], "Notifications": [1,2], "RetainedCounters": 0, "StopAtCapacity": false }, { "Misc": { "entry": [] }, "ID": 1002, "Name": "Surf Europe", "StartTime": "2010-05-08 00:00", "StopTime": "2020-12-12 00:00", "StopFallthrough": false, "Currency": "SEK", "Capacities": [4], "Duration": 24, "DurationUnit": 2, "ResetType": 1, "ResetInterval": 1, "ResetIntervalUnit": 1, "Price": 0, "Enforcements": [1], "Notifications": [3,4], "RetainedCounters": 0, "StopAtCapacity": false } ] } Retrieving a specific Product UDR in area TEST as JSON GET http://localhost:9090/PCC/Products/TEST/Product/1001 HTTP/1.0 Accept: application/json Example output: { "Misc": { "entry": [] }, "ID": 1001, "Name": "Surf Europe", "StartTime": "2015-05-08 00:00", "StopTime": "2020-12-12 00:00", "StopFallthrough": false, "Currency": "SEK", "Capacities": [3], "Duration": 24, "DurationUnit": 2, "ResetType": 1, "ResetInterval": 1, "ResetIntervalUnit": 1, "Price": 0, "Enforcements": [1], "Notifications": [1,2], "RetainedCounters": 0, "StopAtCapacity": false } Retrieving all ProductMapping UDRs in area TEST as JSON GET http://localhost:9090/PCC/Products/TEST/ProductMapping HTTP/1.0 Accept: application/json Example output: { "ProductMappings": [ { "ID": 1001, "Priority": 1, "Arguments": [".*"], "Targets": [1001,1002] }, { "ID": 1002, "Priority": 2, "Arguments": [".*"], "Targets": [1003,1004] } ] } Retrieving a specific ProductMapping UDR in area TEST as JSON GET http://localhost:9090/PCC/Products/TEST/ProductMapping/1001 HTTP/1.0 Accept: application/json Example Output: { "ID": 1001, "Priority": 1, "Arguments": ["Arg 1","Arg 2"], "Targets": [1001,1002] } Updating a UDR Updates are made using PUT . Example Updating a ProductMapping UDR in area TEST using XML PUT http://localhost:9090/PCC/Products/TEST/ProductMapping/<id> HTTP/1.0 Content-Type: application/xml Content-Length: 185 The format of the xml-data should be structured as follows: <ProductMapping> <Priority>1</Priority> <Arguments>Arg 1</Arguments> <Arguments>Arg 2</Arguments> <Targets>1000</Targets> <Targets>1001</Targets> </ProductMapping> Deleting a UDR Deleting a UDR is done by using the DELETE method. Example Deleting a ProductMapping UDR with a specific key in area TEST DELETE http://localhost:9090/PCC/Products/TEST/ProductMapping/<id> HTTP/1.0 Clearing an Area Clearing an area is done with a HTTP DELETE call to /PCC/Products/<source area>/admin/clear . Example Clearing area TEST. DELETE http://localhost:9090/PCC/Products/TEST/admin/clear HTTP/1.0 Copy One Area to Another Copying one area to another is done with a HTTP PUT call to /PCC/Products/<source area>/admin/copyArea?dest=<destination area> . Example Copying data from TEST to PROD. PUT http://localhost:9090/PCC/Products/TEST/admin/copyArea?dest=PROD HTTP/1.0 Content-Length: 0 Error Codes There are several different codes that can be returned for the different operations. For admin commands: http://<host>:<port>/PCC/Products/<area>/admin/clear http://<host>:<port>/PCC/Products/<area>/admin/copyArea http://<host>:<port>/PCC/Products/<area>/admin/refresh Error code Description Error code Description 200 Will be returned if the last operation was successful. 500 Will be returned if there was an error. When creating a UDR: http://<host>:<port>/PCRF/Rules/<area>/<udr-type> Error code Description Error code Description 201 Will be returned if the UDR was created. 409 Will be returned if a UDR with the stated key already exists, or if there are dependencies missing. 415 Will be returned if the UDR key is of type string and the key is missing, or if the key type is incorrect. 500 Will be returned if the UDR requires references that are missing, or if there was an error. When retrieving one UDR: http://<host>:<port>/PCRF/Rules/<area>/<udr-type>/<id> Error code Description Error code Description 200 Will be returned if the requested UDR was found. 204 Will be returned if there is no UDR with the stated ID. 500 If there was an error. When retrieving all UDRs: http://<host>:<port>/PCRF/Rules/<area>/<udr-type> Error code Description Error code Description 200 Will be returned with an empty list or with a list containing the UDRs. When updating a UDR: http://<host>:<port>/PCRF/Rules/<area>/<udr-type>/<id> Error code Description Error code Description 200 Will be returned if the UDR was updated successfully. 408 Will be returned if the keys in the URL and the XML are different, or the key in the URL is set to "0". 409 Will be returned if the UDR requires references that are missing, or if there is not UDR with the stated key. 500 Will be returned if there was an error. When deleting a UDR: http://<host>:<port>/PCRF/Rules/<area>/<udr-type>/<id> Error code Description Error code Description 200 Will be returned if the UDR was deleted successfully. 204 Will be returned if there is no UDR with the stated key. 409 Will be returned if the UDR is referenced by another UDR. 500 Will be returned if there was an error.

---

# Document 1391: External - Sequential Format - MediationZone Documentation 9.3 - InfoZone

**Source:** ratanon/mz93-documentation
**URL:** https://infozone.atlassian.net/wiki/spaces/MD93/pages/204612811/External+-+Sequential+Format
**Categories:** chunks_index.json

A sequential external format specification consists of two parts; the record declaration and the field declaration. The record declaration can contain information about UDR size and how the record type is identified. The field declarations may be grouped into larger structures such as bit_block and set . The syntax of the external format declarations is declared as follows: external <format_name> [: <record declaration>] { <content declarations> }; The comma-separated elements of the record declaration list may be (in any order): terminated_by( <terminator> ) dynamic_size( <expression> ) static_size( <constant expression> ) identified_by( <conditional expression> ) The content declarations can be: field declarations bit_block declarations set declarations switched_set declarations This chapter includes the following sections: Record Declaration Field Declarations Expressions

---

# Document 1392: mzcli - systemimport - MediationZone Documentation 9.3 - InfoZone

**Source:** ratanon/mz93-documentation
**URL:** https://infozone.atlassian.net/wiki/spaces/MD93/pages/547979797
**Categories:** chunks_index.json

Usage systemimport [ -s|-skipexisting ] [ -pp|-preservepermissions ] [ -nameconflict re|an|sk ] [ -keyconflict re|an|sk ] [ -namekeyconflict rn|rk|an|sk ] [ -he|-holdexecution [ r|sr|sir|wr ] ] [ -nr|-norollback ] [ -no|-newowner ] [ -cp|-configfrompackage ] [ -iv|-importextrefvalues ] [ -select <xml-selection file> [ -dryrun ] [ -onerror < ABORT | IGNORE > ] ] [ -m|-message ] [ -u|-upgrade ] [ -dryrun ] <export file|directory> [password] ---------------------------------------------------- Import Conflict re = Replace sk = Skip an = Add New rk = Replace Key conflict rn = Replace Name conflict Holdexecution r = Restart sr = Stop and Restart sir = Stop Immediate and Restart wr = Wait for completion and Restart This command imports a ZIP file, an MZP file, or a directory. If an import entry is in conflict with an entry that already exists in the current system, the entry will not be imported. An example of such a conflict might be an identical entry name but a different ID. If you try to import the same MZP file or workflow package twice you get an error. The error is given if the checksums of MZP files are identical. Note! If you export the same configuration twice the checksums will differ. A workflow group that is scheduled to start while an import activity is happening, will not start until the import is complete. Options Option Description Option Description [-s|-skipexisting] If you use the skipexisting option, the imported data will not overwrite existing configurations that have the same key, name, type, and folder. This means that repeatedly importing a configuration, does not overwrite the data. [-pp|-preservepermissions] When user permissions are modified, set the preservepermissions parameter to prevent user permissions in the current system from being updated while importing a configuration. [-nameconflict re|an|sk] Decide what to do when there is a name conflict; replace, add new, or skip. Default is to skip the item when there is a name conflict. Note! If -nameconflict is not specified and there is a name conflict, the configuration is skipped. To avoid this, use -dryrun to verify before importing. [-keyconflict re|an|sk] Decide what to do when there is a key conflict; replace, add new, or skip. Default is to skip the item when there is a key conflict. Note! If -keyconflict is not specified and there is a key conflict, the configuration is skipped. To avoid this, use -dryrun to verify before importing. [-namekeyconflict rn|rk|an|sk] Decide what to do when there is a key or name conflict; replace, add new, or skip. Default is to skip the item when there is a key or a name conflict. Note! If neither of -namekeyconflict, -keyconflict, or -nameconflict is specified and there is a key or name conflict, the configuration is skipped. To avoid this, use -dryrun to verify before importing. [-he|-holdexecution [ r | sr | sir | wr ] ] Use the holdexecution option to prevent scheduled workflow groups from being started while importing configurations. If a workflow or a workflow group does not stop within 5 minutes (300 seconds) when doing a systemimport with either one of the following holdexecution parameters: sr , sir , and wr , a timeout will occur. You can change the timeout value by setting the Platform property mz.import.suppress.timeout . When the import is completed and a workflow group is still running, systemimport -holdexecution [ r | sr | sir | wr ] awaits the current running workflow member to come to a stop, and then restarts the whole group instead of continuing the execution of the member that follows. If you do not specify any of the r , sr , sir or wr options: A batch workflow or a workflow group will remain suppressed until all the workflows finish executing. Then, the workflow or the members of the workflow group, become idle. A real-time workflow group will return to the running state. systemimport -holdexecution generates events. To retrieve the events data, configure an Event Notification to transfer it according to your preferences. holdexecution Parameters Select the action that should resolve held executions: r (restart): When the import activity is done, and a workflow group is partly executed, specifying this option will restart that workflow group. Workflow groups that are fully executed, will not be restarted. A workflow that is started manually, will be restarted if it has been stopped. sr (stop and restart): Stops the workflows or workflow groups that are still running after an import is complete, waits for them to come to a stop or finish processing a batch, and then restarts synchronously all the workflow groups and all the manually started workflows that had not executed completely within the timeout boundaries. Note! A workflow that becomes unreachable after a system import has begun, will be restarted only when and if the contact with the Execution Context that it runs on, is regained while still importing. If a workflow is unreachable when system import is started, the import is aborted and the following error message is generated: Abort Import: At least one wf that is Unreachable . sir (stop immediately and restart): Stops the workflows or workflow groups that are still running after an import is complete, even in the middle of processing a batch, and synchronously restarts all the workflow groups and all the manually started workflows that had not executed completely within the timeout boundaries. Note! An unreachable workflow is restarted once contact with the Execution Context that it runs on, is regained. wr (wait for completion and restart): After an import is complete, synchronously restarts all the workflow groups and all the manually started workflows that had not executed completely within the timeout boundaries. Note! Any workflow that runs past the timeout limit is restarted as soon as it completes execution. Example - Using the holdexecution Option $ systemimport -s -he r export.zip $ systemimport -s -he sr export.zip $ systemimport -s -he sir export.zip $ systemimport -s -he wr export.zip [-nr|-norollback] When you us the systemimport command, a file that contains rollback information will be created. This file contains data about configuration changes during the system import, and is saved in the directory where you apply the command. You use the rollback file to undo a system import and return to the configuration that you had before the system import. Note! Use the importrollback command only to revert the systemimport command and not for the purpose of a system rollback, see https://infozone.atlassian.net/wiki/spaces/MD93/pages/547979531/mzcli+-+importrollback?atlOrigin=eyJpIjoiYmYwYzY2ZWViNjc1NGNmNGExMDFiMGExODQyZGFjMDciLCJwIjoiYyJ9 . To suppress the creation of the rollback file, provide either a nr or a norollback option. [-no|-newowner] Change ownership of the configuration on import. The user must match an user already defined in the https://infozone.atlassian.net/wiki/spaces/MD93/pages/204737438 . [ -cp|-configfrompackage ] Add this option if you would like to import the Workflow Package (MZP) as configuration instead of a Workflow Package. [ -iv|-importextrefvalues ] Add this option if you would like to import the values from External References. [-select <xml-selection file> [-dryrun ] [-onerror < ABORT | IGNORE > ] ] Note! Do not use -select for Workflow Packages (MZP files). The -select <xml-selection file> parameter enables you to: Provide systemimport with an XML file that specifies your selection of configurations and workflow tables. Use [ -dryrun ] to test data compatibility prior to actually importing Note! Dryrun is only applicable to ZIP file and directory. Use [ -onError < ABORT | IGNORE > ] to manage an occurrence of an error XML Selection File This selection information that you find in the XML selection file corresponds to the selection information that you specify on the System Import tool view, in the Desktop user interface. The XML selection file consists of two main tags: <configurations> : contains your configuration import selections <workflows> : contains your workflow tables import selections <configurations> Select configurations from the <Export file|directory> that systemimport imports. Use the resolveDependencies attribute to either include (true), or ignore (false), dependent configurations. See the following example: Example - The resolveDependencies attribute <import> <configurations> <!-- Ignoring dependencies of the Default.x configuration--> <configuration name="Default.x" resolveDependencies="false"/> <!-- Including dependencies of the Default.y configuration--> <configuration name="Default.y" resolveDependencies="true"/> <!-- Ignoring dependencies of the Default.z configuration--> <!-- Note: Equal to selection of Default.x above --> <configuration name="Admin.C07E02_DEMO_BWF"/> <!-- Ignoring dependencies of configurations within the folder --> <configuration foldername="systemunits"/> <!-- Including dependencies of all the configurations in the folder --> <configuration foldername="billing" resolveDependencies="true"/> </configurations> </import> To import all the configurations that are included in a specific folder, include the following text in the XML file: <configuration foldername="myFolder"/> Note! If you specify configuration selections in the XML file that do not exist in the Export file, a warning is generated. <workflows> This XML tag enables you to use systemimport [-select <xml-selection file>] to import both workflow configurations and their CSV file in one action. Use this tag to associate workflow tables with CSV data files. Note! Set the keepOld attribute to true in order to prevent removal of workflow table data which has no match in the export file. Use false to overwrite the data. This parameter is only used during import, and has no effect during export. The onError attribute can either be set from the XML selection file, or from the systemimport in-line command. If set from both, the XML selection file attribute is the value that applies. For further information about the values that you can choose from, see onError. This parameter is only used during import, and has no effect during export. Set the encryptPassword attribute to the workflow configuration password if the workflow configuration is password protected. Example - The XML selection tags <import> <configurations> <configuration name="myFolder.DB_PROFILE"/> <configuration name="myFolder.APL_PROFILE" resolveDependencies="true"/> <configuration foldername="myFolder"/> </configurations> <workflows > <workflow name="Mobile.FTP_workflow" wfTable="/home/user1/FTP_workflows.csv"/> <workflow name="Mobile.SFTP2_workflow" wfTable="/home/user1/SFTP2_workflows.csv" resolveDependencies="true"/> <workflow name="Mobile.GGSN1_workflow" wfTable="/home/user1/GGSN1_workflows.csv" resolveDependencies="true" onError="ask"/> <workflow name="Mobile.GGSN3_workflow" wfTable="/home/user1/GGSN3_workflows.csv" resolveDependencies="true" onError="ignore"/> <workflow name="Mobile.GGSN4_workflow" wfTable="/home/user1/GGSN4_workflows.csv" resolveDependencies="true" onError="abort"/> <workflow name="Mobile.GGSN5_workflow" wfTable="/home/user1/GGSN5_workflows.csv" resolveDependencies="true" keepOld="false" encryptPassword="password" onError="ask"/> </workflows> </import> [ -m|-message] If you want to add a comment when using the systemimport command, the -m or -message option can be used as in the following example: Example - message $ systemimport -m "My Import" /home/Directory/<file to import>.zip "My Import" will be the commented. The comment will replace the default information saved when making a system import, and will both be included in the System Log message that is generated, as well as visible when selecting to view history in any of the configurations in the imported data. [-u|-upgrade] When exports have been made in a previous version of MediationZone, they may have to be upgraded. In this case you can use the -u or -upgrade option as in the following example: Example - upgrade $ systemimport -u <file to import>.zip The configurations will then be upgraded. [-dryrun] To test data compatibility prior to actually importing. Note! Dry run is only applicable to ZIP file and directory. <export file|directory> Specify the path to the directory or ZIP file that contains the configurations you want to import. [password] To import encrypted configurations, provide a password. Return Codes Listed below are the different return codes for the systemimport command: Code Description Code Description 0 Will be returned if the command is successful. 1 Will be returned if the argument count is incorrect or argument(s) are invalid. 2 Will be returned if the command was unable to find an export (file|directory) at the supplied path. 3 Will be returned if the import could not be started due to locked import. 4 Will be returned if any errors were reported during the import. 5 Will be returned if the XML file did not contain any configurations or workflows to import. 8 Will be returned if the XML file did not contain any workflows to use in dry run. 10 Will be returned if the import results in invalid workflows due to compilation errors. 14 Will be returned if there are configurations not imported 20 Will be returned if the value for a supplied option or option is missing. 100 Will be returned if an error occurs while parsing the selection file 101 Will be returned if an error occurs while parsing a node in the selection XML file. 102 Will be returned if an error occurs while getting the attribute from a configuration tab, or if expected wfTable attribute in tag with the supplied name is missing. 103 Will be returned if the import was unable to parse the value for a booolean XML attribute. 104 Will be returned if an error occurs while parsing dependencies for a configuration. 300 Will be returned if an OutOfMemoryError occurs during import.

---

# Document 1393: Enhanced User Security - MediationZone Documentation 9.3 - InfoZone

**Source:** ratanon/mz93-documentation
**URL:** https://infozone.atlassian.net/wiki/spaces/MD93/pages/204613167/Enhanced+User+Security
**Categories:** chunks_index.json

The user security can be enhanced by keeping the property install.security as true in install.xml before installation. After the installation, property mz.security.user.control.enabled would be set to true in platform.conf. Use STR to view platform configuration. If mz.security.user.control.enabled set to true after installation, all users are required to change the password during their first login after the property has take effect. If an admin should reset the password for a user, the user will also be required to change password when they re-login. Password Rules If enhanced user security is enabled, the default password rules are: The password must : Be at least eight characters long. Include at least one special character and one that is either a number or a capital letter. new user will have to reset password on first time login. The password must not : Contain more than two identical characters in an uninterrupted sequence. Such as "aaa". Include the username. Be in alphabetical sequence, such as Abcd. Be in numerical sequences, such as 1234. Be in any US keyboard pattern, such as Qwerty. Contain any whitespace. Be identical to any of the recent twelve (minimum) passwords used for the user ID. Info! Repetitive characters that are not consecutively sequenced are still valid. Such as "adadad". Other Password Rules If you have a custom password policy that you will want to include with the default policies listed above, you can modify or add new password rules with the Platform properties that are stated in the section Enhanced User Security Platform Properties of the Platform Properties .

---

# Document 1394: mzcli - systemimport - MediationZone Documentation 9.3 - InfoZone

**Source:** ratanon/mz93-documentation
**URL:** https://infozone.atlassian.net/wiki/spaces/MD93/pages/547979797/mzcli+-+systemimport
**Categories:** chunks_index.json



---
**End of Part 58** - Continue to next part for more content.
