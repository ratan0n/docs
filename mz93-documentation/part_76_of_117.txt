# RATANON/MZ93-DOCUMENTATION - Part 76/112

---
**Dataset:** ratanon/mz93-documentation
**Part:** 76 of 112
**GitHub:** https://github.com/ratan0n/docs/tree/main/mz93-documentation
**Size:** ~66.3 KB
---

The Desktop provides a convenient user interface, displaying configurations, tools, and inspectors, with different options available for the different views. Open Desktop window The Desktop window is organized into two main sections: To the left you have the Standard Desktop Buttons , which allows you to expand lists of configurations, tools, and other options, see Standard Desktop Buttons and Options below for more information. The main view displays the selected tools and opened configurations in a tabbed arrangement. Standard Desktop Buttons and Options The Desktop user interface includes the following standard features: Feature Description Feature Description Desktop Buttons Open Browser - Click this button to open the Browser. Here you can see all available configurations and their properties. Open Configuration - Click this button to open a list of available configuration types to create a new configuration. Open Inspection - Click this button to open a list of available inspectors, see Inspection for more information. Open Tools - Click this button to open a list of available tools, see Tools & Monitoring for more information. Open Open Tabs - Click this button to open a list of all open tabs, which may be useful if you have many tabs open. Open Change Password - Click this button to open the Change Password dialog where you can change your user password. Open Documentation - Click this button to open the user documentation. Open Status - Click this button to open a list of status messages along with version information. Open Exit - Click this button to exit the Legacy Desktop. Tab Right-Click Menu There are different closing options available when right-clicking a tab. Open The tab right-click menu Close - Select this option to close the selected tab. Close Other - Select this option to close all other tabs in the Desktop window. Close All - Select this option to close all tabs in the Desktop window. Tab Button Panel The button panel is visible at the top of a tab. It is dynamic and changes according to the type of Configuration, Inspector, or Tool that is opened in the currently displayed tab. For a description of the specific buttons, refer to Build View , Inspection , and Tools & Monitoring . The following figure shows the button panel visible for a workflow configuration. Open The tab button panel for a workflow configuration Tabs Configurations and tools are opened in separate tabs, in the right part of the Desktop window. However, dialogs that are opened from right-click menu options, e.g. the MIM Browser or UDR Browser, are opened in a dialog box and not in another tab. Click the Open Tabs button to display a list with all the currently opened tabs. Open Open Tabs List dialog When exiting the Desktop, all tabs are closed, and they are not restored the next time you log in unless you have set the property mz.gui.restart.tabs to true . See Desktop Properties for more information. To reorder the tabs, click a tab and drag it to a different position along the top of the window. To move a tab to a separate Desktop window, click and drag it outside the current window. This can be useful when running and analyzing several workflows in the Workflow Monitor, to be able to view the monitors side by side. If there is only one tab open in the Desktop and the tab is moved to a separate window, the original Desktop window will be closed. A Tool, Inspector, or Configuration can only be open in one tab at a time. It is possible to move tabs between several Desktop windows. Browser View The Browser displays a list of all configurations and makes it possible to easily navigate between them. In the Browser you also filter what configurations are shown, by selecting entries of a specific type. You also have the option to display configurations with folders and subfolders. The Browser supports a set of operations that can be performed on the configurations by using the right-click menu. Each configuration has Properties where permissions are set and where you can view history, references, and other basic information. Refer to Properties in Configuration Browser for more information. Button Description Button Description Open To open the Browser , click the Browser button in the upper left part of the interface. Open The Browser View In the Browser there are two pre-existing folders: Default - This folder is where all configurations are stored if no other folder is specified. SystemTask - This folder contains workflows for performing different background routines. For further information, refer to System Task Workflows in Workflow Types . Note! The Default and SystemTask folders cannot be renamed or deleted. Subfolders It is possible to arrange your configurations in a structure with subfolders. Open Subfolder structure To enable this functionality you need to set the property platform mz.subfolder.enabled to true , and restart the Platform and any Legacy Desktop clients. When enabled, you can create a subfolder by using an underscore in the folder name when creating a new folder. Open Creating a subfolder If you want to use another character to define subfolders than underscore, you can use the property mz.subfolder.separator to define another separator. See Platform Properties for more information. Note! Subfolders are only available in Legacy Desktop. Right-Click Menu In this section, the different options available in the right-click menu of the Browser View are described. Note that some of the options have keyboard shortcuts - these are listed in grey color according to the used operating system. Right-click a configuration and select one of the following options: Option Description Option Description Column View Enables you to switch between Compact or Details viewing modes. When the Details mode is selected, additional information is shown about each item: the granted permissions, Owner, Modified By, and the Modification Date. Refresh Select this option to refresh the selected folder, subfolder, or configuration. Expand Select this option to expand the selected folder or subfolder to display all the subfolders and configurations that it contains. Collapse Select this option to collapse the selected folder or subfolder to not display all the subfolders or configurations. New Configuration Select this option to create a new profile based on the menu list. New Folder... Select this option to create a new folder. Open Configuration(s)... Available when at least one configuration is selected. Select this option to open the selected configuration(s). Export Configuration(s) Available when at least one configuration is selected. Select this option to export the selected configurations. The System Exporter dialog opens with the configuration(s) pre-selected. Note! When exporting from the Configuration Navigator, configuration dependencies are not automatically selected. This can be achieved by selecting the Select Dependencies checkbox in the System Exporter dialog. For further information see System Exporter . Download... Downloads the selected configuration. Cut Select this option to put one or more configurations on the clipboard to move the configuration to another location. Select the menu option Paste in the folder where the configurations should be stored. This option is not applicable if the configuration is locked. For further information see Locks in Administration and Management in Legacy Desktop . Copy Select this option to put one or more configurations on the clipboard to copy the configurations to another location. Select the menu option Paste in the folder where the copied configurations should be stored. Paste Select this option to store configurations that have been cut or copied to the clipboard in the selected folder. Delete... Select this option to delete the selected configuration(s). If the configuration is referenced by another configuration, a warning message is displayed, informing you that you cannot remove the configuration. For further information see The References Tab in 6.2 Configuration Browser . You can force the deletion of a folder and all the configurations that it contains. A message is displayed asking if you are sure that you want to continue, in order to avoid deletion by mistake. Note that there is no restore option for this function. All the configurations are permanently removed. Rename... Select this option to change the name of the selected configuration. Take particular care when renaming a configuration. If, for example, an APL script is renamed, workflows that are using this script will become invalid. This is important to know when you rename folders that contain many ultra format configurations or APL configurations. Renaming a folder with ultra formats or APL configurations will make all referring configurations invalid. Encrypt... Select this option to encrypt the selected configurations. Decrypt... Select this option to decrypt the selected configurations. Validate... Select this option to validate the configuration. A validation message is shown to the user. Show Properties Select this option to launch the Properties dialog for the selected configuration. For further information, see the Properties section below. Documentation Select this option to launch the Documentation dialog for the selected configuration. For further information, see the Documentation section below. Properties To open the Properties dialog, right-click a configuration and select Show Properties . Open The Properties dialog box This dialog contains four different tabs: Basic , which contains basic information about the configuration, Permission , where you set permissions for different users, References , where you can see which other configurations that are referenced by the selected configuration, or that refers to the selected configuration, and History which displays the revision history for the configuration. The Basic tab is displayed by default. The Basic Tab The Basic tab is the default tab in the Properties dialog and contains the following information: Configuration Information Description Configuration Information Description Name Displays the name of the configuration. Type Displays the configuration type. Key Displays the internal key used by MediationZone to identify the configuration. Folder Displays the name of the folder in which the configuration is located. Version Displays the version number of the configuration, see the History tab for further information about the different versions. Permissions Displays the permissions granted to the current user of the configuration. Permissions are shown as R (Read), W (Write), and X (eXecute). If the configuration is encrypted, an E is shown. For further information about permissions, see The Permissions Tab in Configuration Browser . Owner Displays the username of the user that created the configuration. The owner can: Read, modify (write), and execute the configuration. Modify the permissions of user groups to read, modify, and execute the configuration. Modified by Displays the username of the user that made the last modifications to the configuration. Modified Displays the date when the configuration was last modified. If you want to use the information somewhere else you can highlight the information and press CTRL-C to copy the information to the clipboard. The Permissions Tab The Permissions tab contains settings for what different user groups are allowed to do with the configuration: Open The Permissions tab As access permissions are assigned to user groups, and not individual users, it is important to make sure that the users are included in the correct user groups to allow access to different configurations. R W X E Permission Description R W X E Permission Description R - - - Allowed only to view the Configuration, given that the user is granted access to the application. - W - - Allowed to edit and delete the Configuration. - - X - Allowed only to execute the Configuration. R W - - Allowed to view, edit, and delete the Configuration, given that the user is granted access to the application. - W X - Allowed to edit, delete, and execute the Configuration. R - X - Allowed to view and execute the Configuration, given that the user is granted access to the application. R W X - Full access. - - - E Encrypted. The References Tab The References tab contains information about which other configurations the current configuration refers to, and which other configurations the current configuration is referenced by: Open The References tab The References tab contains two sub-tabs: Used By , which displays all the configurations that use the current configuration, and Uses , which displays all the configurations that the current configuration uses. To edit any of the configurations, double-click the configuration to open it for editing. The History Tab The History tab contains version information for the configuration: Open The History tab In the version table, the following columns are included: Column Description Column Description Version Displays the version number. Modified Date Displays the date and time when the version was saved. Modified By Displays the user name of the user that saved the version. Comment Displays any comments for the version. If you want to clear the Configuration history, click the Clear Configuration History button. The version number is not affected by this. Documentation To open the Documentation dialog, right-click a configuration and select Documentation . Open The Documentation dialog In this dialog, you can provide information on the selected configuration, for example, a description and the purpose of the configuration. You can use markdown syntax if preferred. The text entered is then included in the automated documentation that you can generate using the Documentation Generator tool. When you have completed the text, click OK to save. For further information, see Documentation Generator . Search Click the Search button to be able to make free text searches. Two options are shown at the top of the list. Option Description Option Description Filter Select to filter for entries that match the entered string. Search Select to find individual entries that match the entered string. Click Find Next to go to each individual entry in turn. Open

---

# Document 1791: Amazon SQS UDRs - MediationZone Documentation 9.3 - InfoZone

**Source:** ratanon/mz93-documentation
**URL:** https://infozone.atlassian.net/wiki/spaces/MD93/pages/299663385/Amazon+SQS+UDRs
**Categories:** chunks_index.json

SqsCollectorCycleUDR The SQS Collection Agent produces UDRs of type SqsCollectorCycleUDR . Field Description Field Description msgAttribute The user-defined message attributes (if any) of the message. A read-only field of type map<string,SqsMessageAttributeUDR(Sqs)> . msgBody The contents of the message. A read-only field of type string . receiptHandle The receipt handle - the unique id for the consumer - of the message. A read-only field of type string . standardAttributes The standard attributes of the message. You have to select All Standard Attributes in the configuration of the agent if you want to retrieve this data, see Amazon SQS Collection Agent Configuration . A read-only field of type map<string,string> . visibility The visibility timeout of the message. This value shows how long the message remains invisible to other consumers of the queue. The visibility parameter in the queue for a particular collected message can be reset by the collection agent. This is done by changing the field value of the collected UDR in APL, and then routing the UDR back to the collection agent. The visibility parameter will not be set for the queue in general, only for the particular message. Note! Routing back a UDR with its original contents to the collector will result in the message being deleted from the queue immediately without waiting for the timeout set in the visibility parameter. A field of type int . SqsForwarderCycleUDR The SQS Forwarder Agent consumes UDRs of type SqsForwarderUDR. This is also the type used in the reply from the agent. All fields of the SqsForwarderUDR are optional except one, the queueName . Field Description Field Description deduplicationId the unique id to avoid duplicates of the message. If left empty, the SQS service will assign the id. An optional field of type string . error If the message cannot be inserted in the queue, the error message from the SQS service is written to the error field. For successfully inserted messages, the error field is null. A read-only field of type string . msgAttribute User-defined attributes of the message. An optional field of type map<string,SqsMessageAttributeUDR(Sqs)> . msgBody The contents of the message. An optional field of type string . msgGroupId The Group Id that the message belongs to. An optional field of type string . queueName The name of the queue that the message will be sent to. A mandatory field of type string . SqsMessageAttributeUDR The SqsMessageAttributeUDR defines custom attributes in the SqsCollectorCycleUDR and the SqsForwarderUDR. Field Description Field Description DataType Amazon SQS supports the following logical data types: String , Number , and Binary value (any) The value of the corresponding DataType

---

# Document 1792: The Prometheus Filter - MediationZone Documentation 9.3 - InfoZone

**Source:** ratanon/mz93-documentation
**URL:** https://infozone.atlassian.net/wiki/spaces/MD93/pages/205001332
**Categories:** chunks_index.json

Use this filter to configure the Prometheus metrics that are going to be exposed for scraping. The purpose of the Prometheus Filter is to prevent the flooding of metrics in the storage of the Prometheus host. The filter is positive, so you define what you want to get. Except in the situation where no Prometheus Filter exists or all existing Prometheus Filters are disabled, then all available metrics are exposed for scraping. The exception is MIM metrics from batch workflows. In the case of MIMs from batch workflows, no metrics will be collected unless there is a filter whitelisting them. A Prometheus filter consists of one or many metric filters. Each metric filter has a Metric Name Filter and optionally a number of Label Filter(s) . A metric that passes at least one of the metric filters will be exposed for scraping. Open Exa mple o f a Prometheus filter with one metric filter that has no label filters. Setting Description Setting Description Ena bled Whether this Prometheus Filter is enabled or not. Metric Name Filter A filter is applied to the metric name. Label Filter(s) A filter that applies to a label that exists on the metric(s) passes the corresponding metric name filter. To Add a Metric Filter To add a metric filter, take the following steps: Click the Add button. In the dialog that is displayed, enter a Metric Name Filter in the form of a regular expression. Optionally, specify one or many label filter(s) by entering the Label along with a corresponding Label Value Filter The Label Value Filter has to be entered in the form of a regular expression. Click Add to add the metric filter. Click Close when done. Open For example, five metric filters are configured. See the detailed description in the table below. Setting Description Setting Description jvm_.* java_.* process_.* Will give you Global statistics (JVM, processes, event management). com_digitalroute_event.* MIM metrics related to the event handling system. com_digitalroute_wf_.* workflow=Default.myWorkflow.* Workflow MIM metrics for the workflows in the Default folder that has a name beginning with "myWorkflow".

---

# Document 1793: SAP HANA DB - MediationZone Documentation 9.3 - InfoZone

**Source:** ratanon/mz93-documentation
**URL:** https://infozone.atlassian.net/wiki/spaces/MD93/pages/204639514/SAP+HANA+DB
**Categories:** chunks_index.json

This section contains information that is specific to the database type SAP HANA. Note! The default MediationZone installation with configured clean up tasks in SystemTasks shall work fine with an SAP HANA DB instance of 64GB. If additional MediationZone processing services are configured to use the same SAP HANA DB instance, it is likely that additional resources will be needed to accommodate to the increased load. The services mentioned are Aggregation, Inter-workflow, Duplicate UDR checking and Data Veracity that use the SAP HANA DB storage. Warning ! It is possible that errors and misconfigurations in workflow can occur during the design and implementation. This can lead to inefficient use of resources such as a spike in memory consumption. Addressing these errors before deployment to production is crucial to ensure optimal usage of SAP HANA DB resources. Supported Functions The SAP HANA database can be used with the following functionality: Callable Statements (APL) Database Bulk Lookup Functions (APL) Database Table Related Functions (APL) Database Agents Data Masking Profile Event Notifications Prepared Statements (APL) Shared Table Profile SQL Collection/Forwarding Agents SQL Loader Agent Task Workflows Agents (SQL) Note! When using SAP HANA the property max.cached.prepared.statements has to be set to 0 in the Execution Context in order to be able to use PreparedStatements . In addition to the functions listed above, the SAP HANA database can be used with the following functionality: Audit Profile Note! The SAP HANA database availability is dependent on scenario and customer landscape. Therefore, any solution designed using the jdbc connection to SAP HANA for real-time applications must be made to handle the same availability as achieved by the implementation of the underlying SAP HANA instance. Properties When selecting the SAP HANA database type, you can configure the following property using the Properties tab in the Database profile: sapdb.connectionpool.maxlimit Preparations A driver, provided by your SAP contact, is required to connect an SAP HANA database. This driver must be stored on the Platform Container host and each Execution Container host that will connect to a SAP HANA database. To access the SAP HANA database, follow the steps below: Copy the driver to the directory MZ_HOME/3pp in the Platform or EC Container. Restart the Platform and ECs for the change to take effect. Advanced Connection Configuration for SAP HANA with TLS/SSL When connecting to an SAP HANA database with TLS/SSL enabled, the connection string will require additional properties for the connection. Open SAP HANA Advanced Connection Setup with a JDBC connection string to a SAP HANA database with TLS/SSL enabled. For list of JDBC connection string properties required to connect your TLS/SSL enabled SAP HANA hosting server, you can refer to the SAP HANA documentation at the SAP Help Portal.

---

# Document 1794: User Defined Action UDRs - MediationZone Documentation 9.3 - InfoZone

**Source:** ratanon/mz93-documentation
**URL:** https://infozone.atlassian.net/wiki/spaces/MD93/pages/205035367
**Categories:** chunks_index.json

It is possible to define an Action UDR and send it from the Collection workflow, in a ConsumeCycleUDR , to communicate actions back to the forwarding workflow. The UDR can be sent regardless of the Send Reply over Bridge setting in the Workflow Bridge profile.

---

# Document 1795: Function Blocks for Agents in Real-Time Workflows - MediationZone Documentation 9.3 - InfoZone

**Source:** ratanon/mz93-documentation
**URL:** https://infozone.atlassian.net/wiki/spaces/MD93/pages/205686476/Function+Blocks+for+Agents+in+Real-Time+Workflows
**Categories:** chunks_index.json

The function blocks described in this section only apply for Python agents in real-time workflows. The available function blocks are: timeout stopInput timeout This function block is called when using the setTimeout function. UDRs may be routed in a timeout function block. When possible, always route to an asynchronous route from the timeout function block. def timeout(obj) Example - timeout function block sessions = {} def consume(input): setTimeout(input.key, 1.2) sessions[input.key] = sessions.get(input.key, 0) + input.value def timeout(obj): debug('Timed out, removing %s' % obj) del sessions[obj] stopInput Note! This function block only applies for the Python collection agent. This function block is called when the workflow does not want the collector to produce any more data. def stopInput() Example - stopInput function block def stopInput(): debug('stopInput called')

---

# Document 1796: PCC Extensions - MediationZone Documentation 9.3 - InfoZone

**Source:** ratanon/mz93-documentation
**URL:** https://infozone.atlassian.net/wiki/spaces/MD93/pages/204677512
**Categories:** chunks_index.json

Apart from the built-in data models for PCC, you can also create your own data models. The data models are defined in xml format, and then packed into an mzp that is committed into the system. Then they will be available from the regular interfaces for provisioning. To create a PCC Extension data model: Create XML files describing your data model and store it in the /mediationzone/packages/pcrf/src/devkit_tools/example/model/ folder. Go to the /mediationzone/packages/pcrf/src/devkit_tools/example/ folder and run the generate.sh script to generate your *.jar file. $./generate.sh A /build directory will be created with all the required classes and resources. A *.jar file will be created and placed in a new sub directory called /build. There is an example of a 5G PCF Rules model included in the Development Toolkit, see Development Toolkit User's Guide . Data Model for PCF Session Management Policy

---

# Document 1797: Maintaining Archives - MediationZone Documentation 9.3 - InfoZone

**Source:** ratanon/mz93-documentation
**URL:** https://infozone.atlassian.net/wiki/spaces/MD93/pages/205032008/Maintaining+Archives
**Categories:** chunks_index.json

The Archive Cleaner task removes outdated archives that has has expired according to the Purge criteria in the Archive profile. The Archive Cleaner task is accessed from Execution Manager, which is opened by clicking the Tools button in the upper left part of the Desktop window. The Archive Cleaner is only configurable with respect to scheduling criteria. The cleanup of outdated files is mastered by removing the reference as well as the file itself from the archive directory. For further information, also see Archive Cleaner in 3.1.1 Workflow Types . Resetting entry_id Sequence For each new archived file, the agent will add an entry in the database with an incremental sequence number known as entry_id. This sequence number will NOT auto cycle after reaching its maximum value. The user is required to manually alter or reset the sequence in this scenario to prevent overflow. You can use the following SQL statements for resetting the entry_id. Note! When resetting entry_id, you are required to execute the Archive Cleaner so that newer archive entries will not clash with the older entries. Oracle ALTER SEQUENCE MZOWNER.SEQ_ARCHIVE_ENTRY_ID CYCLE; PostgreSQL ALTER SEQUENCE mzowner.archive_entries_entry_id_seq CYCLE;

---

# Document 1798: SCP Collection Agent Input/Output Data and MIM - MediationZone Documentation 9.3 - InfoZone

**Source:** ratanon/mz93-documentation
**URL:** https://infozone.atlassian.net/wiki/spaces/MD93/pages/205001917/SCP+Collection+Agent+Input+Output+Data+and+MIM
**Categories:** chunks_index.json

Input/Output Data The Input/Output data is the type of data an agent expects and delivers. The agent produces bytearray types. MIM For information about the MIM and a list of the general MIM p arame ters, see Administration and Management . Publishes MIM Parameter Description Source Filenames This MIM parameter contains a list of names of the files that are about to be collected from the current collection directory. Note! When the agent collects from multiple directories, the value of this parameter is cleared after the collection of each directory. Then, the MIM value is updated with the listing of the next directory. Source Filenames is of the list<any> type and is defined as a header MIM context type. File Retrieval Timestamp This MIM parameter contains a timestamp, indicating when the file transfer starts. File Retrieval Timestamp is of the date type and is defined as a header MIM context type. Source File Count This MIM parameter contains the number of files that were available to this instance for collection at startup. The value is static throughout the execution of the workflow, even if more files arrive during the execution. The new files will not be collected until the next execution. Source File Count is of the long type and is defined as a global MIM context type. Source Filename This MIM parameter contains the name of the currently processed file, as defined at the source. Source Filename is of the string type and is defined as a header MIM context type. Source Files Left This parameter contains the number of source files that are yet to be collected. This is the number that appears in the Execution Manager backlog. Source Files Left is of the long type and is defined as a header MIM context type. Source Host This MIM parameter contains the name of the host from which files are collected, as defined in the Host field in the Connection tab. Source Host is of the string type and is defined as a global MIM context type. Source Pathname This MIM parameter contains the path from where the currently processed file was collected, as defined in the Source tab. Source Pathname is of the string type and is defined as a global MIM context type. Source Username This MIM parameter contains the login username to the host from which the file was collected, as defined in the Connection tab. Source Username is of the string type and is defined as a global MIM context type. Accesses The agent does not access any MIM resources.

---

# Document 1799: REST Server_Deprecated Agent - MediationZone Documentation 9.3 - InfoZone

**Source:** ratanon/mz93-documentation
**URL:** https://infozone.atlassian.net/wiki/spaces/MD93/pages/204740312/REST+Server_Deprecated+Agent
**Categories:** chunks_index.json

The REST Server_Deprecated agent allows the receiving of any HTTP requests from client applications and responds with an acknowledgment from the Analysis agent. The agent produces the REST UDR, which contains both request and response fields. The request fields of the UDR include the header, method, body, and client resource URI. After the Analysis agent has processed the request, the REST Server_Deprecated agent routes the REST UDR back, which includes the original request as well as the response from the server that is determined from the APL codes. The REST Server_Deprecated Agent can support the OAuth 2.0 protocol for authorization with the use of the Authorization Server. The Authorization Server is a service provider in MediationZone which is used to generate OAuth 2.0 access tokens. For further information on how to setup and configure the Authorization Server, see Authorization Server For further information about the UDR types used by the REST Server_Deprecated agent, see REST Server_Deprecated UDR Types . Open REST Server_Deprecated agent workflow Prerequisites The reader of this information should be familiar with: Representational state transfer (REST) RFC 2616 - Hypertext Transfer Protocol -- HTTP/1.1 RFC 6749 - OAuth 2.0 Authorization Framework RFC 7617 - Basic HTTP Authentication Scheme RFC 5246 - Transport Layer Security (TLS) Protocol This section includes the following subsections: REST Server_Deprecated Agent Configuration REST Server_Deprecated Agent Events REST Server_Deprecated Agent Example REST Server_Deprecated Agent Input/Output Data and MIM REST Server_Deprecated Agent UDR Types

---

# Document 1800: SAP CC  Batch Agent in Batch Workflows - MediationZone Documentation 9.3 - InfoZone

**Source:** ratanon/mz93-documentation
**URL:** https://infozone.atlassian.net/wiki/spaces/MD93/pages/205001780/SAP+CC+Batch+Agent+in+Batch+Workflows
**Categories:** chunks_index.json

This section describes how to configure the SAP CC Batch agent in batch workflows, and contains the following subsections: SAP CC Batch Agent Configuration - Batch SAP CC Batch Agent Input/Output Data and MIM - Batch SAP Batch Agent Events - Batch

---

# Document 1801: Available When the Platform Is Running - MediationZone Documentation 9.3 - InfoZone

**Source:** ratanon/mz93-documentation
**URL:** https://infozone.atlassian.net/wiki/spaces/MD93/pages/204646486/Available+When+the+Platform+Is+Running
**Categories:** chunks_index.json

When the Platform is running and user is logged in, a more extensive list of commands, used to manage the system, will be available. The following commands are available: change-password configuration derbybackup desktopadmin disconnect dumpsyslog generate_pcc_classes importrollback logger packageexport pico plist premove refreshdbmeta resumeexecution service sldreg slowmethods system systemexport systemimport topo trace ultra unregister user vcexport vcimport wfcommand wfdebug wfdisable wfenable wfexport wfgroupaddwf wfgroupaddwfgroup wfgroupdisable wfgroupenable wfgrouplist wfgroupmodify wfgroupremovewf wfgroupremovewfgroup wfgroupstart wfgroupstop wfimport wflist wfstart wfstop

---

# Document 1802: Redis Profile - MediationZone Documentation 9.3 - InfoZone

**Source:** ratanon/mz93-documentation
**URL:** https://infozone.atlassian.net/wiki/spaces/MD93/pages/204998705
**Categories:** chunks_index.json

A Redis profile is used to read and write data in a Redis database and can be accessed by real-time workflows using Aggregation agents. The Redis profile is loaded when you start a workflow that depends on it. Changes to the profile become effective when you restart the workflow. The Redis profile has been verified on Redis Labs Enterprise Cluster (RLEC). Note! To ensure aggregation functions correctly with the Redis profile, you must have the Enterprise edition of Redis. Configuration To create a new Redis profile, click the New Configuration button from Build View , and then select Redis Profile from the selection screen. Th e contents of the buttons bar may change depending on which configuration type has been opened in the currently displayed tab. The Redis profile uses the standard menu items and buttons that are visible for all configurations, and these are described in Common Configuration Buttons . The Edit button content is specific to the Redis profile configurations. Item Description Item Description External References Open Select this menu item to enable the use of External References in the Redis profile configuration. This can be used to configure the use of the following fields, and the respective external reference keys available: Host Port Max Retries Retry Interval Operation Timeout Password For further information, see Using External Reference in Agent Profile Fields and External Reference Profile . The Redis configuration contains two tabs: Connectivity and Advanced . Connectivity Tab The Connectivity tab is displayed by default. Open Redis profile - Connectivity tab The following settings are available in the Redis profile: Setting Description Setting Description Host Enter the IP address/DNS name of the cluster. Port Enter the listening port of the cluster. Password Enter the password of the cluster. Operation Timeout (ms) Enter the number of milliseconds after which Redis "CRUD" operations, i e create, read, update, and delete, should timeout. Setting a lower value than the default 1000 ms may have a positive impact on throughput performance. However, if the value is set too low, indicated by a large number of operation timeouts errors in the EC logs, a lower throughput can be expected. Retry Interval Time (ms) Enter the time interval, in milliseconds, that you want to wait before trying to read the cluster configuration again after a failed attempt. The default value is 5. Max Number of Retries Enter the maximum number of retries. The default value is 30. Advanced Tab The Advanced tab contains additional properties that you can use for performance tuning. Open Redis profile - Advanced tab The property mz.redis.socket.timeout specifies how long the Redis client will try to open a socket connection before it times out, while the property mz.redis.connection.timeout determines the maximum amount of time that the Redis client waits to read data from the Redis server before it times out. Idle connections will timeout after the time specified in mz.redis.connection.time.limit has expired. These connections will be returned to the pool and are considered unused. The profile will periodically remove (evict) unused connections to the Redis cluster. Use mz.redis.connection.time.limit to control the time between the eviction intervals. Connections in use are periodically and unconditionally reset. Use mz.redis.connection.time.limit to control the time between the reset intervals. In case of topology changes the connections are reset after a delay. Use mz.redis.topology.limit.time to set the length of this delay.

---

# Document 1803: Configuring Alarm Detection - MediationZone Documentation 9.3 - InfoZone

**Source:** ratanon/mz93-documentation
**URL:** https://infozone.atlassian.net/wiki/spaces/MD93/pages/205658248/Configuring+Alarm+Detection
**Categories:** chunks_index.json

MediationZone includes the capability to proactively monitor many different parts of the system, and raise stateful alarms if a configured condition is detected. Alarms can be managed within the system, or be sent to any external source such as a network management system using protocols such as SNMP traps, or e-mail. Combinations of multiple alarm conditions can be defined as triggers for an alarm. Open Example of an Alarm Detection configuration with two conditions The Alarm Detection Configuration UI is intended for catching of a small subset of available system events. Available Alarm Conditions: System Event Workflow Alarm Value Workflow Execution Time Workflow Group Execution Time Workflow Throughput MediationZone can integrate with external alarm handling systems using a wide variety of events and metrics. Metrics based events: For alarm conditions that require metrics based data (time series) - for instance infrastructure performance, data processing details, MIMs, etc - Prometheus can be used, as MediationZone has plug-and-play integration. Please refer to section System Insight (SI) . Message based events: Using the Event Notification Manager ( Event Notifications Configuration ), all events in the system can be caught and forwarded to SNMP traps, log files, and databases.

---

# Document 1804: Workflow Bridge Batch Forwarding Agent Configuration - MediationZone Documentation 9.3 - InfoZone

**Source:** ratanon/mz93-documentation
**URL:** https://infozone.atlassian.net/wiki/spaces/MD93/pages/205035274/Workflow+Bridge+Batch+Forwarding+Agent+Configuration
**Categories:** chunks_index.json

To open the Workflow Bridge forwarding agent configuration, click Build  New Configuration . Select Workflow from the Configurations dialog. Select Batch as the workflow type. Click Add agent and select Workflow bridge from the Processing tab of the Agent Selection dialog. Open Workflow Bridge forwarding agent configuration dialog for a batch workflow Setting Description Setting Description Profile This is the profile to use for communication between the workflows. For information about how to configure a Workflow Bridge profile, see Workflow Bridge Profile . Workflow Bridge supports one or several batch forwarding workflows connected to one or several collection workflows. Workflows in the same workflow configuration can use different profiles. For this to work, the profile must be set to Default in the Workflow Table tab found in the Workflow Properties dialog. For further information on the Workflow Table tab, see Workflow Table . To sel ect a profil e, click on the Browse... button, select the profile to use, and then click OK . Stream ID Workflow Bridge collection and forwarding agents use Stream IDs to manage connections between multiple workflow instances. Instead of creating separate profiles for each pair of workflows, you can use a single profile and assign a Stream ID to ensure that the correct workflows are linked. This is particularly useful when scaling your system, as it allows new workflow instances to automatically find their corresponding counterparts. Example  Configuring a Stream ID in Workflow Bridge Collection and Forwarding Agents Scenario: You need to scale your system by adding multiple instances of connected workflows. Instead of manually configuring separate Workflow Bridge profiles for each instance, you can use Stream IDs to automatically pair workflows. For example, if three processing workflows (A, B, and C) need to send data to three corresponding collection workflows (X, Y, and Z), you can define stream IDs like "A-X", "B-Y", and "C-Z". This ensures each processing workflow sends data to the correct collection workflow while maintaining a simpler, more scalable configuration.

---

# Document 1805: TLS Configuration Properties - MediationZone Documentation 9.3 - InfoZone

**Source:** ratanon/mz93-documentation
**URL:** https://infozone.atlassian.net/wiki/spaces/MD93/pages/204678627/TLS+Configuration+Properties
**Categories:** chunks_index.json

The TLS support uses a keystore file, generated by using the Java standard tool keytool . For further information about keytool , see the JDK product documentation. TLS is configured with properties that are typically set on the container level. Note! Quotes and double quotes surrounding the target path and property names are required for some properties to prevent overwriting. For further information, see Working with STR . The available properties are: p ico.rcp.tls.keystore Use this property to set keystore path and to enable use of TLS for all RCP connections that are not from the local host. If this property is not set, TLS will not be used. $ mzsh topo set 'topo://container:<container>/val:common."pico.rcp.tls.keystore"' <keystore path> pico.rcp.tls.keystore.alias Use this property if the keystore contains multiple private keys. RCP will prefer to use the key with this keystore alias. If it is not set and the keystore contains more than one private key, it is undefined which key is used. $ mzsh topo set 'topo://container:<container>/val:common."pico.rcp.tls.keystore.alias"' <alias> pico.rcp.tls.keystore.password Use this property to set the password for the keystore, as selected in keytool. $ mzsh topo set 'topo://container:<container>/val:common."pico.rcp.tls.keystore.password"'  `mzsh encryptpassword <password>` pico.rcp.tls.key.password Use this property to set password for the key, as chosen in keytool . By default this is the same as the keystore password. (This is the default for keytool ). $ mzsh topo set 'topo://container:<container>/val:common."pico.rcp.tls.key.password"'  `mzsh encryptpassword <password>` pico.rcp.tls.require_clientauth Use this property if client authentication (two-way authentication) is required. The default value is false . $ mzsh topo set 'topo://container:<container>/val:common."pico.rcp.tls.require.clientauth"' true

---

# Document 1806: Out-maps - MediationZone Documentation 9.3 - InfoZone

**Source:** ratanon/mz93-documentation
**URL:** https://infozone.atlassian.net/wiki/spaces/MD93/pages/204678321
**Categories:** chunks_index.json

Out-maps are used in encoders to map an internal format to an external format. Example - out_map internal IFormat1 { int f1; ascii f2; }; external EFormat1 { ascii f1 : static_size(2), terminated_by(" "); ascii f2 : static_size(10), terminated_by(" "); }; out_map OutMap : internal(IFormat1), external(EFormat1) { automatic; }; The automatic mapping for out-maps only attempts to bind every field name of the external format to the respective internal format. Just as with the in-maps, no additional formats or fields are created. Like the in-maps, out-maps support explicit mappings. As for in-maps, specially named options can also be supplied in the out_map depending on the type of the external format. The type specific options are: Option Description Option Description PER_aligned Only applicable for ASN.1 based formats. Specifies that PER encoding (ALIGNED version) is to be used. PER_unaligned Only applicable for ASN.1 based formats. Specifies that PER encoding (UNALIGNED version) is to be used. Optional Fields There are some additional considerations for the case where optional external fields are encoded. An internal field can be defined as optional, enabling to encode the corresponding external field as not present. Internal fields with value null may still be considered present and are encoded as, for instance, an empty string. To override this, use the APL command udrUnsetPresent prior to encoding. Consider the following example, where an optional field within an incoming ASN.1 record is encoded (the definition of myInt varies). Example - Encoding Optional Fields asn_block { main_udr ::= SEQUENCE { fieldA [APPLICATION 5] INTEGER OPTIONAL }; }; in_map inM : external( main_udr ), internal( myInt ) { automatic; }; out_map outM : internal( myInt ), external( main_udr ) { automatic; }; decoder myDEC : in_map( inM ); encoder myENC : out_map( outM ); Case 1 - Optional internal field: If fieldA is defined as optional in the internal format definition, it will be present in the encoded record if it was present in the internal record, even if the value is null . It will not be present if it was not present in the internal record. internal myInt { int fieldA : optional; }; Case 2 - Mandatory internal field: If fieldA is defined as mandatory in the internal format definition, it is always present in the encoded record. internal myInt { int fieldA ; }; Case 3 - No mapped internal field: internal myInt { };

---

# Document 1807: Preparing JDBC Drivers - MediationZone Documentation 9.3 - InfoZone

**Source:** ratanon/mz93-documentation
**URL:** https://infozone.atlassian.net/wiki/spaces/MD93/pages/204669932/Preparing+JDBC+Drivers
**Categories:** chunks_index.json

This section covers post-installation steps that are required when using an Oracle, Oracle RAC, PostgreSQL, or SAP HANA platform database. It includes the following subsections: Oracle Connection Oracle RAC Connection PostgreSQL Connection SAP HANA Connection

---

# Document 1808: Error Correction System (ECS) - MediationZone Documentation 9.3 - InfoZone

**Source:** ratanon/mz93-documentation
**URL:** https://infozone.atlassian.net/wiki/spaces/MD93/pages/205881850
**Categories:** chunks_index.json

MediationZone contains a storage repository called the Error Correction System (ECS), which is used for erroneous UDRs and batches. UDRs can be tagged with a configurable case and routed to an ECS Forwarding Agent for storage in ECS at any point in the mediation flow, as shown in the workflow below. Open Erroneous UDRs routed to ECS

---

# Document 1809: Netezza - MediationZone Documentation 9.3 - InfoZone

**Source:** ratanon/mz93-documentation
**URL:** https://infozone.atlassian.net/wiki/spaces/MD93/pages/204998522/Netezza
**Categories:** chunks_index.json

This section contains information that is specific to the database type Netezza. Supported Functions The Netezza database can be used with: sqlexec (APL) SQL Loader Agent For data loading, it is recommended that you use the SQL Loader Agent. You can also use APL function sqlExec for both data loading and unloading. For information on how to use sqlExec with Netezza see the section below, APL Examples. For further details, see also the IBM Netezza Data Loading Guide. Preparations This section describes preparations that you must perform before attempting to connect to a Netezza database. A driver, provided by your IBM contact, is required to access the Netezza database. This driver must be stored on each host (Platform or EC) that will connect to a Netezza database. For MediationZone to access the Netezza database, follow the steps below: Copy the Netezza files to the directory MZ_HOME/3pp in the Platform or EC. Restart the Platform and EC for the change to take effect. APL Examples This section gives examples of how to use the APL function sqlExec with a Netezza Database profile. Example - Load data from an external table on the Netezza database host initialize { int rowcount = sqlExec("NETEZZA.NetezzaProfile", "INSERT INTO mytable SELECT * FROM EXTERNAL '/tmp/test.csv' USING (delim ',')"); } Example - Load data from an external table on the EC host initialize { int rowcount = sqlExec("NETEZZA.NetezzaProfile", "INSERT INTO mytable SELECT * FROM EXTERNAL '/tmp/test.csv' USING (delim ',' REMOTESOURCE 'JDBC')"); } Example - Unload data to an external table on the EC host initialize { int rowcount = sqlExec("NETEZZA.NetezzaProfile", "CREATE EXTERNAL TABLE '/tmp/test.csv' USING (DELIM ',' REMOTESOURCE 'JDBC') AS SELECT * FROM mytable"); }

---

# Document 1810: Avro Types and UDRs - MediationZone Documentation 9.3 - InfoZone

**Source:** ratanon/mz93-documentation
**URL:** https://infozone.atlassian.net/wiki/spaces/MD93/pages/205684981
**Categories:** chunks_index.json

Types mapping Types described in the Avro specification have to be mapped to types present in the MediationZone platform. You can find the mapping in the table below: Avro type Corresponding MZ type null null boolean boolean int int* long long* float float* double double* string string record AvroRecordUDR enum AvroEnumUDR fixed AvroFixedUDR *Numeric types need casting while preparing data for encoding. See Avro Decoder Example example to see the usage. UDRs The following UDRs should be used while working with Avro Decoder/Encoder AvroDecoderUDR AvroDecoderUDR is used as an input for Avro Decoder. The following fields are included in the AvroDecoderUDR : Field Description data (bytearray) This field contains a binary encoded avro message payload. This should be just a message payload without any metadata. readerSchemaID (string) Avro Reader SchemaID - ID of the compatible schema used for reading data writerSchemaID (string) Avro Writer SchemaID - schema used for encoding the message DynamicAvroUDR DynamicAvroUDR is an output of Avro Decoder. It consists of only one field called data . The type of data field depends on a schema used for decoding operation. It can be both primitive or complex type. See https://infozone.atlassian.net/wiki/spaces/MD92/pages/182648833/Avro+Types+and+UDRs#Types-mapping for mapping Avro types to MediationZone type. Example If type of the top element in a schema is record then the field type of data will be AvroRecordUDR and if type is string then the field type of data will be string. See Avro Decoder Example to see an example usage of this UDR. The following fields are included in the DynamicAvroUDR : Field Description data (any) Contains content decoded using a decoder AvroEncoderUDR AvroEncoderUDR is used as an input for Avro Encoder. The following fields are included in the AvroEncoderUDR : Field Description data (any) This field contains a UDR/type to be encoded using a selected schema writerSchemaID (string) Avro Writer SchemaID - schema used for encoding the message AvroEnumUDR AvroEnumUDR is used to represent Enum avro type. The following fields are included in the AvroEnumUDR : Field Description fullname (string) Name of the enum field (example example.avro.myFixed) symbol (string) Selected value of the specific enum type AvroFixedUDR AvroFixedUDR is used to representive Fixed avro type. The following fields are included in the AvroFixedUDR : Field Description bytes (bytearray) Byte value of the field fullname (string) Name of the fixed field (example example.avro.myFixed) AvroRecordUDR AvroRecordUDR is used to represent Avro Record structure. The following fields are included in the AvroRecordUDR : Field Description fields (map<string,any>) Map containing fields of the record. fullname (string) Name of the record including the namespace (example example.avro.User3)

---

# Document 1811: Charging Gateway Function (CGF) 3G/4G - MediationZone Documentation 9.3 - InfoZone

**Source:** ratanon/mz93-documentation
**URL:** https://infozone.atlassian.net/wiki/spaces/MD93/pages/205658453/Charging+Gateway+Function+CGF+3G+4G
**Categories:** chunks_index.json

Definition Charging Gateway Function (CGF) is defined using the Charging architecture and principles outlined by 3GPP TS32.240 (Ref 1), and 3GPP TS32.295 (Ref 2) as the baseline. It is constructed as a set of capabilities to facilitate charging for telecom network connectivity services delivered by the CSP using 3G/4G networks (GPRS/EPC), characterized by, and limited to: CGF Architecture options Charging Data Function (CDF) integrated in the Network Element (NE), interfacing the CGF using the Ga interface (GTP). Charging Data Function (CDF) as a stand-alone element, interfacing the CGF using the Ga interface (GTP), or using an alternate supported interface Output Data Targets Billing Domain (BD) functions via the Bx, and/or vendor proprietary, interfaces Interconnect billing platforms Roaming settlement platforms Revenue Assurance systems Fraud Management systems Analytics and reporting platforms Data warehouse and data lake systems Commercial Models and purposes Direct B2C connectivity Direct B2B connectivity Telecom network inbound roaming Telecom network outbound roaming This Right to Use (RTU) grants the licensee the right to use DigitalRoutes MediationZone software in accordance with this definition.

---

# Document 1812: Command Line Tool - MediationZone Documentation 9.3 - InfoZone

**Source:** ratanon/mz93-documentation
**URL:** https://infozone.atlassian.net/wiki/spaces/MD93/pages/204613185/Command+Line+Tool
**Categories:** chunks_index.json

The Command line Tool mzsh is a command line interface to the system, and can be used to list, add and remove packages, or to regenerate and/or upgrade configurations. For further information about how to start mzsh and the available mzsh commands, see Command Line Tool Reference Guide . Loading

---

# Document 1813: Duplicate Batch Profile - MediationZone Documentation 9.3 - InfoZone

**Source:** ratanon/mz93-documentation
**URL:** https://infozone.atlassian.net/wiki/spaces/MD93/pages/204672784/Duplicate+Batch+Profile
**Categories:** chunks_index.json

The Duplicate Batch profile is loaded when you start a workflow that depends on it. Changes to the profile become effective when you restart the workflow. Configuration To create a new Duplicate Batch profile configuration, go to Build  New Configuration . Select Duplicate Batch Profile from the Configurations dialog. Duplicate Batch profile configuration Note! If the Detection Method is modified after a Duplicate Batch Detection agent has been executed, the already stored information will not match any records processed with the new profile version. The items in the menu bar may change depending on the configuration type. The Duplicate Batch profile uses the standard menu items, as described in Build View . The Duplicate Batch profile configuration contains the following settings: Setting Description Setting Description Max Cache Age (Days) Enter the number of days you want to keep the batch information in the database. Use CRC Select this checkbox to create a checksum from the batch file data. You can use this checksum when searching for duplicate batch files by comparing the files' checksums. Use Byte Count Select this checkbox to use the number of bytes in the batch files for duplicate detection. Use MIM Value Select this checkbox to use a MIM value for duplicate detection. A MIM name defined in the Named MIMs table is compared with a MIM Resource that can be connected both with batches and workflows. Note! When you use MIM values as a detection method, both empty and non-empty batches will be evaluated. The duplicate batch detection will also be performed regardless of the data on the incoming routes, as well as if there is no data on the incoming routes. This is not the case for the other detection methods. Named MIMs Click the Add button to create a list of user-defined MIM names. When the Duplicate Batch Detection agent is configured, each MIM name is assigned to one MIM Resource for which detection will be applied. Within the same workflow configuration, the profiles configured to Use MIM Value must map to the same MIM names.

---

# Document 1814: SQL Loader Agent UDRs - MediationZone Documentation 9.3 - InfoZone

**Source:** ratanon/mz93-documentation
**URL:** https://infozone.atlassian.net/wiki/spaces/MD93/pages/204609547/SQL+Loader+Agent+UDRs
**Categories:** chunks_index.json

The Route FileReferenceUDR checkbox in the configuration dialogs in the Disk , FTP and SFTP agents should be selected when using the SQL Loader agent. Route FileReferenceUDR checkbox The SQL Loader agent then forwards an SQLLoaderResultUDR containing information about loaded file, number of inserted rows, execution time and any error messages, for logging purposes. Workflow with the SQL Loader agent UDR Types The UDR types used in combination with the SQL Loader agent are FileReferenceUDR and SQLLoaderResultUDR : FileReferenceUDR The FileReferenceUDR is the UDR format used to send data from the collection agent to the SQL Loader agent. The following fi elds are included in the FileReferenceUDR : Field Description Field Description directory (string) This field states the name of the directory the data file is located in. filename (string) This field states the name of the file data should be collected from. fullpath (string) This field states the full path to the data file. OriginalData (long) This field contains the original data in byte array format. SQLLoaderResultUDR The SQLLoaderResultUDR is the UDR that the SQL Loader agent sends out after having loaded the data into the database. This UDR contains information for logging purposes that should be handled by another agent in the work fl ow. The following fi elds are included in the SQLLoaderResultUDR : Field Description Field Description errorMessage (string) This field contains any error message that might have been returned during the loading of data. executionTime (long) This field indicates the time it took to load the data into the database. filename (string) This field contains the name of the file from which data was uploaded. rowsAffected (long) This field indicates the number of affected rows. OriginalData (long) This field contains the original data in byte array format. For more information on the Ultra Format Definition Language and UDR format, refer to Ultra Reference Guide .

---

# Document 1815: HTTP Batch Agent Transaction Behavior - MediationZone Documentation 9.3 - InfoZone

**Source:** ratanon/mz93-documentation
**URL:** https://infozone.atlassian.net/wiki/spaces/MD93/pages/204673493/HTTP+Batch+Agent+Transaction+Behavior
**Categories:** chunks_index.json

Emits The agent emits commands that changes the state of the file currently processed. Command Description Begin Batch The agent will emit beginBatch before the first content of the file is routed into the workflow. The agent will also use the ECS batch service and route the data to it. End Batch The agent will emit endBatch after the final part of the file has been routed into the workflow. Retrieves The agent retrieves commands from other agents and based on them generates a state change of the file currently processed. Command Description Hint End Batch When hintEndBatch is called the agent will call endBatch as soon as the current data block has been routed from the agent. If more data is available from the web server the agent will call beginBatch and then continue to process the rest of the file. Cancel Batch If a Cancel Batch message is received, the agent sends the batch to ECS. Note! If the Cancel Batch behavior defined on workflow level is configured to abort the workflow, the agent will never receive the last Cancel Batch message. In this situation ECS will not be involved, and the file will not be moved. APL code where hintEndBatch is followed by a cancelBatch will always result in workflow abort. Make sure to design the APL code to first evaluate the Cancel Batch criteria to avoid this sort of behavior.

---

# Document 1816: FTP Collection Agent Input/Output Data and MIM - MediationZone Documentation 9.3 - InfoZone

**Source:** ratanon/mz93-documentation
**URL:** https://infozone.atlassian.net/wiki/spaces/MD93/pages/204607588/FTP+Collection+Agent+Input+Output+Data+and+MIM
**Categories:** chunks_index.json

Input/Output Data The Input/Output data is the type of data an agent expects and delivers. The agent produces bytearray types. MIM For information about the MIM and a list of the general MIM par ameter s, see Administration and Management . Publishes MIM Parameter Description File Retrieval Timestamp This MIM parameter contains a timestamp, indicating when the file transfer started. File Retrieval Timestamp is of the date type and is defined as a header MIM context type. Source Filename This MIM parameter contains the name of the currently processed file, as defined at the source. Source Filename is of the string type and is defined as a header MIM context type. Note! When collecting files from a VAX file system, the name of the source file will contain both path and filename. Source Filenames This MIM parameter contains a list of file names of the files that are about to be collected from the current collection directory. Note! When the agent collects from multiple directories, the MIM value is cleared after collection of each directory. Then, the MIM value is updated with the listing of the next directory. Source Filenames is of the list<any> type and is defined as a header MIM context type. Note! When collecting files from a VAX file system, the name of the source file will contain both path and filename. Source File Count This MIM parameter contains the number of files that were available to this instance for collection at startup. The value is static throughout the execution of the workflow, even if more files arrive during the execution. The new files will not be collected until the next execution. Source File Count is of the long type and is defined as a global MIM context type. Source Files Left This parameter contains the number of source files that are yet to be collected. This is the number that appears in the Execution Manager in Running Workflows tab in the Backlog column. Source Files Left is of the long type and is defined as a header MIM context type. Source File Size This parameter provides the size of the file that is about to be read. The file is located on the server. Source File Size is of the long type and is defined as a header MIM context type. Source Host This MIM parameter contains the name of the host from which files are collected, as defined in the Source or Advanced tabs. Source Host is of the string type and is defined as a global MIM context type. Source Pathname This MIM parameter contains the path name, as defined in the Source tab. Source Pathname is of the string type and is defined as a global MIM context type. Source Username This MIM parameter contains the login user name, as defined in the Source tab. Source Username is of the string type and is defined as a global MIM context type. Accesses The agent does not itself access any MIM resources.

---

# Document 1817: System Statistics in Desktop - MediationZone Documentation 9.3 - InfoZone

**Source:** ratanon/mz93-documentation
**URL:** https://infozone.atlassian.net/wiki/spaces/MD93/pages/205783887/System+Statistics+in+Desktop
**Categories:** chunks_index.json

The System Statistics subsystem in MediationZone collects and consolidates execution information. During execution, MediationZone continuously monitors and logs the resource utilization of the different hardware nodes and can provide reports over a given time interval. The throughput of workflows can also be monitored using this mechanism. The statistical information can be viewed graphically over any period, and be printed. The following figure shows an example of monitoring of throughput and resource utilization: Open Example of System Statistics usage In MediationZone the system statistics functionality is divided into Automatic Statistics and Customized Statistics , as described in the next coming sections.

---

# Document 1818: KDR - MediationZone Documentation 9.3 - InfoZone

**Source:** ratanon/mz93-documentation
**URL:** https://infozone.atlassian.net/wiki/spaces/MD93/pages/204742938/KDR
**Categories:** chunks_index.json

The KDR UDRs collected by the KPI Management agent hold the source data for KPI calculations. In your APL configuration, you can map the fields of this UDR type to the fields in your service model, e g metric or dimension objects. The timestamp of the KDR UDRs are used to trigger closing and opening of periods. Open Relation between KDR timestamps, Window Size, and periods The smallest timestamp among the first KDRs that are routed to KPI Management agent determines the start of the initial period for each respective KPI. The start time is calculated as: timestamp - (timestamp mod windowSize) The end of the periods are determined by period start and window size. When a KDR contains a timestamp that exceeds the end of the period and if the delay property is set to 0 (zero) the output is sent to the Workflow. The period is then closed. KDRs that are collected later and that belongs to the closed period will be skipped. In the figure above, the delay property is set to 1 (one) second. If the delay is configured to be greater than 0 then the trigger for output will be delayed until the KPI Management agent receives a timestamp that exceeds the end of the period with the added delay. This property is used to prevent that periods are closed too early due to late arriving data. The default value of this property is 0 (zero). For further information about how to set the delay property, see KPI Agent . Processed KPIs will be flushed automatically when you close a workflow. The following fields are included in the KDR UDRs: Field Type Description Field Type Description key bytearray This field is reserved for future use. timestamp long This field must contain a timestamp (e g in Unix time) time for sorting the KDR data into a time periods. The meaning of this value can be arbitrary but the contained values should be chronologically consistent. For example the timestamp may indicate either the start or end of a session but not both. type string This field must contain a string that identifies the KDR type. The type is used in the definitions of metric - and dimension objects in the service model. values map<string,any> This field must contain a map of key-value pairs where the key is an arbitrary string , and the value contains the input data. The values are used in the definitions of metric - and dimension objects in the service model. Example - Mapping input to KDR UDR in APL kpimanagement.KDR kdr = udrCreate(kpimanagement.KDR); kdr.type = input.type; kdr.timestamp = input.start_time; kdr.values = mapCreate(string, any); mapSet(kdr.values, "dimension_1", input.end_time); mapSet(kdr.values, "dimension_2", input.end_time); mapSet(kdr.values, "call_length", input.call_length); mapSet(kdr.values, "connect_latency", input.connect_latency);

---

# Document 1819: Data Veracity Profile - MediationZone Documentation 9.3 - InfoZone

**Source:** ratanon/mz93-documentation
**URL:** https://infozone.atlassian.net/wiki/spaces/MD93/pages/204738346/Data+Veracity+Profile
**Categories:** chunks_index.json



---
**End of Part 76** - Continue to next part for more content.
