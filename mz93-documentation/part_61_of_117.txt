# RATANON/MZ93-DOCUMENTATION - Part 61/112

---
**Dataset:** ratanon/mz93-documentation
**Part:** 61 of 112
**GitHub:** https://github.com/ratan0n/docs/tree/main/mz93-documentation
**Size:** ~70.0 KB
---

To open the HTTP/2 Server agent configuration dialog from a workflow configuration, you can do either one of the following: double-click the agent icon select the agent icon and click the Edit button The Agent Configuration consists of the following tabs: 1 Server Tab 2 Overload Protection Tab 3 OpenAPI Tab 4 5G Tab 5 Authentication Tab Server Tab Open HTTP/2 Server Agent Configuration - Server tab The Server tab contains the following settings: Setting Description Setting Description Settings Use SSL Select this option to use the SSL. Security Profile Enable 2-way Authentication If you have selected to use SSL, you can select this option to enable 2-way Authentication. If this option is selected, the Security Profile used must be configured using Java Truststore. Host Enter the IP address or hostname that you want the agent to bind to. Port Enter the port number you want the agent to bind to. Request Handling Default connection concurrent streams Fundamentally HTTP/2 is designed to make it easy for a client to send multiple parallel requests. Each request is entitled to a thread and if blocking APIs are used, then there are many ways a client can cause that thread to block. To handle the resource problem this can cause, the setting Default connection concurrent streams can be used. The setting specifies the maximum number of concurrently open streams allowed per single HTTP/2 connection. The default value uses in Jetty HTTP/2 server is 128. Larger values increase parallelism, but cost a memory commitment. Route Error to APL Select this option if you want to route HTTP errors to APL for custom handling. For more information on how to handle the error using APL, refer to Route Error to APL . Use Context Cache Select this option if you need to route HttpRequestCycle udrs to workflows running on different picos. There will be one entry per http request received by the http2 server agent. The cache can be configured with maximum size and maximum time an entry can exist in the cache. Max Cache Size Maximum number of http contexts that will be temporally saved on pico that the workflow is running on. A cache entry is removed when the server sends a http response or when a cache timeout has happened for this specific entry. Max Cache TTL(ms) Maximum time an entry can be saved in the cache. Important: if the time needed for processing a request is greater than Max Cache TTL - a response may not be sent back. Timeout Client Timeout (sec) The period in seconds after which the HTTP/2 Server should close the connection if a client is inactive. That is, this is the period of inactivity from when the client has opened the connection or received the last expected response until the server should close the connection. For example, if Client Timeout is set to 6, this means that the server will close the connection if the client is inactive for 6 seconds. Server Timeout (sec) The period in seconds before which the HTTP/2 Server has to reply to a request. That is, this is the period within which a server has to process a request and send a response to a client. If the time limit is reached, an error response with a status code of 500 will be sent. Responses Default Charset Select the character set you want to use as default character set. UTF-8 is preselected. This character set will be used if the character set requested by Accept-Charset is not found in system. GZIP Compression Level If gzip is requested, then the response will be be gzipped with the compression level you specify in this field, 1-9. Route Error to APL When enabling Route Error to APL, you will send the request over as part of the RequestCycle UDR where you will then be able to use the Analysis agent to customize your own response. The example shown below has an If statement to catch any requests with errors by checking for isError that are set to True . The APL code will then go on to populate the response and route it back to the HTTP/2 Server agent. import ultra.openapi.Test_5G.TS29510_Nnrf_NFDiscovery; consume { http.RequestCycle cycleUdr = (http.RequestCycle) input; debug("input from client n" + cycleUdr); ProblemDetails problemDetails = udrCreate(ProblemDetails); http.Response response = udrCreate(http.Response); if (cycleUdr.isError) { // cycleUdr.isError will be true if any errors is encountered while processing the request list<string> headers = listCreate(string); listAdd(headers, "application/problem+json"); mapSet(response.headers, "Content-Type", headers); problemDetails.title = "Request Error"; problemDetails.cause = cycleUdr.errorMessages[0]; // cycleUdr.errorMessages is a list containing error messages set from the error encountered problemDetails.status = cycleUdr.errorStatusCode; // cycleUdr.errorStatusCode contains the status code of the error encountered response.openAPIUDR = problemDetails; response.statusCode = cycleUdr.errorStatusCode; } cycleUdr.response = response; debug("after apl logic n" + cycleUdr); udrRoute("to_server", cycleUdr); Overload Protection Tab Open HTTP/2 Server Agent Configuration - Overload Protection tab The Overload Protection tab controls overload protection and contains the following settings: Setting Description Setting Description Enable Overload Protection Select this option to enable overload protection. Number of Requests If you have selected enable overload protection, enter the maximum number of requests that are allowed to be sent during the time specified in Average Period (sec) . When this number of requests has been reached, further requests will be blocked until the time specified in Wait Duration (sec) has passed, then a retry will be attempted. Period (sec) Enter the time in seconds for which the number of requests should be counted. Wait Before Retry (sec) Enter the number of seconds to wait before attempting to retry a request. OpenAPI Tab Open HTTP/2 Server Agent Configuration - OpenAPI tab The OpenAPI tab contains the following settings: Setting Description Setting Description OpenAPI Use OpenAPI Profile Select this option if you want the agent to use the OpenAPI profile(s). OpenAPI Profile Browse and select the profiles to be used. This field is enabled when the Use OpenAPI Profile option is selected. Click Add to browse for the available OpenAPI profiles. Caution! There are no limits to the number of profiles users can select. However, by selecting a large number of OpenAPI profiles will have significant impact on the overall performance of the workflow. Enable Validation Select this option if you want to validate the OpenAPI profile. Warning! Turning this option ON will have a very significant performance impact on the overall performance of the flow. When validation is enabled, each payload will be validated against the Open API schema, an operation that can be very resource-intensive. We recommend enabling this setting only during development and testing and disabling it in a stable production environment. Note! Strict validation is applied against the OpenAPI specification due to the upgrade of third-party libraries. For Example, if the response contains the body but the schema doesn't expect the response to contain the body then it will cause validation failure. Refer to this link for further information https://bitbucket.org/atlassian/swagger-request-validator/issues/246/validator-does-not-check-a-response-body Override Error Response Override Error Response on Server Shutdown Select this option to enable the customization of the HTTP response for when a request to the server is received upon the server being terminated. Override Error Response on Server Overload Select this option to enable the customization of the HTTP response for when a request to the server is received upon the server being overloaded. Note! Overload protection should be enabled to utilize this feature. Status Code The HTTP error code for the error response. The default error code set is 503 for server shutdown and 429 for server overload. Content Type Enter the media type to be used as part of the HTTP header for the response. The default media type is "application/problem+json". UDR Type Browse for the UDR that will be populated as part of the HTTP response message. UDR Field The fields in the selected UDR Type will be shown in this column. Type The data type for the each of the UDR fields will be shown here. supports the following data type: String BigInt Boolean Int Value Enter a value that conforms to the data type of the UDR field. The value will then be parsed into the HTTP response when the error is triggered. 5G Tab Open HTTP/2 Server Agent Configuration - 5G tab The 5G tab contains the following settings: Setting Description Setting Description 5G Use 5G Profile Select this option if you want the agent to use a 5G profile. 5G Profile Browse and select the profile to be used. This field is enabled when the Use 5G Profile option is selected. NRF Address (Primary) Enter one or more primary NRF (NF Repository Function) address in this list. Additional NRF Address Settings (Secondary) Enable Fall Back (Reconnect to primary address when it is available) Select this option to have the agent reconnect to the primary NRF address from the secondary address. The agent will send a heartbeat repeatedly to the primary NRF address to determine its availability. NRF Address (Secondary) Enter one or more secondary NRF (NF Repository Function) address in this list, this is to allow for alternative connections when the heartbeat with the primary NRF Address is not established. Examples The following are examples of how multiple NRF addresses could be configured. Example - Configuring Multiple Primary NRF Addresses Use the primary and secondary NRF addresses below as reference to the following examples. Primary NRF Address (P1) contains a Secondary NRF Address (S1) (P1) http://localhost:8000 contains (S1) http://localhost:8001 Primary Address (P2) (P2) http://localhost:9000 Example 1 - Successful connection to all primary addresses Address P1 S1 P2 Address P1 S1 P2 Availability Result Connected Connected Example 2 - Connect to secondary address when primary address is unavailable Address P1 S1 P2 Address P1 S1 P2 Availability Result Connected Connected Example 3 - Connect to all remaining primary addresses when any of the primary and secondary addresses are unavailable Address P1 S1 P2 Address P1 S1 P2 Availability Result Connected Note! When the primary (P1) and secondary (S1) addresses are unavailable, the system will not attempt to reconnect. Users are required to re-initiate the workflow to reconnect. Example 4 - All primary and secondary addresses are unavailable upon initiating the workflow Address P1 S1 P2 Address P1 S1 P2 Availability Result The workflow is aborted. Note! Configuring multiple primary and secondary NRF addresses in a workflow in the legacy desktop When multiple primary NRF addresses are used in a workflow, the workflow table in the legacy desktop shows the primary and secondary NRF addresses in the following manner: Open Each primary NRF address and its secondary NRF addresses are displayed in corresponding to the respective row. In the example above, the first primary NRF address contains three secondary NRF addresses. These pairs are displayed in the first row of each table. While each primary NRF address is listed vertically in the table, secondary NRF addresses are listed within the same row, separated by commas. Proxy Support If a proxy server is needed to reach NRF servers please look at HTTP Proxy Support in order to configure the proxy. Authentication Tab The Authentication tab contains settings for the following Authentication types: Static Dynamic Below are the supported algorithm for OAuth 2.0: ES256 ES384 ES512 RS256 RS384 RS512 Static Open Selecting Static will provide the following settings: Setting Description Setting Description Use Token Authentication Select this option if you want to use token authentication. Access Token Required Select this option if you want the JSON Web Token (JWT) access token to be verified against the public key. Public Key Public key used for decoding JSON Web Token (JWT) access token. When setting the Authentication Level of the workflow table, the different levels represent different settings as shown below: Authorization Level Use Token Authentication Access Token Required Authorization Level Use Token Authentication Access Token Required None No No Optional Yes No Required Yes Yes Dynamic Open Selecting Dynamic will provide the following settings: Setting Description Setting Description Setting Description Setting Description Settings JWKS URI This is the JSON Web Key Set (JWKS) endpoint of an OpenID Connect (OIDC) server that returns JWKS as JSON objects and MUST use the https scheme. For example, https://<server_domain>/.well-known/jwks.json Note! Access token received in response MUST contain the following. If the access token does not have any of these, it will result in an error: Header: typ, alg, kid Payload: iss, sub, jti, iat, exp, client_id, scope Timeout Request Timeout (sec) Timeout period in seconds for the request to the OpenID Connect (OIDC) server to wait for a response before timing out. The default value is 10 seconds. Read Timeout (sec) Timeout period in seconds for reading from OpenID Connect (OIDC) server before timing out. The default value is 5 seconds. Cache Settings Info! Cached response (JSON Web Key or JWK) from JWKS URI endpoint are for performance reason. It is used to minimise the need to query JWKS URI endpoint. It is advisable to follow OpenID Connect (OIDC) server key rotation policy. Cache Duration (sec) Time in seconds for the duration of the cache. The default value is 86400 seconds. Cache Size Total number of JWKs to be cache that are returned from JWKS URI. The default value is 30.

---

# Document 1424: Radius Client Agent - MediationZone Documentation 9.3 - InfoZone

**Source:** ratanon/mz93-documentation
**URL:** https://infozone.atlassian.net/wiki/spaces/MD93/pages/205653744/Radius+Client+Agent
**Categories:** chunks_index.json

The Radius Client agent sends radius requests to one or many Radius servers. You include the Radius Client agent in a workflow in order to transmit requests from the workflow. During runtime, a Radius UDR that includes a request field that is assigned with a value is routed into the Radius Client agent. When the answer field is assigned, the Radius UDR is routed back. Open Example Radius Client Workflow The Radius Client agent supports IPv4 and IPv6 environments. When combined with the Radius Server agent, MediationZone operates as a Radius Proxy. This section includes the following subsections: Radius Client Agent Configuration Radius Client Agent Input/Output Data and MIM Radius Client Agent Messages

---

# Document 1425: SAP CC Online Agent Configuration - MediationZone Documentation 9.3 - InfoZone

**Source:** ratanon/mz93-documentation
**URL:** https://infozone.atlassian.net/wiki/spaces/MD93/pages/204609065
**Categories:** chunks_index.json

You open the SAP CC Online agent configuration dialog from a workflow configuration. To open the SAP CC Online agent configuration, click Build  New Configuration . Select Workflow from the Configurations dialog. When prompted to Select workflow type , select Realtime . Click Add agent and select SAP CC Online from the Agent Selection dialog. Connection Tab The Connection tab contains configuration data that is required to connect to a re mo te s erve r. Open SAP CC Online agent configuration dialog - Connection tab Setting Description Setting Description Hosts In this section, add IP address/hostname and external charging port of at least one SAP Convergent Charging Core server Dispatcher Instance. The SAP CC Online agent will try to connect to the listed hosts until a connection is successfully established with one of them. Note! When Hosts is set to Default or Per Workflow in Workflow Properties, you can specify multiple hosts in the workflow table. Each host must be separated by a semi-colon. For example: host1:2000;host2:2000 . Note! If you upgrade, or import a configuration, from a version previous to MedationZone 7.2, the Host and Port settings are no longer included in the workflow table for your workflow. Instead, you must manually configure the Hosts setting in the Workflow Table tab in the Workflow Properties dialog. Connection Settings Enable Authentication Select this check box to enable charging API authentication. Note! Charging API Authentication is only available for SAP CC version 4.1 SP2 and later. User Name SAP CC user id Password The password for the SAP CC user Timeout The timeout (in milliseconds) to apply for each charging request. This value corresponds to the maximum time that SAP CC can take to execute one charging request. Enable Secured Connection Select to use TLS encrypted communication with Hosts . For more information about setting up Secured Connection, refer to SAP CC Secured Connection . Keystore Path The path to the keystore on an Execution Container host. The path must be the same for all hosts. Note! The keystore format to be used by this particular agent is PKCS12 only. Keystore Password The password of the keystore. Advanced Setting s T ab The Advanced Settings tab contains configurations rel ated to charging request behavior. Open SAP CC Online agent configuration dialog - Advanced tab Setting Description Setting Description Default charging properties Transaction Set to Return This parameter controls the content of the charging answer. Select No Transaction if no details shall be returned in the charging answer. Only the status (success or failure) and the price will be returned. Select Master Transaction if the details of the price computation shall be returned in the charging answer. It includes user defined notification that may be raised by the price plan. This applies only to the master transaction. Select All Transactions if the details of the price computation shall be returned in the charging answer. It includes user defined notifications that may be raised by the price plan. This applies only to the master and dependents transactions. Select All Transaction and Recurring if the details of the price computation shall be returned in the charging answer. It includes user defined notifications that may be raised by the price plan. This applies master transactions and dependents, but also one-shot- and recurring transactions, which may be triggered by the usage event. In Session Cleanup Transaction Set to Return This parameter controls the content of the charging answer in the case a session cleanup occurred during a charging request. The same value as for Transaction Set to Return applies here. Session Time To Live Defines the default session 'time to live' (in seconds) for the session charging request. This is the time period during which a session is considered active if no updates occurred. Default Session Resolution This parameter controls the default session termination to apply when a session has reached its 'time to live'. The session (in fact, the last reservation) could be either: Cancelled - Cancel Confirmed - Confirm Reservation Renewal Listener Listen For Reservation Renewal Events Select to listen for Reservation Renewal Events from SAP Convergent Charging. Listener Identifier Identifies the listener that the client binds to in order to receive Reservation Renewal Events. The Listener Identifier registered by an agent must be in the range of 1 to 127. If several agents use the same Listener Identifier the first agent to register will receive the events. If the first agent to register the Listener Identifier becomes unavailable, the second agent to register will receive the events. Spending Status Monitoring Listen For Spending Status Reports Select to listen for Spending Status Reports from SAP Convergent Charging. Listener Identifier Identifies the listener that the client binds to in order to receive Spending Status Reports. The Listener Identifier registered by an agent must be in the range of 1 to 127. If several agents use the same Listener Identifier the first agent to register will receive the events. If the first agent to register the Listener Identifier becomes unavailable, the second agent to register will receive the events. Default Monitoring Listener Identifier This is the default ID that will be used for the monitoring session. Default Monitoring Session TTL This is the default Time To Live value (in seconds) that will be used. Debugging Enable Debug Events Select this check box to enable debug mode. Useful for testing purposes. Response Data Convert Bigdecimal Response to String Select this check box to allow conversion of the BigDecimal data type from the SAP Convergent Charging response into string. By default, the check box is empty. Note! In terms of backwards compatibility, enabling this option prevents any compatibility issues with workflows that support the configurations from before the BigDecimal data type was introduced in version 8.0.5.0. Flow Control Tab The Flow Control tab contains configurations required to control the request flow with Con verg ent Charging Core Server. Canceled - Cancel Confirmed - Confirm Open SAP CC Online agent configuration dialog - Flow Control tab Setting Description Setting Description Enable Flow Control This parameter determines if the flow controller is activated or not on the SAP CC Stateful Service Client. Queue Properties Queue Size This parameter controls the maximum number of waiting requests to be executed by the SAP Convergent Charging core server. This is mandatory to make sure that the core server is not flooded with too many requests. Requests that cannot fit in the queue wait until the size reaches the Re-accept Request Threshold parameter explained below. The value of this parameter depends on: The total number of incoming requests that can be handled by the available SAP CC Dispatchers (refer to the description of the SAP CC STATEFUL_SERVICE_QUEUE_SIZE parameter) The number of SAP CC Stateful Service Clients connected within the different workflows. Note! Take into account that additional SAP CC Stateful Service Clients may exist in the overall landscape. Example - Setting the queue size Consider the following scenario: A SAP CC landscape can handle 30000 requests using 3 Dispatchers, each configured with a queue size set to 10000. 5 connected SAP CC Stateful Service Clients The maximum queue size for all the flow controllers should be set to a value that is lower than 30000 requests (e.g. 25000), and thus, the Queue Size for each SAP CC agent can be set to 5000 requests. In addition, the Re-accept Request Threshold value can be set to 4995. Re-accept Request Threshold This parameter defines the threshold of the queue below which waiting requests are processed again. This parameter is only relevant when some requests are waiting because the queue has reached its size. Note! It is strongly recommended to activate flow control in a production system. The SAP CC Online agent relies on the Asynchronous CC client and if no control is enabled, the agent will send as many requests as possible to the SAP Convergent Charging core server, which could lead to two unexpected behaviors: Increased latency of charging requests. An unstable server that will not be able to answer the requests. Monitoring Event Tab The Monitoring Event tab contains configurations for sending an event related to latency, for example, the number of successfully processed UDRs, erroneous UDRs, and so on. The monitoring information is sent through a CC Monitoring Event. For further information about how to set up the CC Monitoring Event, see Event Notifications . It is recommended that you do not enable these monitoring features in a p roduc tion landscape. Open SAP CC Online Agent Configuration - Monitoring Event Tab Setting Description Setting Description Enable Global Event Select to send a CC Monitoring Event when the Workflow is stopped. Enable Spot Event Select to send a CC Monitoring Event with a configured frequency, see Spot Frequency below. Spot Frequency Configure the frequency (in seconds) for how often a CC Monitoring Event shall be sent. Default frequency is 1000 second.

---

# Document 1426: Configuring Properties - MediationZone Documentation 9.3 - InfoZone

**Source:** ratanon/mz93-documentation
**URL:** https://infozone.atlassian.net/wiki/spaces/MD93/pages/204638117/Configuring+Properties
**Categories:** chunks_index.json

In each Execution Container, open the pcc.properties file, located in the MZ_HOME/etc directory, and enter the names of your newly created profiles in the following properties: mz.pcc.storage.redis.config.profile= mz.pcc.storage.redis.buckets.profile= Example - mz.pcc.properties mz.pcc.storage.redis.config.profile=MyFolder.config mz.pcc.storage.redis.buckets.profile=MyFolder.bucket In the PCC Config Storage Properties group, ensure that the property mz.pcc.config.storage.class is set to com.digitalroute.pcc.storage.config.redis.RedisConfigStorage . In the PCC Bucket Storage Properties group, ensure that the property mz.pcc.bucket.storage.class is set to com.digitalroute.pcc.buckets.storage.redis.RedisBucketStorage. Save the pcc.properties file. In order for the ECs to be able to locate the pcc.properties file, you must set the Execution Context property mz.pcc.properties . $ mzsh topo set topo://container:<container>/pico:<pico>/val:config.properties.mz.pcc.properties <path> Example - mz.pcc.properties $ mzsh topo set topo://container:exec1/pico:ec1/val:config.properties.mz.pcc.properties '${mz.home}/"etc/pcc.properties"' $ mzsh topo set topo://container:exec1/pico:ec2/val:config.properties.mz.pcc.properties '${mz.home}/"etc/pcc.properties"' Important! It is important that the pcc.properties property file is located in the stated directory in all Execution Containers. Restart the ECs. For further information about the settings in the Redis profile, see Redis Configuration in PCC System Administration .

---

# Document 1427: GCP PubSub Profile - MediationZone Documentation 9.3 - InfoZone

**Source:** ratanon/mz93-documentation
**URL:** https://infozone.atlassian.net/wiki/spaces/MD93/pages/205652789
**Categories:** chunks_index.json

The GCP PubSub Profile is used for setting up the Google PubSub Subscription and Topic for a Google Cloud Project. This profile requires the GCP Profile to establish a connection with the GCP Service. Currently, the profile can be used with the following agents: GCP PubSub Subscriber agent Menus The contents of the menus in the menu bar may change depending on which configuration type has been opened in the currently displayed tab. The GCP PubSub Profile uses the standard menu items and buttons that are visible for all configurations, and these are described in Build View . The Edit menu is specific for the GCP PubSub Profile configurations. Item Description Item Description External References Select this menu item to enable the use of External References in the GCP PubSub Profile configuration. This can be used to configure the following fields: Project Subscription Topic For further information, see Using External Reference in Agent Profile Fields and External Reference Profile . Configuration The following settings are available when you have selected Use Json File as the Input Option in the GCP Profile. Open GCP PubSub Profile Setting Description Setting Description GCP Profile Choose the GCP Profile that contains the Service Account key that will authenticate the GCP PubSub Subscriber agent. Project The GCP Project namespace contains the PubSub subscription and associated topics. Subscription The ID of the subscription. A subscription directs messages on a topic to subscribers. Messages can be pushed to subscribers immediately, or subscribers can pull messages as needed Topic The name of the PubSub topic that you want the Subscriber agent to retrieve messages from or pull from the Publisher agent. A topic forwards messages from publishers to subscribers.

---

# Document 1428: HTTP Proxy Support - MediationZone Documentation 9.3 - InfoZone

**Source:** ratanon/mz93-documentation
**URL:** https://infozone.atlassian.net/wiki/spaces/MD93/pages/204613057
**Categories:** chunks_index.json

MediationZone can be configured to route outgoing HTTP traffic through an HTTP proxy. This is commonly required in networking environments where the execution context has limited access to the internet. Proxy configuration has to be performed on each Execution Context (EC) that is required to route HTTP traffic through a proxy. Proxy support is available for: HTTP APL functions HTTP Batch agent GCP agents HTTP/2 Client agent Salesforce Streaming agent Web Services agents This page has the following sub-sections: 1 Configuring Proxy Support 2 Authenticating the Proxy 3 Example Configuration Configuring Proxy Support Standard Java system properties are used to configure MediationZone to route HTTP traffic through an HTTP proxy. These properties must be configured at the Execution Context (EC) level for all execution contexts. Refer to proxy properties here: Execution Context Properties . It is often necessary to provide a list of destinations that should not be routed through the proxy. This list can be configured using the proxy property http.nonProxyHosts . Note that this property, despite the name, applies to both http and https traffic. Authenticating the Proxy MediationZone supports basic authentication to HTTP proxy. The username and password are configured using system properties. Refer to the proxy properties here: Execution Context Properties . Example Configuration Here is an example of how to configure the system properties to use an HTTP Proxy. Use the following command to edit the system properties. mzsh topo open ec1 config { classpath {} jvmargs { args=[] maxMetaspace=[ "-XX:MaxMetaspaceSize=196M" ] } properties { mz.webserver.xframeoptions=DENY pico.groups="" ec.backlog.dir="/Users/mzadmin/mz9/mz9HttpProxy/tmp" ec.webserver.port=9090 http.proxyHost=192.168.205.4 http.proxyPort=3128 https.proxyHost=192.168.205.4 https.proxyPort=3128 http.proxyUser=test http.proxyPassword=DR-4-D999C75BC7A3C4AF1B4DAA7F134EEED9 https.proxyUser=test https.proxyPassword=DR-4-D999C75BC7A3C4AF1B4DAA7F134EEED9 http.nonProxyHosts="localhost|*.foo.com" jdk.http.auth.proxying.disabledSchemes="" jdk.http.auth.tunneling.disabledSchemes="" } vendor-jvmargs { hp {} sun {} } }

---

# Document 1429: Archiving Agents MultiForwardingUDR Input - MediationZone Documentation 9.3 - InfoZone

**Source:** ratanon/mz93-documentation
**URL:** https://infozone.atlassian.net/wiki/spaces/MD93/pages/205031972
**Categories:** chunks_index.json

When the agent is set to use MultiForwardingUDR input, it accepts input of the UDR type MultiForwardingUDR declared in the package FNT. The declaration follows: internal MultiForwardingUDR { // Entire file content byte[] content; // Target filename and directory FNTUDR fntSpecification; }; The content of the MultiForwardingUDR will be stored at the path that you have set in the fntSpecification field. Use the APL functions fntAddString and fntAddDirDelimiter to set the value of this field. For further information about these functions, see 16. FNTUDR Functions APL Reference Guide . When the files are received they are written to temp files in the DR_TMP_DIR directory situated in the root output folder. The files are moved to their final destination when an end batch message is received. A runtime error will occur if any of the fields have a null value or if the path is invalid on the target file system. A UDR of the type MultiForwardingUDR which has a target filename that is not identical to its precedent is saved in a new output file. Note! After a target filename that is not identical to its precedent is saved, you cannot use the first filename again. For example: Saving filename B after saving filename A, prevents you from using A again. Instead, you should first save all the A filenames, then all the B filenames, and so forth. Archiving Example Example - Archiving This example shows the APL code used in an Analysis agent connected to a forwarding agent expecting input of type MultiForwardingUDRs. In this example, the data is being buffered in the consume block. This makes it possible to route a complete batch to multiple files from the drain block. Note that the execution context needs available memory to buffer the whole file. import ultra.FNT; bytearray data; MultiForwardingUDR createMultiForwardingUDR (string dir, string file, bytearray fileContent) { //Create the FNTUDR FNTUDR fntudr = udrCreate(FNTUDR); fntAddString(fntudr, dir); fntAddDirDelimiter(fntudr);//Add a directory fntAddString(fntudr, file);//Add a file MultiForwardingUDR multiForwardingUDR = udrCreate(MultiForwardingUDR); multiForwardingUDR.fntSpecification = fntudr; multiForwardingUDR.content = fileContent; return multiForwardingUDR; } beginBatch { data = baCreate(0); } consume { data = baAppend(data, input); } drain { //Send MultiForwardingUDRs to the forwarding agent udrRoute(createMultiForwardingUDR("dir1", "file1", data)); udrRoute(createMultiForwardingUDR("dir2", "file2", data)); } Local Archiving Example Example - Local Archiving This example shows the APL code used in an Analysis agent connected to a forwarding agent expecting input of type MultiForwardingUDRs. import ultra.FNT; MultiForwardingUDR createMultiForwardingUDR (string dir, string file, bytearray fileContent){ //Create the FNTUDR FNTUDR fntudr = udrCreate(FNTUDR); fntAddString(fntudr, dir); fntAddDirDelimiter(fntudr);//Add a directory fntAddString(fntudr, file);//Add a file MultiForwardingUDR multiForwardingUDR = udrCreate(MultiForwardingUDR); multiForwardingUDR.fntSpecification = fntudr; multiForwardingUDR.content = fileContent; return multiForwardingUDR; } consume { bytearray file1Content; strToBA (file1Content, "file nr 1 content"); bytearray file2Content; strToBA (file2Content, "file nr 2 content"); //Send MultiForwardingUDRs to the forwarding agent udrRoute(createMultiForwardingUDR ("dir1", "file1", file1Content)); udrRoute(createMultiForwardingUDR ("dir2", "file2", file2Content)); } The Analysis agent mentioned previous in the example will send two MultiForwardingUDRs to the forwarding agent. Two files with different contents will be placed in two separate sub folders in the root directory.

---

# Document 1430: Python Collection Agent Configuration - Batch - MediationZone Documentation 9.3 - InfoZone

**Source:** ratanon/mz93-documentation
**URL:** https://infozone.atlassian.net/wiki/spaces/MD93/pages/204674240/Python+Collection+Agent+Configuration+-+Batch
**Categories:** chunks_index.json

The Python collection agent configuration consists of two tabs: General and MIM . General Tab The General tab consists of three different sections: Python code for the execute block, input/output UDR types, and Interpreter configuration. Open The Python collection agent configuration - General tab Setting Description Setting Description Code Area This is the text area where you enter your code, see Python Writer's Guide for further information. Entered code will be color coded depending on the code type, and for input assistance, a pop-up menu is available. Below the text area there are line, column and position indicators. See Python Code Editor Assistance . Output Types Select the output types that you have. Output Routes Enter the routes that each output type is sent out on. Interpreter select which Python Interpreter Profile you want to use. If no selection is made the interpreter that has been set as default in the Python Manager will be used. MIM Tab In the MIM tab, you can set the MIMs that you want the Python collection agent to publish. Open The Python collection agent configuration - MIM tab Column Description Column Description Assigned Select when the MIM resource is assigned a value. Can be one of: batch - Value is assigned from the consume block. header - Value is assigned in the beginBatch block. trailer - Value is assigned in the endBatch block. global - Value is assigned from any block. Name Enter the MIM resource name. Type Select the data type of MIM resource.

---

# Document 1431: Web Service Agents - MediationZone Documentation 9.3 - InfoZone

**Source:** ratanon/mz93-documentation
**URL:** https://infozone.atlassian.net/wiki/spaces/MD93/pages/205035053/Web+Service+Agents
**Categories:** chunks_index.json

This section describes the Web Service profile and agents. The agents are collection and processing agents for real-time workflow configurations. Prerequisites The reader of this information should be familiar with: Web Services WSDL Overview Web Service is a software system that supports interaction between computers over a network. The Web Service agents communicate through SOAP in XML syntax, and use WSDL files. The Web Service agents support: Web Service Interoperability Organization Basic Profile 1.1 WSDL 1.1 XML 1.0 SOAP 1.1 Partial support of Web Service Security 1.1 HTTP 1.1 HTTP Basic Access Authentication Updatable Authorization header per request HTTPS IPv4 and IPv6 The mustUnderstand attribute is only supported in Web Service Security headers. To enable Web Service transactions : Define a Web Service (WS) profile or profiles. Include the Web Service agents and their configurations in a workflow. The Web Service Agents There are two Web Service agents that you can include in real-time workflows in the w orkflow configuration dialog : The Web Service Provider agent The Web Service Request agent Web Service Provider Agent The Web Service Provider agent works in the same way as a Service Provider, or server, in the sense that it receives requests from a client, or clients, and transfers the requests to a workflow. In a synchronous operation, when the collection agent receives a reply back from the workflow, it delivers the response to the requesting client. In an asynchronous operation the collection agent does not receive any reply, and therefore does not respond the client. Open The Web Service Provider - synchronous operation Open The Web Service Provider - asynchronous operation Web Service Request Agent The Web Service Request agent works in the same way as a Service Requester, or a client, that sends a request to a server, where a certain service is available. In a synchronous operation, when the processing agent receives a reply, it delivers the reply to its configured output. In an asynchronous operation, the requester does not receive any reply and does not deliver one, either. Open The Web Service Requester Open The Web Service Requester - asynchronous operation The section contains the following subsections: Web Service Profile Web Service Provider Agent Web Service Request Agent Web Service UDR Type Structure Web Service Example

---

# Document 1432: Setting Up the SNC - MediationZone Documentation 9.3 - InfoZone

**Source:** ratanon/mz93-documentation
**URL:** https://infozone.atlassian.net/wiki/spaces/MD93/pages/204609231/Setting+Up+the+SNC
**Categories:** chunks_index.json

The SNC (Secure Network Communcations) is available and enabled by default in the SAP RFC agent to provide additional security layer to the connection. This page contains the additional information and steps to setting up the SNC for SAP RFC Profile. Environment Preparation On all servers, update the .bashrc with the following env variables. The SNC directory is assumed to be /sapmntmz/snc. sudo sed -i -e '$a export SECUDIR=/sapmntmz/snc/sec' /home/mzadmin/.bashrc sudo sed -i -e '$a export SNC_LIB=/sapmntmz/snc/libsapcrypto.so' /home/mzadmin/.bashrc Configuration Follow the steps below to set up the required SNC. Note! You are required to replace the <values> in the following commands with your local values. Prior to setting up the SNC, ensure that the SAP tooling is installed in the /sapmntmz/snc directory. On the CM server, generate a client PSE with the following: ./sapgenpse get_pse -p cmr.pse -x cmr@e1r8 "CN=<cn_name_value>,OU=<ou_value),O=<o_value>,C=<c_value>" Create the credentials and attach them to the OS users. ./sapgenpse seclogin -p cmr.pse -x cmr@e1r8 -O mzadmin Export the certificate. ./sapgenpse export_own_cert -o cmr.crt -p cmr.pse -x cmr@e1r8 Import the certificate to the SAP RFC server. This certificate does not require a signature. The SAP RFC Server provides a signed certificate to be placed in local PSE on the CM server. ./sapgenpse maintain_pk -a E1R_SNC_Certificate.crt -p cmr.pse -x cmr@e1r8 Next, restart the platform. mzsh system stop && mzsh restart platform && mzsh system start SNC Validation Once you have completed the configuration, you can now validate the SNC by creating an RFC Profile with the SNC option selected. For more information, refer to SAP RFC Profile .

---

# Document 1433: Architecture Overview PCC - MediationZone Documentation 9.3 - InfoZone

**Source:** ratanon/mz93-documentation
**URL:** https://infozone.atlassian.net/wiki/spaces/MD93/pages/205029833/Architecture+Overview+PCC
**Categories:** chunks_index.json

The Policy Charging and Control (PCC) solution consists of the following components: MediationZone - Contains the Access, Control and Execution Zones for the execution of workflows. Real-time Data Repository - For storage of runtime information, available to any Execution Zone. This is called Data Repository throughout this document. The Policy Charging and Control solution is designed for high availability, with high throughput and low latency. The setup of the solution depends on which type of data repository you have selected: Couchbase, Redis (ElastiCache Cluster on AWS), or MySQL Cluster. PCC Setup when Using Couchbase When using Couchbase, the setup is divided into the following parts: Open PCC Architecture when using Couchbase [CZ01] and [CZ02] - Two separate Platforms Containers, their databases, and various monitoring and management processes for the collection of statistics. Two [CZs] are required for failover purposes, and one of them will be on standby. [EZ01] and [EZ02] - Two Execution Containers, hosting the pico instances, i.e. ECs, that run the workflows that are required by the PCC solution. Two are required for failover purposes. [DR01], [DR02] and [DR03] - A Couchbase cluster that contains the Data Repository where all data pertaining to processing is stored. The minimum cluster should consist of three nodes with one replication per bucket. Names within [ ] are used throughout the document to describe on what machines the corresponding function is to be installed, e g [CZ01] or [EZ01]. When the number is omitted, e g [CZ], the name refers to both [CZ01] and [CZ02] etc. This instruction is written for the recommended minimal High Availability installation of the Policy Charging and Control solution which consists of seven machines when using Couchbase. In order for the solution to be highly available, an additional process surveillance tool is required for ensuring that all processes are up and running, and for the failover of e.g. [CZ] to a different machine in case it goes down. See High Availability in PCC for more information. When Couchbase is used as a data repository, the functionality is split between a minimum of three nodes in a cluster. PCC Setup when Using Redis When using Redis for PCC in AWS, you use Amazon ElastiCache. Monitoring functions are not included in this setup. The setup is divided into the following parts: Open PCC Architecture when using Redis [CZ01] and [CZ02] - Contains the MediationZone Control Zone and various management processes for the management of the data repository. Two [CZs] are required for failover purposes, and one of them will be on standby. [EZ01+DR01], [EZ02+DR02] - Contain the Execution Zones, where the workflows are executed, as well as the Data Repository where all data pertaining to processing is stored. Two [EZs] are required for failover purposes. This instruction is written for the recommended minimal High Availability installation of the Policy Charging and Control solution. For information on how many shards to create, see https://docs.aws.amazon.com/AmazonElastiCache/latest/UserGuide/Shards.html . For information on the high availability of Amazon ElastiCache, see https://aws.amazon.com/documentation/elasticache/ . This instruction is based on the assumption that each "component" above corresponds to one machine, i.e. the names within [] are used throughout the document to describe on what machines the corresponding function is to be installed. Referring to [CZ] means the machines containing all the functions listed in that component. PCC Setup when Using MySQL Cluster When using MySQL Cluster, the setup is divided into the following parts: Open PCC Architecture when using MySQL Cluster [CZ01] and [CZ02] - Two separate Platforms Containers, their databases, and various monitoring and management processes for the collection of statistics. Two [CZs] are required for failover purposes, and one of them will be on stand-by. [EZ01] and [EZ02] - Two Execution Containers, hosting the pico instances, i e ECs, that run the worfklows that are required by the PCC solution. Two are required for failover purposes. [DR01] and [DR02] - Contains the Data Repository where all data pertaining to processing is stored. Names within [ ] are used throughout the document to describe on what machines the corresponding function is to be installed, e g [CZ01] or [EZ01] . When the number is omitted, e g [CZ], the name refers to both [CZ01] and [CZ02] etc.

---

# Document 1434: Recover - EC and SC - MediationZone Documentation 9.3 - InfoZone

**Source:** ratanon/mz93-documentation
**URL:** https://infozone.atlassian.net/wiki/spaces/MD93/pages/205657691/Recover+-+EC+and+SC
**Categories:** chunks_index.json

When the CMS receives an exit code from the monitor script that indicates failure on an EC or SC, the following measures apply: Stop the pico instance by calling the offline script. All workflows will be brought down immediately, interrupting the current batches being processed. Example $ ./offline <$JAVA_HOME> <$MZ_HOME> mzadmin ec1 Shutting down ec1...done. The pico instance should be down, but to make sure it is completely down, call the clean script. Example $ ./clean <$JAVA_HOME> <$MZ_HOME> mzadmin ec1 Start the pico instance in an alternative container. Example $ ./online <$JAVA_HOME> <$MZ_HOME> mzadmin ec1 Starting ec1...done. Note! When an EC has recovered, workflows scheduled to be activated periodically will be brought up automatically the next time they are due to start. The same applies to workflows scheduled by triggers. Note that if chains of events are configured, the counting will restart, since triggered events are kept in memory only. Unscheduled workflows are not started automatically. For this purpose, modify the online script to log in to $MZ_HOME/bin/mzsh and restart them. A service that is running in an SC may fail over to another SC. If there are no redundant SCs, or if failover is not supported by the service, it will be restarted automatically when the SC recovers .

---

# Document 1435: Limitations of porting existing DTK agents from Version 8 to Version 9 - MediationZone Documentation 9.3 - InfoZone

**Source:** ratanon/mz93-documentation
**URL:** https://infozone.atlassian.net/wiki/spaces/MD93/pages/204676531/Limitations+of+porting+existing+DTK+agents+from+Version+8+to+Version+9
**Categories:** chunks_index.json

The following is a list of limitations to be taken care of when porting existing DTK agents: All compilation errors must be resolved based on the latest generated code Classes that are no longer available in version 9: DRGeneratedFormContract.java DRAgentConfigData.java There are changes to the new generated code class structure. Some of which are no longer generated or supported. See Creating New Config Class for the supported code class structure.

---

# Document 1436: Kafka Batch Collection Events - MediationZone Documentation 9.3 - InfoZone

**Source:** ratanon/mz93-documentation
**URL:** https://infozone.atlassian.net/wiki/spaces/MD93/pages/301138211/Kafka+Batch+Collection+Events
**Categories:** chunks_index.json

Agent Events The Kafka batch collection agent has two agent events: Event Description Event Description Assigned The event is emitted the first time a workflow is started, followed by the partition/partitions it is assigned. Rebalance The event is emitted when a workflow is rebalanced, followed by the partition/partitions it is assigned. Note! Stand-by workflows do not emit any events. A stand-by workflow is a workflow that does not have any partitions assigned, which happens when there are no more available partitions. Debug Events

---

# Document 1437: Starting, Stopping and Restarting Picos - MediationZone Documentation 9.3 - InfoZone

**Source:** ratanon/mz93-documentation
**URL:** https://infozone.atlassian.net/wiki/spaces/MD93/pages/205881349
**Categories:** chunks_index.json

This page describes how to start, stop and restart picos in the Pico Management screen in Desktop. Starting Picos To start picos that are not running: Select the check box(es) for the pico(s) you want to start. Open Not started pico selected in Pico Management screen Click on the Start button. The state will change from Not-started to flashing Starting . Open When the pico has been successfully started, the state will change to Running . Open Stopping Picos To stop picos that are running: Select the check box(es) for the pico(s) you want to stop. Open Running pico selected in Pico Management screen Click on the Stop button. The state will change from Running to flashing Stopping . Open When the pico has been successfully stopped, the state will change to Not-started . Open Restarting Picos To stop picos that are running: Select the check box(es) for the pico(s) you want to restart. Open Running pico selected in Pico Management screen Click on the Restart button. The state will change from Running to flashing Restarting . Open When the pico has been successfully restarted, the state will change to Running Open and you will get a notification that the pico has been successfully restarted. Open

---

# Document 1438: Data Veracity Collection Agent Input/Output Data and MIM - MediationZone Documentation 9.3 - InfoZone

**Source:** ratanon/mz93-documentation
**URL:** https://infozone.atlassian.net/wiki/spaces/MD93/pages/204606751/Data+Veracity+Collection+Agent+Input+Output+Data+and+MIM
**Categories:** chunks_index.json

Input/Output Data The input/output data is the type of data an agent expects and delivers. The agent produces data depending on the data type of the r eproc essing group. Data Types Description Data Types Description UDR Type When the Collection agent is configured to collect the UDRs, the agent output type will be UDRType (DataVeracity). The UDRType (DataVeracity) is available in the UDR Internal Format Browser as follows: Open Batch Type When the Collection agent is configured to collect the Batch files, the agent output type will be BatchType (DataVeracity). The BatchType (DataVeracity)is available in the UDR Internal Format Browser as follows: Open MIM For information about the MIM and a list of the general MIM parameters, see Meta Infor mation Model in MIM . MIM Value Description MIM Value Description Agent Name The name of the agent. Outbound UDRs The number of UDRs routed from the agent. Accesses The agent does not itse lf access any MIM resources.

---

# Document 1439: FTP Collection Agent Configuration - MediationZone Documentation 9.3 - InfoZone

**Source:** ratanon/mz93-documentation
**URL:** https://infozone.atlassian.net/wiki/spaces/MD93/pages/205685502/FTP+Collection+Agent+Configuration
**Categories:** chunks_index.json

You open the FTP collection agent configuration dialog from a workflow configuration. To open the FTP collection agent configuration, click Build  New Configuration . Select Workflow from the Configurations dialog. When prompted to Select workflow type , select Batch . Click Add agent and select FTP from the Collection tab of the Agent Selection dialog. The Filename Sequence and Sort Order tabs are described in Workflow Template . Connection Tab The Connection tab is used to configure the remote server connection. Open The FTP Collection Agent Configuration - Connection tab Setting Description Setting Description Connection Information Host Enter the hostname or IP address of the remote host. If a connection cannot be established to this host, the Additional Hosts specified in the Advanced tab, are tried. Username Enter the username for the remote host account. Password Enter the associated password. Transfer Type Select the data transfer type to be used during file retrieval. Binary - agent uses binary transfer type. Default setting. ASCII - agent uses ASCII transfer type. Collection Retries Enable Select this check box to enable repetitive connection attempts. When this option is selected, the agent will attempt to connect to the host as many times as is stated in the Max Retries field. If the connection fails, a new attempt will be made after the number of seconds entered in the Retry Interval (s) field. Retry Interval(s) Enter the time interval in seconds, between retries. If a connection problem occurs, the actual time interval before the first attempt to reconnect will be the time set in the Timeout field in the Advanced tab plus the time set in the Retry Interval(s) field. For the remaining attempts, the actual time interval will be the number of seconds entered. Max Intervals Enter the maximum number of trial intervals. Restart Retries Settings En able Select this check box to enable the agent to send a RESTART command if the connection is lost during a file transfer. The RESTART command contains the necessary interrupt information and will continue from that spot. Before selecting this option, ensure that the target FTP server supports the RESTART command. When this option is selected, the agent will attempt to re-establish the connection, and resume the file transfer from the point in the file stated in the RESTART command, as many times as is entered in the Max Restarts field. When a connection has been re-established, a RESTART command will be sent after the number of seconds entered in the Retry Restarts Interval(s) field. Note! The RESTART Retries settings will not work if you have selected to decompress the files in the Source tab! Note! RESTART is not always supported for transfer type ASCII. For further information about the RESTART command, see http://www.w3.org/Protocols/rfc959/ . Retry Restarts Interval(s) Enter the time interval, in seconds, you want to wait before initiating a restart. This time interval will be applied for all restart retries. If a connection issue occurs, the actual time interval before the first attempt to send a RESTART command will be the time set in the Timeout field in the Advanced tab plus the time set in the Retry Interval(s) field. For the remaining attempts, the actual time interval will be the specified number of seconds. Max Restarts Enter the maximum number of restarts per file you want to allow. If more than one attempt to send the RESTART command has been made, the number of used retries will be reset as soon as a file transfer is completed successfully. Source Tab The Source tab contains configuration options related to the remote host, source directories, and source files. The following text describes the configuration options available when no custom strategy has been chosen. Open The FTP collection agent configuration - Source tab Setting Description Setting Description Collection Strategy If there is more than one collection strategy available, a Collection Strategy drop-down menu list will be made visible. For further information about collection strategies, see Appendix 4 - Collection Strategies . File Information Directory Enter the absolute path to the source directory where the source files reside. If the FTP server is of UNIX type, the path name must be specified as relative to the home directory of the account. Include Subfolders Select this check box if you have subfolders in the collection source directory. Note! Subfolders that are in the form of a link are not supported. If you select Enable Sort Order in the Sort Order tab, the sort order selected will also apply to subfolders. Filename Enter the name of the source files on the remote host. Regular expressions according to Java syntax apply. For further information, see http://docs.oracle.com/javase/8/docs/api/java/util/regex/Pattern.html . Example To match all file names beginning with TTFILE , type: TTFILE.* Note! When collecting files from VAX file systems, the names of the source files must include both the path and filename when entering the regular expression. Compression Select the compression type. This option determines if the agent will decompress the files before passing them to the workflow. No Compression - the agent will not decompress the files. Gzip - the agent will decompress the files using Gzip. Before Collection Move to Temporary Directory If this option is enabled, the source files will be moved to a subdirectory called DR_TMP_DIR in the source directory, before collection. This option supports safe collection when source files repeatedly use the same name. Append Suffix to Filename Enter the suffix that you want to be added to the file name prior to collection. Important! Before you execute your workflow, make sure that none of the file names in the collection directory include this suffix. Inactive Source Warning (h) If enabled, when the configured number of hours have passed without any file being available for collection, a warning message (event) will appear in the System Log and Event Area: The source has been idle for more than <n> hours, the last inserted file is <file>. After Collection Move to If enabled, the source files will be moved from the source directory (or from the directory DR_TMP_DIR if using Move to Temporary Directory ) to the directory specified in the Destination field, after collection. Note! The Directory has to be located in the same file system as the collected files. The absolute path names must be defined. If a file with the same filename, but with different content, already exists in the target directory, the workflow will abort. If a file with the same file name, and the same content, already exists in the target directory, this file will be overwritten and the workflow continue running. Rename Options Rename If this option is enabled, the source files will be renamed after the collection, and remain (or moved back from the directory DR_TMP_DIR if using Move to Temporary Directory ) in the source directory. Note! When the File System Type for VAX/VMS is selected, there are special considerations. If a file is renamed after collection on a VAX/VMS system, the filename might become too long. In that case, the following rules apply: A VAX/VMS filename consists of <file name>.<extension>;<version>, where the maximum number of characters for each part is: <file name>: 39 characters <extension>: 39 characters <version>: 5 characters If the new filename turns out to be longer than 39 characters, the agent will move part of the filename to the extension part. If the total sum of the filename and extension part exceeds 78 characters, the last characters are truncated from the extension. An example: A_VERY_LONG_FILENAME_WITH_MORE_THAN_39_ CHARACTERS.DAT;5 will be converted to: A_VERY_LONG_FILENAME_WITH_MORE_THAN_39_. CHARACTERSDAT;5 Note! Creating a new file on the FTP server with the same file name as the original file, but with other content, will cause the workflow to abort. Creating a new file with the same file name AND the same content as the original file will overwrite the file. Remove If enabled, the source files will be removed from the directory (or from the directory DR_TMP_DIR , if using the Move to Temporary Directory option, after collection. Ignore If enabled, the source files will remain in the source directory after the collection. This field is not available if the Move to Temporary Directory option is enabled. Destination Enter the full pathname to the directory on the remote host into which the source files will be moved after the collection. This field is only available if Move to is enabled. Prefix and Suffix Prefix and/or suffix that will be appended to the beginning and the end of the name of the source files, respectively, after the collection. These fields are only available if Move to or Rename is enabled. Warning! If Rename is enabled, the source files will be renamed in the current (source or DR_TMP_DIR ) directory. Be sure not to assign a Prefix or Suffix , giving files new names still matching the Filename regular expression. That will cause the files to be collected over and over again. Search and Replace Select either the Move or Rename option. Search : Enter the part of the filename that you want to replace. Replace: Enter the replacement text. Search and Replace operate on your entries in a way that is similar to the Unix sed utility. The identified filenames are modified and forwarded to the target agent in the workflow. This functionality enables you to perform advanced filename modifications, as well: Use regular expression in the Search entry to specify the part of the filename that you want to extract. Note! A regular expression that fails to match the original file name will abort the workflow. Enter Replace with characters and meta characters that define the pattern and content of the replacement text Search and Replace Examples To rename the file file1.new to file1.old , use: Search: .new Replace: .old To rename the file JAN2011_file to file_DONE , use: Search: ([A-Z]*[0-9]*)_([a-z]*) Replace: $2_DONE Note that the search value divides the file name into two parts by using parentheses. The replace value applies to the second part by using the place holder $2 . Keep (days) Enter the number of days to keep moved or renamed source files on the remote host after collection. In order to delete the source files, the workflow has to be executed (scheduled or manually) again, after the configured number of days. Note! A date tag is added to the filename, determining when the file may be removed. This field is only available if the Move to or Rename option is enabled. UDR Type Section Route FileReferenceUDR Select this check box if you want to forward the data to an SQL Loader agent. For more information, see SQL Loader Agent . Advanced Tab The Advanced tab contains advanced FTP service configuration options. For example, if the FTP server does not return the file listed in a well-defined format, you can use Disable File Detail Parsing . For further information, see the available options. Open The FTP collection agent configuration - Advanced tab Setting Description Setting Description Command Port Enter the port number of the remote FTP server. Timeout (s) Enter The maximum time, in seconds, to wait for a server response. A value of 0 will result in an indefinite wait. Passive Mode (PASV) This option must be enabled if FTP passive mode is used for the data connection. In passive mode, the channel for data transfer between the client and server is initiated by the client instead of the server. This is used when firewalls block standard FTP connections. Disable File Detail Parsing Disables parsing of file detail information received from the FTP server. This enhances the compatibility with unusual FTP servers but disables some functionality. If file detail parsing is disabled, file modification timestamps will not be available to the collector. The collector does not have the ability to distinguish between directories and simple files, sub directories in the input directory must for that reason not match the filename's regular expression. The agent assumes that a file named DR_TMP_DIR is a directory because a directory named DR_TMP_DIR is used when Move to Temporary Directory under the Source tab is activated. Therefore, it is not allowed to name a regular file in the collection directory DR_TMP_DIR. Note! When collecting files from a VAX file system, this option has to be enabled. Additional Hosts Here you can enter additional host names or IP addresses that can access the source directory for file collection. These hosts are tried, in sequence from top to bottom. Use the Add , Edit , Remove , Up , and Down buttons to configure the order of the hosts in the list.

---

# Document 1440: Installation and Setup - MediationZone Documentation 9.3 - InfoZone

**Source:** ratanon/mz93-documentation
**URL:** https://infozone.atlassian.net/wiki/spaces/MD93/pages/204676475/Installation+and+Setup
**Categories:** chunks_index.json

In the instructions below, you will prepare the development environment setup for your Legacy Desktop. The following file will be downloaded: File Description Source File Description Source devkit_ <version> .zip Desktop devkit package on the platform Download the devkit package to the PC where you will use Legacy Desktop and do the DTK work either from the Downloads dialog that you open from User Settings in Desktop or from: http(s)://<platform host>:9000/download/devkit Create an installation directory for the DTK. $ mkdir <devkit dir> Extract the devkit package to your installation directory <devkit dir> $ unzip devkit_<version>.zip Setting Up the Environment Variables for the DTK. In your development environment or build scripts, you must include the devkit.jar in the class path. that was extracted above, in devkit_<version>/lib in the class path. For example: $ javac -cp <devkit dir>/lib/devkit.jar -sourcepath . com/mycompany/myplugin/*.java Where: com/mycompany/myplugin/, is your the code that you will build

---

# Document 1441: General Functions - MediationZone Documentation 9.3 - InfoZone

**Source:** ratanon/mz93-documentation
**URL:** https://infozone.atlassian.net/wiki/spaces/MD93/pages/204677814/General+Functions
**Categories:** chunks_index.json

This chapter describes functions that are commonly used for working with object data types that are available in APL. This chapter includes the following sections: Bit Operation Functions Bytearray Functions Date Functions IP Address Functions List Functions Map Functions OAuth Functions String Functions Type Comparison Functions Type Conversion Functions UDR Functions UUID Functions

---

# Document 1442: OSS Mediation 5G - MediationZone Documentation 9.3 - InfoZone

**Source:** ratanon/mz93-documentation
**URL:** https://infozone.atlassian.net/wiki/spaces/MD93/pages/204648064/OSS+Mediation+5G
**Categories:** chunks_index.json

Definition OSS Mediation provides the Operational Support System (OSS) components of a CSPs system landscape with the ability to ingest operational network data to derive insights into network health and subscriber experience. OSS Mediation is defined as a set of capabilities for 5G networks (5GC), characterised by, and limited to: Originating Data Sources Operational data, events, and alarms received directly from network elements or probes Operational data, events, and alarms received from Network Management Systems (NMS) Output Data Targets Network Performance Management systems Analytics systems Data warehouse and data lake systems The data collected must have the sole purpose of being used for Operation Support Systems (OSS), in the sub-domains of Fault Management, Performance Management, Service Assurance (for example Customer Experience Management), Geo Location and Content Delivery Networks. Charging and monetisation purposes, among others, are excluded from this right to use. This Right to Use (RTU) grants the licensee the right to use DigitalRoutes MediationZone software in accordance with this definition.

---

# Document 1443: Amazon SQS Collection Agent Configuration - MediationZone Documentation 9.3 - InfoZone

**Source:** ratanon/mz93-documentation
**URL:** https://infozone.atlassian.net/wiki/spaces/MD93/pages/299663446/Amazon+SQS+Collection+Agent+Configuration
**Categories:** chunks_index.json

You can open the SQS Collection Agent configuration dialog from a workflow configuration. Click Build  New Configuration . Select Workflow from the Configurations dialog. When prompted to select workflow type then select Batch . Click Add Agent and select SQS Collection from the Collection tab of the Agent Selection dialog. Setting Description Setting Description AWS profile The AWS connection details as configured in the Amazon Profile configuration, see Amazon Profile Queue name The name of the queue to collect messages from Max messages to receive The maximum number of messages received per request from the SQS queue (range can be set from 1-10) Poll time (seconds) The frequency to poll for more data (range can be set from 0-20) Standard attributes Defines if the standard attributes will be collected All - collects all standard attributes None - collect no standard attributes Note that user-defined attributes are always collected Note! Use the Test Connection button to test the connection to Amazon and the availability of the configured queue.

---

# Document 1444: Task Agents - MediationZone Documentation 9.3 - InfoZone

**Source:** ratanon/mz93-documentation
**URL:** https://infozone.atlassian.net/wiki/spaces/MD93/pages/205658021/Task+Agents
**Categories:** chunks_index.json

Task Agents are available for Task Workflows, and are responsible for executing specific procedures. For instance managing data in databases, starting test configuration, and executing shell scripts.

---

# Document 1445: Workflow Monitoring Framework - MediationZone Documentation 9.3 - InfoZone

**Source:** ratanon/mz93-documentation
**URL:** https://infozone.atlassian.net/wiki/spaces/MD93/pages/205849379/Workflow+Monitoring+Framework
**Categories:** chunks_index.json

MediationZone publishes Meta Information Model (MIM) values from running workflows via JMX, this metadata can be monitored via external supervising tools such as JConsole. Also the platform functionality publishes information for supervision. The image below illustrates a JConsole window receiving runtime metadata (i.e. MIM values) from a workflow and also system parameters such as the event queue. Open Example of the JConsole window showing workflow MIM information In the Console, the MIM values can be monitored both in the form of current value and historic charts as depicted below (charts are presented by double-clicking the value digits). Open Viewing MIM information in a chart

---

# Document 1446: UI Builder Component UDRs - MediationZone Documentation 9.3 - InfoZone

**Source:** ratanon/mz93-documentation
**URL:** https://infozone.atlassian.net/wiki/spaces/MD93/pages/205034894/UI+Builder+Component+UDRs
**Categories:** chunks_index.json

The UI Builder Component UDRs contain UDR types for the following UI components. Button UDR CheckBox UDR Dialog UDR DropDown UDR Form UDR GenericElementUDR GenericInputField UDR Grid Component UDRs Header UDR Icon UDR IntegerField UDR Label UDR Link UDR NumberField UDR Password UDR PlainText UDR RadioButtonGroup UDR Table Component UDRs TextArea UDR TextField UDR

---

# Document 1447: Data types - MediationZone Documentation 9.3 - InfoZone

**Source:** ratanon/mz93-documentation
**URL:** https://infozone.atlassian.net/wiki/spaces/MD93/pages/204612125


---
**End of Part 61** - Continue to next part for more content.
