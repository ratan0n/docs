# RATANON/MZ93-DOCUMENTATION - Part 70/112

---
**Dataset:** ratanon/mz93-documentation
**Part:** 70 of 112
**GitHub:** https://github.com/ratan0n/docs/tree/main/mz93-documentation
**Size:** ~68.4 KB
---

You open the SCP forwarding agent configuration dialog from a workflow configuration. To open the SCP forwarding agent configuration, click Build  New Configuration . Select Workflow from the Configurations dialog. When prompted to Select workflow type , select Batch . Click Add agent and select SCP from the Forwarding tab of the Agent Selection dialog. Part of the configuration may be done in the Filename Template service tab described in Workflow Template . Connection Tab Open The SCP forwarding agent configuration - Connection tab For information about the Connection tab, see the figure, The SCP Collection Agent Configuration - Connection Tab in SCP Collection Agent Configuration . Target Tab Open The SCP forwarding agent configuration - Target Tab The Target tab contains configuration settings related to the remote host, target directories, and target files. Setting Description Setting Description Input File Handling Input Type The agent can act on two input types. Depending on which one the agent is configured to work with, the behavior differs. The default input type is bytearray, that is the agent expects bytearrays. If nothing else is stated the documentation refers to input of bytearray. If the input type is MultiForwardingUDR , the behavior is different. For further information about the agent's behavior in MultiForwardingUDR input, see SCP Forwarding Agent MultiForwardingUDR Input . File Information Directory Enter the absolute pathname of the target directory on the remote host, where the forwarded files will be placed. The pathname may also be given relative to the home directory of the user's account. The files will be temporarily stored in the automatically created subdirectory DR_TMP_DIR in the target directory. When an End Batch message is received, the files are moved from the subdirectory to the target directory. Create Directory When enabled, this will create the directory, or the directory structure, of the path that you specify in Directory. Note! The directories are created when the workflow is executed. Compression Select the compression type of the destination files. Determines whether the agent will compress the output files as it writes them. No Compression - the agent will not compress the files. Gzip - the agent will compress the files using gzip. Note! No extra extension will be appended to the target filenames, even if compression is selected. Target File Handling Produce Empty Files If enabled, the agent will create empty output files for empty batches rather than omitting those batches. Handling of Already Existing Files Select the behavior of the agent when the file already exists, the alternatives are: Overwrite - The old file will be overwritten and a warning will be logged in the System Log. Add Suffix - If the file already exists the suffix ".1" will be added. If this file also exists the suffix ".2" will be tried instead and so on. Abort - This is the default selection and is the option used for upgraded configurations, that is workflows from an upgraded system. Temporary File Handling Use Temporary Directory If this option is selected, the agent will move the file to a temporary directory before moving it to the target directory. After the whole file has been transferred to the target directory, and the endBatch message has been received, and the temporary file is removed from the temporary directory. Use Temporary File If there is no write access to the target directory and, hence, a temporary directory cannot be created, the agent can move the file to a temporary file that is stored directly in the target directory. After the whole file has been transferred, and the endBatch message has been received, the temporary file will be renamed. The temporary filename is unique for every execution of the workflow. It consists of a workflow and agent ID, and a file number. Abort Handling Select how to handle the file in case of cancelBatch or rollback, either Delete Temporary File or Leave Temporary File. Note! When a workflow aborts, the file will not be removed until the next time the workflow is run. Advanced Tab Open The SCP forwarding agent configuration - Advanced tab The Advanced tabs contain configurations related to a more specific use of the SCP service, which might not be frequently utilized. Setting Description Setting Description Advanced Settings Port Enter the port number the SCP service will use on the remote host. Timeout (s) Enter the maximum time, in seconds, to wait for a response from the server. 0 (zero) means to wait forever. Accept New Host Keys If selected, the agent overwrites the existing host key when the host is represented with a new key. The default behavior is to abort when the key mismatches. Caution! Selecting this option causes a security risk since the agent will accept new keys regardless if they possibly belong to another machine. Enable Key Re-Exchange Used to enable and disable automatic re-exchange of session keys during ongoing connections. This can be useful if you have long lived sessions since you may experience connection problems for some servers if one of the sides initiates a key re-exchange during the session. Buffered Mode Select this check box if you want to enable buffered mode on the SCP client. Additional Hosts Additional Hosts List of additional host names or IP addresses that may be used to establish a connection. These hosts are tried, in sequence from top to bottom, if the agents fail to connect to the remote host set in the Connection tab. Use the Add , Edit , Remove , Up, and Down buttons to configure the host list. After Treatment Execute Select between the two options: Before Move : Execute the following command and its arguments prior to transfer. After Move : Execute the following command and its arguments on the local copy of the transferred UDR, after transfer. Command Enter a command or a script Arguments This field is optional. Each entered parameter value has to be separated from the preceding value with a space. The temporary filename is inserted as the second last parameter, and the final filename is inserted as the last parameter, automatically. This means that if, for instance, no parameter is given in the field, the arguments will be as follows: $1=<temporary_filename> $2=<final_filename> If three parameters are given in the Arguments field, the arguments are set as: $1=<parameter_value_#1> $2=<parameter_value_#2> $3=<parameter_value_#3> $4=<temporary_filename> $5=<final_filename> Backlog Tab The Backlog tab contains configurations related to backlog functionality. If the backlog is not enabled, the files will be moved directly to their final destination when an end batch message is received. If the backlog however is enabled, the files will first be moved to a directory called DR_POSTPONED_MOVE_DIR and then to their final destination. For further information about transaction behavior, see the section, Retrieves in SCP Forwarding Agent Transaction Behavior . When the backl og is initialized and when backlogged files have transferred a note is registered in the System Log. Open The SCP forwarding agent configuration - Backlog tab Setting Description Setting Description Enable Backlog When selected, this will enable the backlog functionality. When not selected the agent's behavior is similar to the standard SFTP forwarding agent. Directory Base directory in which the agent will create sub-directories to handle backlogged files. Absolute or relative path names can be used. Type Files is the maximum number of files allowed in the backlog folder. Bytes is the total sum (size) of the files that reside in the backlog folder. If a limit is exceeded the workflow will abort. Size Enter the maximum number of files or bytes that the backlog folder can contain. Processing Order Determine the order by which the backlogged data will be processed once the connection is reestablished, and select between First In First Out (FIFO) or Last In First Out (LIFO). Duplicate File Handling Specifies the behavior if a file with the same file name as the one being transferred is detected. The options are Abort or Overwrite and the action is taken both when a file is transferred to the target directory or to the backlog. Security Tab Open The SCP forwarding agent configuration - Security tab For information about the Security tab, see the description under SCP Collection Agent Configuration Note! Due to an upgrade of the Maverick library for MediationZone version 8.1.5.0, the default handling of the advanced security has changed. Users should take note of the behaviour change for the Advanced Security Option for the SCP agents. The Advanced Security Option will be disabled by default. Users will have to enable it on their own accord from the Security Tab in the SCP agents configuration. With Advanced Security Option disabled, Maverick will manage the connection between the SCP agent and the server. Maverick will attempt to connect with the STRONG security level. Failing to do so, it will auto downgrade the security level to WEAK and attempt to connect, this behaviour will allow our agents to work well with backwards compatibility for servers with older instances of the Maverick library. Furthermore, having STRONG security level will result in a performance degradation. However, when a user manually enables the Advanced Security Option from the security tab, Maverick will instead assign the WEAK security level, which will not be as strict or resource intensive as the STRONG security level. For more information about security levels, you can refer to this page: https://www.jadaptive.com/managed-security-in-our-java-ssh-apis/

---

# Document 1656: Data Veracity Collection Agent - MediationZone Documentation 9.3 - InfoZone

**Source:** ratanon/mz93-documentation
**URL:** https://infozone.atlassian.net/wiki/spaces/MD93/pages/205032266/Data+Veracity+Collection+Agent
**Categories:** chunks_index.json

The Data Veracity Collection agent fetches data sent to the internal Data Veracity tables by workflows configured to do so. Data is sent to the Data Veracity t ables as UDRs. Open An example workflow collecting UDRs from the Data Veracity tables as defined by the Data Veracity profile Which UDRs to collect is determined by selecting the Data Veracity Profile and then choosing one or many of the UDRs that were defined in the profile. It is only possible to have one active Data Veracity collection workflow per reprocessing group at a time. Note! Collecting UDRs from the Data Veracity tables does not mean that they are physically removed from the database tables, only that their state is changed. Automatic UDR removal can be managed by the predefined task DataVeracity_Maintenance, provided that the UDR or batch is marked for deletion. For further information, see Data Veracity Maintenance System Task . Force deletion directly from the Data Veracity Search UI is also possible if the user has full administrative rights. The section contains the following subsections: Data Veracity Collection Agent Configuration Data Veracity Collection Agent Events Data Veracity Collection Agent Transaction Behavior Data Veracity Collection Agent Input/Output Data and MIM Data Veracity Collection Example

---

# Document 1657: Simple Version Control - MediationZone Documentation 9.3 - InfoZone

**Source:** ratanon/mz93-documentation
**URL:** https://infozone.atlassian.net/wiki/spaces/MD93/pages/204676849/Simple+Version+Control
**Categories:** chunks_index.json

In this scenario, the exported configurations are simply stored in a Version Control System. Open Chain of events: Team A develops new workflows. The configurations are exported with the vcexport command to the local working copy. The resulting xml and schema files are checked in to the Version Control System. If Team A wants to modify existing workflows, these are checked out from the Version Control System to the local working copy. The exported configurations are imported into MediationZone. The configurations are modified, saved and exported to the local working copy again. The new xml files from the new export can now be compared with the previous versions using a diff tool. The updated xml and schema files are checked in to the Version Control System.

---

# Document 1658: SCP Agents Server Keys - MediationZone Documentation 9.3 - InfoZone

**Source:** ratanon/mz93-documentation
**URL:** https://infozone.atlassian.net/wiki/spaces/MD93/pages/205034575/SCP+Agents+Server+Keys
**Categories:** chunks_index.json

The SSH protocol uses host verification to guard against attacks where an attacker manages to reroute the TCP connection from the correct server to another machine. Since the password is sent directly over the encrypted connection, it is critical for security that an incorrect public key is not accepted by the client. The agent uses a file with the known hosts and keys. It will accept the key supplied by the server if either of the following is fulfilled: The host is previously unknown. In this case the public key will be registered in the file. The host is known and the public key matches the old data. The host is known however has a new key and the user has configured to accept the new key. For further information, see the description of the Advanced tab. If the host key changes for some reason, the file will have to be removed (or edited) in order for the new key to be accepted.

---

# Document 1659: Encoder Agent Meta Information Model and Events - MediationZone Documentation 9.3 - InfoZone

**Source:** ratanon/mz93-documentation
**URL:** https://infozone.atlassian.net/wiki/spaces/MD93/pages/204607271/Encoder+Agent+Meta+Information+Model+and+Events
**Categories:** chunks_index.json

Meta Information Model For information about the MIM and a list of the general MIM parameters, see Administration and Management in Legacy Desktop . This agent does not publish nor access any MIM parameters. Agent Message Events There are no message events for this agent. Debug Events There are no debug events for this agent.

---

# Document 1660: Python Agents - MediationZone Documentation 9.3 - InfoZone

**Source:** ratanon/mz93-documentation
**URL:** https://infozone.atlassian.net/wiki/spaces/MD93/pages/205001394/Python+Agents
**Categories:** chunks_index.json

This section describes the Python profiles and agents, and the Python Manager. You configure the Python collection and processing agents to use an Interpreter profile. The Python Connector agent is a real-time collection agent that you use to connect MediationZone to an external exploration tool. The Python collection agent can collect data from any source supported by Python. The Python collection, processing, and Python Connector agents can use the Python code added to Python Module configurations. Each of the agents, with the exception of the Python Connector agent, runs a Python process. The Python agents support Python 3. Prerequisites The reader of this information is expected to be familiar with: UDR structure and contents Analysis Programming Language Python Programming Language The section contains the following subsections: Python Interpreter Profile Python Module Python Code Editor Assistance Python Writer's Guide Python Agents in Real-Time Workflows Python Agents in Batch Workflows Listing Python Processes

---

# Document 1661: mzcli - wfgrouplist - MediationZone Documentation 9.3 - InfoZone

**Source:** ratanon/mz93-documentation
**URL:** https://infozone.atlassian.net/wiki/spaces/MD93/pages/547980070/mzcli+-+wfgrouplist
**Categories:** chunks_index.json

Usage usage: wfgrouplist <pattern matching expression for workflow group names> ... [ -valid ] [ -invalid ] [ -active ] [ -inactive ] [ -scheduled ] [ -unscheduled ] [ -mode < D | E > ] [ -short ] [ -members ] Lists the groups that are configured in the system. If no option is used, the list contains four columns: Workflow Group Names, State, Mode, and Scheduled (true/false). Options Command line switch Description Command line switch Description [-valid] Lists all valid groups. [-invalid] Lists all invalid groups. [-active] Lists all active groups. [-inactive] Lists all inactive groups. [-scheduled] Lists all the scheduled workflow groups. [-unscheduled] Lists all the workflow groups that are not scheduled. [-mode <D|E>] Lists only workflow groups marked with a specified mode: D - Disabled E - Enabled [-short] If set only the Workflow Group Names will be listed. [-members] Lists the members of the workflow groups and some details of the members, for example, Mode. Return Codes Listed below are the different return codes for the wfgrouplist command: Code Description 0 Will be returned if the command was successful. 13 Will be returned if the arguments are not recognized.

---

# Document 1662: FTP EWSD Configuration - MediationZone Documentation 9.3 - InfoZone

**Source:** ratanon/mz93-documentation
**URL:** https://infozone.atlassian.net/wiki/spaces/MD93/pages/205685584/FTP+EWSD+Configuration
**Categories:** chunks_index.json

You open the FTP EWSD collection agent configuration dialog from a workflow configuration. To open the configuration, click Build  New Configuration . Select Workflow from the Configurations dialog. When prompted to Select workflow type, select Batch . Click Add agent and select FTP EWSD from the Collection tab of the Agent Selection dialog. The dialog contains two tabs ; Switch and Advanced . Switch Tab This tab contains the remote host and source file parameters. Open FTP/EWSD agent configuration dialog - Switch tab Setting Description Setting Description Host Name Enter the host name or the IP address of the switch that is to be connected. User Name Enter the name of the user from whose account on the remote Switch the FTP session is created. Password Enter the user password. Filename Enter the name the cyclic file that the agent should collect. Remote File is Cyclic Select this checkbox to enable a transaction safe retrieval of data from the switch. This is useful when you want to retrieve statistical switch data. Multiple File View Select this checkbox to enable sectioning and thereby a more effective data management of the file. Clear to stay in single file view. For further information see Multiple File View Option in FTP EWSD Agent . Advanced Tab This tab enables you to specify advanced use of the FTP service parameters. Open The FTP/EWSD agent configuration dialog - Advanced tab Item Description Item Description Command Port Enter a number between 1 and 65535 to define the port that the FTP service will use to communicate with the agent from a remote switch. Timeout (sec) Enter the maximum length of time, in seconds, while the agent should await a reply after sending a command, before a timeout is called. 0 (zero) means "wait forever". Number of Retries The number of times to retry upon TCP communication failure. This is for the FTP command channel only. An IO failure during the file transfer will not trigger retries. If value set to O no retires will be done. Delay (sec) Enter the length of the delay period between each connection atempt. Local Data Port Enter the number of the port through which the agent should expect input data connections ( FTP PORT command). Enter 0 (zero) to have the operating system select a random port number that is not being used currently, according to the system specifications for each data connection. Enter a non-zero value to have the agent use the same local port for all the data connections. Value range: 0 - 65535. Local Address Enter the IP-address of the local endpoint, used both for commands and for data transmission channels. Keep Alive Select this check box to have the agent tell the system to perform a continuous test that the remote host is running. This enables you to identify bad connections. Note! The keep-alive interval (Idle time) is system dependent. Default is 7200 000 (milliseconds). Passive Mode (PASV) Select this check box when using an FTP passive mode connection. Currently, Siemens does not support this option. However, some firewalls require passive mode. Binary Transfer Select this checkbox to enable binary transfer. Clear to enable ascii transfer. FTP Command Trace Select this checkbox to debug the communication with the remote switch. See a log of the commands and responses in the workflow editor Event Area. The LIST command results are traced as well. Release File Slice After Retrieval Select this checkbox to release all the file slices after successful retrieval. File release is initiated by the FTP delete command. Automatic Seq No Assignment Select this checkbox to enable automatic numbering of the file slices in Multiple File View mode. If this option is checked, the number management is done in SAMAR. Don't Collect The Active File Slice Select this checkbox to have the agent collect only file slices that are prior to the active one.

---

# Document 1663: FTPS Forwarding Agent MultiForwardingUDR Input - MediationZone Documentation 9.3 - InfoZone

**Source:** ratanon/mz93-documentation
**URL:** https://infozone.atlassian.net/wiki/spaces/MD93/pages/205685683/FTPS+Forwarding+Agent+MultiForwardingUDR+Input
**Categories:** chunks_index.json

When the agent is set to use MultiForwardingUDR input, it accepts input of the UDR type MultiForwardingUDR declared in the package FNT. The declaration follows: internal MultiForwardingUDR { // Entire file content byte[] content; // Target filename and directory FNTUDR fntSpecification; }; The MultiForwardingUDR content is stored at the path set in the fntSpecification field. Use the APL functions fntAddString and fntAddDirDelimiter to set the value of this field. For more information, see FNTUDR Functions in APL Reference Guide . When the files are received they are written to temp files in the DR_TMP_DIR directory in the root output folder. The files are moved to their final destination when an end batch message is received. A runtime error occurs if any of the fields have a null value or if the path is invalid on the target file system. A UDR of the type MultiForwardingUDR which has a target filename that is not identical to its precedent is saved in a new output file. Note! After a target filename that is not identical to its precedent is saved, you cannot use the first filename again. For example: Saving filename B after saving filename A, prevents you from using A again. Instead, you should first save all the A filenames, then all the B filenames, and so forth. Non-existing directories are created if the Create Non-Existing Directories checkbox in the Filename Template tab is selected. If not selected, a runtime error occurs if a previously unknown directory exists in the FNTUDR of an incoming MultiForwardingUDR . Every configuration option referring to bytearray input is ignored when MultiForwardingUDR s are expected. For more information about Filename Template, see Workflow Template . Example - APL code to send MultiForwardingUDRs This example shows the APL code used in an Analysis agent connected to a Forwarding agent expecting input of type MultiForwardingUDR s. import ultra.FNT; MultiForwardingUDR createMultiForwardingUDR (string dir, string file, bytearray fileContent){ //Create the FNTUDR FNTUDR fntudr = udrCreate(FNTUDR); fntAddString(fntudr, dir); fntAddDirDelimiter(fntudr);//Add a directory fntAddString(fntudr, file);//Add a file MultiForwardingUDR multiForwardingUDR = udrCreate(MultiForwardingUDR); multiForwardingUDR.fntSpecification = fntudr; multiForwardingUDR.content = fileContent; return multiForwardingUDR; } consume { bytearray file1Content; strToBA (file1Content, "file nr 1 content"); bytearray file2Content; strToBA (file2Content, "file nr 2 content"); //Send MultiForwardingUDRs to the forwarding agent udrRoute(createMultiForwardingUDR ("dir1", "file1", file1Content)); udrRoute(createMultiForwardingUDR ("dir2", "file2", file2Content)); } The Analysis agent sends two MultiForwardingUDR s to the Forwarding agent. Two files with different contents are placed in two separate subfolders in the root directory. The Create Non-Existing Directories checkbox in the Filename Template tab in the configuration of the Forwarding agent must be selected if the directories do not previously exist.

---

# Document 1664: Database Collection Agent Transaction Behavior - MediationZone Documentation 9.3 - InfoZone

**Source:** ratanon/mz93-documentation
**URL:** https://infozone.atlassian.net/wiki/spaces/MD93/pages/204738322/Database+Collection+Agent+Transaction+Behavior
**Categories:** chunks_index.json

The Database collection agent performs additional operations to ensure that data is not recollected or lost if the workflow aborts before the collection of a batch has finished correctly. A unique Transaction ID is retrieved for each new batch. The pending transaction table is queried for all pending Transaction IDs, to be compared with the transaction IDs in the working table, from which the agent will collect. The SQL query is built and executed, and all matching rows are collected. In addition to the user defined condition, the agent adds some conditions to the query, to ensure that pending data, cancelled data and data marked as collected is not collected. For each row that has been successfully converted to a UDR, the agent updates its Transaction ID column to the Transaction ID retrieved in bullet 1. When all rows matching the query have been successfully collected, the After Collection configuration in the Source tab, is used. If Remove, all rows with the given Transaction ID are removed in batches of the size configured as the Commit Window Size , in the Advanced tab. If Mark as Collected , all rows with the given Transaction ID are updated with the reserved Transaction ID value -1 . If Run SP , the user defined stored procedure is executed. For further information, see After Collection Stored Procedure in Tables and Stored Procedures . Emits The agent emits commands that changes the state of the file currently processed. Command Description Begin Batch Emitted after the SQL select statement execution. End Batch Emitted after the SQL select statement execution, when all possible matching rows have been successfully inserted as UDRs in the workflow. Note! If the SQL select statement does not return any data, Begin and End Batch will not be emitted. Not even if Produce Empty Files is selected in a Forwarding Disk agent. Retrieves The agent retrieves commands from other agents and based on them generates a state change of the file currently processed. Command Description Cancel Batch All rows with the current Transaction ID are updated with the reserved Transaction ID -2 . If these rows are to be recollected, the Transaction ID column must first be set to 0 (zero). If set to NULL this row cannot be collected. The database row that issued the Cancel Batch request is written to the System Log. Note! If the Cancel Batch behavior defined on workflow level is configured to abort the workflow, the agent will never receive the last Cancel Batch message. In this situation the rows will not be updated with the reserved Transaction ID -2 . Hint End Batch An End Batch call will be issued, causing the original batch returned by the SQL query to be split at the current UDR. The database commit command is executed, followed by a new select statement to fetch the remaining UDRs from the table.

---

# Document 1665: User Settings - MediationZone Documentation 9.3 - InfoZone

**Source:** ratanon/mz93-documentation
**URL:** https://infozone.atlassian.net/wiki/spaces/MD93/pages/204997359
**Categories:** chunks_index.json

Click the User icon on the top right side of the Desktop Online User Interface to open the User Settings menu. Open User Settings menu The menu contains the following options: Option Description Option Description Profile Click the Profile option to open the User profile dialog. Open User profile dialog The following settings are available: Username - Displays your username. Name - Displays your full name as registered in the system. Email - Displays your email address as registered in the system. Enable High Contrast Mode - You can enable the High Contrast mode to make texts across the system easier to read in case of visual impairment problems. Theme - You can select between Light or Dark mode. You can also choose to follow the mode set by the Operating System by selecting System . About Click on the About option to display information about your installation. Open About dialog Installed packages Click the Installed packages option to display information about all the installed packages in the system. The same information can be obtained by using the mzsh https://infozone.atlassian.net/wiki/x/tSMyD command. You can use the Search field to search for any specific package. Open Installed packages dialog Downloads Click the Downloads option to open the Downloads dialog. Open Downloads dialog From this dialog you can download Desktop Launcher and Devkit. Click on the respective file names and they will be downloaded. Change password Click the Change password option to change your password. Open Change password dialog Enter your Current password, enter a New password , and then reenter the new password in the Confirm password field. Click Submit to apply. Log out Click this option to log out of Desktop.

---

# Document 1666: Disk Forwarding MultiForwardingUDR Input - Batch - MediationZone Documentation 9.3 - InfoZone

**Source:** ratanon/mz93-documentation
**URL:** https://infozone.atlassian.net/wiki/spaces/MD93/pages/205032668/Disk+Forwarding+MultiForwardingUDR+Input+-+Batch
**Categories:** chunks_index.json

When the agent is set to use MultiForwardingUDR input, it accepts input of the UDR type MultiForwardingUDR declared in the package FNT. The declaration follows: internal MultiForwardingUDR { // Entire file content byte[] content; // Target filename and directory FNTUDR fntSpecification; }; The content of the MultiForwardingUDR will be stored at the path that you have set in the fntSpecification field. Use the APL functions fntAddString and fntAddDirDelimiter to set the value of this field. For further information about these functions, see FNTUDR Functions in APL Reference Guide . When the files are received they are written to temp files in the DR_TMP_DIR directory situated in the root output folder. The files are moved to their final destination when an end batch message is received. A runtime error will occur if any of the fields have a null value or if the path is invalid on the target file system. A UDR of the type MultiForwardingUDR which has a target filename that is not identical to its precedent is saved in a new output file. Note! MultiforwardingUDRs with their own specific target filenames will be saved into their specific output files. UDRs with filename A will be saved to filename A and UDRs with filename B will be saved to filename B regardless of precedence. Non-existing directories will be created if the Create Non-Existing Directories check box under the Filename Template tab is checked. If not checked, a runtime error will occur if a previously unknown directory exists in the FNTUDR of an incoming MultiForwardingUDR . Every configuration option referring to bytearray input is ignored when MultiForwardingUDR s are expected. Example - APL code to send MultiForwardingUDRs This example shows the APL code used in an Analysis agent connected to a forwarding agent expecting input of type MultiForwardingUDR s. import ultra.FNT; MultiForwardingUDR createMultiForwardingUDR (string dir, string file, bytearray fileContent){ //Create the FNTUDR FNTUDR fntudr = udrCreate(FNTUDR); fntAddString(fntudr, dir); fntAddDirDelimiter(fntudr);//Add a directory fntAddString(fntudr, file);//Add a file MultiForwardingUDR multiForwardingUDR = udrCreate(MultiForwardingUDR); multiForwardingUDR.fntSpecification = fntudr; multiForwardingUDR.content = fileContent; return multiForwardingUDR; } consume { bytearray file1Content; strToBA (file1Content, "file nr 1 content"); bytearray file2Content; strToBA (file2Content, "file nr 2 content"); //Send MultiForwardingUDRs to the forwarding agent udrRoute(createMultiForwardingUDR ("dir1", "file1", file1Content)); udrRoute(createMultiForwardingUDR ("dir2", "file2", file2Content)); } The Analysis agent mentioned previous in the example will send two MultiForwardingUDR s to the forwarding agent. Two files with different contents will be placed in two separate sub folders in the root directory. The Create Non-Existing Directories check box under the Filename Template tab in the configuration of the forwarding agent must be checked if the directories do not previously exist.

---

# Document 1667: Kafka Real-Time Collection Agent Input/Output and MIM - MediationZone Documentation 9.3 - InfoZone

**Source:** ratanon/mz93-documentation
**URL:** https://infozone.atlassian.net/wiki/spaces/MD93/pages/301138435/Kafka+Real-Time+Collection+Agent+Input+Output+and+MIM
**Categories:** chunks_index.json

Input/Output Data This section includes information about the data type that the agent expects and delivers. The agent retrieves messages from Kafka and creates one KafkaRecord per message and produces KafkaRecord types. Meta Information Model (MIM) Published MIMs MIM Parameter Description MIM Parameter Description Estimated Lag Estimated lag is the sum of the currently outstanding messages for the assigned topic/partitions for this agent. Estimated Lag is of type long and is defined as a header MIM context type.

---

# Document 1668: TCP/IP Agents - MediationZone Documentation 9.3 - InfoZone

**Source:** ratanon/mz93-documentation
**URL:** https://infozone.atlassian.net/wiki/spaces/MD93/pages/205002293/TCP+IP+Agents
**Categories:** chunks_index.json

This section describes the TCP/IP agents. These are collection and forwarding agents for real-time workflow configurations. The TCP/IP forwarding agent is listed among the processing agents in Desktop while the TCP/IP collection agent is listed among the collection agents. Prerequisites The reader of this information should be familiar with: TCP/IP The section contains the following subsections: TCP/IP Forwarding Agent TCP/IP Collection Agent A TCP/IP Example

---

# Document 1669: MIM Functions - MediationZone Documentation 9.3 - InfoZone

**Source:** ratanon/mz93-documentation
**URL:** https://infozone.atlassian.net/wiki/spaces/MD93/pages/204612404/MIM+Functions
**Categories:** chunks_index.json

The MIM functions allows the agent to publish its own MIM values or to read MIM values from other agents. Note! The MIM functions cannot be used within global APL scripts, that is in code saved in the APL Code Editor. The following functions for OAuth described here are: 1 mimGet 2 mimIsNull 3 mimPublish 4 mimSet mimGet Returns the value of a MIM resource available in the workflow. any mimGet ( string category , string mimResourceName ); Parameter Description Parameter Description category Name of the agent or workflow owning the MIM resource mimResourceName Name of the MIM resource whose value is to be returned Returns MIM value as any type. The result always needs to be type casted or else compilation fails Example - Using mimGet mimGet("Workflow", "Batch Count"); // Retrieving a MIM resource owned by the workflow. mimGet("Disk_1", "Source File Count"); // Retrieving a MIM resource owned by the agent "Disk_1". mimIsNull Evaluates if a MIM resource is defined. Available to evaluate MIMs of non-object types, such as int . boolean mimIsNull ( string category , string mimResourceName ); Parameter Description Parameter Description category Name of the agent or workflow owning the MIM resource. mimResourceName Name of the MIM resource to look for. Returns true or false . mimPublish Publishes a MIM resource. The method call can only be used outside a function block. void mimPublish ( assigned , string name , mimType ); Parameter Description Parameter Description assigned Keyword that identifies when the MIM resource is assigned a value. Can be one of: batch - Value is assigned from the consume block. header - Value is assigned in the beginBatch block. trailer - Value is assigned in the endBatch block. global - Value is assigned from any block. name MIM resource name. Must be a string constant. mimType Data type of MIM resource Returns Nothing Note! Real-time workflows can only publish MIMs of type global. mimSet Assigns a value to a user defined MIM resource. The function may be called at any time. Note that it is the responsibility of the user to make sure the MIM value is available in accordance with the specified assigned type (refer to the section above, mimPublish). void mimSet ( string name , any value ); Parameter Description Parameter Description name Name of the MIM resource to assign a value value Value to assign - must match the published MIM type Returns Nothing MIM Example Example - MIM Note that mimSet is made from a drain block. This to make sure the MIM exists when called from any other agent. The calls will be made at endBatch (for trailer MIMs), which always occurs after drain . mimPublish(trailer, "Total duration", int); int duration; beginBatch { duration = 0; } consume { duration = duration + input.CallDuration; } drain { mimSet( "Total duration", duration ); }

---

# Document 1670: The Streaming Telemetry UDR Types - MediationZone Documentation 9.3 - InfoZone

**Source:** ratanon/mz93-documentation
**URL:** https://infozone.atlassian.net/wiki/spaces/MD93/pages/204609576/The+Streaming+Telemetry+UDR+Types
**Categories:** chunks_index.json

The UDR type created in the Streaming Telemetry agent can be viewed in the UDR Internal Format Browser. To open the browser right-click in the editing area of an APL Editor and select UDR Assistance... . The browser opens. How to Split a Request Routers impose limits to the number of paths that can be present in a subscription request. In case more paths are needed, it is possible to split a request so that the agent sends two or more requests with fewer paths in each one. APL can be used to perform this split. Both StreamingTelemetrySessionUDR.subscribeRequest.gnmiRequest and StreamingTelemetrySessionUDR.subscribeRequest.jtiRequest are lists of SubscribeRequest and SubscriptionRequest items, respectively. The agent treats StreamingTelemetrySessionUDR as a single request identified by the sessionKey. However, if the list in the subscribeRequest contains multiple items, then multiple subscriptions are sent to the router. When a new StreamingTelemetrySessionUDR with the same sessionKey is received by the agent, all the previous subscriptions associated with that sessionKey are cancelled and a new set of subscriptions are sent. Input UDRs StreamingTelemetrySessionUDR This UDR is used to trigger a new subscription based on the paths defined in the JTI or gNMI UDR. Available fields are: Field Description Field Description connectionAction (ConnectionAction) Use this field to tell the agent whether to connect or disconnect. context (any) This is an internal working field that can be used in the workflow configuration to keep track of and use internal workflow information related to the request, when processing the answer. password (string) Password to log into the gNMI or JTI server. username (string) Username to log into the gNMI or JTI server. serverHost (string) Address of host to send request to. serverPort (int) Port of host to send request to. sessionKey (string) Unique identifier for this session. This key is only used by the agent. subscribeRequest (RequestType) UDR to define the request. For more information see description of RequestType. ConnectionAction Available field: Field Description Field Description value (int) The value can be one of DISCONNECT, NEW_CONNECTION, or UPDATE_CONNECTION, which are present in the UDR as constants. RequestType Set one of the gnmiRequest or jtiRequest. The one latest set will be used. The field requestCase decides which one is used. Available fields are: Field Description Field Description gnmiRequest (list<GnmiSubscribeRequest>) A list of subscribe requests as defined in the gNMI proto file. jtiRequest (list<JtiSubscriptionRequest>) A list of subscribe requests as defined in the telemetry proto file. requestCase (int) The value can be one of JTI_TYPE, GNMI_TYPE, or NOT_DEFINED. Output UDRs StreamingTelemetryResponseUDR Contains information subscribed to in the triggering session UDR. This UDR is sent out at the intervals configured in the session UDR, according to the corresponding protocol. Available fields are: Field Description Field Description response(ResponseType) The UDR that holds the response. session (StreamingTelemetrySessionUDR) The UDR that triggered the subscription. sessionKey (string) Unique identifier for this session. This key is only used by the agent. ResponseType Contains one of the gnmiResponse or jtiResponse. The field requestCase decides which one is used. Available fields are: Field Description Field Description gnmiResponse(SubscribeResponse) Subscribe response as defined in the gNMI proto file. jtiResponse (OpenConfigData) Subscribe response as defined in the telemetry proto file. error (Error) UDR to describe an error. responseCase (int) The value can be one of JTI_TYPE, GNMI_TYPE, ERROR_TYPE or NOT_DEFINED. Error Available fields are: Field Description Field Description code (int) Error code from gRPC layer, or minus one (-1) if not defined. message (string) The error message. The oneOf type in gNMI For gNMI (in gRPC) there is a type called oneOf , which corresponds to the standard function of a Radio Button, meaning that only one field value can be chosen at any one time. In APL this is implemented so that there are two fields; one for all the possible field values, and one for specifying the value chosen. The field values are available as constants. However, the SubscribeResponse constants are not available in the UDR externally, they are only available internally. To clarify, for SubscribeResponse there is a field called "responseType" with the field values 0, 1, 3, and 4, where: 0 = No value is set 1 = UPDATE 3 = SyncResponse 4 = Error (deprecated) These values match the gNMI SubscribeResponse type.

---

# Document 1671: Search - MediationZone Documentation 9.3 - InfoZone

**Source:** ratanon/mz93-documentation
**URL:** https://infozone.atlassian.net/wiki/spaces/MD93/pages/247693513
**Categories:** chunks_index.json

You can locate specific configurations, tools, Data Management applications, Ultra, or APL using the Search bar at the Top Menu Bar of the Desktop. You can also apply particular search terms to your query to find content relevant to the terms. The search terms available for you to use in your query are: Search Terms Description Search Terms Description apl: Using apl: allows you to query every APL code in the system. Example Query for finding an event in APL apl: event Open Searching for event in the APL codes. new: Using new: allows you to create new configurations from the search bar. Example Query for Creating a new profile new: profile Open Creating a new profile using the search bar. ultra: Using ultra: allows you to query every Ultra Format in the system. Example Query for finding event in Ultra ultra: event Open Searching for event in Ultra workflow: Using workflow: will query the Analysis Agent, Aggregation Agent or Python Code within every workflow in the system. Example Query for finding session in codes configured in workflows workflow: session Open Searching for session in workflows.

---

# Document 1672: Database Functions - MediationZone Documentation 9.3 - InfoZone

**Source:** ratanon/mz93-documentation
**URL:** https://infozone.atlassian.net/wiki/spaces/MD93/pages/205656792
**Categories:** chunks_index.json

The following sets of functions are used for managing data in databases accessed via Database profiles: Database Table functions - Look up and insert data into tables Callable Statement functions - Execute stored procedures Prepared Statement functions - Efficiently execute statements multiple times and has support for failover Database Bulk functions - Bundle multiple queries into one SQL statement Note! All database-related APL functions use a db connection pool, and they pick a connection from the pool for each invocation. Connection properties, such as the transaction state, are handled internally by each function and are never visible in APL. These database functions are currently designed to work with the following database data types; character , string , integer and date data types such as VARCHAR, INTEGER, NUMBER, DATE, TIMESTAMP and BOOLEAN. Other database data types are restricted for APL database functions. The list below contains examples of such types, usually very large data types or custom objects, structures and similar types. Large object data types such as BLOB/CLOB User-defined structures/objects User-defined collections/arrays Spatial/Geometry JSON, XML The BLOB data is parsed and stored as a hex string and CLOB data as a string. To insert BLOB data using APL, you must use string/bytearray. Warning! PostgreSQL does not support BLOB/CLOB. The BLOB equivalent for PostgreSQL will be BYTEA and CLOB equivalent will be TEXT. This chapter includes the following sections: Callable Statements Database Bulk Functions Database Table Functions Prepared Statements

---

# Document 1673: Aggregation Transaction Behavior - Batch - MediationZone Documentation 9.3 - InfoZone

**Source:** ratanon/mz93-documentation
**URL:** https://infozone.atlassian.net/wiki/spaces/MD93/pages/204639910/Aggregation+Transaction+Behavior+-+Batch
**Categories:** chunks_index.json

This section includes information about the Batch workflow's Aggregation agent's transaction behavior. The Real-Time Aggregation agent does not have transaction behavior. For information about the general transaction behavior, see Workflow Monitor . Emits The agent emits commands that change the state of the file currently processed. Command Description Cancel Batch The agent itself does not emit Cancel Batch messages. However, if the code contains a call to the method cancelBatch this causes the agent to emit a Cancel Batch. Hint End Batch If the code contains a call to the method hintEndBatch , this causes the agent to emit a Hint End Batch. Retrieves The agent retrieves commands from other agents and, based on those commands, changes the state change of the file currently processed. Command Description Begin Batch When a Begin Batch message is received, the agent calls the beginBatch function block, if present in the code. End Batch When an End Batch message is received, the agent calls the endBatch function blocks, if present in the code. Prior to End Batch, possible timeouts are called. Thus, when a time limit is reached, the timeout function block will not be called until the next End Batch arrives. If the workflow is in the middle of a data batch or is not currently receiving any data at all, this could potentially be some time after the configured timeout. Cancel Batch When a Cancel Batch message is received, the agent calls the cancelBatch function block, if present in the code.

---

# Document 1674: TCP/IP Forwarding Agent - MediationZone Documentation 9.3 - InfoZone

**Source:** ratanon/mz93-documentation
**URL:** https://infozone.atlassian.net/wiki/spaces/MD93/pages/205002311/TCP+IP+Forwarding+Agent
**Categories:** chunks_index.json

The TCP/IP forwarding agent allows data to be distributed from a workflow, using the standard TCP/IP protocol. Several connections at a time are allowed. The agent can also send various UDRs back into the workflow. All handling of these UDRs are done through APL commands. Warning! Deprecation Netty version 3 is deprecated from version 9.0.0 of MediationZone. The TCP/IP forwarding agent supports IPv4 and IPv6 environments. Open A TCP/IP forwarding workflow example The section contains the following subsections: TCP/IP Forwarder UDR Types TCP/IP Forwarding Agent Configuration TCP/IP Forwarding Agent Input/Output Data and MIM TCP/IP Forwarding Agent Events

---

# Document 1675: Post Upgrade - MediationZone Documentation 9.3 - InfoZone

**Source:** ratanon/mz93-documentation
**URL:** https://infozone.atlassian.net/wiki/spaces/MD93/pages/204638026/Post+Upgrade
**Categories:** chunks_index.json

Depending on the version you are upgrading from and to, one or several steps may be needed in order to get the system up and running. Read the section Post Upgrade in the Release Notes for each upgraded version for further information regarding the required steps, if there is such a section available for the release. Note! During the upgrade process, the content of $MZ_HOME/common/lib is purged and replaced with updated jar files. If you added any additional jar files to your previous installation of MediationZone, you need to add them again after the upgrade is complete. Note! If you wish to use the Legacy Desktop you need to do a new installation, see Installation and Configuration of Legacy Desktop . This section contains the following subsection: Black Box for Deprecated or Unsupported Agents

---

# Document 1676: Security Profile - MediationZone Documentation 9.3 - InfoZone

**Source:** ratanon/mz93-documentation
**URL:** https://infozone.atlassian.net/wiki/spaces/MD93/pages/205031381/Security+Profile
**Categories:** chunks_index.json

With the Security Profile, you can make encryption configurations that can be used by various agents. The profile consists of three tabs: General , Advanced, and External Keystore . General Tab Open Security Profile - General Tab Keystore Settings The following settings are available: Settings Description Settings Description Type You have the following options: Java Keystore External Keystore <None> Selecting External Keystore or <None> disables the rest of the keystore settings. Selecting External Keystore will require additional input in the External Keystore tab . Path Enter the location of the keystore from which you want to read the key. Password Enter the relevant keystore password. Public Key Alias The encryption alias to use. In a client, it should be the alias to the server public certificate. If left empty the Keystore Alias will be used to encrypt the message. Private Key Alias If the keystore contains more than one key, specify the alias of the key that you want to use. Key Password The Key Password fields is optional. You can enter the key password, or if you leave this field empty, the Password that you entered is the default. Example - How to Create a Symmetric Crypto Key keytool -keystore test.ks -storepass password -genseckey -keysize 128 -alias testkey -keyalg AES Example - How to Create a Keystore File with Security Contents The example code below shows how to create a Java keystore file for both the server and client connection. In this example, the file will be generated containing the associated security certificate, public and private key. Code Block keytool -genkey -alias server -keyalg RSA -keystore ./server.jks Note! Remember the password issued for the server.jks file. Example - How to Create a Client-Specific Keystore File To create a client-specific Java Keystore file, you can use the keytool command with the required variables. In this example, the generated file will be for a specific client and contain only their certificate and public key. Code Block keytool -export -alias server -keystore ./server.jks -file ./server.cer ... keytool -import -alias client -file ./server.cer -keystore ./client.jks ... Note! Execution of these commands will present password entry prompts, and you will need to remember the entered passphrase. Truststore Settings The following settings are available: Field Description Field Description Type You can select from the following options: Java Truststore Use Java Keystore External Truststore Use External Keystore <None> Selecting Use Java Keystore disables the rest of the truststore settings and the keystore specified in Keystore Settings is used. Selecting External Truststore or Use External Keystore disables the rest of the truststore settings and will require more input in External Keystore tab. Selecting <None> disables the rest of the truststore settings. Path Enter the location of the truststore that you want to use. Password Enter the relevant truststore password. Advanced Tab Open Security Profile - General Tab The Advanced tab enables you to make more detailed configurations for which cipher suites to accept. The following settings are available: Settings Description Settings Description Enable TLS Settings If you want to change the TLS security parameters, select this check box. The default setting is to use the settings from the Java installation. Accepted Protocols You can select if you want agents using this profile to accept only TLS version 1.3 or any TLS version. The default setting is to only accept version 1.3. Used Cipher Suites You can select if you want agents using this profile to use only suites that are enabled by default, or any suites. The default setting is to only use suites that are enabled by default. Cipher Suite Must Match In this field, you can enter any characters that you want the cipher suites to match. You can also enter lists of regular expressions, one per row, that you want the cipher suites to match. Suites not matching your entry are greyed out in the Result on this JVM field. Cipher Suite Must Not Match If you want to exclude cipher suites, you can enter any characters in this field which excludes suites matching the characters. You can also enter lists of regular expressions, one per row, for cipher suites to exclude. Result on this JVM This field displays the cipher suites available on the current JVM. External Keystore Tab The External Keystore tab enables you to store your SSL certificates in one secure location. Currently, it can be stored in Azure KeyVault, Google Secret Manager or HashiCorp Vault. Note! Using the Security profile with External Keystore configured with Kafka agents is not supported. Azure KeyVault Open Azure KeyVault as External Keystore For information about the installation and setup of an Azure KeyVault, see https://azure.microsoft.com/en-us/products/key-vault . Settings Description Settings Description Azure KeyVault Profile Choose an Azure KeyVault Profile to use for the credentials. Certificate name The name of the certificate in Azure KeyVault Google Secret Manager Open Google Secret Manager as External Keystore For information about the installation and setup of Google Secret Manager, see https://cloud.google.com/secret-manager/docs . MediationZone requires a base64 encoded PFX certificate to be stored as a Secret in Google Secret Manager. Settings Description Settings Description Google Secret Manager Profile Choose a Google Secret Manager Profile to use for the credentials. Name The name of the certificate stored in Google Secret Manager. Version The version of the Secret. Key Password Password of the certificate. Generating and Uploading a Certificate Run the following command to create a self-signed PFX keystone file: keytool -genkey -keyalg RSA -keystore Server.pfx -storetype PKCS12 keystore = name of the pfx file, for example, server.pfx Note! When prompted for first and last name, the hostname where the certificate is valid should be entered, for example, localhost. Other values can be anything. Encode the PFX file with base64 by running this command: base64 -i Server.pfx -o Server.b64 -i = name of the input file -o = name of the output file for the base64 string Create a secret on Google Secret Manager with the value of the Server.b64 . HashiCorp Vault Open HashiCorp Vault as External Keystone For information about the installation and setup of a vault, see https://learn.hashicorp.com/vault . Info! When setting up your vault, it is recommended that you have the following set up: Set up a Key-Value (kv) Secret Enable Userpass authentication instead of the default token authentication. Set up a policy with read and list permissions and assign it to a user. Settings Description Settings Description Auth Methods Select the authentication method used to access the vault. Address The address for the vault. The format of the address begins with the hypertext transfer protocol, either HTTP or HTTPS, followed by the IP address of the vault and the TCP port used by the TCP listener of the vault. Example https://127.0.0.1:8200 Username Enter the vault username. Password Enter the vault password. Path The full path of the vault secret engine that contains the relevant keystore or truststore. Example secret/digitalroute/mz/security/server Uploading a Keystore into Your Vault MediationZone requires certain criteria to be met when uploading the keystore into your vault. The following command will help show you how to upload. vault kv put secret/digitalroute/mz/security/<PATH_PREFIX>/keystore filecontent="$(cat <PATH_TO_KEYSTORE>.jks | base64)" password=<PASSWORD> keyalias=<KEYALIAS> keypassword=<KEYPASSWORD> You need to configure the mandatory attributes. The workflow will abort if it calls a Security profile with vault credentials saved in a different format than listed in the table below. Supported Formats Attribute Value Format Attribute Value Format filecontent Base64 String keyalias String keypassword String password String Uploading a Truststore into Your Vault MediationZone requires certain criteria to be met when uploading the truststore into your vault. The following command will help show you how to upload it. vault kv put secret/digitalroute/mz/security/<PATH_PREFIX>/truststore filecontent="$(cat <PATH_TO_TRUSTSTORE>.jks | base64)" password=<PASSWORD> You need to configure the mandatory attributes. The workflow will abort if it calls the security profile with the vault credentials that are saved in a different format as listed in the table below. Attribute Value Format Attribute Value Format filecontent Base64 String password String

---

# Document 1677: Basic Administration PCC - MediationZone Documentation 9.3 - InfoZone

**Source:** ratanon/mz93-documentation
**URL:** https://infozone.atlassian.net/wiki/spaces/MD93/pages/204613285/Basic+Administration+PCC
**Categories:** chunks_index.json

This chapter contains information about the basic administration of a PCC System. This chapter includes the following sections: Control Zone and Execution Zone Data Repository

---

# Document 1678: Deployment Support - MediationZone Documentation 9.3 - InfoZone

**Source:** ratanon/mz93-documentation
**URL:** https://infozone.atlassian.net/wiki/spaces/MD93/pages/205658390/Deployment+Support
**Categories:** chunks_index.json

MediationZone can be deployed on physical hardware, or in Virtual Machines. Virtual Machines can be located either on-premises in a VM cluster (such as VMWare vSphere), or leveraging Virtual Machines hosted by public cloud providers (for example AWS EC2, GCP GCE, Azure VM) The modular architecture enables cost-efficient mediation solutions. Test system One server maintains the execution of all zones  this represents a local server on which the mediation processes are configured and validated, for later export to production servers. Single production server Multiple access zone clients access a single server (or cluster) that manages the execution of control zone as well as execution zone logic. Multiple production servers Multiple access zone clients access a single server (or cluster) that manages the control zone. Workflows are distributed to any number of execution zone servers based on data volumes and specific deployment requirements. New functionality, customizations and business processes can be dynamically implemented, and there is no downtime on an executing system when the changes are made. In the case of patches or enhancements to the executable, the changes are introduced to the code server that will automatically propagate the change to all parts of an installation (i.e. clients, Execution Contexts etc.). In the case of changes to the business processes, the changes can be made on a running workflow and will not lead to any downtime of the processing, it will become active the next time the workflow is started. Workflow Mapping to Execution Contexts Workflows can be mapped to Execution Contexts in several ways. The distribution can be up to the Platform to decide, in which case it can be configured to base it on load or number of workflows already running. A workflow - or a configured group of workflows - can be pre set to execute on particular Execution Contexts. Also, there is the possibility to map one or several Workflow Templates, including how many of each Template's instances that shall be started on a ECs with a particular name pattern. This way, the cluster can be easily scaled up and down. Please see section Execution Elasticity for more information.

---

# Document 1679: Data Hub Profile - MediationZone Documentation 9.3 - InfoZone

**Source:** ratanon/mz93-documentation
**URL:** https://infozone.atlassian.net/wiki/spaces/MD93/pages/204676337/Data+Hub+Profile
**Categories:** chunks_index.json

The Data Hub profile is used by the Data Hub Forwarding Agent and Data Hub Task Agent to connect to an Impala database via Cloudera JDBC, and an HDFS. This profile is also used to map the input UDRs to the Data Hub forwarding and an Impala database table. Data Hub Query also uses the profile to access the data stored in the Impala database. The Data Hub profile is loaded when you start a workflow that relies on it. Changes to the profile become effective when you restart the workflow. Configuration To create a new Data Hub profile configuration, click the New Configuration in the Build view and select Data Hub Profile from the Configurations browser. The contents of the menus in the menu bar may change depending on which configuration type that has been opened in the currently active tab. The Data Hub profile uses the standard menu items and buttons that are visible for all configurations, and these are described in Build View . Impala Tab The Impala tab contains connection settings for the Impala database. Open Data Hub profile configuration - Impala tab Setting Description Setting Description Host Enter the hostname or the IP address of the Impala database. Port Enter the port number that is configured for the connection into the Impala database. Enable TLS Allows the user to enable the TLS functionality for the connection to the Impala database. Allow Self Signed Cert Checkbox to enable the usage of Self Signed Certificates. If this checkbox is selected, both Trust Store File Path and Trust Store Password will be disabled. Trust Store File Path Enter the location of the trust store file. This path is used to store certificates from other Certified Authorities. The setup is required to establish a successful connection at the client side. Note! This field is enabled when the Enable TLS checkbox is selected. However, when the Allow Self Signed Cert checkbox is selected, this field is disabled. Trust Store Password Enter the passphrase of the trust store file. This password is used to access the certificates stored in the trust store. Note! This field is enabled when the Enable TLS checkbox is selected. However, when the Allow Self Signed Cert checkbox is selected, this field is disabled. Key Store File Path Enter the location of the key store file. This path is used to store your credential. This is required when setting up the server side on the SSL. Note! This field is enabled when the Enable TLS checkbox is selected. Key Store Password Enter the passphrase of the key store file. This password is used to access the credentials stored in the key store. Note! This field is enabled when the Enable TLS checkbox is selected. Database Name Click the Refresh button next to Database Name to retrieve a list of available databases and then select a database from the drop-down menu. The Tables Mapping tab will appear. Refresh Click this to retrieve a list of available databases. Test Connection Click to test the JDBC connection to the Impala database. HDFS Tab The HDFS tab contains the properties required for the connection to HDFS as well as properties for staging paths. Open Data Hub profile configuration - HDFS tab Setting Description Setting Description HDFS URI Enter the URI of the HDFS NameNode. Staging Path Enter the absolute path to an existing directory on the HDFS. This directory will be used as a staging directory for the data. MZ Temp Path Enter the path for temporarily storing the files locally before it is inserted into the HDFS staging directory. Create Directory Select this to create the MZ Temp Path directory if it does not exist. Advanced Tab The Advanced tab contains the properties needed for Data Hub agent to connect to any Cloudera configurations that has LDAP and Kerberos enabled. Open Data Hub profile configuration - Advanced tab See the text in the Properties field for further information about the other properties that you can set. Kerberos JVM Due to the behavior of the Kerberos JVM, Data Hub profiles and agents that will interface with a Kerberos-enabled Cloudera must be configured to run on the same EC. Kerberos Keytab You will need to ensure the .keytab file is located in the same host as the EC that will be running the workflow with the Data Hub agent. Tables Mapping Tab Open Data Hub profile configuration - Tables Mapping tab Setting Description Setting Description Table Select a database table from the drop-down list. The name of the table columns and their data type will appear. Hint! You can map more than one table to a UDR type. This makes it possible to use the same profile for multiple Data Hub agents. Note! If you have created a new table that appears to be missing in the drop-down list, click the Refresh button in Impala tab and then reselect the database. The table should now be listed. UDR Type Click the Browse button and then select a UDR type that will be routed to a Data Hub agent. For information about Ultra types that can be mapped to Impala types, see Compatible Types below. Auto Map Click this button to automatically map UDR fields and database columns with identical names. The automatic mapping is not case-sensitive. If a field cannot be mapped, the current value in the UDR Field column remains unchanged. Column The name of the columns in the selected table. Type This displays a list of valid Impala types based on the Column in the selected table. Each column must be mapped against a type. For information about Ultra types that can be mapped to Impala types, see Compatible Types below. UDR Field Select a UDR field from the drop-down list. This represents selectable fields available based on the selected UDR Type above. Date Hint Select the date format to be stored in the table. This is required for a partition column. A date in the Ultra format can be stored as INT , BIGINT and SMALLINT types. When the column is a partition, you must select the corresponding date format from this drop-down list: yyyyMMddHH - e g 2018123013 yyyyMMdd - e g 20181230 yyyyMM - 201812 yyyy - 2018 The selected format determines the granularity of date pickers in the Web UI. When you change the Date Hint value of a partition column for an existing profile, make sure to review the settings of Data Hub task workflows that depend on the updated profile and table. If the table already contains data when you change the Date Hint of a partition column, the Data Hub task agent will fail to delete any of the partitions. To resolve this issue you must manually delete the partitions that contain the old format, e g using Cloudera Hue. When the UDR fields do not have names that match the database columns, you can map these manually by clicking the corresponding cell and selecting the field from a drop-down list. Compatible Types The following table shows allowed mappings of Impala types to Ultra types. Impala Type Impala Range Ultra Type Ultra Range Impala Type Impala Range Ultra Type Ultra Range STRING Maximum of 32,767 bytes string Unlimited INT -2147483648 to +2147483647 int -2,147,483,648 to +2,147,483,647 short -32,768 to +32,767 byte -128 to +127 FLOAT 1.40129846432481707e-45 to 3.40282346638528860e+38 (positive or negative) float 1.40129846432481707e-45 to 3.40282346638528860e+38 (positive or negative) DOUBLE 4.94065645841246544e-324d to 1.79769313486231570e+308 (positive or negative) double 4.94065645841246544e-324d to 1.79769313486231570e+308d (positive or negative) float 1.40129846432481707e-45 to 3.40282346638528860e+38 (positive or negative) BOOLEAN TRUE or FALSE boolean true or false BIGINT -9223372036854775808 to +9223372036854775807 long -9223372036854775808 to +9223372036854775807 int -2,147,483,648 to +2,147,483,647 short -32,768 to +32,767 byte -128 to +127 REAL 4.94065645841246544e-324d to +1.79769313486231570e+308 (positive or negative) double 4.94065645841246544e-324d to 1.79769313486231570e+308d (positive or negative) SMALLINT -32768 to +32767 short -32,768 to +32,767 byte -128 to +127 TINYINT -128 to +127 byte -128 to +127 TIMESTAMP YYYYMMDDHH date yyyyMMddHH

---

# Document 1680: ParquetType - MediationZone Documentation 9.3 - InfoZone

**Source:** ratanon/mz93-documentation
**URL:** https://infozone.atlassian.net/wiki/spaces/MD93/pages/205653390/ParquetType
**Categories:** chunks_index.json

The ParquetDecoderUDR includes a schema field that describes the schema of the payload. This schema makes use of ParquetType to describe fields.

---

# Document 1681: Event Notifications - MediationZone Documentation 9.3 - InfoZone

**Source:** ratanon/mz93-documentation
**URL:** https://infozone.atlassian.net/wiki/spaces/MD93/pages/204736858
**Categories:** chunks_index.json



---
**End of Part 70** - Continue to next part for more content.
