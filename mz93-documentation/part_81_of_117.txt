# RATANON/MZ93-DOCUMENTATION - Part 81/112

---
**Dataset:** ratanon/mz93-documentation
**Part:** 81 of 112
**GitHub:** https://github.com/ratan0n/docs/tree/main/mz93-documentation
**Size:** ~65.6 KB
---

For detailed information regarding each tab, use the following tabs to refer to the information you want: Basic Tab The Basic tab contains settings related to the location and authentication of the remote server. Open REST Client_Deprecated agent configuration - Basic tab Setting Description Setting Description Base URL This is the target URL for requests from the REST Client_Deprecated agent. Enter the URL in the following format: <protocol>://hostname:<optional-port>/<optional-path> The supported protocols are HTTP and HTTPS. If no port is specified, the agent will default to 80 for HTTP and 443 for HTTPS. Note! When the protocol in the base URL is set to https, the option to Use TLS will be enabled. Use TLS Enable Transport Layer Security for the REST Client_Deprecated agent. This option is configurable when https is set as the protocol in the base URL. Security Profile Note! When the Base URL has the protocol set to https, Use TLS is disabled, and Security Profile is left empty, the REST Client_Deprecated agent will trust all certificates. Advanced Tab The Advanced tab contains settings related to the HTTP/HTTPS connection and handling of incoming requests. Open REST Client_Deprecated agent configuration - Advanced tab Setting Description Setting Description Timeout (ms) Enter the maximum response time from the remote server in milliseconds. If the response time from the server exceeds this value, the REST Client_Deprecated agent updates the Error field of the outgoing RESTCycleUDR . For further information about UDR types, see REST Client_Deprecated UDR Types . The default value is 5000 ms. Max Outstanding Requests Enter the maximum number of outstanding requests that the agent can handle simultaneously. A request that is received by the agent is considered outstanding until a corresponding response is received from the remote server. If the number of requests exceeds this value, the REST Client_Deprecated agent updates the Error field of the outgoing RESTCycleUDR . New requests are not sent by the agent until the number of outstanding requests decreases. For further information about UDR types, see REST Client_Deprecated UDR Types . The default value is 100 requests. You will also be able to define the max-chunk-size and max-content-length of the requests received by the agent. You can set the properties on the EC running the REST Client_Deprecated agent or on a container that are running the EC's with the REST Client_Deprecated agents. For details on the properties, you can refer to Execution Context Properties or Container Properties . Authentication Tab The Authentication tab contains settings related to the supported authentication types that can be used by the REST Client_Deprecated agent. Different settings are available for the various authentication types. These include: None - No authentication (default value) Basic - Authentication according to the 'Basic' HTTP Authentication Scheme (RFC 7617) OAuth 2.0 - Authentication according to the OAuth 2.0 Authorization Framework (RFC 6749) None When you select None in Authentication Type , there are no additional settings. Basic Basic authentication requires a username and a password, which are base64 encoded and sent in the header of the request. When you select Basic in Authentication Type , the following settings are available: Open REST Client_Deprecated agent configuration - Authentication tab (basic) Setting Description Setting Description Username Enter a username for an account on the remote server. The username must not include colon (:) characters. Password Enter the password associated with the username. OAuth 2.0 RFC 6749 specifies four grant types for authentication. At the time of writing, the only available grant types are "Client Credentials" and "Resource Owner Password Credentials". These types require additional parameters that are sent to an authorization server. Token Expiry A request that is using an invalid token, e g due to expiry, will fail and an error code will be set in the corresponding RESTCycleUDR that the agent routes back to the workflow. For an expired token, server will send error response that contains header WWW-Authenticate=Bearer,error=invalid_token . The agent will automatically attempt to obtain a new token, but you must configure your APL to resend the failed request. Settings Open REST Client_Deprecated agent configuration - Authentication tab (OAuth 2.0) When you select OAuth 2.0 in Authentication Type , the following settings are available: Setting Description Setting Description Grant Type Select the grant type: Client Credentials The agent fetches the access token from the Access Token URI during initialization, using client id and client secret for basic authentication. The credentials are base64 encoded and sent in the header of the request. The response contains an access token, which is then used in subsequent requests. Resource Owner Password Credentials The agent fetches the access token from the Access Token URI during initialization, using the following credentials for authentication: Client ID Client Secret Username Password The credentials are sent in the body of the request. The response contains an access token, which is then used in subsequent requests. Client Auth Type Select the client authentication method: client_secret_basic - The credentials are base64 encoded and sent in the header of the request. client_secret_post - The credentials are sent in the body of the request. Client ID Enter the unique client identifier issued by the authorization server. Client Secret Enter the client secret. Username Enter the resource owner username, i e end-user granting access to a protected resource. This field is required when you have selected Resource Owner Password Credentials from the drop-down list Grant Type . Password Enter the password associated with the username. This field is required when you have selected Resource Owner Password Credentials from the drop-down list Grant Type . Access Token URI Enter the URI where the access token can be obtained. Base URL Field Some authentication servers may provide a base URL in the response body that the REST Client_Deprecated agent must use in subsequent requests. When this is applicable, enter the name of the key in the JSON formatted string that holds the base URL. The value extracted from the response overrides, the Base URL, that you have configured in the Basic tab. In the following example, the base URL is available in instance_url . Example - Base URL in response from authentication server {"access_token":"00D5E0000008lbR...", "instance_url":"https://cs84.example.com", "id":"https://example.com/id/00D5E0000008lbRUAQ/0055E000000HRCHQA4", "token_type":"Bearer","issued_at":"1490699031149", "signature":"tWccV/a3r0y/JoMRTUbpiviwmslJD2J29yTtSz7yDHE="} Additional Parameters Some authentication servers may require additional parameters in the body of the token requests. To add a parameter, click the Add button and then enter the name of the parameter in the Key field and the value of the parameter in the Value field. Do not use escape characters in the value field, these will be added automatically by the REST Client_Deprecated agent. For instance, " Example Domain " will be sent as "https%3A%2F%2example.com%2F". If you need to have dynamically configurable client credentials for OAuth 2.0, you may also use the OAuth2UDR for this, see REST Client_Deprecated UDR Types for further information.

---

# Document 1918: TLS Standard Setup - MediationZone Documentation 9.3 - InfoZone

**Source:** ratanon/mz93-documentation
**URL:** https://infozone.atlassian.net/wiki/spaces/MD93/pages/205848693/TLS+Standard+Setup
**Categories:** chunks_index.json

The TLS requires that you set up a keystore to contain certificates and private keys. Follow the steps below to set up a keystore. For instructions to include client authentication (two-way authentication), see Enabling Client Authentication . Example - How to Create a Symmetric Crypto Key keytool -keystore test.ks -storepass password -genseckey -keysize 128 -alias testkey -keyalg AES Example - How to Create a Keystore File with Security Contents The example code below shows how to create a Java keystore file for both the server and client connection. In this example, the file will be generated containing the associated security certificate, public and private key. Code Block keytool -genkey -alias server -keyalg RSA -keystore ./server.jks Note! Remember the password issued for the server.jks file. Example - How to Create a Client-Specific Keystore File To create a client-specific Java Keystore file, you can use the keytool command with the required variables. In this example, the generated file will be for a specific client and contain only their certificate and public key. Code Block keytool -export -alias server -keystore ./server.jks -file ./server.cer ... keytool -import -alias client -file ./server.cer -keystore ./client.jks ... Note! Execution of these commands will present password entry prompts, and you will need to remember the entered passphrase.

---

# Document 1919: Agent Selection Dialog - MediationZone Documentation 9.3 - InfoZone

**Source:** ratanon/mz93-documentation
**URL:** https://infozone.atlassian.net/wiki/spaces/MD93/pages/204604724/Agent+Selection+Dialog
**Categories:** chunks_index.json

The Agent Selection dialog contains all the available agents, represented as icons. Different icons are available, depending on which kind of workflow type that you have selected. There are different agents for Batch, Realtime, or Task workflow types. You open the Agent Selection dialog from a workflow configuration. To open the Agent Selection dialog, click Build  New Configuration . Select Workflow from the Configurations dialog. When prompted to select workflow type, select either Batch, Realtime Or Task . Click Add Agent to open the Agent Selection dialog. Agent Selection dialog - Processing tab Real-time and batch workflow configurations contain three types of agents, collection, processing, and forwarding. These are sorted into different tabs, depending on the type of data an agent expects and delivers. The tabs are labelled Collection , Processing, and Forwarding . Task Workflow configurations have only one agent type and always contain a single agent. The different agent types Batch and Real-Time Workflow Agents Collection Agents A collection agent is responsible for the gathering of data from external systems or devices, such as opening a file and reading it byte-by-byte and then passing it into the workflow. A collection agent must produce one or several data types. The workflow configuration validates that the data types between the collection agent and the connected agents are compatible. Note! Real-time collection agents may also receive data from the workflow in order to send responses to the external system or device. Processing Agents A processing agent expects to be fed with data and to deliver data on one or several outgoing routes. Inside a workflow, data propagates between agents as streams, that is, as a flow of bytes or UDRs. A simple processing agent can, for example, be a counter counting the throughput. There are also more complex types, for instance, agents that, depending on the processed result, deliver data on different routes. The processing agent decodes (translates) an incoming byte stream into a UDR object and the encoding agent does the opposite. Forwarding Agents A forwarding agent is responsible for distributing data from the workflow to other systems or devices. An example would be to create a file from a data stream and transfer it to another system using FTP. Different agents act differently on the Begin Batch and End Batch messages. The forwarding agents, for instance, need a set of boundaries in order to close a file or commit a database transaction. A forwarding agent must receive one or several data types. The workflow configuration validates that the data types between the forwarding agent and the connected agents are compatible. For detailed information about specific collection-, processing-, and forwarding agents, see Appendix 2 - Batch and Real-Time Workflow Agents . Task Workflow Agents Task workflow agents are used to execute system housekeeping tasks such as removing files or cleaning up database tables. These agents do not receive any data from other agents nor do they publish data to other agents. For detailed information about specific task agents, see Appendix 3 - Task Workflow Agents .

---

# Document 1920: GCP Storage Collection Agent Input/Output Data and MIM - MediationZone Documentation 9.3 - InfoZone

**Source:** ratanon/mz93-documentation
**URL:** https://infozone.atlassian.net/wiki/spaces/MD93/pages/204607804/GCP+Storage+Collection+Agent+Input+Output+Data+and+MIM
**Categories:** chunks_index.json

Input/Output Data The Input/Output data is the type of data an agent expects and delivers. The agent produces bytearray types. MIM For information about the MIM and a list of the general MIM parameters, see Administration and Management . Publishes MIM Value Description File Modified Timestamp This MIM parameter contains a timestamp, indicating when the file is stored in the collection directory. File Modified Timestamp is of the date type and is defined as a header MIM context type. File Retrieval Timestamp This MIM parameter contains a timestamp, indicating when the file processing starts. File Retrieval Timestamp is of the date type and is defined as a header MIM context type. Source File Size This MIM parameter contains the file size, in bytes, of the source file. Source File Size is of the long type and is defined as a header MIM context type. Source Filename This MIM parameter contains the name of the currently processed file, as defined at the source. Source Filename is of the string type and is defined as a header MIM context type. Source Filenames This MIM parameter contains a list of file names of the files that are about to be collected from the current collection directory. Note! When the agent collects from multiple directories, the MIM value is cleared after the collection of each directory. Then, the MIM value is updated with the listing of the next directory. Source Filenames is of the list<any> type and is defined as a Header MIM context type. Source File Count This MIM parameter contains the number of files, available to this workflow for collection at startup. The value is constant throughout the execution of the workflow, even if more files arrive during the execution. The new files will not be collected until the next execution. Source File Count is of the long type and is defined as a global MIM context type. Source Pathname This MIM parameter contains the path to the directory where the file currently under processing is located. Source Pathname is of the string type and is defined as a global MIM context type. The path is defined in the Amazon S3 tab. Source Files Left This parameter contains the number of source files that are yet to be collected. This is the number that appears in the Execution Manager backlog. Source Files Left is of the long type and is defined as a header MIM context type. Accesses The agent does not access any MIM resources.

---

# Document 1921: APN Agent - MediationZone Documentation 9.3 - InfoZone

**Source:** ratanon/mz93-documentation
**URL:** https://infozone.atlassian.net/wiki/spaces/MD93/pages/285638657/APN+Agent
**Categories:** chunks_index.json

This section describes the APN profile and agent. The agent is a processing agent available in real-time workflow configurations. The APN agent allows push notifications to be sent to mobile devices using Apple certificates. Open An example of APN workflow The agent requires a profile containing configurations for the certificate, and needs to be provided with Title, Body, and Device token for the messages to be sent. There are also two UDR types specific for the APN agent; APNUDR and APNResult . Note! The APN agent does not support HTTP Proxy. Prerequisites The user of this information should be familiar with: Apple Push Notification Service ( https://developer.apple.com/notifications/ ) The section contains the following subsections: APN Profile APN Agent Configuration APN UDRs APN Agent MIM and Events

---

# Document 1922: Archive Profile - MediationZone Documentation 9.3 - InfoZone

**Source:** ratanon/mz93-documentation
**URL:** https://infozone.atlassian.net/wiki/spaces/MD93/pages/204640150
**Categories:** chunks_index.json

Profiles containing storage, naming scheme and lifetime for targeted files are configured in the Archive profile. You can configure several workflows to use the same profile, however only one of the workflows may be active at a time. The Archive profile is loaded when you start a workflow that depends on it. Changes to the profile become effective when you restart the workflow. Configuration To create a new Archive profile configuration, click the New Configuration button in the upper left part of the Desktop window, and then select Archive Profile from the me n u. Open Archive profile configuration dialog The contents of the menus in the menu bar may change depending on which configuration type that has been opened. The Archive profile uses the standard menu items and buttons that are visible for all configurations, and these are described in Build View . The Edit button is specific for Archive profile configurations. Item Description Item Description External References Select to Enable External References in an agent profile field. Refer to Enabling External References in an Agent Profile Field in External Reference Profile for further information. See also, the section below, Enabling External References. The full path of each filename to store in the archive is completely dynamic via the Archive File Naming Algorithm. The name is determined by three parameters: AAA/BBB/CCC Where: Name placeholder Description Name placeholder Description AAA Represents one of the base directories specified in the Base Directory list in the Archive profile. If several base directories exist, this value will change according to the frequency selected from the Switch Policy list. The system automatically appends a directory delimiter after this name. BBB This part is constructed from the Directory Template . If the template contains one or several Directory delimiters this part will enclose one or several directory levels itself. For instance, if the template contains Month, Directory delimiter, Day this will yield new directories every day, named 03/01 , 03/02 ... 03/31 , 04/01 , 04/02 ... 04/30 and so on. In this example, files are stored in a directory structure containing all months, which in turn contains directories for all days (which in turn will contain all files from that day). The system automatically appends a directory delimiter after this name. CCC This is the name the file will get. It is defined on each archiving agent using configurations from the Filename Template tab in the Archiving agent configuration dialog. The Archive profile configuration contains the following settings: Setting Description Setting Description Switch Policy If several base directories are configured, the switch policy determines for how long the Archive services will populate each base directory before starting to populate the next one (daily, weekly, or monthly). After the last base directory has been populated, the archiving wraps to the first directory again. Base Directory One or several base directories that can be used for archiving of files. For considerable amounts of data to be archived, several base directories located on different disk partitions might be needed. Directory Template List of tokens that, in run-time, builds subdirectory names appended to one of the base directories. The tokens could be either special tokens or user defined values. Subdirectories on any level, can be constructed by using the special token Directory delimiter. See the section below, Directory Template. Remove Entries (days) If enabled, files older than the entered value will be deleted from the archive. Depending on the agent using the profile, the removal will occur differently. Note! The days that user can define will just be between 1 to 365 days only. Any days more than that will not be supported. For the Local Archiving agent the cleanup of outdated files is mastered by the workflow. It removes the file from its archive directory in the initialize block. For the Archiving agent the cleanup of outdated files is performed by the Archive Cleaner task. It removes the references, as well as the files themselves from its archive directory. Consequently, the data storage is also dependent on the setup of the task scheduling criteria. Keep Files Files will not be deleted. If Keep Files and Remove Entries (days) are combined, only references in the database are removed while the files remain on disk. ( not valid for the Local Archiving agent). Directory Template Open Add Directory Template dialog Setting Description Setting Description Special token Tokens to be used as part of the directory name. Year - Inserts four digits representing the year the file was archived. Month - Inserts two digits representing the month the file was archived. Day - Inserts two digits representing the day of the month the file was archived. Hour - Inserts two digits representing the hour (24) of the day the file was archived. Agent directory name - Inserts the MIM value(s) defined in the Agent Directory Name list in the Archiving agent configuration dialog. Day index - Inserts a day index between zero and the value entered in Remove Entries (days) field. This number is increased by one every day until Remove Entries (days) - 1 is reached. It then wraps back to zero. Day index may not be used in the template if Remove Entries (days) is disabled. Directory delimiter - Inserts the standard directory delimiter for the operating system it distributes files to. This way, a sub-directory is created. Text If enabled, the token is entered from the text field. When disabled, the token is instead selected from the Special token list. Enabling External Referencing Click the External References button to enable external referencing of profile fields. For detailed instructions, see External Reference Profile . When you apply external referencing to profile fields, the following profile parameters are affected: Setting Description Setting Description Base Directory The directory paths that you add to this list are included in the properties file that contains the External References. Example - Directory path myBaseDirectoryKey = /mypath/no1, /mypath/no2 Remove Entries (days) The value with which you set this entry is included in the properties file and interpreted as follows: myRemoveEntriesKey = 1 #! Remove after 1 day myRemoveEntriesKey = 365 #! Remove after 365 days myRemoveEntriesKey = -1 #! Do not remove. #! This value is equal to clearing the #! check-box. Keep Files In the properties file a checked entry is interpreted as true or yes , and a cleared entry as false or no .

---

# Document 1923: Variables and Variable Scope - MediationZone Documentation 9.3 - InfoZone

**Source:** ratanon/mz93-documentation
**URL:** https://infozone.atlassian.net/wiki/spaces/MD93/pages/204677796/Variables+and+Variable+Scope
**Categories:** chunks_index.json

Variables in APL may be either global or local: Global - Declared outside functions and function blocks Local - Declared in a function or function block // Declaration without initialization int myInt1; //Declaration with initialization int myInt2 = 42; The declaration order of variables is relevant for the initialization in the sense that earlier variables may be used as input to later variables. Example - Declaration order of global variables // Legal int f1 = 1; int f2 = f1 + 1; // Illegal! The following will not compile! int f3 = f4 + 1; int f4 = 1; The scoping rules are as follows: Global variables are available in all functions and blocks. Note that they cannot be accessed from another agent or by an external APL script. All blocks define a separate scope. Any non-anonymous block statement (statements within a {} block) defines a scope. Example - Scope int a; //Variable a is global consume { int b; //Variable b is local to the consume block { //anonomous block int c; //Variable c is local to the consume block; } for(int d=0;d<10;d++) { //Variable d is local to the for-loop } } 'Variable hiding' is not allowed. For instance, if a variable myVar has been declared in global scope, it is not permitted to declare another variable myVar anywhere else in the code. Example - 'Variable hiding' is not allowed int myVar; consume { if (true){ int myVar; //illegal! myVar is already declared as a global variable } } Example - 'Variable hiding' is not allowed consume { int myVar; if (true){ int myVar; //illegal! myVar already declared before on a higher level } } Example - 'Variable hiding' is not allowed consume { if (true) { int myVar; //myVar will only be valid within this block } myVar = 2; //illegal! myVar does not exist here if (true) { int myVar; //myVar can be declared again as it is in a separate scope from above } int myVar; //ok! since it is a separate scope from above } For the built-in function block variables, such as the input variable in the consume block, Variable hiding is allowed. Final Variables To prevent variables from being changed, the final keyword is used: final int myVar = 100; Note! Only numeric and string types are supported for final variables. Persistent Variables Note! Applicable for batch workflows only. All variables are by default reset between workflow activations. However, if a value of a global variable has to be saved between each activation, the persistent keyword can be used. The variable declaration as follows: persistent int myVar = 100; Persistent variables are read from the database between initialize and beginBatch and saved between endBatch and deinitialize. Consequently, any assignment to the persistent variable in initialize only works the first time, once you have a persistent value this will overwrite the value from initialize. Like all other variable types, persistent variable names are unique for each agent within a workflow. Note! A persistent variable cannot be altered after it has been entered into the database. It will be kept there until the workflow is removed or the value is overwritten, that is, when the workflow configuration is saved with a new name using the Save As... option. Example - Persistent variables persistent int counter; initialize { counter = 0; debug( "Value in initialize: " + counter ); } beginBatch { counter = counter + 1; debug( "Value in beginBatch: " + counter ); } The debug output from initialize will read zero each time, while the debug output from beginBatch will read the actual value. First time activated (one input batch): Value in initialize: 0 Value in beginBatch: 1 Fifth time activated (one input batch): Value in initialize: 0 Value in beginBatch: 5

---

# Document 1924: Salesforce Streaming API Agent Configuration - MediationZone Documentation 9.3 - InfoZone

**Source:** ratanon/mz93-documentation
**URL:** https://infozone.atlassian.net/wiki/spaces/MD93/pages/204642670/Salesforce+Streaming+API+Agent+Configuration
**Categories:** chunks_index.json

To open the Salesforce Streaming API agent configuration, click Build  New Configuration . Select Workflow from the Configurations dialog. When prompted to Select workflow type , select Realtime . Click Add agent and select Salesforce Streaming from Processing tab of the Agent Selection dialog. Double-click the agent icon or right-click the icon and select Edit agent , to display the Agent Configuration dialog. The Salesforce agent configuration In the Salesforce Streaming API agent configuration, you provide the credentials needed to access the Salesforce server and state how many reconnection attempts you want. Setting Description Setting Description Login URL Enter the URL to the Salesforce login site. Username Enter the username for logging in to Salesforce. Password Enter the password for logging in to Salesforce. Security Token Enter the security token for logging in to Salesforce. Reconnection Timeout Enter the timeout value in seconds. If the agent loses connection to Salesforce, it attempts to reconnect. If the connection is not recovered before the timeout expires, the workflow aborts. HTTP Proxy for Salesforce Streaming API When HTTP traffic is required to be routed through a proxy please look at HTTP Proxy Support in order to configure the proxy.

---

# Document 1925: SAP CC Notification Agent Events - MediationZone Documentation 9.3 - InfoZone

**Source:** ratanon/mz93-documentation
**URL:** https://infozone.atlassian.net/wiki/spaces/MD93/pages/204609123/SAP+CC+Notification+Agent+Events
**Categories:** chunks_index.json

Agent Message Events There are no agent message events for this agent. Debug Events Debug messages are dispatched in debug mode. During execution, the messages are displayed in the Workflow Monitor. You can configure Event Notifications that are triggered when a debug message is dispatched. For further information about the debug event type, see Debug Event . The agent produces the following debug events: Notifications received in XML format

---

# Document 1926: SQL Forwarding Agent Transaction Behavior, Input/Output Data and MIM - Real-Time - MediationZone Documentation 9.3 - InfoZone

**Source:** ratanon/mz93-documentation
**URL:** https://infozone.atlassian.net/wiki/spaces/MD93/pages/204740785/SQL+Forwarding+Agent+Transaction+Behavior+Input+Output+Data+and+MIM+-+Real-Time
**Categories:** chunks_index.json

Transaction Behavior Emits This agent does not emit anything. Input/Output Data The Input/Output data is the type of data an agent expects and delivers. The agent routes out commitUDR s every time a commit is performed. How often a commit is performed is determined by the configuration of the Volume (UDRs) and Time (sec) options, which you set in the SQL processing agent configuration dialog. The following fields are included in the commitUDR : Field Description commitTimestamp (long) This field contains the timestamp in milliseconds when a commit occurs. lastUDR (DRUDR) This field is populated with the last UDR in the batch that was committed. The agent routes out errorUDR or errorUDRList UDRs if an error occurs. See Handling Erroneous UDRs - Real-Time . MIM For information about the MIM and a list of the general MIM parameters, see MIM . Publishes MIM Parameter Description Agent Name (string) This MIM parameter contains the name of the SQL forwarding agent. Inbound UDRs (long) This MIM parameter contains the UDRs routed to the agent. No of discarded expired UDRs (int) This MIM parameter contains the number of UDRs that have been discarded as they have exceed the configured TTL. Outbound UDRs (long) This MIM parameter contains the UDRs routed from the agent. Accesses The agent does not access any MIM parameters.

---

# Document 1927: External - ASN.1 Formats - MediationZone Documentation 9.3 - InfoZone

**Source:** ratanon/mz93-documentation
**URL:** https://infozone.atlassian.net/wiki/spaces/MD93/pages/204646900
**Categories:** chunks_index.json

Ultra provides support for parsing a subset of ASN.1 definitions, which can be used to decode from and encode to the corresponding BER or PER encoded data. ASN.1 parsing is requested in UFDL via the asn_block construct. The syntax of the ASN.1 blocks is declared as follows: asn_block { -- ASN.1 definitions here }; All ASN.1 constructed types declared either SEQUENCE, SET, or CHOICE, are treated as external format declarations. The name of the resulting external format will be the name of the ASN.1 definition. Any ASN.1 module name is added to the name space. That is, the total name space for the ASN.1 definition is <folder>.<configuration name>.<ASN.1 module name> . All occurrences of the dash character ( - ) in identifiers are converted to underscores since dashes are not valid in Ultra type naming. Any in-map or out-map using an external ASN.1 type will by default specify BER encoding. PER encoding can be selected by specifying one of the map options to PER_aligned or PER_unaligned . Notes on ASN.1 Inter Module References It is currently not possible to refer to non-constructed types or list types (that is, SEQUENCE OF and SET OF) declared in other modules. These must be contained within the asn_block to where they are referred. Any constructed ASN.1 types that are referred must be specified in an ASN.1 IMPORT statement to become available, for example: MyType ::= SET(field1 TAC, field2 MobileOriginatedCall) If TAC and MobileOriginated are declared in another asn_block in the same module like this: TAC ::= OCTET STRING; MobileOriginatedCall ::= SET ( .... ) the following applies: The TAC declaration must be duplicated in the asn_block of MyType . MobileOriginatedCall must be imported within the asn_block containing MyType . ASN.1 Primitive Type Mapping ASN.1 types are automatically mapped by Ultra as follows (this applies when there are automatic statements in the in-maps): ASN.1 Type: Ultra Type mapped to: ASN.1 Type: Ultra Type mapped to: BOOLEAN boolean bcd string bigint bigint All ASN.1 string types except OCTET STRING string OCTET STRING bytearray ENUMERATED int INTEGER int REAL float or bigdec By default, the float ultra type is automatically mapped to the REAL ASN.1 type. Substituting ASN.1 type REAL with bigdec casts the field as BigDecimal type. Mapping to bigdecimal Another method of mapping a REAL type to BigDecimal, is to use internal. //Create a flat internal that will be used to populate with integer and bigdecimal values. internal flatInternal { int calledNumber; bigdec duration; }; BIT STRING bitset mapping is used. Bitset is mapped to Bit String and vice versa; bitset<->bitstring For BER BIT STRING encoding: '0410'H is the correct encoding of the bit string '0001'B ("{3}" in APL debug, length of 4 bits. Note! The string representation here does not actually give complete information since the length is not included. It can be inconvenient to have the same string representation for '0001'B and '000100'B, but the reason is that the same string representation as the Java BitSet class is used. In BER, these values are handled differently. For example, '0001'B is encoded as 0x0410, while '000100'B is encoded as 0x0210. For further information about how BIT STRING is encoded/decoded in BER, see ITU-T specification X.690 (the first byte is not part of the bitstring itself - instead it encodes the number of unused trailing bits in the last byte in the bitstring encoding, which starts after the first byte). NULL bytearray (with value null ) Ultra Extensions Within a UFDL asn_block it is possible to use some extensions which are not part of the ASN.1 standard. These are added to provide better automatic decoding support for some formats. Direct BCD Support A bcd type is introduced. The ASN.1 formats encoded in BER frequently use the OCTET STRING to describe BCD data, leading to complicated processing. By replacing these entries with the bcd type, Ultra automatically converts such entries. The syntax for the bcd type declaration is declared as follows: bcd(lsn_fd) bcd(msn_fd) bcd(lsn_fd) terminated_by(<expr>) bcd(msn_fd) terminated_by(<expr>) Note! There is a limitation when using terminated_by with bcd for specfying field sizes. A detailed explanation of the limitation can be found in the Field Declarations section. Data Support Many ASN.1 formats declare date and time information as OCTET STRING . The date type converter is introduced to manage an automatic conversion to date instances. A possible syntax of date declaration is declared as follows: Time ::= OCTET STRING date({HH,mm,ss}) (SIZE(3)) Date ::= OCTET STRING date({yy,MM,dd})(SIZE(3)) Date ::= OCTET STRING date({cc,yy,MM,dd} , {yy,MM,dd}) DateTime ::= OCTET STRING date({cc,yy,MM,dd,HH,mm,ss}) Note! These are applicable to OCTET STRINGS only. Using Sequential Record Types Some ASN.1 definitions contain data with an OCTET STRING declaration that contains additional structures. In order to manage this, it is possible to split such declarations into sequential record types. It is also possible to use sequential formats to describe constructed ASN.1 types. In this case the tag must be declared as constructed (a MediationZone specific keyword) to allow Ultra to correctly encode the type. Example - Simple sequential record type An example of a simple type is the definition within an asn_block (module GSM): AddressString ::= OCTET STRING (SIZE(1..20)) It can be brought outside the asn_block and redefined as: external GSM.AddressString { bit_block : static_size(1) { int npi : msb(3), lsb(0); int ton : msb(7), lsb(4); }; bcd(msn_fd) msisdn : dynamic_size(udr_size-1), terminated_by(0xF); }; Example - Complex sequential record type An example of a complex type occurs when a field - fieldB - is to be decoded differently depending on the value of another field - fieldA . This ASN.1 definition: ComplexType ::= [APPLICATION 1] SEQUENCE { fieldA INTEGER, fieldB OCTET STRING } Can be replaced with the sequential format: external ComplexType_Seq { int tagA: static_size(1); int lengthA: static_size(1); int fieldA: dynamic_size(lengthA); // Definitions of SubType1 and SubType2 not included // in this example. SubType1 fieldB1: present if( fieldA == 1 ); SubType2 fieldB2: present if( fieldA == 2 ); }; And the extended ASN.1: ComplexType ::= [APPLICATION 1 constructed] ComplexType_Seq Mapping of ASN.1 INTEGER Type and bigint Support Since INTEGER types are automatically mapped to int , which is a 32-bit integer type, INTEGER s that are longer than 4 bytes cause decoding errors. This can be avoided by using the bigint type instead of INTEGER . The only difference between bigint and INTEGER is that bigint is automatically mapped to the bigint type, which can support INTEGER s of any size. Options for in_map and out_map By default, ASN.1 external formats are decoded and encoded as BER. However, the decoding and encoding behavior can be modified by options on the in_map and out_map declarations. The available options are: Option Effect Option Effect CER_length When encoding to BER, use the indefinite length encoding instead of definite length encoding (which is default) ignore_unknown_tags When decoding BER data, the presence of unknown tags will no longer be considered as decoding errors, they will simply be ignored instead. PER_aligned Instead of BER, use PER ALIGNED encoding PER_unaligned Instead of BER, use PER UNALIGNED encoding ASN Language Limitations The ASN.1 compiler is mostly concerned with the type notation of ASN.1. Elements of type notation not supported are: COMPONENTS OF WITH COMPONENT WITH COMPONENTS ABSENT/PRESENT ANY, ANY DEFINED BY ObjectDescriptor DEFAULT DEFINITIONS EXPLICIT, EXPLICIT TAGS INCLUDES MACRO PRIVATE UTCTime EXTERNAL GeneralizedTime OPERATIONS There are also limitations regarding the support of value notation or macro notation. It is only supported to declare INTEGER constants and use them in constraint specifications. There is also limited support for information object classes and OBJECT IDENTIFIER types. Object identifiers are decoded to bytearrays and the information object content is only decoded according to the class definition. BER Limitations In addition to the general ASN.1 limitations there are also some limitations regarding BER that must be taken into consideration: Explicit tags are not supported - All tags are by default implicit (except for tags of CHOICE types, which are always assumed to be explicit according to the ASN.1 standard). Any attempt to specify explicit tagging will result in a compilation error. All string fields are encoded/decoded according to ISO8859-1 except for UTF8String . No validation to ensure that mandatory fields are actually present is performed for SEQUENCE and SET types. Not all character types are supported. However, GraphicalString, IA5String, VisibleString, NumericString , and UTF8String are supported. PER Limitations In addition to the general ASN.1 limitations there are also some limitations regarding PER that must be taken in consideration: For string types, constraints on the permitted alphabet are not handled. Fragmented encoding (encoding for large-size fields) is not supported. Not all character types are supported. However, GraphicalString, IA5String, VisibleString, NumericString , and UTF8String are supported.

---

# Document 1928: Editing a Bulk of UDRs - MediationZone Documentation 9.3 - InfoZone

**Source:** ratanon/mz93-documentation
**URL:** https://infozone.atlassian.net/wiki/spaces/MD93/pages/204612759/Editing+a+Bulk+of+UDRs
**Categories:** chunks_index.json

Other than editing UDRs one at a time, it is also possible to edit a group of UDRs at once. Select the UDRs of interest, or none (this way all UDRs within the file are considered) and click Bulk Edit... Open The Bulk Edit file - data dialog Setting Description Setting Description UDR Type If you have selected UDRs in the UDR File Editor and opened Bulk Edit, the UDR type of the selected UDRs is displayed in this field. If you want to change to another UDR type, click the Browse... button to open the UDR Internal Format Browser where you can select a different UDR type. Filter UDRs and assign UDR fields In this field, you can write custom APL code to edit all selected UDRs. Close Click this button to close the Bulk Edit file - data dialog. Apply Changes Click to apply the changes defined in the APL code. Note! When bulk editing UDRs, the changes of the UDRs are not traceable. All selected UDRs are updated, although their values may not change. Auto Edit Mode This mode allows the editing of bulk of UDRs using matchers and assignments. This mode is available in Legacy Desktop only. Setting Description Setting Description Matchers Defines the UDRs targeted for update. For further information about adding Matchers, see the section below, Add Matcher . Join Style Indicates if All or Any will apply to the conditions in the Matchers list Field Specifies the fields to examine when defining target UDRs Matcher Configuration The expression to apply when matching. Ericsson IOG/IN formats: (see External - Ericsson IOG/IN Records ). This special format type is described through the inw variant of the external block. Assignments Defines the changes to be made to the targeted UDRs. For further information about adding Assignments, see the section below, Add Assignment. Field Fields to edit Assignment Configuration The new value of the field Add Matcher A Matcher is added by selecting Add in the Matchers section. The fields are explained in the table below: Setting Description Setting Description UDR Field List of available fields to use as matchers. Depending on the field type, the Matcher Type list updates to display valid choices. Matcher Type Defines the check criterion for the field. The content of the list varies depending on the field type. Supported types and some of their possible matchers are: Alphanumeric (string, char) - Contains, Begins With, Matches RegExp, etc. Date - Equals, Before, After etc. Numeric - Not Equals, Greater Than, Less Than etc. Bytearray - Is null, Not null, Length equals, Length not equals, Byte at position equals Parameter Some field types can consist of several parts. For instance, date types can contain separate values for year, month, and day. Regular numeric/alphanumeric fields will have Value stated. Is APL Indicates the possibility of entering variable values for the validation field via the use of APL code in the Value column. This feature makes it possible to refer to other fields within the same UDR (as well as call to APL functions) during processing. In the image below, the P155_PackageLength field is of type int . If Is APL is disabled, the Matcher Configuration is interpreted as an int instead of a function. Value The value of the field. By default, a constant is entered. If Is APL is selected, APL syntax can be used to create a variable definition.

---

# Document 1929: SNMP Request Agent Configuration - MediationZone Documentation 9.3 - InfoZone

**Source:** ratanon/mz93-documentation
**URL:** https://infozone.atlassian.net/wiki/spaces/MD93/pages/204643134/SNMP+Request+Agent+Configuration
**Categories:** chunks_index.json

Open To open the SNMP Request agent configuration dialog from a workflow configuration, you can do the following: right-click the agent icon and select Configuration... double-click the agent icon The configuration dialog contains the settings required to select the target UDR fields from the MIB modules defined in the SNMP Collection profile. You can perform either of the following to configure the UDR fields: Configure the UDR fields to poll directly in the agent configuration by referencing an SNMP Collection profile. Create an OID profile and then configure the agent to reference the OID profile. Using an OID profile allows several agents to use the same configuration and the configuration only needs to be maintained in one place. You can also use different SNMP OID profiles for different workflows in the same workflow configuration. The network elements to be polled, must be listed in a network element CSV file. The file should be located on the EC host, where you execute the SNMP workflows. Open SNMP Request Agent configuration dialog Setting Description Setting Description Name This shows the selected SNMP Request agent name. General Profile Type Select which profile type you want the SNMP Request agent to use; an SNMP Collection profile or an SNMP OID profile. SNMP Collection Profile Select the SNMP Collection Profile. Network Element File Full Path The full path to the network element file, including the directory at the EC where the Network Element File file is located, and the file name. The file should be in CSV format. Poll/Field/Instances (only available when SNMP Collection is selected as the profile type) Add the UDR types and fields to be available for polling in this section, and select the Poll check box for the ones you want to poll. Continuous requests for the specified OIDs will be sent out. Do not enable this if you want to send out dynamic requests from APL to the OID by using the generated structure. Network Element File The Network Element File holds the list of Network Elements to poll. The file should be in CSV format . After the IP address or FQDN of your target network element you can specify a number of parameters, see below. The IP-address or FQDN of the target network element is a mandatory parameter. The rest of the parameters (see below) are optional. If you skip them the agent uses the default settings from the selected SNMP Collection Profile. Order of parameters in Network Element File CSV_COMMUNITY, CSV_DESCRIPTION, CSV_VERSION (1-SNMPv1, 2-SNMPv2c, 3-SNMPv3), CSV_TIMEOUT, CSV_RETRIES, CSV_USER, CSV_CONTEXT_NAME, CSV_CONTEXT_ENGINE_ID, CSV_AUTH_PROTO (1-None, 2-MD5, 3-SHA1), CSV_AUTH_PASSWORD, CSV_PRIV_PROTO (1-None, 2-DES, 3-AES), CSV_PRIV_PASSWORD The format of the Network Element File This is an example of how a Network Elements CSV file can look like: (In this case 4 Network Elements are using IP addresses and one is defined using FQDN) 10.46.48.104,public,,2,10000,3,initial,,,3,12345678,1,12345678 10.46.48.108,public,,2,10000,3,initial,,,3,xxxxx,, 10.46.48.33 10.46.48.177,public,,2,5000,20,initial,,,3,abc123,1,12345678 Router_abc,public,,2,10000,3,initial,,,3,xxxxx,, The network element file is checked for changes every 10 seconds. If the file is updated, the information is reloaded into executing workflows without the need to restart the workflow. Adding UDR Fields Click on the Add new UDR field button and the OID UDR Browser dialog appears. Select the UDR fields to poll. You can add several UDR fields. Click OK or Apply to add selected fields. Sometimes the exact OID to request is not known in advance. For instance, the OID string can be composed from a base OID part and an instance part that is the value of a previous response message. A dynamic request can then be performed by creating an SnmpRequestUDR from APL and routing it to the SNMP collection agent. Open You create an SnmpRequestUDR in APL and configure it by setting: remotehost (string) - The address of the network element to request. remoteport (int) - The port of the network element to request. community (string) - The community string to be used in the request. baseoid (string) - The base part of the OID to request. instanceoid (string) - The instance part of the OID to request. unresolved (boolean) - Set to true to make the request an unresolved request, which makes the response get the flattened OID - Value form. tree (boolean) - Set to true to make the request a tree request, which retrieves the entire sub tree from the specified OID. Works only for unresolved requests. The UDR is then routed to the SNMP Request agent. This triggers a request to the specified host + port using the specified OID and community string. The response is received as usual, in the flattened unresolved form or in the hierarchical UDR structure, depending on whether the unresolved flag was set in the request or not. For resolved requests, the specified OID must be in the SNMP Collection profile. The specified host + port + community must be included in the list of network elements (CSV file + profile input). SnmpRequestUDR example: hrSWRun.zip . Download this export and import it to see an example on how dynamic, triggered requests can be used. Using an OID Profile If you want the OID configuration, that is UDR types and fields to be polled, to be available for several agents, create an SNMP OID profile. See SNMP OID Profile for further information.

---

# Document 1930: TextMessage UDR - MediationZone Documentation 9.3 - InfoZone

**Source:** ratanon/mz93-documentation
**URL:** https://infozone.atlassian.net/wiki/spaces/MD93/pages/204675417/TextMessage+UDR
**Categories:** chunks_index.json

The TextMessage UDR is used for sending text frames over a websocket. The following fields are included in the TextMessage UDR: Field Description Field Description data (string) This field contains the data in string format. URI (string) This field contains the Uniform Resource Identifier in string format. securityInformati on (T LSInformation (websocket)) This field contains information about the certificate chain and also which protocol and cipher suite are used .

---

# Document 1931: Analysis Agent Syntax Highlighting and Right-click Menu - MediationZone Documentation 9.3 - InfoZone

**Source:** ratanon/mz93-documentation
**URL:** https://infozone.atlassian.net/wiki/spaces/MD93/pages/204606393/Analysis+Agent+Syntax+Highlighting+and+Right-click+Menu
**Categories:** chunks_index.json

In the code area, the different parts of the code are color-coded according to type, for easier identification. When right-click in the code area, a context-sensitive popup menu appears, enabling easy access to the most common actions you might want to perform. Code Definition The text is color-coded according to the following definitions: Brown - Strings Blue - Functions Cyan - Own (user-defined) functions Green - Types Purple - Keywords Orange - Comments Hint! To refresh the text press Ctrl+Shift+L. Right-click Menu The right-click menu has the foll owin g options: Open Text Editor right-cl ick menu Option Description Option Description UDR Assistance... Opens the UDR Internal Format Browser from which the UDR Fields may be inserted into the code area. MIM Assistance... Open the MIM Browser from which the available MIM Resources may be inserted into the code area. UDR Internal Format Browser You use the UDR Internal Format Browser to easily insert UDR Fields into the code area. It opens in a dialog box that overlaps over the Agent Configuration screen. Open UDR Internal Format Browser The layout of the UDR Internal Format Browser is presented in two main sections  on the left, there is the UDR Types list, and on the right, there are the UDR Fields that correspond to the selection. Select a UDR Type from the presented list. You can expand on the types by clicking on the arrow button to show an individual type. Additionally, you can use the Search field box to find a particular type. Buttons to Expand All or Collapse All list items are also available. When the UDR type is selected, proceed to the UDR Fields selection on the right. The shown results can be filtered using the following options: Option Description Option Description Show Optional Select this option to show optional UDR fields. Show Readable Select this option to show readable UDR fields. Datatype You can filter the datatypes by using this dropdown menu list. Enable this option and select an entry. The available options are the following: bigint , bigdec, bitset, boolean, byte, bytearray, char, date, double, float. int, ipaddress, list<any>, map<any, any>, long, short, string , and void . You can also use the filter input field to type in a string to search for a particular UDR field. Select the appropriate one from the list and press OK to confirm the selection. The other available dialog boxes are Cancel, Refresh, and Apply. MIM Browser You use the MIM Browser to easily insert MIMs into the code area. It opens in a dialog box that overlaps over the Agent Configuration screen. Open The MIM Browser It shows the available selection of MIM types under dropdown sections based on their type. You can optionally use the buttons available on the top bar to Expand All or Collapse All available items. Make your selection and press OK to confirm. You can also Close the MIM Browser by clicking on the button. APL Code Completion To make APL coding easier, the APL Code Completion feature helps you to find and add APL functions and their respective syntax. To access APL Code Completion, place the cursor where you want to add an APL function, press CTRL+SPACE and select the correct function. In order to reduce the number of hits, type the initial characters of the APL function. The characters to the left of the cursor will be used as a filter. APL Code Completion covers: Installed APL functions APL functions defined in APL Code configurations APL functions created with Development Toolkit Function blocks such as beginBatch and consume Flow control statements such as while and if Installed UDR formats UDR formats created with the Development Toolkit User-defined UDR f orma ts Open APL Code Completion

---

# Document 1932: SNMP Request Agent - MediationZone Documentation 9.3 - InfoZone

**Source:** ratanon/mz93-documentation
**URL:** https://infozone.atlassian.net/wiki/spaces/MD93/pages/204740645/SNMP+Request+Agent
**Categories:** chunks_index.json

Open To poll the network, the SNMP Request agent periodically sends queries to the network elements in the network. These queries determine the behavior of the devices, for example, operational status, or the data in the MIB (Management Information Base) variables of the devices. The polling configuration consists of the following parts: Poll definitions, which define the data to retrieve, which is basically your target UDR. This is configured either in the agent's configuration, or in a separate SNMP OID profile. Poll scope, consisting of the devices (network elements) to poll (input CSV file). This is configured in the agent's configuration. Polling interval and other poll properties. This is configured in the SNMP Collection profile. The SNMP Request agent produces user configured UDRs as a result of SNMP polling. For the user convenience the target UDR follows the hierarchical structure of MIB Object definitions. Automatic Polling Policy The agent implements automatic polling policy. For example in case of SNMPv2C and SNMPv3 it will use Get-Bulk to retrieve the table data. In case of SNMPv1 it will use series of Get-Next requests as SNMPv1 does not support Get-Bulk requests. Note that the Polling Interval is a global scope parameter which is configured in the SNMP Collection profile and applies to all Network Elements listed in the CSV file. Triggered Dynamic Requests The agent also supports sending single targeted requests, triggered by sending it a special request UDR. Such single requests can be of type scalar to fetch a single value, or tree to fetch an entire sub tree (SNMP Walk). For scalar requests, the response can be in the form of the same hierarchical structure as for polling requests, or as a simple OID - Value mapping. For tree requests, the response is always a flattened structure in the form of an OID - Value map. This section contains the following sub-sections: SNMP Request Agent Configuration SNMP Request Agent Input/Output Data, MIM and Events

---

# Document 1933: Creating Tables - MediationZone Documentation 9.3 - InfoZone

**Source:** ratanon/mz93-documentation
**URL:** https://infozone.atlassian.net/wiki/spaces/MD93/pages/204638140/Creating+Tables
**Categories:** chunks_index.json

To create the necessary tables in the database: In the /mysql/bin directory connect to the database with the following command: $ mysql -uroot -p<password> -h <IP address to the MySQL Server> Show existing databases: mysql> show databases; The current databases should be displayed. Create the PCC database: mysql> create database pcc; The PCC database should now be created. Connect to the database: mysql> use pcc; The database should now be changed to pcc. Create the tables by running the scripts pcc_bucket_mysqlc.sql and pcc_config_mysqlc.sql : mysql> source <path>/pcc_bucket_mysqlc.sql; mysql> source <path>/pcc_config_mysqlc.sql; verify that the creation has been done by either: mysql> show tables; mysql> describe bucket_storage; mysql> describe config_storage; Exit MySQL when you are done: mysql> exit

---

# Document 1934: Kafka Batch Collection Agent - MediationZone Documentation 9.3 - InfoZone

**Source:** ratanon/mz93-documentation
**URL:** https://infozone.atlassian.net/wiki/spaces/MD93/pages/301138115/Kafka+Batch+Collection+Agent
**Categories:** chunks_index.json

The Kafka batch collection agent consumes messages from Kafka. A batch will be forwarded when the configured batch size is reached or when the hardcoded timeout of 5 seconds is reached. For topics written transactionally, the agent ensures that only committed messages are read (using the Kafka property isolation.level=read_committed , see Kafka Documentation ). For topics written non-transactionally, the agent reads all messages. Note! The workflow will remain running when all messages have been consumed and will wait for more messages. You can stop the workflow from Desktop Online, mzsh commands, or the operations REST interface. The stop will be delayed for 5 seconds. Workflow Example A simple workflow with a Kafka batch collection agent can look like this: Open Example workflow with a Kafka batch collection agent This workflow example has been created as follows: Workflow Design Create the workflow with the following agents: Agent Configuration Kafka Collects messages from Kafka. Define the size of the files forwarded by the Disk forwarding agent with the Batch Size setting. Analysis Receives KafkaRecord UDRs and creates output UDRs based on the contents of the input UDR. An offset is used to create a unique id. Encoder Encodes the data to the format the files will be forwarded in. Disk Creates files. The size of the files is configured in the Kafka collector agent. Kafka Collector Configure the Kafka collector agent to batch up the collected messages in groups of 100. Open Kafka batch collection configuration with Batch Size set to 100 Kafka Profile The Kafka profile defines the broker from which you want to collect data and you must have created it before you can select it in the Execution tab of the Workflow Properties . Open Workflow Properties with Kafka profile selected Analysis Agent Configure the Analysis agent to create the output UDR and then map the contents of the Kafka message. A unique id is created using the offset from the input UDR. consume { Default.UFL_test.test_TI myUDR = udrCreate(Default.UFL_test.test_TI); myUDR.offSet = (string)input.offset; myUDR.value = baToStr(input.value); udrRoute(myUDR); }

---

# Document 1935: Date Functions - MediationZone Documentation 9.3 - InfoZone

**Source:** ratanon/mz93-documentation
**URL:** https://infozone.atlassian.net/wiki/spaces/MD93/pages/205656684/Date+Functions
**Categories:** chunks_index.json

All date related functions conforms to the standard Java date functions. Years, entered with two digits, will refer to 1900 if they are between 70 and 99 and refer to year 2000 if they are between 00 and 69. Warning! The Date functions cannot operate on null arguments. The following functions for Date described here are: dateAdd* The following functions adds a specified number of years, months, days, hours, minutes, seconds, or milliseconds to a date value. void dateAddYears ( date d, int years ) void dateAddMonths ( date d, int months ) void dateAddDays ( date d, int days ) void dateAddHours ( date d , int hours) void dateAddMinutes ( date d, int minutes ) void dateAddSeconds ( date d , int seconds) void dateAddMilliseconds ( date d, int milliseconds ) Parameter Description d/years/months/days A date/year/month/day... Returns Nothing dateCreate* The following functions creates a full date, based on current system timestamp of the host, or a given date and/or time: date dateCreateNow() date dateCreate ( int year, int month, int day, int hour, int minute, int second ) Creates dates where either the date or time part is set: date dateCreateFromDate ( int year, int month, int day ) date dateCreateFromTime ( int hour, int minute, int second ) date dateCreateFromMilliseconds ( long milliseconds ) Creates a copy of a date: date dateCreateCopy( date d ) Parameter Description d/year/month/day A date/year/month/day... Returns A date dateCreateNowMilliseconds The dateCreateNowMilliseconds function returns the current date of the operating system in milliseconds of the operating system. long dateCreateNowMilliseconds() Parameter Description Returns The current date in milliseconds dateDiff The dateDiff function calculates the difference in milliseconds between two dates. The return value is date1 - date2 which means that the result may be negative. long dateDiff ( date date1, date date2 ) Parameter Description date1 The date to subtract from date2 The date to subtract with Returns The difference in milliseconds dateGet* Given a date, the following functions return the year number, month number, day number (Monday=1, Tuesday=2, etc), hour (24 hour clock), minute, second, or millisecond. int dateGetYear( date d ) int dateGetMonth( date d ) int dateGetDay( date d ) int dateGetDayOfWeek( date d ) int dateGetHours24( date d ) int dateGetMinutes( date d ) int dateGetSeconds( date d ) int dateGetMilliseconds( date d ) string dateGetTZ( date d ) Note! The function dateGetTimeZone() is deprecated, please use dateGetTZ() instead. For further information about time zone settings, see Database Configuration in the System Administrator's Guide . Parameters: Parameter Description d The date to convert Returns Integers stating year/month/day/hour/second for all functions except dateGetTZ , which returns the time zone in the way stated by the JVM's TimeZoneID. Example - When debugging the current time zone with dateGetTZ The syntax used when debugging the current time zone with dateGetTZ : debug( dateGetTZ( dateCreateNow() ) ); dateGetAsMilliseconds Given a date, the function dateGetAsMilliseconds returns the total number of milliseconds since 1 Jan, 1970. This function is the inverse of dateCreateFromMilliseconds . long dateGetAsMilliseconds( date d ) Parameter Description d The date to examine. Returns The total number of milliseconds since 1 Jan, 1970. dateGMTOffset The dateGMTOffset function returns the number of milliseconds diverging from GMT. long dateGMTOffset( date d ) Parameter Description d The date to examine Returns Number of milliseconds diverging from GMT dateHas* Given a date the following functions return true if the date includes a date or time part. boolean dateHasDate( date d ) boolean dateHasTime( date d ) Parameter Description d The date to examine Returns true or false dateInDaylightTime Given a date, the dateInDaylightTime functions returns true if the date is a daylight-saving date. boolean dateInDaylightTime( date d ) Parameter Description d The date to examine Returns true or false dateIsLeapYear Given a date, the dateIsLeapYear function performs a leap year evaluation. boolean dateIsLeapYear( date d ) Parameter Description d The date to examine Returns true or false dateNanoseconds The dateNanoseconds function returns the operating system uptime in nanoseconds. This is mainly used to measure code execution times. Note! The returned value will have nanosecond precision, however not necessarily nanosecond accuracy, since it is dependent on how frequently values are updated in the operating system. long dateNanoseconds() Parameter Description Returns The current value of the most precise available system timer in nanoseconds. dateSet* The following functions sets different parts of a given date: void dateSetYear ( date d, int year ) void dateSetMonth ( date d, int month ) void dateSetDay ( date d, int day ) void dateSetHours24 ( date d , int hours) void dateSetMinutes ( date d, int minutes ) void dateSetSeconds ( date d , int seconds) void dateSetMilliseconds ( date d, int milliseconds ) void dateSetTZ ( date d, string timeZone ) The following functions sets the complete date or time part of a date: void dateSetDate ( date d, int year, int month, int day ) void dateSetTime ( date d, int hour, int minute, int second) Note! The function dateSetTimeZone() is deprecated. Use dateSetTZ() instead. For dateSetTimeZone() , timezone did not take effect until date was retrieved by one of the dateGet*-functions. With dateSetTZ() timezone takes effect immediately. For further information about time zone settings, s ee Database Configuration in the System Administrator's Guide . Parameter Description d/year/month/day A date/year/month/day... Note! The component to be set needs to represent a valid value in order not to throw an exception at a later stage. For instance; Month= 1-12, Hours=0-23, Minutes=0-59, Milliseconds=0-999. Also, the date needs to represent a valid date. For instance February 31 is invalid. timeZone An optional string stating the timezone to set Returns Nothing

---

# Document 1936: Batch-Based Real-Time Agents - Agent Configuration - MediationZone Documentation 9.3 - InfoZone

**Source:** ratanon/mz93-documentation
**URL:** https://infozone.atlassian.net/wiki/spaces/MD93/pages/205035430
**Categories:** chunks_index.json



---
**End of Part 81** - Continue to next part for more content.
