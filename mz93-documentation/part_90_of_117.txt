# RATANON/MZ93-DOCUMENTATION - Part 90/112

---
**Dataset:** ratanon/mz93-documentation
**Part:** 90 of 112
**GitHub:** https://github.com/ratan0n/docs/tree/main/mz93-documentation
**Size:** ~68.5 KB
---

For information about the MIM and a list of the general MIM parameters, see Administration and Management in Legacy Desktop . Meta Information Model Publishes MIM Parameters Description Source File Count This MIM parameter contains the number of files, available to this instance for collection at startup. The value is constant throughout the execution of the workflow, even if more files arrive during the execution. The new files will not be collected until the next execution. Source File Count is of the long type and is defined as a global MIM context type. Batch Retrieval Timestamp This MIM parameter contains a timestamp, indicating when the batch was read in the beginBatch block. Batch Retrieval Timestamp is of the date type and is defined as a header MIM context type. Base Directory This MIM parameter contains the name of the Base directory from which the agent locates files. This is defined in the agent configuration. Base Directory is of the string type and is defined as a global MIM context type. Source Files This MIM parameter contains a list of all source files that will be included and processed in the upcoming batch, that is the file content will be set to null. Source Files is of the list<CollectedFileUDR> type and is defined as a header MIM context type. Source Files Left This MIM parameter contains the number of source files that are yet to be collected. This is the number that appears in the Execution Manager backlog. Source Files Left is of the long type and is defined as a header MIM context type. Accesses The agent does not access any MIM parameters. Note! For a list of the general MIM parameters, see Administration and Management in Legacy Desktop . Agent Message Events There are no agent message events for this agent. Debug Events There are no debug events for this agent.

---

# Document 2119: Performance Tuning with File Storage - MediationZone Documentation 9.3 - InfoZone

**Source:** ratanon/mz93-documentation
**URL:** https://infozone.atlassian.net/wiki/spaces/MD93/pages/205031549/Performance+Tuning+with+File+Storage
**Categories:** chunks_index.json

This page describes how to tune the Aggregation agent with file storage. Aggregation Cache The Aggregation agent can store sessions on the file system, using a storage server, but also in a cache. The maximum size of the cache will be determined by the Max Cached Sessions parameter in the Aggregation profile and the average size in memory of a session. It is difficult to estimate the exact memory consumption through testing but the following should be considered when implementing an Aggregation workflow: Try to keep the session data small. Specifically, do not use large maps or lists in the sessions. These will take up a lot of memory. If memory issues are encountered, try decreasing the Max Cached Sessions . In order to find out if the cache size is overdimensioned, you can study the memory of the Execution Context that is hosting the workflow in System Statistics. For information about System Statistics, see /wiki/spaces/MD93/pages/204742117 . To avoid a large aggregation cache causing out of memory errors, the aggregation cache detects that the memory limit is reached. Once this is detected, sessions will be moved from the memory cache to the file system. Note! This has a performance impact, since the agent will have to read these sessions from the file system if they are accessed again. The Aggregation agent will log information in the EC's log file if the memory limit has been reached and the size of the cache needs to be adjusted. You can also specify when updated aggregation sessions shall be moved from the cache to the file system by setting the Execution Context property mz.aggregation.storage.maxneedssync property in the relevant <pico> .conf file. This property shall be set to a value lower than Max Cached Sessions. For performance reasons, this property should be given a reasonably high value, but consider the risk of a server restart. If this happens, the cached data might be lost. Hint! To speed up the start of workflows that run locally (on the EC), set the Execution Context property mz.aggregation.storage.profile_session_cache property in the relevant <pico> .conf file to true (default value is false ). By doing so, the aggregation cache will be kept in memory for up to 10 minutes after a workflow has stopped. This in turn enables another workflow, that runs within a 10 minute interval after the first workflow has stopped, and that is configured with the same profile, to use the very same allocated cache. Note that since the cache remains in memory for up to 10 minutes after a workflow stopped executing, other workflows using other profiles might create caches of their own during this time. The memory space of the respective aggregation caches will add up in the heap. If the EC at a certain point runs out of memory, performance deteriorates as cache is cleared and, as a result, sessions have to be read from and written to disk. The profile session cache functionality is only enabled in batch workflows where the Aggregation profile is not set to read-only, and the storage is placed locally to the EC. Memory Handling in Real-Time Warning! In real-time, when memory caching without any file storage, i e Storage Commit Interval is set to zero, make sure that you carefully scale the cache size to avoid losing a session due to cache over-runs. An over-run cache is recorded by the system event in the System Log. For further information, see Aggregation Session Inspector . While the aggregation cache will never cause the EC to run out of memory, it is still recommended that you set the Max Cached Sessions low enough so that there is enough space for the full cache size in memory. This will increase system performance. Multithreading If you have many sessions ending up in timeout, you can improve the performance by enabling multithreading, i e use a thread pool, for the timeout function block in the Aggregation agent. When multithreading is enabled, the workflow can hand over sessions to the pool via the queue without having to wait for the read operations to complete, since the threads in the thread pool will take care of that. With many threads, the throughput of read operations completed per second can be maximized. Multithreading is enabled by adding the property mz.aggregation.timeout.threads , with a value larger than 0, in the relevant <pico> .conf file. Example - Enabling multithreading, setting the property value to 8 mzsh topo set topo://container:<container>/pico:<pico name>/val:config.properties.mz.aggregation.timeout.threads 8

---

# Document 2120: Amazon SQS Collection Agent Configuration - MediationZone Documentation 9.3 - InfoZone

**Source:** ratanon/mz93-documentation
**URL:** https://infozone.atlassian.net/wiki/spaces/MD93/pages/299663446
**Categories:** chunks_index.json

You can open the SQS Collection Agent configuration dialog from a workflow configuration. Click Build  New Configuration . Select Workflow from the Configurations dialog. When prompted to select workflow type then select Batch . Click Add Agent and select SQS Collection from the Collection tab of the Agent Selection dialog. Setting Description Setting Description AWS profile The AWS connection details as configured in the Amazon Profile configuration, see Amazon Profile Queue name The name of the queue to collect messages from Max messages to receive The maximum number of messages received per request from the SQS queue (range can be set from 1-10) Poll time (seconds) The frequency to poll for more data (range can be set from 0-20) Standard attributes Defines if the standard attributes will be collected All - collects all standard attributes None - collect no standard attributes Note that user-defined attributes are always collected Note! Use the Test Connection button to test the connection to Amazon and the availability of the configured queue.

---

# Document 2121: Agent State Event - MediationZone Documentation 9.3 - InfoZone

**Source:** ratanon/mz93-documentation
**URL:** https://infozone.atlassian.net/wiki/spaces/MD93/pages/204605224/Agent+State+Event
**Categories:** chunks_index.json

This event is dispatched when an agent state changes. The following fields are included: agentName - The name of the agent issuing the event. agentState - The state of the agent. The following are available: Aborted, Active, Created, Idle, Stopped. Fields inherited from the Base event The following fields are inherited from the Base event, and described in more detail in Base Event : category contents - Workflow: <Workflow name>, Agent: <Agent name>, State: <state> eventName origin receiveTimeStamp severity timeStamp Fields inherited from the Workflow event The following fields are inherited from the Workflow event, and described in more detail in Workflow Event : workflowKey workflowName workflowGroupName

---

# Document 2122: PCC Buckets - MediationZone Documentation 9.3 - InfoZone

**Source:** ratanon/mz93-documentation
**URL:** https://infozone.atlassian.net/wiki/spaces/MD93/pages/204611758
**Categories:** chunks_index.json

Search this document: PCC Buckets delivers the capability to create and manage buckets based on subscriber information. With the PCC Buckets package, buckets can be created and used for usage counting. Depending on the subscribers' actions, consumed or exhausted buckets can either be deleted or reset. With PCC Buckets you can create and manage buckets based on subscriber information. PCC Buckets enable you to configure your Policy Control and Charging solution, either on the Desktop, by applying APL functions or using the REST HTTP Interface. Prerequisites The reader of this document should be familiar with: The HTTP protocol Terms and Acronyms This section contains glossaries for all terms and acronyms used throughout the PCC and MediationZone documentation. PCC Terms and Acronyms Term/Acronym Definition Term/Acronym Definition PCC Policy and Charging Control PCRF Policy and Charging Rules Function 3GPP 3rd Generation Partnership Project General Terms and Acronyms For information about general Terms and Abbreviations used in this document, see the Terminology document. Chapters The following chapters and sections are included: Data Model for PCC Buckets Provisioning of PCC Buckets Runtime APL Support for PCC Buckets

---

# Document 2123: ECS (Error Correction System) Inspector - MediationZone Documentation 9.3 - InfoZone

**Source:** ratanon/mz93-documentation
**URL:** https://infozone.atlassian.net/wiki/spaces/MD93/pages/205849121/ECS+Error+Correction+System+Inspector
**Categories:** chunks_index.json

The ECS Inspector is used to inspect and maintain UDRs and batches located in ECS, to view and edit their content, and to add them to different Reprocessing Groups. The latter is a prerequisite for the data to be collected by an ECS Collection Agent. Open Example of forwarding and collection of UDRs from ECS

---

# Document 2124: AMQP Agent Input/Output Data and MIM - MediationZone Documentation 9.3 - InfoZone

**Source:** ratanon/mz93-documentation
**URL:** https://infozone.atlassian.net/wiki/spaces/MD93/pages/205031804/AMQP+Agent+Input+Output+Data+and+MIM
**Categories:** chunks_index.json

Input/Output Data The input/output data is the type of data that an agent expects to receive and delivers. The agent expects AMQP UDRs of type: Received Publish RequestCycle Subscribe and it can deliver AMQP UDRs of type: Received Error RequestCycle SubscribeOK See AMQP UDRs for further information. MIM The AMQP agent does not have any agent-specific MIM paraders. For information about the MIM and a list of the general MIM parameters, see MIM .

---

# Document 2125: CC Monitoring Event - MediationZone Documentation 9.3 - InfoZone

**Source:** ratanon/mz93-documentation
**URL:** https://infozone.atlassian.net/wiki/spaces/MD93/pages/204638926/CC+Monitoring+Event
**Categories:** chunks_index.json

The CC Monitoring Event is triggered based on the options set in the configuration for the monitoring event in the SAP CC Online agent. The event will be sent when the workflow has stopped or during configurable intervals when the workflow is running. The following fields are available for CC Monitor events in the Event Setup tab: CC Monitoring event specific fields agentId averageLatency duration erroneousUDR eventType maxLatency medianLatency minLatency percentil90Latency percentil95Latency percentil99Latency processedUDRs recordingStartDate throughput totalAverageLatency totalDuration totalErroneusUDR totalProcessedUDRs totalThroughput Fields inherited from the Base event The following fields are inherited from the Base event, and can also be used for filtering, and described in more detail in Base Event : category contents eventName origin receiveTimeStamp severity timeStamp

---

# Document 2126: mzcli - wfstop - MediationZone Documentation 9.3 - InfoZone

**Source:** ratanon/mz93-documentation
**URL:** https://infozone.atlassian.net/wiki/spaces/MD93/pages/547980256/mzcli+-+wfstop
**Categories:** chunks_index.json

Usage usage: wfstop [ -immediate ] <pattern matching expression for workflow names> ... This command stops one or more workflows. The command does not kill all processes but rather sends a message to all the agents to stop. If the workflow cannot be stopped, an error message will be shown stating why it was not stopped. Options Option Description Option Description [-immediate] The workflow is stopped without waiting for a batch to finish. Return Codes Listed below are the different return codes for the wfstop command: Code Description Code Description 0 Will be returned if the command was successful or if the argument count is incorrect. 1 Will be returned if no user is logged in. 1-> The number of non-matching workflow names as parameters, or the number of failed workflow stops.

---

# Document 2127: Python Collection Agent Input/Output Data and MIM - Batch - MediationZone Documentation 9.3 - InfoZone

**Source:** ratanon/mz93-documentation
**URL:** https://infozone.atlassian.net/wiki/spaces/MD93/pages/204608834/Python+Collection+Agent+Input+Output+Data+and+MIM+-+Batch
**Categories:** chunks_index.json

Input/Output Data

---

# Document 2128: Groups Tab - MediationZone Documentation 9.3 - InfoZone

**Source:** ratanon/mz93-documentation
**URL:** https://infozone.atlassian.net/wiki/spaces/MD93/pages/204998278/Groups+Tab
**Categories:** chunks_index.json

The Groups tab in the Access Controller Desktop Online dashboard will allow you to create new access groups, update existing access groups and remove an access group. These actions will require a user to have Write permission for Access Controller. Users with the Execute permission can only view the access groups. Groups Table A list of access groups will be displayed in the Groups Table when clicking into the Groups tab. Administrator is a predefined access group. By default, this group has full access to all the activities and functions in the system and it cannot be deleted. You are only permitted to change the Access Controller permissions for the Administrator group. Open Groups table with 3 defined groups. Add Group To add a new group to the system: Click New Group button . Fill in the details according to the description below and click Save button. Setting Description Setting Description Name Enter the name of the group. Valid characters are: A-Z, a-z, 0-9, '-', '.' and '_' Description Descriptive information about the group. Allow Access Through SCIM Check to enable access through SCIM API. Refer SCIM Application This column is a list of all the applications in the system. Execute Check to enable the members of the access group to start an instance of the relevant application or view the data. Clear to prohibit the access group members from using it. Write Check to enable the members of the access group to edit and save a configuration within the relevant application. Note! When access group A is granted Write access to an application, if any of the configuration related to the application has their permission set to access group B, members of access group A that are not members of access group B will not have any permission to work on the configuration. For more information on how to set access groups in your configuration, refer to the Permission Tab under Build View . Checking Write for Data Management and Tools & Monitoring features will allow members of the access group to manipulate the data contained within. Clear to prohibit the user from doing so. Application Category A drop down menu that allows the user to filter on application type. Options are ALL, CONFIGURATION, INSPECTOR, TOOL, WEB, WEB_API. Select All Enables Write (if applicable) and Execute for all permissions in the chosen category. Deselect All Disables Write and Execute for all permissions in the chosen category. For information about how to modify configuration permissions, see Build View . Note! For LDAP users to be able to login, you will have to create an Access Group with the same name as the LDAP Group name that is tied to the LDAP user. Open Access Controller - Add New Access Group screen Edit Group To add edit a group in the system: Click Edit button on the selected Group . Make changes and click Save button. Info! Group Name cannot be changed. Open Access Controller - Edit Access Group screen Delete Group To add edit a group in the system: Click Delete button on the selected Group . Click Delete button on the confirmation message. Note! The Administrator Group is not allowed to be deleted. Open Access Controller - Delete Access Group confirmation message

---

# Document 2129: KPI Output - MediationZone Documentation 9.3 - InfoZone

**Source:** ratanon/mz93-documentation
**URL:** https://infozone.atlassian.net/wiki/spaces/MD93/pages/204676937/KPI+Output
**Categories:** chunks_index.json

The dimension objects in a service model are instantiated during processing. The so called "instance objects" are created dynamically, based on the fields in the input data and the service model, and referenced in KPIOutput UDRs. Example - Relation between input data, service model and KPI output Example Input, Service Model, and output (incomplete model) Analysis of the example : The figure above has two kpi objects, Region.KPI_01 and Site .KPI_02 . Each node property in the kpi objects describes a path into a tree object, i e tree1/Region/Site and tree1/Region . In this example, there is only one tree with a root node ( tree1 ). The difference between the two kpi objects is that the former refers to the final level in the tree (Site) while the latter only refers to the first level under the root node ( Region ). Both kpi objects refer to the same metric, ExampleMetric , which must also be defined in the service model. The input data contains only one value ( Region_1 ) in the field that identifies region . Two sites ( Site_1 and Site_2 ) are represented in the input data, resulting in separate KPIOutput UDRs for the same kpi object ( Region.KPI_01 ). The value of instancePath is different in the two UDRs: /Region_1/Site_1 /Region_1/Site_2 Note how the value in the field instancePath reflects the path in the service model. A third UDR is created for the kpi object Region.KPI_02 . The node in this object only references Region , which is the same for all the records. The value of instancePath in this UDR is Region_1 . Break

---

# Document 2130: Oracle Database Online Backup and Restore in Amazon Web Services - MediationZone Documentation 9.3 - InfoZone

**Source:** ratanon/mz93-documentation
**URL:** https://infozone.atlassian.net/wiki/spaces/MD93/pages/204744704/Oracle+Database+Online+Backup+and+Restore+in+Amazon+Web+Services
**Categories:** chunks_index.json

Amazon RDS provides two different methods for backing up and restoring your Amazon database instances, automated backups and database snapshots. Automated backups automatically back up your database instance during a specific, user-definable backup window, and keeps the backups for a limited, user-specified period of time (called the backup retention period); you can later recover your database to any point in time during that retention period. database snapshots are user-initiated backups that enable you to back up your database instance to a known state, and restore to that specific state at any time. Amazon RDS keeps all database snapshots until you delete them. For more information about these methods, see the Amazon Web Services documentation. How to perform automated backups: http://docs.aws.amazon.com/AmazonRDS/latest/UserGuide/USER_WorkingWithAutomatedBackups.html How to perform snapshot backups: http://docs.aws.amazon.com/AmazonRDS/latest/UserGuide/Overview.BackingUpAndRestoringAmazonRDSInstances.html To restore the database from a backup: Shut down MediationZone. Restore the database according to the Amazon Web Services documentation. If you are restoring from an automated backup, see http://docs.aws.amazon.com/AmazonRDS/latest/UserGuide/USER_PIT.html . If you are restoring from a snapshot, see http://docs.aws.amazon.com/AmazonRDS/latest/UserGuide/USER_RestoreFromSnapshot.html . Update property url in the standard service storage-dispatcher . mzsh topo set topo://services:standard/val:storage-dispatcher.storage-dispatcher1. config.url "<jdbc connection string>" Start MedationZone.

---

# Document 2131: The User Interface Dialog - MediationZone Documentation 9.3 - InfoZone

**Source:** ratanon/mz93-documentation
**URL:** https://infozone.atlassian.net/wiki/spaces/MD93/pages/204676690/The+User+Interface+Dialog
**Categories:** chunks_index.json

The GUI class is used to collect and display the configuration data required for the agent to operate. The user interface will be implemented in a JPanel that the Workflow Editor will put in a dialog. The Workflow Template automatically adds the OK and Cancel buttons. You must extend the DRAgentUI class, that in turn extends the JPanel class. The Workflow Template will create an instance of this class when an agent is dropped or loaded into the workflow. The instance will be kept until the agent is deleted or the workflow is re/unloaded. Defining the User Interface The first method to call is the constructor. Here it may be suitable to create all the user interface components to be used in the dialog. However, when the GUI class is constructed, all variables that may be useful are not yet available. These include, the agent name and the Workflow Template environment. If this information is required the initialize method must be used. Initialization and Deinitialization The initialize method will be called once after the class is constructed. In this method the agent's name and the Workflow Template environment is available. The deinitialize method is called once prior to the destruction of the class. Displaying Configuration Data The displayConfig method is called every time the agent is double-clicked prior to the dialog display. The method is handed a DRStorable configuration object that is either null , if the agent has not yet been configured, or contains data if it has. The data has to be type casted to the appropriate type before usage. It is important that all components in the user interface are cleared in this method before they get populated with the supplied data. If not, old data may reside in the Java components if they were previously filled and Cancel was pressed. A hint is to populate, for instance, combo boxes with data in this method, if they contain environmental data such as database names or route names. This will ensure that these will get updated each time the user interface dialog is displayed. If they are only populated in the constructor, the workflow would have to be reloaded, or a new agent would have to be dropped in order to refresh these components. If the agent supports update of running configurations, it should be considered which fields should be possible to update. Making fields available or not for update is done in the following way. First check if the inherited method isDynamicUpdate returns true . If that is the case the fields that should not be available for update should be disabled. The fields that should be available for update should be enabled or disabled depending on their field instance types. If a field has a field instance type other than final, it should be enabled. If the field instance type of the field is final it should be disabled. Example - Enabling/disabling a field available for dynamic update Enabling/disabling a field available for dynamic update depending on its field instance type: boolean enablePort = !data.getPortFieldInstanceType() .equals(DRFieldInstanceType.FINAL); _portFld.setEnabled( enablePort ); Collecting Data The collectConfig method collects the configuration from the user interface when OK is clicked. Validation of User Data Data entered in the user interface is validated when OK is clicked. The data gets validated against the validation rules specified in the configuration contract. If a validation error occurs a dialog will be displayed containing the message specified in the contract. It is important that references to Workflow Template environment entities, such as route names and MIM resources, are also validated. The recommended way of designing, for instance route names selection, is to populate a user interface component in the displayConfig method. That way, the user cannot select one that is invalid. However, when the user interface dialog has been validated and confirmed, the user may change names on routes and on agents invalidating the previous validation. To prevent this, such external entities must be validated again in the Inspectable class. User Interface for Commands To create a command to interact with an active workflow, the DRCommandUI class should be extended. The Inspectable class must return the class name in the getCommandUIClassName method. All methods defined in the User Interface for Commands must be implemented in the same way as the corresponding methods in the DRAgentUI class.

---

# Document 2132: pico - MediationZone Documentation 9.3 - InfoZone

**Source:** ratanon/mz93-documentation
**URL:** https://infozone.atlassian.net/wiki/spaces/MD93/pages/204612513
**Categories:** chunks_index.json

This command is used to: list, add, or delete EC groups view pico instances mark for shutdown usage: pico <command> [<args>] Add a Group Usage: -add GroupName Delete a Group Usage: -delete GroupName List Groups Usage: -list Regexp View Running Groups & Processes Usage: -view Pico Name Mark ec for shutdown Usage: -mark_for_shutdown <Pico Name> <IP/Host> <true/false> -list usage: pico -list Use pico -list to list available EC groups. Example - pico -list The following commands list all EC groups. mzsh <username>/<password> pico -list Output: ecgroup2 ec ecgroup1 ec -view usage: pico -view <pico name> Use pico -view to view the status of pico instances in the system. Example - pico -view The following displays the status for all pico instances in the system. mzsh <username>/<password> pico -view Output: Pico Start Memory Response Error Marked For Name Time (Used, Commited, Max) Time (ms) Status Shutdown ec1 (ip:port) <time> 1.1, 24.2, 27.6 1 OK ec2 (ip:port) <time> 1.2, 23.3, 28.7 1 OK MZSH:45881 (ip:port) <time> 5.9, 15.5, 47.5 2 OK Platform (ip:port) <time> 8.2, 20.0, 27.6 2 OK The Memory column is a comma-separated list of Used, Committed, and Maximum memory, and Response Time is measured in milliseconds. If Error Status indicates "Error", an OutOfMemoryError has occurred and additional information will be included in the output. For example, in case of an OutOfMemoryError on the Platform, the following could be shown: Platform: Mon Jan 23 09:59:47 CET 2012 OutOfMemoryError on platform at platform-e6410. See log/platform.log for more information OutOfMemoryError is further described in https://infozone.atlassian.net/wiki/x/hCc0D If Error Status indicates "Connection failure", an RCP error has occurred. The following command displays the status of the pico instance named ec1. mzsh <username>/<password> pico -view ec1 Output: Pico Name: ec1 (10.0.0.8:37197) OS: LINUX OS Version: 2.6.38-11-generic-pae Architecture: I386 Processors: 8 Java Version: 1.8.0_121 Loaded Classes: 2854 -add usage: pico -add <ec group name> Use pico -add to add an EC group to the system. Example - pico -add The following command adds an EC group named ecgroup1. mzsh <username>/<password> pico -add ecgroup1 Output: Group ecgroup1 added -delete usage: pico -delete <ec group name> Use pico -delete to delete an EC group from the system. Example - pico -delete The following command deletes an EC group named ecgroup1. mzsh <username>/<password> pico -delete ecgroup1 Output: Group ecgroup1 deleted -mark_for_shutdown usage: pico -mark_for_shutdown <ec1 localhost true> Use pico -mark_for_shutdown to signal to the Platform that an EC is scheduled to be shut down. As a result, the Platform will not assign workflows to the EC. Example - pico -mark_for_shutdown The following command signals that the EC named EC1 should not be assigned workflows mzsh <username>/<password> pico -mark_for_shutdown ec1 localhost true Output: OK Return Codes Listed below are the different return codes for the pico command: Code Description Code Description 0 Will be returned if the command was successful. 1 Will be returned if arguments can not be parsed or if arguments are missing. 2 Will be returned if the communication with the Platform fails. 3 Will be returned if checking of user privileges failed, or if pico already exists when trying to add a new pico. 4 Will be returned if the user does not have permission to add or delete picos. 5 Will be returned if an unexpected error occurs.

---

# Document 2133: MediationZone 9.3 Release - MediationZone Documentation 9.3 - InfoZone

**Source:** ratanon/mz93-documentation
**URL:** https://infozone.atlassian.net/wiki/spaces/MD93/pages/204678755
**Categories:** chunks_index.json

Open The release information for MediationZone 9.3 contains the following: Executive Summary New Features and Enhancements Important Information Known Issues Bug Fixes

---

# Document 2134: Manage View - MediationZone Documentation 9.3 - InfoZone

**Source:** ratanon/mz93-documentation
**URL:** https://infozone.atlassian.net/wiki/spaces/MD93/pages/205030108/Manage+View
**Categories:** chunks_index.json

The Manage view contains options for Data Management , Tools, and Monitoring , and you open the view by clicking on the Manage button in the top button bar. When you click on an option, a new screen will open. You can use the Search field to search for a specific option. Open Manage view The following options are available. Data Management Data Management Option Description Aggregation Session Inspector In Aggregation Session Inspector you can view and edit existing aggregation sessions, see Aggregation Session Inspector . Archive Inspector You can use the Archive Inspector to locate files in an archive, see Archive Inspector . Data Hub With Data Hub you can store and query large amounts of data processed by the system, see Data Hub User's Guide Data Veracity You can use Data Veracity when UDRs fail validation and need to be manually handled before they can be successfully processed. With Data Veracity you can examine UDRs, mark them for deletion, force delete them, or update them, see Data Veracity . Duplicate Batch Inspector With the Duplicate Batch Inspector, you can view the metadata cache used for duplicate checking, see Duplicate Batch Agent . Duplicate UDR Inspector With the Duplicate UDR Inspector, you can view UDRs that have been identified as duplicates, see Duplicate UDR Inspector . PCC Buckets With PCC Buckets you can create and manage buckets based on subscriber information. With the PCC Buckets package, buckets can be created and used for usage counting, see PCC Buckets . PCC Extensions With PCC Extensions you can create your own data sets, in addition to the built-in data models for PCC, see PCC Extensions . PCC Policy Control You can use PCC Policy Control to manage PCC rules using the defined rules data model, see PCC Rules . PCC Routing Control With PCC Routing Control you can route and transform real-time data such as Diameter messages, see PCC Routing Control . PCC Usage Management With PCC Usage Management you can provision products in accordance with the defined PCC product sets, see PCC Buckets . Reference Data Management With Reference Data Management you can query and edit specific table sets in relational databases while schema permissions remain unaltered, see Reference Data Management User's Guide . Tools & Monitoring Option Description Access Controller In Access Controller you can define permissions rights for the users of the system, see Access Controller . Alarms and Events Alarms and Events is a monitoring tool that you can use to keep track of the various Alarms and Event Notifications configured in your workflows, see Alarm Detection and Event Notifications . Conditional Trace With Conditional Trace you can troubleshoot active instances, and set up trace filters on agents and UDRs in real-time workflow routes and Analysis agents for either a specific field value or a range of field values, see https://infozone.atlassian.net/wiki/spaces/MD93/pages/204676782 . EC Groups The EC Groups tool allows you to view and add EC Groups, see https://infozone.atlassian.net/wiki/spaces/MD93/pages/204671006 . Encrypt Password Encrypt Password allows you to encrypt any password and print out the result onto the text field, see https://infozone.atlassian.net/wiki/spaces/MD93/pages/204737275 . Execution Manager Execution Manager allows you to enable, activate, and monitor multiple workflow groups, see https://infozone.atlassian.net/wiki/spaces/MD93/pages/205030703 . Log Files With Log Files, you can access different types of log files, see https://infozone.atlassian.net/wiki/spaces/MD93/pages/205031026 . Log Filter In the Log Filter tool, you can edit log settings for the picos and update the logging dynamically, see https://infozone.atlassian.net/wiki/spaces/MD93/pages/314998785 . Python Manager With Python Manager you manage Python executables, see https://infozone.atlassian.net/wiki/spaces/MD93/pages/205030732 . System Exporter System Exporter enables you to export data from your system into a ZIP file, a specific directory, an MZ Package (MZP) file, or to Git, see https://infozone.atlassian.net/wiki/spaces/MD93/pages/204605469 . System Importer System Importer enables you to import data to your system, either from a ZIP file, a specific directory, an MZ Package (MZP), or from Git, see https://infozone.atlassian.net/wiki/spaces/MD93/pages/204998199 . System Log System Log stores events and errors that have been registered in the system. In addition, it also handles duplicate events within a time frame. The System Log tool allows you to browse and purge the stored log files, see https://infozone.atlassian.net/wiki/spaces/MD93/pages/204639211 . System Statistics System Statistics collects and consolidates execution information. System Statistics continuously monitors and logs the resource utilization of the different hardware nodes and can provide reports over a given time interval. The throughput of workflows can also be monitored using this mechanism. The statistical information can be viewed graphically over any period, and be printed. See https://infozone.atlassian.net/wiki/spaces/MD93/pages/312868905 . UDR File Editor The UDR File Editor allows you to view and edit the content of UDR files, see https://infozone.atlassian.net/wiki/spaces/MD93/pages/204737474 . Ultra Format Converter The Ultra Format Editor allows you to convert persisted UDRs into an updated UDR format, see https://infozone.atlassian.net/wiki/spaces/MD93/pages/204737474 .

---

# Document 2135: SMPP Examples - MediationZone Documentation 9.3 - InfoZone

**Source:** ratanon/mz93-documentation
**URL:** https://infozone.atlassian.net/wiki/spaces/MD93/pages/205002044/SMPP+Examples
**Categories:** chunks_index.json

This section contains one example each for the SMPP Receiver and Transmitter agents. Receiver Agent In this workflow example for the SMPP Receiver agent: Open Receiver workflow example The SMPP receiver agent sends DELIVER_SM UDRs to the Analysis agent, which contains the following code: consume { DELIVER_SM_RESP deliver_sm_resp = udrCreate(DELIVER_SM_RESP); if ((input.sequence_number % 2) == 0) { deliver_sm_resp.command_status = 2; } else { deliver_sm_resp.command_status = 0; } udrRoute(deliver_sm_resp); } With this code, the Analysis agent will: Create a UDR of DELIVER_SM_RESP type called deliver_sm_resp. Check whether the sequence number in the incoming DELIVER_SM UDR is even or odd. If the sequence number is even, the command_status field in the deliver_sm_resp UDR will be set to 2, and if it is odd, the field will be set to 0. The deliver_sm_resp UDR will then be routed back to the SMPP receiver agent. Transmitter agent In this workflow example for the SMPP Transmitter agent: Open Transmitter workflow example The TCP/IP agent sends TCP_TI UDRs into the workflow using a decoder that defines this UDR type. The Analysis agent contains the following code: import ultra.SMPP; consume { if (instanceOf(input, TCP_TI)) { TCP_TI tcp_udr = udrCreate(TCP_TI); tcp_udr = (TCP_TI) input; strToBA(tcp_udr.response, "message=" + tcp_udr.message + "rn"); SUBMIT_SM submit_sm = udrCreate(SUBMIT_SM); bytearray sm; strToBA(sm, "MESSAGE", "UTF-16BE"); submit_sm.short_message = sm; submit_sm.data_coding = 8; submit_sm.source_addr = "555123456"; submit_sm.destination_addr = "555987654"; udrRoute(tcp_udr, "OUT_TCP"); udrRoute(submit_sm, "OUT_SMPP"); } } } which will: Import the SMPP Ultra formats If the received UDR is of the TCP_TI type, the UDR will be named tcp_udr, and the response field in the UDR will be populated with the text "message=<contents of the message field>" in bytearray format. Create a UDR of type SUBMIT_SM called submit_sm. Create a bytearray object called sm, and populate this bytearray with the text "MESSAGE" in bytearray format with UTF-16BE encoding. Populate the short_message field in the submit_sm UDR with the new bytearray. Set the data coding to 8, which equals the UTF-16BE encoding according to the specification. Set the source address to 555123456 and the destination address to 555987654. Route the submit_sm UDR to the SMPP transmitter agent, and the tcp_udr UDR to the TCP/IP agent. The SMPP transmitter agent will then send SUBMT_SM_RESP UDRs back to the Analysis agent when receiving the corresponding SUBMIT_SM_RESP UDRs from the SMSC. The SUBMIT_SM_RESP UDRs contain the original SUBMIT_SM for which the SMSC has responded.

---

# Document 2136: DRRealtimeAgent - MediationZone Documentation 9.3 - InfoZone

**Source:** ratanon/mz93-documentation
**URL:** https://infozone.atlassian.net/wiki/spaces/MD93/pages/205655658/DRRealtimeAgent
**Categories:** chunks_index.json

This class defines no new functions on top of DRAgent . It is the superclass for all realtime agents. A realtime agent receiving raw data can create a task from it and schedule it for decoding. See the realtime environment. The following sequence diagram shows in which order methods are called for the realtime agent. Open Sequence diagram for DRRealtimeAgent For a realtime collection agent example, see: com.digitalroute.devkit.examples.tcpcollection.*

---

# Document 2137: LDAP Authentication - MediationZone Documentation 9.3 - InfoZone

**Source:** ratanon/mz93-documentation
**URL:** https://infozone.atlassian.net/wiki/spaces/MD93/pages/205881453/LDAP+Authentication
**Categories:** chunks_index.json

User authentication is by default performed in MediationZone. As an alternative, you can connect to an external LDAP directory for delegated authentication. This facilitates automation of administrative tasks such as creation of users and assigning access groups. When you create a new user in the Access Controller Users tab, the system will verify against the LDAP Server to make sure that the new user name does not already exist in the LDAP Server. If the LDAP Server is down, you will not be able to create or edit any LDAP users in Users tab. Users that are already included in the Access Controller's Users Tab can still login to the system even when the LDAP Server is down. Note! User created using the Users Tab in Access Controller will not be impacted nor will they have an impact on external authentication servers. LDAP Authentication Preparations Directory Structure The LDAP directory that is used for authentication must conform to the following requirements: The cn attribute of group entries must match an access group defined in the system. For each user in a group entry, the memberUid attribute must be set. All group entries must belong to the object class posixGroup . All user entries must belong to the objectclass posixAccount . The username must be unique. It cannot duplicate a username that already exists in the system. Note! If a user requires administration rights, they must be added to the Administrator access group, which is a default access group. You must create a group named Administrator in the LDAP directory. Secure Access The following steps are required before configuration of authentication with LDAPS or LDAP over TLS: Obtain the server certificate for the authentication server from your LDAP administrator. Start a command shell and copy the server certificate to the platform host. Change directory to $JAVA_HOME/lib/security on the platform host. Install the server certificate using the Java keytool command: keytool -import -file <certificate> -keystore cacerts Active Directory Important Information Directory Structure The LDAP directory that is used for authentication must conform to the following requirements: All user entries must belong to the objectclass user . User's groups have to be provided via memberOf attribute. User's login has to be provided via samaccountname attribute. The username must be unique. It cannot duplicate a username that already exists in the System. LDAP Configuration Select LDAP in Authentication Method dropdown list in the Access Controller Advanced tab. Open Access Controller - Advanced tab with LDAP Authentication example Setting Description Setting Description Authentication Method Select the authentication method to be used. The following settings are available: Default LDAP The default setting is authentication performed by MediationZone. The selected authentication method becomes effective when the configuration is saved. Note! Authentication for the user mzadmin is always performed by MediationZone regardless of the selected authentication method. URL Enter the URL for the external authentication server. The default ports, 389 for LDAP and 686 for LDAPS, are used unless other ports are specified in the URL. Example of LDAP URL ldap://ldap.example.com:389 Example of LDAPS URL ldaps://ldap.example.com:636 Test Connection Click this button to test the connection to the authentication server. LDAP attributes and other settings than the URL are not used when testing the connection. User Base DN Enter the LDAP attributes for user lookups in the external authentication server. The substring %s in this value will be replaced with the username entered at login to produce an identifier that is passed to the LDAP server. Example of User Base DN uid=%s,ou=users,dc=digitalroute,dc=com Group Base DN Enter the LDAP attributes for group lookups in the external authentication server. Example of Group Base DN ou=groups,dc=digitalroute,dc=com Note! The name of the groups created in LDAP Server must be identical to the names configured in Access Controller Access Groups tab . Use TLS Select this check box to enable Transport Layer Security. Note! The following must be considered when using TLS: LDAPS and TLS is not a valid combination. The URL must contain a fully qualified DNS name or the authentication will fail. The default LDAP port, 389, should be used. Use Active Directory Naming Select this check box if you want to use Active directory specific naming. Enable Group Search Bind Credentials Select this check box if you want to enable group search. You must also populate the Bind DN and Password fields. If you want to run an anonymous lookup, leave this check box empty. Bind DN If you want to use a specific Bind DN to search for the group, enter the Bind DN. Password If you want to use a specific Bind DN to search for the group, enter the password to connect LDAP Server.

---

# Document 2138: Bytearray Functions - MediationZone Documentation 9.3 - InfoZone

**Source:** ratanon/mz93-documentation
**URL:** https://infozone.atlassian.net/wiki/spaces/MD93/pages/204612187/Bytearray+Functions
**Categories:** chunks_index.json

The functions described in this section are used to perform operations on variables of the bytearray type. The following functions for Bytearray described here are: 1 baAppend 2 baCreate 3 baCreateFromHexString 4 baGet 5 baHexDump 6 baInsert 7 baReplace 8 baSet 9 baSize baAppend Concatenates two bytearrays and returns the result. None of the input arrays are changed. bytearray baAppend (bytearray array1, bytearray array2 ) Parameter Description Parameter Description array1 A bytearray array2 Another bytearray to append to the end of array1 Returns The concatenated bytearray baCreate Creates a new bytearray of the specified size. bytearray baCreate( int size ) Parameter Description Parameter Description size Size of the new array in bytes Returns A bytearray of the specified size baCreateFromHexString Converts a readable hex string into a bytearray. bytearray baCreateFromHexString( string hexString ) Parameter Description Parameter Description hexString The hex string you want to convert into a bytearray. Returns A new bytearray containing the data from the hex string. Example - Using hex string If the hex string is "100A" the returned byte array will contain 2 bytes; one with decimal value 16 (which equals hex value 10), and one with decimal value 10 (which equals hex value 0A): 00010000 and 00001010 If the hex string contains an odd number of digits/characters, a "0" will be added at the end of the string, and it will then be handled in the same way as in the example above. For example, if the hex string is "123", a "0" will be added, giving a string containing "1230". The returned bytearray will then contain 2 bytes; one with decimal value 18 (which equals hex value 12) and one with decimal value 48 (which equals hex value 30): 00010010 and 00110000 baGet Retrieves a byte value from a bytearray. The index must be in the range 0<=index<baSize( array ) or the workflow will abort with a runtime error. int baGet (bytearray array, int index) Parameter Description Parameter Description array A bytearray index Index of the element to retrieve Returns A decimal representation of the indexed byte Example - Using baGet Consider a bytearray with the following hex dump "00000000: 484a 4c HJL". Accessing the first element according to the example code, will return "72" - the decimal value of 0x48. int myVar = baGet( myBA, 0 ); baHexDump Converts a bytearray into a readable hex dump string, useful for debugging. string baHexDump( bytearray array ) Parameter Description Parameter Description array A bytearray Returns A string containing the hex formatted bytearray Example - Using baHexDump Consider a bytearray created with the code in this example. bytearray myBA = baCreate( 3 ); baSet( myBA, 0, 72 ); baSet( myBA, 1, 74 ); baSet( myBA, 2, 76 ); string myDump = baHexDump(myBA); Using the bytearray as input to baHexDump will output a hex dump with the following appearance: "00000000: 484a 4c HJL" baInsert Inserts one bytearray into another bytearray and returns a new bytearray containing the two merged bytearrays. bytearray baInsert ( bytearray ba1, int pos, bytearray ba2 ) Parameter Description Parameter Description ba1 The bytearray into which you want to insert bytearray ba2 pos The position in bytearray ba1 where you want to insert bytearray ba2 ba2 The bytearray you want to insert into bytearray ba1 Returns A new bytearray containing the data in bytearrays ba1 and ba2 arranged in the order determined by the pos parameter baReplace Replaces the data in one bytearray with the data in another bytearray and returns a new bytearray with the replaced data. bytearray baReplace ( bytearray ba1, int pos, bytearray ba2 ) Parameter Description Parameter Description ba1 The bytearray in which you want bytes to be replaced pos The position in ba1 where you want the replacement to start ba2 The bytearray containing the bytes you want replace the bytes in ba1 with Returns A new bytearray containing the replaced bytes arranged in the order determined by the pos parameter baSet Sets the value of a byte in the bytearray. The index must be in the range 0<=index<baSize( array ) or the workflow will abort with a runtime error. void baSet ( bytearray array, int index, int value ) Parameter Description Parameter Description array A bytearray. index Index of the byte to set value The new value of the byte. The actual value set is ( value & 0xFF ) Returns Nothing baSize Returns the size of an array. int baSize( bytearray array ) Parameter Description Parameter Description array A bytearray Returns The size of the array in bytes

---

# Document 2139: New Features and Enhancements - MediationZone Documentation 9.3 - InfoZone

**Source:** ratanon/mz93-documentation
**URL:** https://infozone.atlassian.net/wiki/spaces/MD93/pages/204647457/New+Features+and+Enhancements
**Categories:** chunks_index.json

Open In this section, you can see information about the new features and functionality in this release. 1 New Features 1.1 New Connectors 1.1.1 New Kafka Agents 1.1.2 Amazon S3 Agents in Real-Time Workflows 1.1.3 Amazon SQS Agents 1.1.4 APN Processing Agent 1.1.5 SAP CC REST Agent 1.2 MariaDB 1.2.1 Supported Agents for MariaDB 1.2.2 Additional APL Functions and Event Notifications Support MariaDB 1.3 Usability 1.3.1 New Command Line Interface 1.3.2 Desktop Search 1.3.3 Log Filter 1.3.4 Support for wfexport and wfimport mzsh Commands 1.3.5 MZSH Command For Shutting Down Desktop and Legacy Desktop 1.4 Integration and Security 1.4.1 User Security Improvements 1.4.2 SAP CTS+ Integration 1.5 Google Secret Manager 1.6 Reference Data Management Supports SAP HANA 1.7 System Statistics 2 Enhancements 2.1 followRedirects Field for RequestCycle UDR in HTTP/2 Agents 2.2 HTTP/2 Client Agent Support Additional OAuth Settings 2.3 Operations REST Interface for Host and Pico 2.4 SAP RFC Processor Agent Supports Execution Time Threshold Configuration 2.5 Configurable Maximum Response Size for HTTP/2 Client 2.6 Data Type Conversion Property for SAP JCo ABAP Type P 2.7 Database Sizing 2.8 Rollback New Features The following new functionality has been added in this release: New Connectors New Kafka Agents Ref: XE-14033 A completely new set of Kafka agents has been designed, which will replace the previous Kafka agents in a later release. The main differences are that the new agents: Include a batch forwarding agent. Store transactions in the Kafka cluster (transactions are only tracked for batch workflows). Store offset in the Kafka cluster only. Enables one consumer to collect from several topics, and one producer to forward to several topics. Include automatic rebalancing for the collection of messages and several workflows can collect messages in parallel from the same topics will keep batch collection workflows in a running state, even when all data has been collected. Use only two UDR types: For more information, see New Kafka Agents . Amazon S3 Agents in Real-Time Workflows Ref: XE-13151, XE-13152 The Amazon S3 collection and forwarding agents can be used for collecting and forwarding files from and to specified buckets and regions in Amazon and they are now also available for real-time workflows. For more information, see Amazon S3 Agents . Amazon SQS Agents Ref : XE-13403 The Amazon SQS Agents act as consumers (collection agents) and producers (forwarding agents) of messages in Amazon Simple Queue Service, which is a fully managed message queueing service. Both standard and FIFO queueing are supported, see SQS Agents for more information. APN Processing Agent Ref: XE-14066 The APN processing agent is now available for real-time workflows. It enables push notifications to be sent to mobile devices using Apple certificates. The APN processing agent includes two distinct UDRs: one for pushing notifications and another for reporting results. For more information, see APN Agent . SAP CC REST Agent Ref: XE-11292 SAP CC REST agent allows you to connect and send charging requests to SAP Convergent Charging on SAP Cloud (RISE). The agent will use API to communicate with the SAP CC server, sending HTTP requests and receiving HTTP responses in return. SAP CC REST agent has its own UDRs separate from other SAP CC agents and it is generated based on YAML files of the REST API version used by the SAP CC server. For more information, see SAP CC REST Agent . MariaDB Supported Agents for MariaDB Ref: XE-13414 MariaDB can now be used with the SQL Collection and Forwarding agents, the SQL Loader agent, and the Task Workflow SQL agent. For more information, see MariaDB . Additional APL Functions and Event Notifications Support MariaDB Ref: XE-13415 You can now select MariaDB when configuring to run the Callable Statements, Database Bulk Lookup Functions, Database Table Related Functions, Event Notifications, and Prepared Statements. For more information, see MariaDB . Usability New Command Line Interface Ref: XE-15667 We have created a new Command Line Interface called mzcli. It does not require connectivity to the platform to execute. See the https://infozone.atlassian.net/wiki/x/wacyD for more information. Desktop Search Ref: XE-13735 You can now search for configurations, APL codes, and Ultra formats using the search bar at the top of the Desktop. You can even use the search bar to create new configurations or to search for tools and Data Management applications. For more information, see Search . Log Filter Ref: XE-12917 You can now update the logging settings for picos dynamically, either in the Log Filter in Desktop Online or using mzsh. You can update log level, select to include stacktrace or not, perform logging for a selected package or class, add logging to an additional file and reset to default settings. For more information, see Log Filter and logger . Support for wfexport and wfimport mzsh Commands Ref: XE-13234 The wfexport command generates a file (CSV, TSV, or SSV) containing data from the Workflow Table. This file includes a header row listing the names of the Workflow Table columns. The wfimport command updates the specified workflow configuration by importing workflows defined in the export file. For more information, see wfexport and wfimport . MZSH Command For Shutting Down Desktop and Legacy Desktop Ref: XE-11515 With the, mzsh desktopadmin command you can shut down all Deskops and Legacy Desktops connected to the Platform, see desktopadmin . Integration and Security User Security Improvements Ref : XE-12201 Enhanced user security is now enabled by default upon installation of the Platform. The property mz.security.user.control.enabled is now set to true in the platform.conf file. Furthermore, the enhanced user security property mz.security.user.password.reset.enabled has been removed. With the property removed, by default, any users registered into the system will now be prompted to change their password on their first login. For more information, see Enhanced User Security . SAP CTS+ Integration Ref: XE-13755 SAP CTS+ (Change and Transport System) can now be integrated with MediationZone. It enables you to manage and transport configurations across different environments with greater flexibility and control. For more information see, SAP CTS+ Integration User's Guide . Google Secret Manager Ref: XE-14275 You can use the Google Secret Manager profile to setup up access credentials and properties for connecting to a Google Secret Manager environment. For more information, see Google Secret Manager Profile . Reference Data Management Supports SAP HANA Ref: XE-13153 The Reference Data profile allows you to select which tables are available for querying and editing through the Reference Data Management dashboard via the RESTful interface. You can now select SAP Hana in the Reference Data profile configuration. For more information, see Reference Data Profile . System Statistics Ref: XE-13313 System Statistics can now be viewed from the Desktop. You can access the System Statistics from the Tools and Monitoring section of the Manage View. For more information, see System Statistics . Enhancements followRedirects Field for RequestCycle UDR in HTTP/2 Agents Ref: XE-14079 To accommodate scenarios where a cookie may be included in the 3xx response message, the followRedirects field is introduced in the HTTP/2 RequestCycle UDR to disable automatic redirection if necessary. For more information, see HTTP/2 UDRs . HTTP/2 Client Agent Support Additional OAuth Settings Ref: XE-14080 The following fields have been added to OAuth 2.0 authentication type in HTTP/2 Client agent - Authentication tab: Client Auth Type : Added options for client_secret_basic and client_secret_post Base URL : This field is added to manage base URL settings For more information, see https://infozone.atlassian.net/wiki/spaces/MD93/pages/204739302 . Operations REST Interface for Host and Pico Ref: XE-13029 The Operations REST API is now available for host and pico. Users can access http(s)://<platform server>:<platform port>/ops/mz/host/v1/api-docs for host and http(s)://<platform server>:<platform port>/ops/mz/pico/v1/api-docs for pico on any given running system Platform. For more information, see https://infozone.atlassian.net/wiki/spaces/MD93/pages/205031043 . SAP RFC Processor Agent Supports Execution Time Threshold Configuration Ref: XE-14268 Two additional options; the Enable Logging for Execution Exceeding Time Threshold checkbox and Execution Threshold Time (min) field are added to the SAP RFC Processor agent configuration to allow users to configure the execution time threshold. When an RFC Function takes too long, any attempt to abort the workflow will be logged in the System Log. See https://infozone.atlassian.net/wiki/spaces/MD93/pages/205034531 for more information. Configurable Maximum Response Size for HTTP/2 Client Ref: XE-13740 Users can now set a maximum size limit for responses received by the HTTP/2 Client. To configure the maximum response size, use the Max Response Content Length field introduced in the Client tab of HTTP/2 Client agent configuration. See https://infozone.atlassian.net/wiki/spaces/MD93/pages/204739302 for more information. Data Type Conversion Property for SAP JCo ABAP Type P Ref: XE-14878 A new property is introduced to define the data type used for converting values when mapping to SAP JCo ABAP Type P (Binary Coded Decimal). The saprfc.bcd.double property provides flexibility to users in handling data types. See Execution Container Properties for more information. Database Sizing Ref: XE-17321 We have provided documentation on approach to plan for database sizing. Rollback In previous versions, rollback has not been available, but in this version rollback in case of failed upgrade has been implemented, see https://infozone.atlassian.net/wiki/spaces/MD94/pages/399147509 .

---

# Document 2140: XML Formats - MediationZone Documentation 9.3 - InfoZone

**Source:** ratanon/mz93-documentation
**URL:** https://infozone.atlassian.net/wiki/spaces/MD93/pages/204613585/XML+Formats
**Categories:** chunks_index.json

MediationZone also includes direct support for XML Schema definitions. Any XML Schema definition can be directly imported into the system and a corresponding XML decoder/encoder is automatically generated. Using this capability, MediationZone can directly support the translation from/to any XML document.

---

# Document 2141: FTP DX200 Agent Preparations - MediationZone Documentation 9.3 - InfoZone

**Source:** ratanon/mz93-documentation
**URL:** https://infozone.atlassian.net/wiki/spaces/MD93/pages/205652706/FTP+DX200+Agent+Preparations
**Categories:** chunks_index.json

Prior to configuring a DX200 agent to use SFTP, consider the following preparation notes: Server Identification Attributes Authentication Server Keys Server Identification The DX200 agent uses a file with known host keys to validate the server identity during connection setup. The location and naming of this file is managed through the property: mz.ssh.known_hosts_file It is set in <pico name>.conf file of the relevant EC to manage where the file is saved. The default value is ${mz.home}/etc/ssh/known_hosts . The SSH implementation uses JCE (Java Cryptography Extension), which means that there may be limitations on key sizes for your Java distribution. This is usually not a problem. However, there may be some cases where the unlimited strength cryptography policy is needed. For instance, if the host RSA keys are larger than 2048 bits (depending on the SSH server configuration). This may require that you update the Java Platform that runs the EC. For unlimited strength cryptography on the Oracle JRE, download the JCE Unlimited Strength Juris- diction Policy Files from http://www.oracle.com/technetwork/java/javase/downloads/jce8-download-2133166.html . Replace the jar files in $JAVA_HOME/jre/lib/security with the files in this package. The OpenJDK JRE does not require special handling of the JCE policy files for unlimited strength cryptography. Attributes DX200 agent support the following SFTP algorithms: blowfish-cbc, cast128-cbc, twofish192-cbc, twofish256-cbc, twofish128-cbc, aes128-cbc, aes256-cbc, aes192-cbc, 3des-cbc. Authentication The DX200 agent support authentication through either username/password or private key. Private keys can optionally be protected by a Key password. Most commonly used private key files, can be imported into . Typical command line syntax (most systems): ssh-keygen -t <keyType> -f <directoryPath> Argument Description Argument Description keyType The type of key to be generated. Both RSA and DSA key types are supported. directoryPath The directory in which you want to save the generated keys. Example The private key may be created using the following command line: > ssh-keygen -t rsa -f /tmp/keystore Enter passphrase: xxxxxx Enter same passphrase again: xxxxxx Then the following is stated: Your identification key has been saved in /tmp/keystore Your public key has been saved in /tmp/keystore.pub When the keys are created the private key may be imported to the DX200 agent: Open Finally, on the SFTP server host, append /tmp/keystore.pub to $HOME/.ssh/authorized_keys . If the $HOME/.ssh/authorized_keys is not there it must be created. Server Keys The SSH protocol uses host verification as protection against attacks where an attacker manages to reroute the TCP connection from the correct server to another machine. Since the password is sent directly over the encrypted connection, it is critical for security that an incorrect public key is not accepted by the client. The agent uses a file with the known hosts and keys. It will accept the key supplied by the server if either of the following is fulfilled: The host is previously unknown. In this case the public key will be registered in the file. The host is known and the public key matches the old data. The host is known however has a new key and the user has been configured to accept the new key. For further information, see the section Advanced Tab in 9.31.3 FTP DX200 Agent Configuration . If the host key changes for some reason, the file will have to be removed (or edited) in order for the new key to be accepted.

---

# Document 2142: Appendix A - MediationZone Interfaces - MediationZone Documentation 9.3 - InfoZone

**Source:** ratanon/mz93-documentation
**URL:** https://infozone.atlassian.net/wiki/spaces/MD93/pages/204647984
**Categories:** chunks_index.json

MediationZone provides connection interfaces to a variety of external systems. Interfaces are grouped into two categories: Offline interfaces Collection and forwarding interfaces specifically used in a file-based environment. Online Interfaces Client and server functionality for workflows that communicate over online-enabled interfaces. For more detailed information: Refer to Product Catalog

---

# Document 2143: Amazon Collection Agent Input/Output and MIM - MediationZone Documentation 9.3 - InfoZone

**Source:** ratanon/mz93-documentation
**URL:** https://infozone.atlassian.net/wiki/spaces/MD93/pages/299663470/Amazon+Collection+Agent+Input+Output+and+MIM
**Categories:** chunks_index.json

Input/Output Data The Amazon Collection Agent retrieves messages from Amazon SQS and converts them to UDRs of type SqsCollectorCygleUDR. MIM For information about the MIM and a list of the general MIM parameters, see Administration and Management in Legacy Desktop | MIM . Publishes The Amazon Collection Agent publishes the following MIMs: MIM Parameter Description MIM Parameter Description <Route> Queue Full Count This MIM parameter contains the amount of Cycle UDRs left in the queue in the route out of the agent. <Route> Queue Full Count is of the long type and is defined as a global MIM context type. <Route> Queue Size This MIM parameter contains the queue size of the Cycle UDRs in the route out of the agent. <Route> Queue Size is of the long type and is defined as a global MIM context type. <Route> UDRs This MIM parameter contains the amount of Cycle UDRs that were routed out of the agent. <Route> UDRs is of the long type and is defined as a global MIM context type. Accesses The Amazon Collection Agent does not access any MIM parameters.

---

# Document 2144: Excel Encoder Agent Input/Output Data and MIM - MediationZone Documentation 9.3 - InfoZone

**Source:** ratanon/mz93-documentation
**URL:** https://infozone.atlassian.net/wiki/spaces/MD93/pages/205685437/Excel+Encoder+Agent+Input+Output+Data+and+MIM
**Categories:** chunks_index.json

Input/Output Data Input/Output data is the type of data that an agent both recognizes and delivers. The Excel Encoder agent consumes ExcelUDRs and delivers bytearray types. MIM For information about the MIM and a list of the general MIM parameters, see MIM . Publishes The Excel Encoder agent does not publish any MIM resources. Accesses The Excel Encoder agent does not access any MIM resources.

---

# Document 2145: Analysis Agent - MediationZone Documentation 9.3 - InfoZone

**Source:** ratanon/mz93-documentation
**URL:** https://infozone.atlassian.net/wiki/spaces/MD93/pages/204672084
**Categories:** chunks_index.json

This section describes the Analysis agent. This is a processing agent for batch and real-time workflow configurations. The Analysis agent is used to process UDRs and, for example, to generate audit data and dispatch events in the system. These activities are established by editing the rich programming language - Analysis Programming Language (APL). The Analysis agent, depending on the configured APL code, can either be a pure processing agent with the ability to examine, alter, route and clone each UDR routed to the agent or it can be the final destination for a UDR in the workflow; a sort of forwarding agent. See the APL Reference Guide for descriptions of the Analysis Programming Language, APL, and the available functions. The Analysis agent can be part of both batch and real-time workflows. Differences in the configuration are described in the section Realtime Workflows in Analysis Agent Configuration . Prerequisites The reader of this information should be familiar with: UDR structure and content Basic programming For information about Terms and Abbreviations used in this section, see the Terminology document. Loading

---

# Document 2146: JSON Encoding Functions - MediationZone Documentation 9.3 - InfoZone

**Source:** ratanon/mz93-documentation
**URL:** https://infozone.atlassian.net/wiki/spaces/MD93/pages/204612386/JSON+Encoding+Functions
**Categories:** chunks_index.json

The functions described in this section encode lists, maps, or UDRs to JSON-formatted strings. 1 jsonEncodeList 2 jsonEncodeMap 3 jsonEncodeUdr 4 jsonFormat 5 jsonEncodeNonNullUdr jsonEncodeList This function encodes a list to a JSON formatted string. string jsonEncodeList ( list<any>list) Parameter Description Parameter Description list The list to encode Returns A JSON formatted string jsonEncodeMap This function encodes a map to a JSON formatted string. string jsonEncodeMap ( map<string,any> map) Parameter Description Parameter Description map The map to encode Returns A JSON-formatted string jsonEncodeUdr This function encodes a UDR to a JSON formatted string. string jsonEncodeUdr ( DRUDR udr) Parameter Description Parameter Description udr The UDR to encode. Returns A JSON-formatted string. jsonFormat This function encodes a value of any type ( any ) into a JSON-formatted string. string jsonFormat(any obj) Parameter Description Parameter Description obj The object to encode. Returns A JSON formatted string. jsonEncodeNonNullUdr This function encodes a UDR to a JSON formatted string and omitting any fields that contain a null value. string jsonEncodeNonNullUdr ( DRUDR udr) Parameter Description Parameter Description udr The UDR to encode. Returns A JSON-formatted string.

---

# Document 2147: Desktop User Interface - MediationZone Documentation 9.3 - InfoZone

**Source:** ratanon/mz93-documentation
**URL:** https://infozone.atlassian.net/wiki/spaces/MD93/pages/204670149/Desktop+User+Interface
**Categories:** chunks_index.json



---
**End of Part 90** - Continue to next part for more content.
