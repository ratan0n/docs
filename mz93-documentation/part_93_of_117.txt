# RATANON/MZ93-DOCUMENTATION - Part 93/112

---
**Dataset:** ratanon/mz93-documentation
**Part:** 93 of 112
**GitHub:** https://github.com/ratan0n/docs/tree/main/mz93-documentation
**Size:** ~63.3 KB
---

The UDRs in PCC.Periods contain information about different time periods when rules associated with the periods should be active. The fields are used for defining a period of time during which a rule is active or not active. If all the fields (except StartTime and StopTime) are left empty, the period will always be active. See APL - PCC Runtime Support for further information about how to use the PCC.Periods UDRs with APL and REST HTTP Interface for information on how to access the PCC.Periods UDRs from the REST HTTP interface. Periods UDR Field Description Field Description ID (int) The unique ID of the period. Name (string) The name of the period, e g used by the Rules UDR. StartTime (date) Defines the start date and time for this period. This is the overall start time for the period and this field is mandatory for all periods. StopTime (date) Defines the end date and time for this period. This is the overall end time for the period and this field is mandatory for all periods. StartTimeOfDay (date) Defines the start time of the day in hours and minutes for this period. The rules using this period will start being active at this time of day. The format should be HH:MM. StopTimeOfDay (date) Defines the end time of the day in hours and minutes for this period. The rules using this period will stop being active at this time of day. The format should be HH:MM. Weekdays (list <int>) Determines which weekdays the period should be active. The days are stated with integer values; 0 - Monday, 1 - Tuesday, 2 - Wednesday, 3 - Thursday, 4 - Friday, 5 - Saturday, and 6 - Sunday. Any combination is possible. IncludedPeriods (list <Period (PCC.Periods)>) Contains a list of other periods that should be included in this period. Since the list contains periods, they can in turn include or exclude other periods in their respective IncludedPeriods and ExcludedPeriods settings, which can be useful for creating a more complex inclusion setup. ExcludedPeriods (list<Period (PCC.Periods)>) Contains a list of other periods that should be excluded from this period. Since the list contains periods, they can in turn include or exclude other periods in their respective IncludedPeriods and ExcludedPeriods settings, which can be useful for creating a more complex exclusion setup. Below is a screenshot of the UDR Assistance displaying the Periods UDR: Open Periods UDR Configuring a Period A period configuration can consist of either a single period or a period including or excluding one or several other periods. To configure a period: Configure each period with StartTime and StopTime and any included/excluded periods. For periods that are not supposed to be active 24 h a day, 365 days a year, configure the fields StartTimeOfDay , StopTimeOfDay , and Weekdays . If no Weekdays are defined, the period will be active every day of the week. If no StartTimeOfDay or StopTimeOfDay are defined, the period will be active all the time that the included periods are active. Add periods that you want to include and exclude for the period in the IncludedPeriods and ExcludedPeriods fields. Note If a period includes other periods, that should all be active during the same hours/minutes and days, you only have to configure the StartTimeOfDay , StopTimeOfDay , and Weekday fields in the top-level period. However, if the included periods should be active during different hours/minutes or days, the StartTimeOfDay , StopTimeOfDay , and Weekdays fields should be configured for each included period and not for the top-level period. Using the settings for including and excluding periods will create a tree structure with one period at the top with one or several periods included and excluded beneath. In order for a configured period to be active, all three of the following criteria must met: The current timestamp must be within the set StartTime and StopTime of the top-level period. If any periods are included, the current time stamp must be within the set StartTimeOfDay and StopTimeOfDay of at least one included period. If any periods are excluded, the current time stamp cannot be within the StartTimeOfDay or StopTimeOfDay of any of the excluded periods. Example of a Period Configuration In this example, we have a period including and excluding five other periods, configured as follows: "Top Level" Period StartTime 2012-01-01 08:00 StopTime 2015-12-31 08:00 Included periods Weekdays, Weekends Excluded periods Midsummer "Weekdays" Period StartTime 2012-01-01 07:00 StopTime 2013-01-01 06:00 StartTimeOfDay 08:00 StopTimeOfDay 16:00 Weekdays Monday(0), Tuesday(1), Wednesday(2), Thursday(3), Friday(4) "Weekends" Period StartTime 2012-01-01 07:00 StopTime 2013-01-01 06:00 StartTimeOfDay 08:00 StopTimeOfDay 16:00 Included periods Ordinary, Christmas "Midsummer" Period StartTime 2012-06-22 12:00 StopTime 2012-06-23 00:00 StartTimeOfDay 12:00 StopTimeOfDay 16:00 Weekdays Friday(4), Saturday(5) "Christmas" Period StartTime 2012-12-24 06:00 StopTime 2012-12-26 00:00 StartTimeOfDay 12:00 StopTimeOfDay 23:00 "Ordinary" Period StartTime 2012-01-01 06:00 StopTime 2013-01-01 00:00 StartTimeOfDay 08:00 StopTimeOfDay 16:00 Weekdays Saturday(5), Sunday(6) Open Example of a Period Configuration If current date and time is 2012-06-08 10:00 ( a Friday ) the period will be active. If current date and time is 2012-12-25 23:20 (a Tuesday ) the period will not be active.

---

# Document 2180: Analysis Programming Language (APL) - MediationZone Documentation 9.3 - InfoZone

**Source:** ratanon/mz93-documentation
**URL:** https://infozone.atlassian.net/wiki/spaces/MD93/pages/204647724/Analysis+Programming+Language+APL
**Categories:** chunks_index.json

APL is a structural language with a syntax that to a great extent resembles Java or C/C++ programming language. It supports most standard features of a programming language, plus interfaces to the MediationZone platform for manual logging of events and errors etc. To enable advanced processing it is also possible to load dynamic plug-in functions. Function Blocks The APL code is divided into function blocks where each block is executed at different stages of the data processing. The number and type of function blocks executed depends on whether the APL is used in a batch or real-time workflow. The figure below illustrates the executed function blocks and their order depending on workflow type. Open Function blocks in batch and real-Time processing workflows Among other things, APL includes support for the following functionality: Conditional expressions: if, else, for Iterative statements: while Wide range of string functions (including regular expressions) Wide range of date functions Routing on different output routes Local and global variables Exception handling Associative maps Database lookups Retrieval of value from any UDR field (including nested) or variable Checking for particular record type Functions (both local to a node and global) Assignment to variables or fields of a UDR Creation of new UDR of any type To add APL to a processing flow, the Analysis Agent or the Aggregation Agent can be used. The APL code is written within the agents to perform tasks like data validation. Separate APL Code configurations can also be imported into these agents. Open Example of APL code in an Analysis agent All logic configured in APL will be dynamically compiled to machine code at runtime for performance reasons. No interpretation of the logic is performed. APL is accessible from the Analysis and Aggregation agents and from various applications in the system where flexibility is required. APL is tightly integrated into the UDR and workflow models, enabling access and manipulation of runtime-, persistent-, and meta-data. Examples of such functionality include: Functionality Description Functionality Description UDR operations UDRs can be viewed, filtered, routed, created, cloned, decoded, encoded and modified, etc. Meta Information Model (MIM) Meta information variables available for a workflow (MIMs) can be accessed, created, published, and assigned. Any published information is available to any agent within the workflow. Error Correction System UDRs failing specified validation criteria can be classified with respect to the error and be routed to the Error Correction System (ECS) for corrective action. Audit Audit and statistical information based on workflow execution can be logged in user-defined database tables. Lookups SQL/LDAP statements and calls to stored procedures can be executed from APL. A number of functions for memory caching and indexing are available, as well as prepared statements and bulk-SQL features for high performance table lookups, with minimal overhead External References Property based definitions of APL values based on a certain key. This functionality enables the APL configuration to make dynamic runtime decisions based on parameters in an externally stored property file. Events MediationZone provides various ways of dispatching information to different parts of the system or externally: Events can be sent to the System Log classified as Error, Warning, or Information Events can also be sent directly to the Event Manager for distribution to other targets (SNMP trap, log file, database table, etc) Debug information can be sent to a log file, or directly to the Workflow Monitor Alarms It is possible to configure and trigger potential Alarm conditions from within the workflow configuration as well as from the alarm detection GUI. These conditions provide a very flexible mechanism to visualize alarms.

---

# Document 2181: IPDR SP Agent Events - MediationZone Documentation 9.3 - InfoZone

**Source:** ratanon/mz93-documentation
**URL:** https://infozone.atlassian.net/wiki/spaces/MD93/pages/205033674/IPDR+SP+Agent+Events
**Categories:** chunks_index.json

Agent Message Events There are no agent message events for this agent. Debug Events Debug messages are dispatched in debug mode. During execution, the messages are displayed in the Workflow Monitor. You can configure Event Notifications that are triggered when a debug message is dispatched. For further information about the debug event type, see Debug Event . The agent produces the following debug events: IPDR/SP Common Configuration This message is displayed when the agent first starts up. There will be a series of properties accompanying this message, among those will be keep alive intervals and ACK time intervals. Template Negotiation Configuration This message is displayed when Template Negotiation is enabled for the agent. Additional messages will be displayed alongside this message depending on the fields chosen in the IPDR SP Template profile. Adding collector with connectionKey(<IP address;port;session) This message is displayed prior to the agent starting the connection process with the IPDR SP exporter. Trying TCP connection to <IP address:port> This message is displayed when the agent is attempting to establish a connection with the IPDR SP exporter. Starting IPDR/SP for collector <IP address;port;session> This message is displayed when the agent has successfully established a connection and started a session with the exporter Received Template definition ID = <template ID>, SN = <link to the appropriate DOCSIS Service Definition Schema Name> This message is displayed when the agent receives the template definition from the exporter. Checking Template for negotiation: SN = <link to the appropritate DOCSIS Service Definition Schema Name> This message is displayed when the agent decides to perform a check on the template definition received from the exporter. Any request to modify the template will be sent by the agent to the exporter after this. Mapping Template (final): SN = <link to the appropritate DOCSIS Service Definition Schema Name> This message is displayed when the agent performs the final mapping of the IPDR SP template after the template negotiations are done. Keepalive timeout - sending keepalive This message is displayed when the agent sends a periodic keepalive to the exporter. Stopping the agent... This message is displayed when the workflow is stopped. Cleaning up... This message is displayed just before the FLOW_STOP and DISCONNECT request is sent to the exporter. Removed collector with connectionKey (<IP address;port;session) This message is displayed when the workflow is stopped, just after cleaning up. Failed to connect to <IP address;port;session> after <count> tries. Giving up. This message is displayed when the agent has trouble establishing connection with the exporter.

---

# Document 2182: KPI Management UDR Types - MediationZone Documentation 9.3 - InfoZone

**Source:** ratanon/mz93-documentation
**URL:** https://infozone.atlassian.net/wiki/spaces/MD93/pages/204677192/KPI+Management+UDR+Types
**Categories:** chunks_index.json

This section describes the UDR types that are used for KPI Management. This section includes the following subsections: KDR KPIAggregatedOutput KPIOutput

---

# Document 2183: Sybase IQ - MediationZone Documentation 9.3 - InfoZone

**Source:** ratanon/mz93-documentation
**URL:** https://infozone.atlassian.net/wiki/spaces/MD93/pages/204737705/Sybase+IQ
**Categories:** chunks_index.json

This section contains information that is specific to the database type Sybase IQ. Note! The Sybase IQ database type requires jConnect v16.0 and later. Supported Functions The Sybase IQ database can be used with: Database Table Related Functions (APL) APL function sqlexec Database Collection/Forwarding Agents Event Notifications SQL Collection/Forwarding Agents SQL Loader Agent Task Workflows Agents (SQL) Preparations The Sybase JDBC driver that is included in the SDK has to be downloaded to the Platform in order to connect to a Sybase IQ database from MediationZone. You must proceed as follows: Go to the SAP Software Solutions web page for information about the SDK and included drivers: https://www.sap.com/index.html . Place the downloaded jar file in the $MZ_HOME/3pp directory . Restart the Platform and ECs. Close Pooled Connections The APL function closePooledConnections enables you to close a pooled connection with the Sybase IQ server. This feature helps you eliminate invalid connections. Note! This function only closes inactive connections, regardless of how long the connections have been idle. int closePooledConnections (string dbProfile) Parameters: Returned Value Description dbProfile The name of the database where the table is stored, preceded by the folder name. Example - Using APL function closePooledConnections persistent int profileUsageCnt; .... if ( profileUsageCnt > 100 ) { closePooledConnections("sybase_iq.mydb"); profileUsageCnt = 0; } Performance Tuning The default maximum number of connections on an Execution Context is five. You can tune this number by setting the Execution Context property sybase.iq.pool.maxlimit in the relevant <pico> .conf file. Example - Setting the maximum number of connections for Sybase IQ $ mzsh topo set topo://container:<container>/pico:<pico name>/val:config.properties.sybase.iq.pool.maxlimit 20 There are two properties available for handling timeout of socket connections and socket threads: sybase.jdbc.socketread.timeout with default value 180000 (3 minutes in milliseconds) sybase.jdbc.socketconnect.timeout with default value 30000 (30 seconds in milliseconds) To specify other timeout values, in milliseconds, set the Execution Context properties in the relevant <pico> .conf file. Example - Setting the timeout for a socket tied to a Sybase IQ connection $ mzsh topo set topo://container:<container>/pico:<pico name>/val:config.properties.sybase.jdbc.socketread.timeout 600000 $ mzsh topo set topo://container:<container>/pico:<pico name>/val:config.properties.sybase.jdbc.socketconnect.timeout 20000 Note! When using the timeout property you must ensure that you set a limit that exceeds your longest running query, otherwise you might terminate a connection while it is executing a query.

---

# Document 2184: Decoder Agent Configuration - MediationZone Documentation 9.3 - InfoZone

**Source:** ratanon/mz93-documentation
**URL:** https://infozone.atlassian.net/wiki/spaces/MD93/pages/204999572/Decoder+Agent+Configuration
**Categories:** chunks_index.json

To open the Decoder agent configuration, click Build  New Configuration . Select Workflow from the Configurations dialog. When prompted to Select workflow type , click Batch  OK . Click Add agent . In the Agent Selection dialog click the Processing tab and select Decoder . Double-click the agent icon or select the icon and click on Edit to display the Agent Configuration dialog. Open Decoder configuration dialog Currently, there are the following built-in decoders available. Different settings are available depending on the Decoder you select. CSV Format JSON MZ Tagged Format Avro Format Open Decoder types Setting Description Setting Description Decoder Click Browse to select from a list of available decoders created in the Ultra Format Editor, as well as the default built-in decoders. Decoder-specific settings are described in the table below. On Error Options to control how to react upon decoding errors. Cancel Batch - The entire batch is cancelled. This is the standard behavior. Route Raw Data - Route the remaining, undecodable, data as raw data. This option is useful if you want to implement special error handling for batches that are partially processed. Full Decode This option is only available when you have selected a decoder created in the Ultra Format Editor. Select this option to fully decode the UDR before it is sent out from the decoder agent. This action may have a negative impact on performance, since not all fields may be accessed in the workflow, making decoding of all fields in the UDR unnecessary. To detect all decoding errors, you must you must select this option. If this checkbox is cleared (default), the amount of work needed for decoding is minimized using "lazy" decoding of field content. This means that the actual decoding work may be done later in the workflow, when the field values are accessed for the first time. Corrupt data (that is, data for which decoding fails) may not be detected during the decoding stage but can cause a workflow to abort later in the process. MZ Tagged Specific Settings Tagged UDR Type Click the Add button to select from a list of available internal UDR formats stored in the Ultra and Code servers, to reprocess UDRs of an internal format and send them out. If the compressed format is used, the decoder automatically detects this. JSON Specific Settings UDR Type Click Browse to select the UDR type you want the Decoder to send out. You can either select one of the predefined UDRs or the DynamicJson UDR, which allows you to add a field of type any for including payload. Unmapped Fields If you have selected DynamicJson as UDR Type , you can select the option data in this field to include the payload. If you have selected another UDR type that contains any, or a map field, you can select to put any unmapped fields into the field you select in this list. All fields of any or map type in the selected UDR type will be available. If set to (None), any unmapped fields will be lost. Schema Path Enter the path to the JSON schema you want to use in this field. CSV Specific Setting UDR Type Click Browse to select the UDR type you want the Decoder to send out. You can either select one of the predefined UDRs or the DynamicCsv UDR if the CSV format is not known. Format Select the CSV format you want to use; Unix , Mac , Windows , or Excel , or select to define your own customized format. If you select Custom , the following four settings will be enabled. Delimiter Enter the delimiter character(s) for the fields in the CSV. Use Quote Select this option if quotes are used in the CSV. Quote If Use Quote is selected, enter the type of quotes used in the CSV. Line Break Enter how line breaks are expressed in the CSV. Avro Specific Settings Schema Registry URL Url to a schema register used for obtaining Avro schema used for decoding. Format: <http> or <https>//<host address>:<port>/<schema_register_endpoint_path> Example: " http://localhost:8081/schemas/ids " It is possible to use a proxy to contact a schema register. See HTTP Proxy Support for information on how to configure the proxy on the execution context level. Schema Field Field in JSON formatted schema register response containing schema Note! The use and settings of private threads for an agent, enabling multi-threading within a workflow, are configured in the Thread Buffer tab. For further information, see the Thread Buffer Tab in Workflow Template .

---

# Document 2185: Managing the Spark Cluster - MediationZone Documentation 9.3 - InfoZone

**Source:** ratanon/mz93-documentation
**URL:** https://infozone.atlassian.net/wiki/spaces/MD93/pages/204677115/Managing+the+Spark+Cluster
**Categories:** chunks_index.json

This section describes how to manage the Spark cluster used by KPI Management. This section includes the following subsections: Starting and Stopping the Spark Cluster Submitting a Spark Application Killing a Spark Application Redeploying Spark Workers Removing Runtime Data Change Procedures Logging Port Configuration Flushing spark

---

# Document 2186: Managing Picos with Topo - MediationZone Documentation 9.3 - InfoZone

**Source:** ratanon/mz93-documentation
**URL:** https://infozone.atlassian.net/wiki/spaces/MD93/pages/205815992
**Categories:** chunks_index.json

This section describes how to create, update, remove, and view pico configurations. Each pico configuration consists of a set of attributes, including templates, system properties, JVM arguments, and classpaths. When you change these attributes in a configuration, the corresponding pico instance must be restarted. A configuration may also include "settings" attributes. Unlike e g properties, this type of attribute may contain array values and changes do not require restart of pico instances. Settings At the time of writing, there are three available settings: state - If set to disabled, this pico will not be started by the system command tags - Add tags to group pico instances in the mzsh command system . pico.groups - This attribute is applicable for ECs. Add pico groups to reference multiple pico instances as an entity in a workflow. You can only reference existing EC groups in the pico.groups attribute. For information about how to create an EC group, see Pico Manager and EC Groups for information about how to create an EC group. Classpaths The default classpath attributes that are set in the pico configuration of the Platform. Agents that are installed on the system may require that additional classpaths are set in the pico configuration of ECs. JVM Arguments A number of JVM arguments controlling the memory usage are set in the default template standard , which is inherited by all other default templates. config { ... jvmargs { args=[ "-server" ] maxDirect=[ "-XX:MaxDirectMemorySize=4096M" ] maxMetaspace=[ "-XX:MaxMetaspaceSize=196M" ] xms=[ "-Xms64M" ] xmx=[ "-Xmx256M" ] } ... } You can add additional JVM arguments in a custom template or override the default values in your pico configurations. Each of the JVM arguments in the template has unique label. This makes it possible to edit individual JVM arguments via the mzsh command topo . It is highly recommended that you follow this pattern and consistently use the same labels in all configurations. Omitting or mixing labels may lead to unpredictable results. For instance, the following labels are used in the standard template. Label JVM Argument Label JVM Argument maxDirect MaxDirectMemorySize maxMetaspace maxMetaspace xms Xms xmx Xmx If you set set any of the above JVM arguments in a custom template, but with different labels. Pico instances may start with conflicting JVM arguments. mzsh topo set topo://container:<container>/pico:<pico>/obj:config.jvmargs  '<label>: ["argument1","argument2"]' Example - Setting JVM arguments mzsh topo set topo://container:main1/pico:platform/obj:config.jvmargs  'xmx:["-Xmx256M"] xms:["-Xms64M"] maxMetaspace:["-XX:MaxMetaspaceSize=196M"] maxDirect:["-XX:MaxDirectMemorySize=4096M"] args : ["-server"]' If you have a large block of APL code, e g 300 lines or more, add the JVM argument -XX:DontCompileHugeMethods to pico configurations of ECs. This causes the the JIT compilation to take effect: mzsh topo set topo://container:<container>/pico:<pico>/obj:config.jvmargs  'dontCompileHugeMethods:["-XX:DontCompileHugeMethods"]' System Properties For information about the available system properties, see System Properties . This chapter includes the following sections: Creating Pico Configurations Updating Pico Configurations Removing Pico Configurations Viewing Pico Configurations and Attributes Resetting and Activating Pico Configurations

---

# Document 2187: Diameter Agents - MediationZone Documentation 9.3 - InfoZone

**Source:** ratanon/mz93-documentation
**URL:** https://infozone.atlassian.net/wiki/spaces/MD93/pages/204606955
**Categories:** chunks_index.json

This section describes the Diameter profiles and the Diameter agents. The agents are processing agent for real-time workflow configurations. Prerequisites The user of this information should be familiar with the Diameter Base Protocol, RFC 6733 ( http://www.faqs.org/rfcs/rfc6733.html ), which obsoletes RF C 35 88 The section contains the following subsections: Diameter Configuration and Design Considerations Diameter Profiles Diameter Stack Agent Diameter Request Agent Diameter Syntax Description A Diameter Example

---

# Document 2188: Log and Notification Functions - MediationZone Documentation 9.3 - InfoZone

**Source:** ratanon/mz93-documentation
**URL:** https://infozone.atlassian.net/wiki/spaces/MD93/pages/204743789/Log+and+Notification+Functions
**Categories:** chunks_index.json

The following functions are used for debugging APL code, or logging user defined messages and events. The following functions for Log and Notification described here are: 1 debug 2 dispatchAlarmValue 3 dispatchEvent 4 dispatchMessage 5 log* 6 log.* 7 mailNotify 8 mailNotifyHtml debug This function prints the supplied argument to the output target specified in the Execution tab of the Workflow Properties dialog. The valid options are File or Event . If File is selected, the debug is saved in the temporary directory specified in the system property pico.tmpdir . The file must be named debug/<workflow name> . Alternatively, the location of the debug file can also be configured by using the mz.wf.debugdir property. Each time a workflow is activated, a new debug information will be generated and overwrite the existing file. If Event is selected, the output is shown in the Workflow Monitor. For further information, see Workflow Monitor . void debug( arg ) Parameter Description Parameter Description arg Argument to write to debug output. Could be any type. Note that printing a UDR type will dump all the field values, which may be a large amount of data. Similarly, the debug output for a table or list type may be very large. There is a special case if arg is a bytearray. In this case, the output string will be the hex dump returned from the baHexDump built-in function. For all other variable types, the output is the direct string conversion, meaning debug ( arg ) is the same as debug ( (string) arg ). Returns Nothing dispatchAlarmValue The function makes it possible to detect alarm situations based on workflow behavior. It dispatches a user defined <value> with a user defined valueName from the workflow. The valueName used must be defined using Alarm Detection. For further information, see Alarm Detection in the Desktop user's guide. void dispatchAlarmValue(string <"valueName">, long value) Parameter Description Parameter Description "valueName" The workflow alarm value name, as defined in the Alarm Detection Editor value Any value to be associated with the name Returns Nothing Example - Using dispatchAlarmValue The following code example displays a situation and syntax useful for the dispatchAlarmValue . consume { if ( timeToPay ) { udrRoute(chargingUdr, "to_billing"); //Enable for 'amount out of range' Alarm Detection dispatchAlarmValue("chargingAmount", chargingUdr.amount); } } dispatchEvent A user can define a customized event type. This is done using an event UDR, optionally extended with user-defined fields. This event UDR can be populated with any information by using APL code, and then be sent, using the dispatchEvent function, to be caught by the Event Notification. The event will have asynchronous event handling, and if there is an error in the notification, or if dispatching is on the way, this will be logged in either the EC log or the Platform log, depending on what the problem is. For further information about Event Notification, see Event Notifications in the Desktop user's guide. void dispatchEvent( UltraEvent eventUDR ) Parameter Description Parameter Description eventUDR The name of the event UDR Returns Nothing dispatchMessage This method is used to produce user defined messages associated to predefined Event Categories. For further information about the Event Notification editor, see Event Notifications in the Desktop user's guide. For instance, an Event Category could be named 'DISASTER', and be configured to send an email to the System Administrator. Then an APL agent could send a detailed description with the dispatchMessage function whenever this error situation is detected. void dispatchMessage ( string string , string <Event Category> ) Parameter Description Parameter Description string Value/message to append to the Event Category <Event Category> Name of a user defined event as declared in the Event Notification Editor. This event must be defined in the Event Notification Editor in order for the APL code to compile. Returns Nothing log* Logs a message string to the System Log of type error, warning or information. The entry will fall under the Workflow category where workflow name will be the name of the current workflow and agent name will be the name of the agent logging the message. void logError ( string message , string parameterName_n , // Optional string|int parameterValue_n , // Optional ... ) void logInformation ( string message , string parameterName_n , // Optional string|int parameterValue_n , // Optional ... ) void logWarning ( string message , string parameterName_n , // Optional string|int parameterValue_n , // Optional ... ) Parameter Description Parameter Description message A main message appearing in the log parameterName_n Name of an optional parameter. If declared, parameterValue_n must be declared as well. parameterValue_n Value of an optional parameter. If declared, parameterName_n must be declared as well. Returns Nothing Example - Using logWarning The following code example logs a warning message, which when displayed in the System Log will look like the following figure: logWarning( "UDR failed validation", "ANUMBER IS ", input.anum, "BNUMBER IS ", input.bnum, "DURATION IS ", input.duration); Open System Log inspection log.* These functions invokes logging with log4j. For information about how to configure the logging, such as to set the log level, see the System Administrator's Guide . void log.fatal (any message, any tag ) //optional void log.error (any message, any tag ) //optional void log.warn (any message, any tag ) //optional void log.info (any message, any tag ) //optional void log.debug (any message, any tag ) //optional void log.trace (any message, any tag ) //optional Parameter Description Parameter Description message A value that will be appear in the message field in the log output This parameter will be ignored if cannot be typecasted to a primitive data type e g string or int. tag Objects(s) that will appear in the tag field in the log output. Returns Nothing Example - Using log.debug consume { log.debug("In consume."); list<int> rcDebug =listCreate(int); int rc=0; listAdd(rcDebug,rc); rc=1; listAdd(rcDebug,rc); log.debug(rc,rcDebug); } mailNotify Sends an email to a configured recipient. In order to operate, the system must have an email remitter and an SMTP mail server defined. For further information on Platform properties, see Platform in the System Administrator's Guide. Warning! If used within the consume block, make sure that conditional expressions guarantees that this function does not get called for each UDR. void mailNotify ( string address , string subject , string message , string sender , //Optional list<string> attachment ) //Optional Parameter Description Parameter Description address Email address to the recipient on the form: "user@xxx.com" subject Text ending up as the email subject message Message string ending up as the body of the email sender Name or address of the sender of the email Optional This field will remain optional only when the attachment field is not populated. Once attachment is populated, the sender field will be a mandatory field. attachment A list that will contain one or many attachments to be sent with the email. Each list entry will be the full directory path of the attachment. The example path could look like: Example "/home/admin/attachments/word.txt" Returns Nothing mailNotifyHtml Sends an email in HTML format to a configured recipient. In order to operate, the system must have an email remitter and an SMTP mail server defined. For further information on Platform properties, see Platform in the System Administrator's Guide. Warning! If used within the consume block, make sure that conditional expressions guarantees that this function does not get called for each UDR. void mailNotifyHtml ( string address , string subject , string message , string sender , //Optional list<string> attachment ) //Optional Parameter Description Parameter Description address Email address to the recipient on the form: " user@xxx.com " subject Text ending up as the email subject message Message string ending up as the body of the email Note Supports standard HTML content. sender Name or address of the sender of the email Optional This field will remain optional only when the attachment field is not populated. Once attachment is populated, the sender field will be a mandatory field. attachment A list that will contain one or many attachments to be sent with the email. Each list entry will be the full directory path of the attachment. Example "/home/admin/attachments/word.txt" Returns Nothing

---

# Document 2189: SAP JCo Uploader Agent UDRs - MediationZone Documentation 9.3 - InfoZone

**Source:** ratanon/mz93-documentation
**URL:** https://infozone.atlassian.net/wiki/spaces/MD93/pages/205653864/SAP+JCo+Uploader+Agent+UDRs
**Categories:** chunks_index.json

The SAP JCo UDR types ( SAP_JCO ) are designed to send records via a workflow to the SAP Convergent Invoicing Server. The SAP_JCO UDR types can be viewed in the UDR Internal Format Browser in the SAP_JCO folder. To open the browser, first open an APL Editor, and, in the editing area, right-click and select UDR Assistance . The UDR types for SAP JCo Agent are described here: 1 HeaderUDR 2 BitFieldUDR 3 RecordUDR HeaderUDR For the first row of the output file, the HeaderUDR describes the RFC name and the format of the file. The following fields are included in the HeaderUDR : Field Description Field Description listOfBitFields (list BitFieldUDR>) A list of field descriptions in the current file. It contains FieldName and FieldType for each field. rfcName (string) The name of the RemoteFunctionCall for this field. This comes from the second field of the file header. sourceFilename (string) The name of the current file. This field is used as a primary key in state handling. version (string) The version of the file. This comes from the first field of the header. BitFieldUDR This UDR is part of the HeaderUDR . The following fields are included in the BitFieldUDR : Field Description Field Description fieldName (string) The name of the field fieldType (string) The type of value RecordUDR Except for the first row (the header), the rest of the output file consists of the content of RecordUDR . The following fields are included in the RecordUDR : Field Description Field Description listOfFields (list<string>) A list of values in this row of the record.

---

# Document 2190: Radius Server Agent Input/Output Data and MIM - MediationZone Documentation 9.3 - InfoZone

**Source:** ratanon/mz93-documentation
**URL:** https://infozone.atlassian.net/wiki/spaces/MD93/pages/205034343/Radius+Server+Agent+Input+Output+Data+and+MIM
**Categories:** chunks_index.json

Input/Output Data

---

# Document 2191: Ultra Reference Guide - MediationZone Documentation 9.3 - InfoZone

**Source:** ratanon/mz93-documentation
**URL:** https://infozone.atlassian.net/wiki/spaces/MD93/pages/204612702
**Categories:** chunks_index.json

Search this document: This section describes the Ultra Format Management utilities of the Platform and includes a detailed description of the Ultra Format Definition Language and how to create format definitions in the language syntax. Chapters The following chapters are included: Format Management Overview Avro Support Ultra Format Configuration UDR File Editor UDR Views Ultra Format Converter Introduction to the Ultra Format Definition Language External - Sequential Format External - Ericsson IOG/IN Records External - ASN.1 Formats Internal Formats In-maps Decoders Out-maps Encoders A Constructed Decoder Example A Sequential Format Example An ASN.1 Format Example XML Schema Support Google Protocol Buffer Support

---

# Document 2192: Parquet Profile - MediationZone Documentation 9.3 - InfoZone

**Source:** ratanon/mz93-documentation
**URL:** https://infozone.atlassian.net/wiki/spaces/MD93/pages/204641970
**Categories:** chunks_index.json

To support the Parquet Encoder and Decoder, create a new Parquet Profile that will be used and shared by Workflow agents. The Parquet Profile allows you to specify a parquet schema as well as parquet encoding options. The Parquet Profile is loaded when you start a workflow that depends on it. Changes to the profile become effective when you restart the workflow. Configuration To create a new Parquet profile configuration, click the New Configuration and then select Parquet Profile from the Configurations dialog. The contents of the menus in the menu bar may change depending on which configuration type is opened. The Parquet profile uses the standard menu items and buttons that are visible for all configurations, and these are described in Build View . The menu in the Parquet profile configuration contains two tabs: Schema and Advanced . Open The Parquet profile's Schema tab is empty when opening a new profile . The section contains the following subsections: Parquet Profile Configuration Schema Parquet Profile Configuration Advanced

---

# Document 2193: The Web Service AbstractWSCycle UDR Type - MediationZone Documentation 9.3 - InfoZone

**Source:** ratanon/mz93-documentation
**URL:** https://infozone.atlassian.net/wiki/spaces/MD93/pages/204675331/The+Web+Service+AbstractWSCycle+UDR+Type
**Categories:** chunks_index.json

All the WSCycleUDR s that belong to a specific WS profile inherit the same AbstractWSCycle . By checking the AbstractWSCycle you can tell which WS profile is applied on certain UDRs. The AbstractWSCycle UDR is used as a marker to connect all WSCycleUDR s belonging to the same WS profile. It consists of the following parts: The AbstractWSCycle UDR consists of the following parts: context errorMessage operation Open AbstractWSCycle UDR fields part of WSCycleUDR Field Description Field Description context (any) This field is used to store information about the context in which the operation has been invoked, when it is needed. errorMessage (string optional) The error message field is set if an error occurred during sending or receiving of a message, or if a Soap Exception occurred at the communication endpoint. operation (string constant) This is a constant string with the name of the operation as value. If the operation corresponding to this WSCycleUDR is operationName , the field will be operationName .

---

# Document 2194: GCP Storage Forwarding Agent Events - MediationZone Documentation 9.3 - InfoZone

**Source:** ratanon/mz93-documentation
**URL:** https://infozone.atlassian.net/wiki/spaces/MD93/pages/204607839/GCP+Storage+Forwarding+Agent+Events
**Categories:** chunks_index.json

Agent Message Events An information message from the agent, stated according to configurations done in an Event Notification configuration. For further information about the agent message Ready with file: name Reported along with the name of the target file when it has been successfully stored in the target directory. If an After Treatment Command is specified, the message also indicates that it has been executed. Debug Events There are no debug events for this agent.

---

# Document 2195: restart - MediationZone Documentation 9.3 - InfoZone

**Source:** ratanon/mz93-documentation
**URL:** https://infozone.atlassian.net/wiki/spaces/MD93/pages/204646451/restart
**Categories:** chunks_index.json

usage: restart [ -q ] [ -f ] <running server process> ... This command is used to stop and start pico instances. Note! This command is valid only for the MZ_HOME owner. If you have specified more than one pico instance, these will be shut down in the reverse order of the arguments. Once the pico instances have stopped, the pico instances will be started in the same order as the arguments. Example - Restarting Pico Instances The following command will close down the pico instance named ec1 and then the Platform. When both processes have stopped, the platform will start the Platform followed by ec1. mzsh <username>/<password> restart platform ec1 The command will fail if the processes are specified in the reverse order since it would attempt to start ec1 before the Platform. Note! The command will behave differently depending on if the user is logged in or not. If a user is not logged in when the shutdown command is executed, the immediate, forced shutdown will be used regardless of if the -f option is used or not. For further details, see the descriptions for the shutdown and startup commands in shutdown and startup . Options The command accepts the following options: Option Description [-q] Generates less or no information messages. [-f] Forced restart of the pico instance(s). If the pico instance is an EC, it will be shut down without waiting for workflows to stop first. This option has no impact on the Platform. Return Codes Listed below are the different return codes for the restart command: Code Description 0 Will be returned if no arguments are given to the command, or if there are no matching server processes to restart. 1-> The sum of the return codes from shutdown and startup.

---

# Document 2196: Setting Environment Variables for Execution Container - MediationZone Documentation 9.3 - InfoZone

**Source:** ratanon/mz93-documentation
**URL:** https://infozone.atlassian.net/wiki/spaces/MD93/pages/204604268/Setting+Environment+Variables+for+Execution+Container
**Categories:** chunks_index.json

Add the following environment variables into a login script for the user mzadmin, ensuring the variables are always used. The example values will be used later on in the installation parameters file; install.xml .

---

# Document 2197: Resolving Hostnames - MediationZone Documentation 9.3 - InfoZone

**Source:** ratanon/mz93-documentation
**URL:** https://infozone.atlassian.net/wiki/spaces/MD93/pages/205848731
**Categories:** chunks_index.json

The section describes how to resolve hostnames that associated with pico instances in a high availability deployment. For a description of the high availability properties that are used by the HA Monitor Server, see High Availability Properties . Cell Properties Property Description pico.rcp.platform.host On a Platform Container host, the hostname specified in this property must resolve to: Virtual IP address of Platform node Local IP address of Platform node in an OpenStack environment Local IP address of Platform node in an Amazon Web Services environment On an Execution Container host, the hostname specified in this property must resolve to: Virtual IP address of Platform node Floating IP address of Platform node in an OpenStack environment Elastic IP address of Platform node in an Amazon Web Services environment Note! The Platform hostname must be static. Container Properties Property Description pico.rcp.server.host On a Platform Container host, the hostname specified in this property must resolve to: Virtual IP address of Platform node Local IP address of Platform node in an OpenStack environment Local IP address of Platform node in an Amazon Web Services environment Note! The Platform hostname must be static On an Execution Container host, the hostname specified in this property must resolve to: Virtual IP address of pico node Local IP address of pico node in an OpenStack environment Local IP address of pico node in an Amazon Web Services environment Loading

---

# Document 2198: ultra - MediationZone Documentation 9.3 - InfoZone

**Source:** ratanon/mz93-documentation
**URL:** https://infozone.atlassian.net/wiki/spaces/MD93/pages/205657120/ultra
**Categories:** chunks_index.json

usage: ultra export <target-jar-file> | import <source-jar-file> |list [-v, --verbose] [-h --historic-only] When you make changes to an ultra format, historic formats a stored on the system. However, these are not included when you perform a system export. You can use the ultra command to export both current and historic ultra formats from one system and import them as historic formats in another. This is useful when the target system must be able to handle e g persisted runtime data that is consistent with a previous version of an Ultra format. Option Description Option Description [ -v --verbose ] Use this option for detailed output from the ultra command. [ -h --historic-only ] Use this option to only include historic formats in the export. This option is not applicable for the import command. export Use the export command to write Ultra formats on the system to disk. These will be stored in a JAR file that contains the Ultra class definitions. Example - Exporting Ultra formats mzsh <username>/<password> ultra export /home/user/mz/ultra/ultraexport.jar Note! The export command cannot overwrite an existing export file. Import Use the import command to import Ultra formats from disk. For each Ultra format (class) in the specified JAR file, the command will perform the import if the format is not already present in the Code Server. If a format in the JAR file is historic or not does not matter during import, since it will be considered historic in the target system. Example - Importing Ultra formats mzsh <username>/<password> ultra import /home/user/mz/ultra/ultraexport.jar List Use the list command to list Ultra formats on the system. Example. Listing Ultra formats mzsh <username>/<password> ultra list Note! If an empty list field disappears when the ascii encodes, you need to set a system property called mz.ultra.terminator.backcomp . If set to true, empty list fields do not disappear and backward compatibility is preserved from MediationZone version 8.1.7.0 and later versions. To set this up, do the following: mzsh topo set [ topo://container ]:main1/pico:platform/val: config.properties.mz .ultra.terminator.backcomp true mzsh restart platform mzsh mzadmin/dr regenerateconfigs -ultra Re-run the workflow Return Codes Listed below are the different return codes for the ultra command: Code Description Code Description 0 Will be returned if the command was successful. 1 Will be returned if the command could not be interpreted, e g if a option that does not exist has been entered. 2 Will be returned if the input file is not found or if the output file already exists.

---

# Document 2199: Desktop Properties - MediationZone Documentation 9.3 - InfoZone

**Source:** ratanon/mz93-documentation
**URL:** https://infozone.atlassian.net/wiki/spaces/MD93/pages/417595393/Desktop+Properties
**Categories:** chunks_index.json

This section describes the properties related to the Desktop that you can set in the STR. A subset of the properties below are explicitly set in the file default.conf during installation. This file must not be updated. If you want to set or override properties, you should update client.conf instead. Properties mz.httpd.security.redirect Default value: false If TLS is enabled and this property is set to true , any attempt to access the webserver using HTTP will cause a redirect to HTTPS. The default behavior is just to return an error. ui.webserver.port Default value: 9001 This property can be used to set the port used by the webserver. ui.webserver.host Default value: 0.0.0.0 This property can be used to control which host/IP that the server should bind on. For example if you have multiple network interfaces on the server, you can choose to just open the desktop on one of them. ui.webserver.strict.host.validation Default value: false Add this property and set it to true if you want to enable string host validation in the desktop webserver. If this is enabled, all HTTP requests will be rejected if they have a Host header that does not match a known address of the desktop server. Ie a name or address resolving to the server or a name declared in the ui.webserver.valid.hosts property ui.webserver.valid.hosts This optional property is a comma-separated list of host names. If set, any hostname in the list will be considered valid when strict host validation has been enabled through the ui.webserver.strict.host.validation property. ui.webserver.invalid.hosts This optional property is a comma-separated list of host names. If set, any hostname specified will always fail validation when strict host validation has been enabled through the ui.webserver.strict.host.validation property.

---

# Document 2200: FTAM IOG Agent Transaction Behavior - MediationZone Documentation 9.3 - InfoZone

**Source:** ratanon/mz93-documentation
**URL:** https://infozone.atlassian.net/wiki/spaces/MD93/pages/204738868/FTAM+IOG+Agent+Transaction+Behavior
**Categories:** chunks_index.json

This section includes information about the FTAM IOG agent transaction behavior. For information about the general transaction behavior, see Workflow Monitor . Emits The agent emits commands that change the state of the file currently processed. Command Description Begin Batch Emitted right before the first byte of each collected file is fed into a workflow. End Batch Emitted just after the last byte of each collected file has been fed into the system. Retrieves The agent retrieves commands from other agents and based on them generates a state change of the file currently processed. Command Description Cancel Batch If a Cancel Batch message is received, the agent sends the batch to ECS. Note! If the Cancel Batch behavior, defined on the workflow level, is configured to abort the workflow, the agent will never receive the last Cancel Batch message. In this situation, ECS will not be involved, and the established copy area will not be deleted.

---

# Document 2201: External - ASN.1 Formats - MediationZone Documentation 9.3 - InfoZone

**Source:** ratanon/mz93-documentation
**URL:** https://infozone.atlassian.net/wiki/spaces/MD93/pages/204646900/External+-+ASN.1+Formats
**Categories:** chunks_index.json

Ultra provides support for parsing a subset of ASN.1 definitions, which can be used to decode from and encode to the corresponding BER or PER encoded data. ASN.1 parsing is requested in UFDL via the asn_block construct. The syntax of the ASN.1 blocks is declared as follows: asn_block { -- ASN.1 definitions here }; All ASN.1 constructed types declared either SEQUENCE, SET, or CHOICE, are treated as external format declarations. The name of the resulting external format will be the name of the ASN.1 definition. Any ASN.1 module name is added to the name space. That is, the total name space for the ASN.1 definition is <folder>.<configuration name>.<ASN.1 module name> . All occurrences of the dash character ( - ) in identifiers are converted to underscores since dashes are not valid in Ultra type naming. Any in-map or out-map using an external ASN.1 type will by default specify BER encoding. PER encoding can be selected by specifying one of the map options to PER_aligned or PER_unaligned . Notes on ASN.1 Inter Module References It is currently not possible to refer to non-constructed types or list types (that is, SEQUENCE OF and SET OF) declared in other modules. These must be contained within the asn_block to where they are referred. Any constructed ASN.1 types that are referred must be specified in an ASN.1 IMPORT statement to become available, for example: MyType ::= SET(field1 TAC, field2 MobileOriginatedCall) If TAC and MobileOriginated are declared in another asn_block in the same module like this: TAC ::= OCTET STRING; MobileOriginatedCall ::= SET ( .... ) the following applies: The TAC declaration must be duplicated in the asn_block of MyType . MobileOriginatedCall must be imported within the asn_block containing MyType . ASN.1 Primitive Type Mapping ASN.1 types are automatically mapped by Ultra as follows (this applies when there are automatic statements in the in-maps): ASN.1 Type: Ultra Type mapped to: ASN.1 Type: Ultra Type mapped to: BOOLEAN boolean bcd string bigint bigint All ASN.1 string types except OCTET STRING string OCTET STRING bytearray ENUMERATED int INTEGER int REAL float or bigdec By default, the float ultra type is automatically mapped to the REAL ASN.1 type. Substituting ASN.1 type REAL with bigdec casts the field as BigDecimal type. Mapping to bigdecimal Another method of mapping a REAL type to BigDecimal, is to use internal. //Create a flat internal that will be used to populate with integer and bigdecimal values. internal flatInternal { int calledNumber; bigdec duration; }; BIT STRING bitset mapping is used. Bitset is mapped to Bit String and vice versa; bitset<->bitstring For BER BIT STRING encoding: '0410'H is the correct encoding of the bit string '0001'B ("{3}" in APL debug, length of 4 bits. Note! The string representation here does not actually give complete information since the length is not included. It can be inconvenient to have the same string representation for '0001'B and '000100'B, but the reason is that the same string representation as the Java BitSet class is used. In BER, these values are handled differently. For example, '0001'B is encoded as 0x0410, while '000100'B is encoded as 0x0210. For further information about how BIT STRING is encoded/decoded in BER, see ITU-T specification X.690 (the first byte is not part of the bitstring itself - instead it encodes the number of unused trailing bits in the last byte in the bitstring encoding, which starts after the first byte). NULL bytearray (with value null ) Ultra Extensions Within a UFDL asn_block it is possible to use some extensions which are not part of the ASN.1 standard. These are added to provide better automatic decoding support for some formats. Direct BCD Support A bcd type is introduced. The ASN.1 formats encoded in BER frequently use the OCTET STRING to describe BCD data, leading to complicated processing. By replacing these entries with the bcd type, Ultra automatically converts such entries. The syntax for the bcd type declaration is declared as follows: bcd(lsn_fd) bcd(msn_fd) bcd(lsn_fd) terminated_by(<expr>) bcd(msn_fd) terminated_by(<expr>) Note! There is a limitation when using terminated_by with bcd for specfying field sizes. A detailed explanation of the limitation can be found in the Field Declarations section. Data Support Many ASN.1 formats declare date and time information as OCTET STRING . The date type converter is introduced to manage an automatic conversion to date instances. A possible syntax of date declaration is declared as follows: Time ::= OCTET STRING date({HH,mm,ss}) (SIZE(3)) Date ::= OCTET STRING date({yy,MM,dd})(SIZE(3)) Date ::= OCTET STRING date({cc,yy,MM,dd} , {yy,MM,dd}) DateTime ::= OCTET STRING date({cc,yy,MM,dd,HH,mm,ss}) Note! These are applicable to OCTET STRINGS only. Using Sequential Record Types Some ASN.1 definitions contain data with an OCTET STRING declaration that contains additional structures. In order to manage this, it is possible to split such declarations into sequential record types. It is also possible to use sequential formats to describe constructed ASN.1 types. In this case the tag must be declared as constructed (a MediationZone specific keyword) to allow Ultra to correctly encode the type. Example - Simple sequential record type An example of a simple type is the definition within an asn_block (module GSM): AddressString ::= OCTET STRING (SIZE(1..20)) It can be brought outside the asn_block and redefined as: external GSM.AddressString { bit_block : static_size(1) { int npi : msb(3), lsb(0); int ton : msb(7), lsb(4); }; bcd(msn_fd) msisdn : dynamic_size(udr_size-1), terminated_by(0xF); }; Example - Complex sequential record type An example of a complex type occurs when a field - fieldB - is to be decoded differently depending on the value of another field - fieldA . This ASN.1 definition: ComplexType ::= [APPLICATION 1] SEQUENCE { fieldA INTEGER, fieldB OCTET STRING } Can be replaced with the sequential format: external ComplexType_Seq { int tagA: static_size(1); int lengthA: static_size(1); int fieldA: dynamic_size(lengthA); // Definitions of SubType1 and SubType2 not included // in this example. SubType1 fieldB1: present if( fieldA == 1 ); SubType2 fieldB2: present if( fieldA == 2 ); }; And the extended ASN.1: ComplexType ::= [APPLICATION 1 constructed] ComplexType_Seq Mapping of ASN.1 INTEGER Type and bigint Support Since INTEGER types are automatically mapped to int , which is a 32-bit integer type, INTEGER s that are longer than 4 bytes cause decoding errors. This can be avoided by using the bigint type instead of INTEGER . The only difference between bigint and INTEGER is that bigint is automatically mapped to the bigint type, which can support INTEGER s of any size. Options for in_map and out_map By default, ASN.1 external formats are decoded and encoded as BER. However, the decoding and encoding behavior can be modified by options on the in_map and out_map declarations. The available options are: Option Effect Option Effect CER_length When encoding to BER, use the indefinite length encoding instead of definite length encoding (which is default) ignore_unknown_tags When decoding BER data, the presence of unknown tags will no longer be considered as decoding errors, they will simply be ignored instead. PER_aligned Instead of BER, use PER ALIGNED encoding PER_unaligned Instead of BER, use PER UNALIGNED encoding ASN Language Limitations The ASN.1 compiler is mostly concerned with the type notation of ASN.1. Elements of type notation not supported are: COMPONENTS OF WITH COMPONENT WITH COMPONENTS ABSENT/PRESENT ANY, ANY DEFINED BY ObjectDescriptor DEFAULT DEFINITIONS EXPLICIT, EXPLICIT TAGS INCLUDES MACRO PRIVATE UTCTime EXTERNAL GeneralizedTime OPERATIONS There are also limitations regarding the support of value notation or macro notation. It is only supported to declare INTEGER constants and use them in constraint specifications. There is also limited support for information object classes and OBJECT IDENTIFIER types. Object identifiers are decoded to bytearrays and the information object content is only decoded according to the class definition. BER Limitations In addition to the general ASN.1 limitations there are also some limitations regarding BER that must be taken into consideration: Explicit tags are not supported - All tags are by default implicit (except for tags of CHOICE types, which are always assumed to be explicit according to the ASN.1 standard). Any attempt to specify explicit tagging will result in a compilation error. All string fields are encoded/decoded according to ISO8859-1 except for UTF8String . No validation to ensure that mandatory fields are actually present is performed for SEQUENCE and SET types. Not all character types are supported. However, GraphicalString, IA5String, VisibleString, NumericString , and UTF8String are supported. PER Limitations In addition to the general ASN.1 limitations there are also some limitations regarding PER that must be taken in consideration: For string types, constraints on the permitted alphabet are not handled. Fragmented encoding (encoding for large-size fields) is not supported. Not all character types are supported. However, GraphicalString, IA5String, VisibleString, NumericString , and UTF8String are supported.

---

# Document 2202: FTP NMSC Agent Transaction Behavior - MediationZone Documentation 9.3 - InfoZone

**Source:** ratanon/mz93-documentation
**URL:** https://infozone.atlassian.net/wiki/spaces/MD93/pages/204673220/FTP+NMSC+Agent+Transaction+Behavior
**Categories:** chunks_index.json

Transaction Behavior Emits Command Description Begin Batch Will be emitted right before the first byte of each collected file is fed into a workflow. End Batch Will be emitted right after the last byte of each collected file has been fed into the system. Cancel Batch Never. Retrieves Command Description Begin Batch Nothing. End Batch Nothing. Cancel Batch If a Cancel Batch message is received, the agent sends the batch to ECS. Note! If the Cancel Batch behavior that is defined on workflow level, is configured to abort the workflow, the agent will never receive the last Cancel Batch message. In such case ECS will not be involved, and the file will not be deleted.

---

# Document 2203: Legacy Desktop - MediationZone Documentation 9.3 - InfoZone

**Source:** ratanon/mz93-documentation
**URL:** https://infozone.atlassian.net/wiki/spaces/MD93/pages/204741656/Legacy+Desktop
**Categories:** chunks_index.json

Search this document: This document describes the Legacy Desktop Client used for all versions of MediationZone prior to 9.0.0. The Legacy Desktop is still required for certain functionality that is currently not available in the regular Desktop and includes: ECS Inspector , see the documentation for Error Correction System for more information ECS Statistics , see the documentation for Error Correction System for more information SNMP Collection Agents Configuration Diff Disk Agents in Real-Time Workflows Subfolders, see Legacy Desktop User Interface for more information Chapters The following chapters and sections are included: Installation and Configuration of Legacy Desktop Legacy Desktop Overview Pico Viewer Disk Agents in Real-Time Workflows Configuration Diff Documentation Generator System Monitor

---

# Document 2204: UDR Views - MediationZone Documentation 9.3 - InfoZone

**Source:** ratanon/mz93-documentation
**URL:** https://infozone.atlassian.net/wiki/spaces/MD93/pages/204646825
**Categories:** chunks_index.json

Open the UDR View configuration by clicking the UDR View button in the UDR File Editor . See UDR File Editor for more information. The UDR View opens up in a new tab in your browser. In the UDR View configuration you can define how UDR data is listed and presented in the UDR File Editor and the Aggregation Session Inspector . Open UDR File Editor with no UDR View applied To create a UDR View configuration: In the UDR View configuration, click Browse... to open the UDR Internal Format Browser dialog. Select the UDR type you want to create a view for and click OK . Click the Add button to open another view of the UDR Internal Format Browser dialog. Select the field in the selected UDR you want to add to the view, click Apply and repeat for all fields you want to add. Click OK or Cancel to close the dialog. You can now rearrange the order of the fields by selecting them and clicking the Up and Down buttons. When your view is finished, click Save As to save your UDR View. In the UDR File Editor you can now select the saved UDR View to display the configured fields as columns in the order you have specified. Open UDR File Editor with a UDR View A UDR View does not have to be applicable to all UDR types within a displayed file. If a field does not exist for a particular UDR, n o such field is displayed.

---

# Document 2205: SFTP Collection Agent Configuration - MediationZone Documentation 9.3 - InfoZone

**Source:** ratanon/mz93-documentation
**URL:** https://infozone.atlassian.net/wiki/spaces/MD93/pages/205001981
**Categories:** chunks_index.json



---
**End of Part 93** - Continue to next part for more content.
