# RATANON/MZ93-DOCUMENTATION - Part 78/112

---
**Dataset:** ratanon/mz93-documentation
**Part:** 78 of 112
**GitHub:** https://github.com/ratan0n/docs/tree/main/mz93-documentation
**Size:** ~68.6 KB
---

With the Secrets profile you can use secrets in the software that originate from one central location. It is currently use d with : Azure Profile GCP Profile SAP RFC Profile . To create a new Secrets profile, click the New Configuration button from the Configuration dialog available from Build View , and then select Secrets Profile from the menu. Buttons The contents of the menus in the menu bar may change depending on which configuration type has been opened in the currently displayed tab. The Secrets profile uses the standard menu items and buttons that are visible for all configurations, and these are described in Common Configuration Buttons . Common Configuration Common Setting Description Common Setting Description Storage Type Select the Secret storage type from the dropdown menu list. The following types are available: Azure KeyVault Secrets - The Secrets are stored in Azure KeyVault Google Secrets Manager - The Secrets are stored in Google Secret Manager Local Storage - The Secrets are stored locally in the configuration. Local Storage Settings Open Secrets Profile - Local Storage Type When the Local Storage type is selected: Setting Description Setting Description Alias This shows the alias of the secret. Secret This shows the associated secret. Azure Keyvault Secrets Settings Open Secrets Profile - Azure KeyVault Storage Type When this option is selected, an Azure KeyVault Profile must be selected. Press the Browse button to open the Select Azure KeyVault Profile dialog box. Open KeyVault Profile Selection Screen Select which profile you want to use and confirm the selection with the OK button. Click the Cancel button to return to the Secrets Profile screen, Clear to remove the current selection, New to open the creation screen for the Azure KeyVault Profiles. When the Azure KeyVault Secrets type is selected: Setting Description Setting Description Alias This shows the alias of the secret. This name must exist as a secret in Azure KeyVault. Google Secrets Manager Settings Open Secrets Profile - Google Secret Manager Storage Type When this option is selected, a Google Secret Manager Profile must be selected. When the Google Secret Manager type is selected you have the following settings: Setting Description Setting Description Name This shows the name of the secret. This name must exist as a secret in Google Secret Manager. Version The version of the Secret. The default is the latest.

---

# Document 1842: Development Toolkit User's Guide - MediationZone Documentation 9.3 - InfoZone

**Source:** ratanon/mz93-documentation
**URL:** https://infozone.atlassian.net/wiki/spaces/MD93/pages/204645031/Development+Toolkit+User+s+Guide
**Categories:** chunks_index.json

Search this document: Development Toolkit (DTK) enables you to develop user-defined programs, and plugins, in Java that you then incorporate into the Platform. Note! While this document does not include general information about Java programming, it contains rules and recommendations that you should apply in order to operate your new plugin with the Platform. This document contains an overview of the classes and interfaces used for the different plugins. For a complete list of all the classes, and the full syntax details, see the JavaDoc which can be found in the unzipped devkit_<version>.zip file, under <dekit_dir>/javadoc when DTK has been installed according to Installation and Setup . In the DTK package, examples of full-featured plugins are also included. The reader is encouraged to examine these examples that can be found in unzipped devkit_<version>.zip file, under <dekit_dir>/dtk/examples. Chapters The following chapters and sections are included: Development Toolkit Overview Installation and Setup Creating a DTK Plugin Agent Plugins Data Serialization Exceptions UDR Plugins Event Plugins Notifier Plugins APL Plugins Ultra Field Plugins Workflow Service Plugins Desktop Plugins Environment Interfaces Configuration Contract Agent Plugin Examples

---

# Document 1843: Kafka Batch Forwarding Agent Events - MediationZone Documentation 9.3 - InfoZone

**Source:** ratanon/mz93-documentation
**URL:** https://infozone.atlassian.net/wiki/spaces/MD93/pages/301138323/Kafka+Batch+Forwarding+Agent+Events
**Categories:** chunks_index.json

Agents Events Debug Events

---

# Document 1844: DRRealtimeProcessor - MediationZone Documentation 9.3 - InfoZone

**Source:** ratanon/mz93-documentation
**URL:** https://infozone.atlassian.net/wiki/spaces/MD93/pages/204742348/DRRealtimeProcessor
**Categories:** chunks_index.json

Defines no new methods on top of DRRealtimeAgent . For information regarding the differences between a Processing and a Forwarding agent, see DRBatchProcessor . A realtime processor may choose to implement DRRealtimeThreadAgent to process incoming data asynchronously. This is the case when a separate thread is used to handle the communication to a back-end entity. Note! The developer must handle the turnover of records entering the consume methods to the executing agent thread. If it prefers to process that data synchronously, but to route the result asynchronously, it must instead implement the DRRealtimeAsyncRouter class. This will be the case if the communication with the back-end is handled by a service of which the agent developer has no thread control, e g RMI or CORBA.

---

# Document 1845: Container Properties - MediationZone Documentation 9.3 - InfoZone

**Source:** ratanon/mz93-documentation
**URL:** https://infozone.atlassian.net/wiki/spaces/MD93/pages/205816051/Container+Properties
**Categories:** chunks_index.json

This section describes properties that are typically set on a container level and applicable to the Platform, ECs and SCs. Property Description Property Description java.library.path Default value: ${mz.home}/common/lib/native This property must be set to ${mz.home}/common/lib/native . mz.httpd.security Default value: false This property enables HTTP communication protected by TLS (i e HTTPS). mz.httpd.security.hsts.enabled Default value: false This property enables the Strict-Transport-Security flag ( HSTS ) for the desktop. mz.httpd.security.hsts.max_age Default value: 63072000 (2 years) If HSTS is enabled, then this property can be used to control the "max-age" value. mz.httpd.security.keystore Default value: "" This property specifies the path to the keystore that is used for HTTP/TLS mz.httpd.security.keystore.password Default value: "" This property must contain the password to the keystore specified in mz.httpd.security.keystore . mz.httpd.security.key.alias Default value: "" This property specifies which of the keys in the keystore that should used for HTTP/TLS (if there are more than one). HTTP will prefer to use the key with this keystore alias. If it is not set and the keystore contains more than one private key, it is undefined which key is used. mz.httpd.security.key.password Default value: "" This property must contain the password to the key to the key that is used for HTTP/TLS. By default (in keytool ), this is the same as the keystore password. mz.picocache.link.use Default value: false If you set this property to true , a links-based implementation will be used for the pico cache, which will save disk space if you have many picos in the same container. mz.picocache.link.target.dir Default value: $MZ_HOME/pico-cache/lib If you have set the mz.picocache.link.use property to true , you can use this property to specify the directory used for the actual jar files, which may be useful if you want to keep all the jar files for the whole system in one place and not split up for each container. pico.rcp.server.bind_interfaces Default value: "" When you set the property pico.rcp.server.host , pico instances will only bind to the interface associated with that IP address. Due to the network configuration, it may be required by pico instances to bind to additional interfaces. You can specify these by specifying a comma-separated list of IP address or hostnames in the property pico.rcp.server.bind_interfaces. It is also possible to set this property to the value ALL to ensure that the pico instances will bind to all interfaces, even though pico.rcp.server.host has been set. If you have not set pico.rcp.server.host , the property pico.rcp.server.bind_interfaces will have no effect. Example - Using pico.rcp.server.bind_interfaces An EC named ec1 has one external and one internal IP address. Other ECs will have to use the hostname ec1host to be able to connect. The name ec1host maps to either the external or internal IP address depending on the client location in the network. To ensure that all connection attempts will use the hostname, you set the property pico.rcp.server.host to ec1host . This will then cause the ec1 to only bind to ec1host which will map to the internal IP address, since this is the local context. If an other EC on the external network, ec2 in this example, tries to connect to ec1, it will use the hostname ec1host which maps to the external IP. This will fail. To ensure connectivity you need to set pico.rcp.server.bind_interfaces to the external IP address or ALL to ensure that the incoming connection attempt from ec2 will succeed. pico.rcp.server.host Default value: "" This property specifies the IP address or hostname of the pico instances. It will be used to determine the interface that the pico instances must bind to and the IP address/hostname that will be used by connecting processes. When you enter the hostname as the value of this property, if a failover occurs, the hostname is retrieved from the DNS enabling reconnection. If you enter the IP address as the value of this property, if it is a static IP address, reconnection issues may occur if the IP address changes. When the value of this property is left blank, the pico instance will bind to all IP addresses of the host. This means that the pico will listen for inbound network traffic on all network interfaces, and may attempt to use any local IP address for outbound network traffic. Note! If there is more than one IP address for the host, this property has to be set with the correct IP address. Make sure to set the property if you use IPv6, or if a high availability environment is configured. For information about high availability, see High Availability Properties . Note! When pico.rcp.server.host is set in the Platform Container, the value must be identical to pico.rcp.platform.host. pico.rcp.tls.keystore Default value: "" This property specifies the path to a keystore and enables the system to use TLS for all RCP connections that are not from the local host. If this property is not set, TLS will not be used. pico.rcp.tls.keystore.alias Default value: "" This property specifies which of the keys in the keystore that should used for RCP/TLS (if there are more than one). RCP will prefer to use the key with this keystore alias. If it is not set and the keystore contains more than one private key, it is undefined which key is used. pico.rcp.tls.keystore.password Default value: "" This property must contain the password to the keystore specified in pico.rcp.tls.keystore . pico.rcp.tls.key.password Default value: "" This property must contain the password to the key that is used for RCP/TLS. By default (in keytool ), this is the same as the keystore password. pico.rcp.tls.require_clientauth Default value: false This property specifies if client authentication is required when these are not running on the local host. pico.tmpdir Default value: MZ_HOME/tmp This property specifies the temp directory you want to use for your picos. pico.upgrade_history Default value: ${mz.home}/upgrade_history This property specifies the directory where the new and old versions of packages patched into the system are stored. rest.client.max.chunk.size Default value: "8m" This property specifies the maximum chunk size of the HTTP response that the REST Client agent should receive from the server. The agent will reject data with sizes that are larger than the value defined by this property. You can also set this property on the pico level, where the value is only applied to the defined EC. You can refer to Execution Context Properties for more information. rest.client.max.content.length Default value: "64m" This property specifies the maximum length of the HTTP content received by the REST Client agent. The agent will reject content that is longer than the specified value defined by this property. Although it is also possible to set the value of this property to infinite, there will be a possibility where the EC will crash from an out of memory error. So do consider setting the memory size of the EC to be higher than the expected size of the HTTP content that the agent will be receiving. You can also set this property on the pico level, where the value is only applied to the defined EC. You can refer to Execution Context Properties for more information.

---

# Document 1846: Label UDR - MediationZone Documentation 9.3 - InfoZone

**Source:** ratanon/mz93-documentation
**URL:** https://infozone.atlassian.net/wiki/spaces/MD93/pages/204643715/Label+UDR
**Categories:** chunks_index.json

The Label UDR is used to create a label that can be associated with a component. Example APL code: // Use the generic element to create a meter GenericElement meter = udrCreate(GenericElement); meter.tag = "meter"; meter.attributes = mapCreate(string, string); mapSet(meter.attributes, "min", "0"); mapSet(meter.attributes, "max", "100"); mapSet(meter.attributes, "value", "50"); // Create a label and associate it with the meter element Label meterLabel = udrCreate(Label); meterLabel.labelFor = meter; meterLabel.labelText = "Level:"; The following fields are included in the Label UDR : Field Description Field Description attributes (map<string,string>) This field may contain extra attributes to be added. cssClasses (list<string>) This field may contain a list of extra values added to class attribute. This is typically used to style the component. Please read more on Bootstrap . id (string) This field may contain the id of the component labelFor (ComponentUDR) This field may contain the component to associate the label with.

---

# Document 1847: DRBatchCollector - MediationZone Documentation 9.3 - InfoZone

**Source:** ratanon/mz93-documentation
**URL:** https://infozone.atlassian.net/wiki/spaces/MD93/pages/204742304/DRBatchCollector
**Categories:** chunks_index.json

The collector is the controller of the workflow. It controls the main execution thread, and when the thread returns from the collector, the workflow will stop. DRBatchCollector defines the execute method, where the workflow thread lives, as well as transaction control methods. These are used to propagate beginBatch and endBatch calls. execute When called, the collector is given the workflow thread. The collector must keep this thread until the workflow should terminate, for instance, when the stop method has been called. The execute method typically emits beginBatch , routes the batch into the workflow and then emits endBatch . beginBatch Propagates a new transaction to the transaction controller and all the workflow agents. endBatch Propagates a transaction end to the transaction controller and all the workflow agents. endBatchHinted Called when another agent has called hintEndBatch in DRBatchServerEnv . The collector may choose to ignore this method, that is, not to implement it in case it cannot be supported. splitBatch When invoked, it will propagate to the other agents that the input batch will be split ( DRBatchProcessor.splittingInfile ). The following sequence diagram shows in which order methods are called for the Batch Collector. Open Sequence diagram for DRBatchCollector For a batch Collection agent example, see com.digitalroute.devkit.examples.diskcollection.*

---

# Document 1848: Routing Control (DRA) 3G/4G - MediationZone Documentation 9.3 - InfoZone

**Source:** ratanon/mz93-documentation
**URL:** https://infozone.atlassian.net/wiki/spaces/MD93/pages/205849497/Routing+Control+DRA+3G+4G
**Categories:** chunks_index.json

Routing Control  Diameter Routing Agent (DRA)  is a function in a 3G or 4G network which provides real-time routing capabilities to ensure that diameter messages are routed among the correct elements in a network. DRA can act as: Relay agent: supports basic Diameter message forwarding with no message modification or inspection function. Proxy agent: supports the ability to inspect and modify Diameter messages. This Right to Use (RTU) grants the licensee the right to use DigitalRoutes MediationZone software in accordance with this definition.

---

# Document 1849: Administration and Management in Legacy Desktop - MediationZone Documentation 9.3 - InfoZone

**Source:** ratanon/mz93-documentation
**URL:** https://infozone.atlassian.net/wiki/spaces/MD93/pages/205655211
**Categories:** chunks_index.json

Desktop Background Color You can start several Desktop applications on a specific computer. To tell the difference between the applications and their respective views you can vary the background color of every Desktop. To change the Desktop application background color, set the Desktop property mz.gui.color.space.active . The value can be any color of the following: blue, green, yellow, orange, red, dark blue, dark green, magenta, or dark red. For further information about Desktop properties, see Desktop Properties . Dynamic Update While a real-time workflow is being executed, you can change the value of the following parameters: The Host and Port parameters of the TCP/IP agent The NAS list of the Radius agent To be able to dynamically update TCP/IP Host and Port parameters, you need to set them to either Default or Per Workflow in the Workflow Properties dialog box. See the figure The Workflow Table Tab in Workflow Table Tab . To update, select Dynamic Update . On the title bar of the monitor dialog box, the text Dynamic Update followed by a number appears. It represents the number of times that you have updated the workflow configuration while running it, that is since the last time you started it. Open Dynamic update Folders Folders enable the user to categorize configurations, and simplify their maintenance and operation. Folders can be created based on traffic type, decode for a specific network element, be based on geographic location, etc. There is a system folder named Default . This folder cannot be renamed or removed. Configuration Naming Configuration names within a folder must be unique. Some named items in the environment are used when constructing file names. To avoid potential conflicts in the file systems, MediationZone converts the conflicting characters when constructing file names. The following characters are allowed. Any other character results in a validation error. a-z A-Z 0-9 - (dash) _ (underscore) The system has an internal key for every configuration. This key is used to identify the configuration. Renaming a configuration does not change this key. The key is constructed using the system name and the date when the configuration was created. You can view the generated key by selecting the Show Properties option in the right-click menu in the Configuration Navigator, as well as in the Configuration Browser and Configuration Tracer. Date and Time Format Codes In various places, date formats are entered. The following list shows valid date and time format codes that can be combined with any characters that are not in the ranges of 'a'-'z' and 'A'-'Z'. For instance, characters such as ':', '.', ' ', '#' and '@' will appear in the resulting time even if they are not specified within single quotation marks. The date syntax conforms to the Java class SimpleDateFormat . This section contains a summary only. For a full description see: http://docs.oracle.com/javase/8/docs/api/java/text/SimpleDateFormat.html Letter Date or time component Example Letter Date or time component Example G Era designator AD y Year 1996; 96 M Month in year July; Jul; 07 w Week in year 27 W Week in month 2 D Day in year 189 d Day in month 10 F Day of week in month 2 E Day in week Tuesday; Tue a am/pm marker PM H Hour in day (0-23) 0 k Hour in day (1-24) 24 K Hour in am/pm (0-11) 0 h Hour in am/pm (1-12) 12 m Minute in hour 30 s Second in minute 55 S Millisecond 978 z Time zone PST; GMT-08:00 Z Time zone -08:00 Example - Date and time patterns are interpreted in U.S. local time The following examples show how date and time patterns are interpreted in U.S. local time. The example shows local date and time 2001-07-04 12:08:56 in the U.S. Pacific time zone. Format Example Format Example "yyyy.MM.dd G 'at' HH:mm:ss z" 2001.07.04 AD at 12:08:56 PDT "EEE, MMM d, ''yy" Wed, Jul 4, '01 "h:mm a" 12:08 PM "hh 'o''clock' a, zzzz" 12 o'clock PM, Pacific Daylight Time "K:mm a, z" 0:08 PM, PDT "yyyyy.MMMMM.dd GGG hh:mm aaa" 02001.July.04 AD 12:08 PM "EEE, d MMM yyyy HH:mm:ss Z" Wed, 4 Jul 2001 12:08:56 -0700 "yyMMddHHmmssZ" 010704120856-0700 Text Editor At various places in the environment, editable text areas are available in order to enter APL code. To assist in writing the code, right-click anywhere in the text area to show a pop-up menu with available host functions. Open Text Editor right-click menu The menu has the following options: Option Description Option Description Font Size Sets the font size. Cut Moves the selected text to the clipboard. You can also press CTRL+X to perform this action. Copy Copies the selected text to the clipboard. You can also press CTRL+C to perform this action. Paste Pastes the contents of the clipboard into the place where the insertion point is. You can also press CTRL+V to perform this action. Select All Selects all the text. You can also press CTRL+A to perform this action. Undo Reverts your last action. You can also press CTRL+Z to perform this action. Redo Redoes the last action that you undid with Undo. You can also press CTRL+Y to perform this action. Find/Replace... Displays a dialog where you can search for text and, optionally, replace it. You can also press CTRL+H to perform this action. Open Find/Replace dialog Quick Find Searches the code for the highlighted text. You can also press CTRL+F to perform this action. Find Again Repeats the search for last entered text in the Find/Replace dialog. You can also press CTRL+G to perform this action. Go to Line... Opens the Go to Line dialog where you can enter which line in the code you want to go to. Click OK and you are redirected to the entered line. You can also press CTRL+L to perform this action. Show Definition If you right-click a function in the code that is defined somewhere else and select this option, you are redirected to where the function is defined. If the function is defined within the same configuration, you jump to the line where the function is defined. If the function is defined in another configuration, the configuration opens and you jump directly to the line where the function is defined. You can also click a function and press CTRL+F3 to perform this action. Note! If you refer to an external function with the same name as a function within the current code, the Show Definition option will point to the function within the current code, while the external function is the one that is called during workflow execution. Show Usages If you right-click a function where it is defined in the code and select this option, a dialog called Usage Viewer opens and displays a list of the Configurations that use the function. You can also select a function and press CTRL+F4 to perform this action. UDR Assistance... Opens the UDR Internal Format Browser from which the UDR Fields can be inserted into the code area. You can also press CTRL+U to perform this action. MIM Assistance... Opens the MIM Browser from which the available MIM Resources can be inserted into the code area. You can also press CTRL+M to perform this action. Import... Imports the contents from an external text file into the editor. Note that the file has to reside on the host where the client is running. Export... Exports the current contents into a new file to, for instance, edit in another text editor or use in another MediationZone system. Use External Editor Opens the editor specified by the Desktop property mz.gui.editor.command, e.g. "notepad.exe" . APL Help... Opens the APL Reference Guide. APL Code Completion Performs code completion on the current line. For more information about Code Completion, see APL Code Completion below. You can also press CTRL+SPACE to perform this action. Indent Adjusts the indentation of the code to make it more readable. You can also press CTRL+I to perform this action. Jump to Pair Moves the cursor to the matching parenthesis or bracket. You can also press CTRL+SHIFT+P to perform this action. Toggle Comments Adds or removes comment characters at the beginning of the current line or selection. You can also press CTRL+7 to perform this action. Surround With Adds a code template that surrounds the current line or selection: for Loop ( CTRL+ALT+F ) while Loop ( CTRL+ALT+W ) Debug Expression ( CTRL+ALT+D ) if Condition ( CTRL+ALT+I ) Block Comment ( CTRL+ALT+B ) APL Code Completion In order to make APL coding easier, the APL Code Completion feature helps you find and add APL functions and their respective syntax. To access APL Code Completion, place the cursor where you want to add an APL function, press CTRL+SPACE and select the correct function. To reduce the number of hits, type the initial characters of the APL function. The characters to the left of the cursor are used as a filter. APL Code Completion covers: All installed APL functions. Function blocks such as beginBatch and consume . Condition statements such as while and if . APL functions created by APL Code configurations. APL functions created with the MediationZone Development Toolkit. APL Code Editor Outline In order to make it easier to navigate in an APL code configuration, there is an Outline navigation panel to the right of the APL Code Editor. The APL Code Editor Outline provides a view of all the blocks, variables, and methods in an APL code configuration and makes it possible to easily navigate between different types in the APL code. The entries in the navigation panel are automatically updated as you make valid entries in the APL Editor. You can also filter what you want to display in the Outline navigation panel. You can search for a specific block, variable, or method using the free text field, or by selecting one of the quick filter buttons for different types: Button Description Button Description b Click to display or hide the blocks within the APL code configuration displayed in the APL Code Editor. v Click to display or hide the variables within the APL code configuration displayed in the APL Code Editor. m Click to display or hide the methods within the APL code configuration displayed in the APL Code Editor. The Outline navigation panel can be hidden or made visible. By default, it is visible and all the elements are displayed. To hide or display the navigation panel, click the vertical Outline button to the right of the APL Code Editor. Open APL Code Editor Outline navigation panel Configuration List Editor The Configuration List Editor appears in many Agent Configuration dialog boxes and usually looks like the example in the figure below, Configuration List Editor. This table enables you to select and list several entries that you want to include in a certain Configuration definition. Open Configuration List Editor Button Description Button Description Add Open Click to open a dialog box where you can add an item to the Configuration list. Edit Open Select a row and click Edit. An Update dialog box opens and enables you to modify the data entry. Remove Open Select a row and click Remove . Open Select an entry from the Configuration list and click Up or Down to move it to an upper or lower position. Note! To change the order of any of the appended rows from ascending to descending, click a column's heading. The new order is not saved for the next time you open this view. UDR Browser In places where one or many UDR types or UDR fields need to be selected, the UDR Browser is utilized. You access the UDR Internal Format Browser from the Analysis or Aggregation agents, by right-clicking in the APL Code area and selecting UDR Assistance... The browser contains all UDR types available in the system: UDR types created in the Ultra Format Editor. These include events and sessions for the Aggregation sub-system. UDR types installed with the system. For further information about UDR types and fields, see the Ultra Reference Guide . Open UDR Internal Format Browser Setting Description Setting Description UDR Types List of available UDR types ordered in a tree structure. You can search for a specific UDR type using the filter text box. You can also expand the folders to display all the subfolders and types by clicking the Expand button. You can collapse the folders again by clicking the Collapse button. If you click the Refresh button, the view is refreshed and the folders are collapsed. Formats created in Ultra Format Editor usually have the following structure: folder name - configuration name - internal type name Note! There are a number of agents, for example Diameter and Inter Workflow, that have predefined UDR types with corresponding folder names. Expand All Open Click this button to expand all of the UDR Types folders to display all the subfolders and types. If you click the Refresh button, the view is refreshed and the folders are collapsed. Collapse All Open Click this button to collapse the UDR Types folders so that only the folders are displayed. UDR Fields Displays the UDR type fields in a tree structure. You can search for a specific UDR type field using the filter text box. To refresh the view, click the Refresh button. To ease identification, the fields are color coded: Optional - Italic black Read-only - Red Default - Blue Nested UDRs - Gray Note! A nested UDR that is optional appears in Italic Black. Show Optional If enabled, fields declared as optional are displayed in black italic text. Show Readonly Select this checkbox to display read-only fields. The text appears in red. Note! Clearing this checkbox also affects the blue text entries. These are reserved fields that you cannot modify. Datatype If enabled, only fields that match the selected data type are displayed. Selection Modes The browser operates in five modes depending on where it is used. Single selection of UDR Type. You can choose the UDR Type either by double-clicking the UDR Type, or by selecting it followed by OK or Apply . OK and double-click dismisses the dialog. Multiple selections of UDR Type. You can choose several UDR Types at once by selecting them followed by OK or Apply . OK or double-click dismisses the dialog. Single selection of UDR fields. Same as for UDR Type, but fields are selected instead. Multiple selections of UDR field. Same as for UDR Type, but fields are selected instead. Field input assistance. You can insert fields in the target text field by double-clicking them, or by selecting them followed by Apply . The OK button is not available. MIM Some agents in a workflow need information from the workflow or other agents in order to operate. For instance, an agent that produces a file might need the source file name and the number of processed UDRs to be used in the outgoing file name. In order to satisfy these requirements, MediationZone uses a model called Meta Information Model (MIM) . Agents may use MIM parameters to publish information during run-time that other agents may need to use. The MIM information is used in various parts of the system, for instance, when selecting which MIM resources to use in a file name. MediationZone uses Java Management Extensions (JMX) to monitor MIM tree attributes in running workflows. For more information, refer to Workflow Monitor . Open A MIM tree example MIM resources for each agent have their values assigned at any time, depending on type. As an example, the Disk collection agent publishes the MIM resource Source Filename which is set at Begin Batch. The agent puts the name of the collected file in this resource before it starts collecting the file. There are in total four types of MIMs: MIM Type Description MIM Type Description Batch Batch MIMs are dynamic values, populated during batch processing. An example of such a value is outbound UDRs. Global A global MIM value can be accessed at any time during the execution phase of a workflow. For instance, static values such as Agent Name. Header Header MIM values are populated when a batch is received for processing (an agent emits Begin Batch ). For example, Source Filename (published by the Disk collection agent). Trailer Trailer MIM values are populated after a batch is processed (an agent emits End Batch ). An example of such a value is Target Filename (published by the Disk forwarding agent). By default, all agents may publish the following MIM resources depending on their Input/Output data types. MIM Parameter Description MIM Parameter Description Agent Name This MIM parameter contains the name of the agent as defined in the workflow editor. All agents publish this resource. The value is set when the workflow starts executing. Agent Name is defined as a global MIM context type. <route name> UDRs (or Bytes) This MIM parameter contains the number of UDRs (or Bytes) routed on the link by the agent. The value is updated continuously during processing. This MIM is not valid for forwarding agents. <route name> UDRs (or Bytes) is defined as a batch MIM context type. <route name> Queue Size This MIM parameter contains the number of objects that are currently in the route's queue. <route name> Queue Full Count This MIM parameter contains the number of queue state changes. The value is updated each time a route's queue enters "full" state. Inbound UDRs (or Bytes) This MIM parameter contains the number of incoming UDRs (or Bytes) since last Begin Batch. The value is updated continuously during batch processing. This MIM is not valid for collection agents. Inbound UDRs (or Bytes) is defined as a batch MIM context type. Outbound UDRs (or Bytes) This MIM parameter contains the number of outgoing UDRs (or Bytes) since last Begin Batch. The value is updated continuously during batch processing. This MIM is not valid for forwarding agents. Outbound UDRs (or Bytes) is defined as a batch MIM context type. Note! Some MIM resources are not available until the agent to which they belong is configured. There are also pico specific MIM resources representing information about the picos' JVMs. These are: MIM Parameter Description MIM Parameter Description Available CPUs This MIM parameter states the number of processors that are available for the JVM. Available CPUs is defined as a global MIM context type. System Load Average This MIM parameter states the average system load during the last minute. The system load is the sum of the number of runnable entitites that are queued or running on the available processors, and this value shows the average of this sum for the last minute. This information is useful for indicating the current system load and may be queried frequently. System Load Average is defined as a global MIM context type. Heap Memory Used Percentage This MIM parameter states JVM's heap size, i.e. the amount of memory that is currently used by the JVM, in percent. Heap Memory Bytes Usedn is defined as a global MIM context type. Non Heap Memory Used Percentage This MIM parameter states the amount of memory outside of the heap (non-heap memory) that is currently used by the JVM, in percent. Non Heap Memory Bytes Used is defined as a global MIM context type. There are workflow specific MIM resources representing information of a running workflow. These are: MIM Parameter Description MIM Parameter Description Batch Cancelled This MIM parameter states if the current batch has been cancelled. Batch Cancelled is defined as a header MIM context type. Batch Count This MIM parameter contains a unique sequence number that is associated with each batch processed by the workflow. This value is increased by 1 up to 2 63 and is saved between workflow invocations. Batch Count is defined as a header MIM context type. Batch Duration This MIM parameter contains the time it took to process a batch. This value is updated during processing. Batch Duration is defined as a batch MIM context type. Batch End Time This MIM parameter contains the end time for the processing of a batch. Batch End Time is defined as a trailer MIM context type. Batch Start Time This MIM parameter contains the start time for the processing of a batch. Batch Start Time is defined as a header MIM context type. Execution Context This MIM parameter contains the name of the Execution Context hosting the current workflow. Execution Context is defined as a global MIM context type. Processed UDRs Interval Duration This parameter contains the duration of an interval in minutes for counting the number of processed UDRs in the current real-time workflow. This MIM parameter is only valid for real-time workflows. Processed UDRs Intverval Duration is defined as a global MIM context type. Processed UDRs Per Interval This parameter contains the UDRs processed during the defined interval in the current real-time workflow. This MIM parameter is only valid for real-time workflows. Processed UDRs Per Intverval is defined as a global MIM context type. Start Time This MIM parameter contains the date and time when the workflow was started. The value is set when the workflow is activated. Start Time is defined as a global MIM context type. Threads Configured This parameter contains the number of workflow threads configured in the current real-time workflow. This MIM parameter is only valid for real-time workflows. Threads Configured is defined as a global MIM context type. Threads Idle This parameter contains the number of workflow idle threads in the current real-time workflow. This MIM parameter is only valid for real-time workflows. Threads Idle is defined as a global MIM context type. Throughput By default, Throughput is the volume-per-time processing rate of a particular workflow or agent. Transaction ID Each batch closed by all workflows receives a unique transaction ID. Cancelled batches receive one as well. This MIM parameter contains the unique transaction ID. Transaction ID is defined as a header MIM context type. Workflow ID This MIM parameter contains the unique identification name of every workflow. Workflow Name This MIM parameter contains the name of the current workflow. The value is set when the workflow is activated. Workflow Name is defined as a global MIM context type. MIM Browser In places where access to MIM resources is needed, the MIM Browser is used. You access the MIM Browser from the Analysis or Aggregation agent, by right-clicking in the APL Code area and selecting MIM Assistance... . The browser contains all MIM resources available in the workflow: Open The MIM Browser The available MIM resources are displayed, ordered in a tree structure. Choose the MIM resource by double-clicking the MIM resource, or by selecting it followed by Apply . Cancel dismisses the dialog. You can also search for a specific MIM resource using the filter text box at the top of the MIM Browser . Locks Configurations that you edit are locked so that they cannot be modified by other users. When you open a locked configuration, a message box appears with information about the user that has access and can edit it. To edit a locked, or read-only, configuration you can save a copy of it with a different name. Open A locked configuration Locks are not persistent. If the system is restarted, all locks are forgotten. Encryption A configuration is persisted using XML and therefore more or less available in a readable form to any user, see Configuration Browser . Some configurations may be sensitive and possibly contain descriptions that are proprietary and must be protected. To protect such configurations, it is possible to encrypt configurations using a passphrase. A configuration is thereby only readable if the passphrase is known by the user. If the passphrase is lost, the configuration should be considered lost as well. There are configurations that generate information to the system, for example, the Ultra format that renders UDRs. A user can have access to the UDRs without knowing the passphrase for the configuration source, by setting the user group execute permission. A user can also import a format or analysis package which has execute permission configured. Encrypted configurations retain their encryption and passphrase across export and import. This means that to open a configuration that is imported from another system, you need its passphrase. The Database profile and some of the agents can use passwords from External References. These can be encrypted, either using the default key, or using a crypto service keystore file. See Using Passwords in External References in External Reference Profile for further information.

---

# Document 1850: Installer Properties for Execution Container - MediationZone Documentation 9.3 - InfoZone

**Source:** ratanon/mz93-documentation
**URL:** https://infozone.atlassian.net/wiki/spaces/MD93/pages/204604288/Installer+Properties+for+Execution+Container
**Categories:** chunks_index.json

Set the following properties in install.xml: Property Description Property Description mz.container Default value: "" Example value: ec1 This property specifies an identifier for the installed container. Each container in your system must have a unique identifier. The typical value of the mz.container is the hostname, or a descriptive value for the purpose of the container. The permitted characters for the container identifier are 'a-z','0-9' and '-'. mz.home Default value: /opt/mz This property specifies the target directory of the installed container and is automatically set to the environment variable you specified for MZ_HOME when Setting Environment Variables for Platform . install.types Default value: platform,ui,ec This property specifies which parts of the system you want to install. For the Execution container installation, you should set this to only ec. install.admin.password Default value: dr This property specifies the password of the MediationZone administrative user mzadmin . install.silent.enabled Default value: false This property enables or disables silent installation. When set to true , the installation proceeds without prompting for user input. If set to false , user interaction will be required. Note! If the keystore location, password, or admin password is invalid or do not meet the required criteria, the installation will be aborted. install.keystore.location Default value: "" This property specifies the path to an existing keystore file. Note! If install.silent.enabled is set to true , an existing keystore path must be provided for Execution Context Only installation. install.keystore.password Default value: "" This property specifies the password for the keystore. When silent installation is enabled, a valid keystore password is required for the existing keystore. install.keystore.alias Default value: "" This property specifies the alias for the keystore entry. If install.silent.enabled is set to true and install.keystore.location is specified, an alias must be provided. install.security Default value: true If this property is set as true , a valid certificate in a keystore is required for the installation. If it is not already prepared, the installation process will create a new one when prompted. See Network Security for more information.

---

# Document 1851: Launcher Service Interface - MediationZone Documentation 9.3 - InfoZone

**Source:** ratanon/mz93-documentation
**URL:** https://infozone.atlassian.net/wiki/spaces/MD93/pages/204647305/Launcher+Service+Interface
**Categories:** chunks_index.json

When you run the Desktop Launcher, you may add one or more launcher services that provide connection settings for MediationZone deployments. You may use launcher services as an alternative to manually entering the settings for each instance. A launcher service is an external web service that returns a list of existing Platform processes to the desktop launcher. The launcher will only know the URL to the service and uses this information to retrieve the list of instances via HTTP GET. Launcher services are useful in a dynamic environment, e g cloud deployments, where platforms are expected to change IP addresses and ports often. But it can also be useful in a static environments since it reduces the need for manual configuration. Response Format In order for the Desktop Launcher to correct parse the response from launcher service, it must adhere to the following format. mz.<unique identifier>.<attribute>=<value> The unique identifier is used for grouping attributes of a MediationZone instance. You may use e g a UUID for this purpose. The following attributes are available: Attribute Description Attribute Description url The URL Platform Container host, e g https://example.com . This attribute is mandatory. name An arbitrary name of the instance that will be displayed in the Desktop Launcher. This is attribute is mandatory. overrides.pico.rcp.platform.port When the Desktop connects to the Platform it retrieves the value of the property pico.rcp.platform port from the STR. If the Desktop will run on a different network than the Platform, you may need to include this attribute in order to override the retrieved value with an external port number. This attribute is optional. Example - GET request with curl and response from launcher service $ curl examplehost.com mz.139808b7-b9ad-4434-9dbd-5233188c6b2c.url=http://10.10.46.1:9000 mz.139808b7-b9ad-4434-9dbd-5233188c6b2c.name=test-environment mz.a01884d2-cd76-4080-857c-db1d42d8ecdc.url=https://example.com:32768 mz.a01884d2-cd76-4080-857c-db1d42d8ecdc.name=prod-environment mz.a01884d2-cd76-4080-857c-db1d42d8ecdc.overrides.pico.rcp.platform.port=32770 Example Implementation Below is an example of a launcher service implementation written in Python. The script will return the contents of the file that is specified in the first argument. #!/usr/bin/env python import sys from BaseHTTPServer import BaseHTTPRequestHandler, HTTPServer class LauncherService(BaseHTTPRequestHandler): def do_GET(self): try: f = open(sys.argv[1], 'r') self.send_response(200) self.send_header('Content-type', 'text/plain') self.end_headers() self.wfile.write(f.read()) f.close() return except IOError: self.send_error(404, 'file not found') def run(): server_address = ('0.0.0.0', 80) httpd = HTTPServer(server_address, LauncherService) print('http server is running...') httpd.serve_forever() if __name__ == '__main__': run() To run the script: Install python 2x. Save the code above in a file named launcher_service.py . Create a file that contains the instance information. For further information, see Response Format above. Set executable permissions on the file: $ chmod +x launcher_service.py Run the script: $ ./launcher_service.py <file> You may now add the service in the Desktop Launcher.

---

# Document 1852: wfgroupstart - MediationZone Documentation 9.3 - InfoZone

**Source:** ratanon/mz93-documentation
**URL:** https://infozone.atlassian.net/wiki/spaces/MD93/pages/204646643/wfgroupstart
**Categories:** chunks_index.json

usage: wfgroupstart <pattern match expression for workflow group names> ... [-w <timeout s>] [-b] Starts one or more workflow groups. With this command, you compare a single pattern match expression, or several, with the full workflow group name, <folder>.<groupconfigurationname>.<workflowgroupname>, of all the workflows. The command accepts wild cards, such as '*' and '?'. For further information see Textual Pattern Matches . To start the workflow group instantly it should be in the Idle state. Otherwise, start occurs once processing is finished and the group is back in Idle state. A workflow group in Invalid state can not be started as the configuration is invalid. If the wfgroupstart command is used in combination with any of the options when the Platform is restarted, the system cannot retain the workflow group state, so the wfgroupstart command will immediate return the exit code 101 - 'Platform down group aborted' Option Description [-w] Use this option to wait for workflow group completion, that is wait for whichever comes first of either a timeout or received exit code declaring the status of the workflow; completed, aborted etc. For further information about exit codes, see Textual Pattern Matches . Note! The [-w] option does only allow one workflow group to be started at the time. [-b] Use this option (block) to wait for the return code that indicates that workflow group has for example completed, aborted or another code. For further information about exit codes, see Textual Pattern Matches . Note! The [-b] option only allows one workflow group to be started at the time. The [-w] option has precedence over the [-b] option. If both are used at the same time the [-w] will be active. Return Codes Listed below are the different return codes for the wfgroupstart command: Code Description 0 Will be returned if the command was successful. 50 Will be returned if the number of arguments is incorrect. 51 Will be returned if an error occurred when parsing arguments. 60 Will be returned if the command line timed out. 70 Will be returned if the group was not found. 71 Will be returned when trying to start more than one group, or if there was an exception due to no user being logged in. 80 Will be returned if there was an exception due to no group being started 90 Will be returned if an unexpected error occurred. 230 Will be returned if the workflow is already running. 231 Will be returned if permission is denied (no execute permission). 232 Will be returned if the group does not exist. 240 Will be returned if the group is invalid.

---

# Document 1853: mzcli - regenerateconfigs - MediationZone Documentation 9.3 - InfoZone

**Source:** ratanon/mz93-documentation
**URL:** https://infozone.atlassian.net/wiki/spaces/MD93/pages/547979686/mzcli+-+regenerateconfigs
**Categories:** chunks_index.json

When certain areas of MediationZone are upgraded, the existing Ultra formats and other configurations may have to be regenerated or upgraded. This section describes the commands available for doing this. These commands require that the Platform is running. Usage regenerateconfigs [-ultra] Options: -ultra = recompiles Ultra formats The regenerateconfigs command recompiles all configurations. The command should only be used by system administrators with authority to maintain the MediationZone software. Options Option Description [-ultra] This option only recompiles the Ultra formats. In prior releases this command was called regenultra. If the regenerateconfigs command is run without the -ultra option, all configurations are recompiled.

---

# Document 1854: High Availability Setup - MediationZone Documentation 9.3 - InfoZone

**Source:** ratanon/mz93-documentation
**URL:** https://infozone.atlassian.net/wiki/spaces/MD93/pages/204744677
**Categories:** chunks_index.json

This chapter describes how to enable high availability by configuring the system for automatic failover of pico instances. Storage and CMS Requirements For all high availability deployments, an external cluster management software (CMS) is required to ensure that failovers are executed. Commonly used CMS products in physical hardware deployments include Veritas, or MC Service guard. For batch processing, a shared or clustered storage should be used. For stateful real-time scenarios with session management, session information should be persisted, using a distributed storage such as CouchBase. When MediationZone is installed in an Open Stack cloud you can use Corosync and Pacemaker for monitoring. In Amazon Web Services you can use CloudWatch to perform the monitoring and Auto Scale to dynamically recreate a failed node. Overview MediationZone provides HA monitor scripts that are executed by the cluster management software. After interpreting the result, additional scripts are available to start and stop pico instances. The provided scripts typically requires some amount of modification in order to work with your CMS product. Each pico instance runs a HA Monitor Server that is responsible for reporting its status. This server is configured via a set of system properties. For further information about these properties, see High Availability Properties . The system properties pico.rcp.platform.host and pico.rcp.server.host must be configured to enable failover to a secondary pico instance. Depending on the pico type and the deployment type the specified hostnames must resolve to local, virtual, floating, or elastic IP addresses. For further information about how to set these properties, see Resolving Hostnames . When you setup the topology of the system, it is important to consider the ability to fail over pico instances and containers. For instance, in a deployment based on physical servers, the CMS product may support failover of an individual pico instance that runs in the Platform Container, e g an EC. However, in Amazon Web Services, Auto Scaling is used to start a copy of the failed host. This will impact all pico instances, including the Platform. For simplicity, it is recommended that the Platform, ECs, and SCs runs in separate containers, and in the case of Amazon Web Servicer and Open Stack, on separate hosts. Configuration of Cluster Monitoring Software Configuring the cluster monitoring software is beyond the scope of the MediationZone documentation. See the applicable third party documentation for this purpose. It is important to configure dependencies and availability of the resources within the cluster correctly. The cluster monitoring software must handle network interfaces, storage and database monitoring, and switching, including dependencies. This chapter includes the following sections: HA Monitor Server Recover - Platform Recover - EC and SC Resolving Hostnames

---

# Document 1855: Duplicate UDR Using Indexing Field Instead of System Time - MediationZone Documentation 9.3 - InfoZone

**Source:** ratanon/mz93-documentation
**URL:** https://infozone.atlassian.net/wiki/spaces/MD93/pages/205032753/Duplicate+UDR+Using+Indexing+Field+Instead+of+System+Time
**Categories:** chunks_index.json

The "cache time window" (see the figure below) decides whether a UDR shall be removed from the cache or not. The maximum number of days to store a UDR in the cache is retrieved from the setting Max Cache Age (days) each time a new batch file is processed (and the age of the UDRs is calculated). The "cache time window" will be moved forward and old UDRs will be removed. Calculation of the UDR age can be done in two ways: Using the latest indexing field (timestamp) of a UDR that is included in the previously processed batch files. Using system time. The following figure illustrates the difference: Open UDR removed from the cache based on indexing field or system time If the system has been idle for an extended period of time, there will be a "delay" in time. So when a new batch file is processed, and if the system time is used for UDR age calculation, the "cache time window" will be moved forward with the delay included, and this might result in all UDRs being removed from the cache, as shown in the figure above. The consequence of this is that the improperly removed UDRs will be considered non-duplicates and, hence, might be handled even though they still are duplicates. If the indexing field is used instead, a more proper calculation will be done, since the "system delay time" will be excluded. In this case, only UDR 1 and UDR 2 will be removed.

---

# Document 1856: SMPP Agents - MediationZone Documentation 9.3 - InfoZone

**Source:** ratanon/mz93-documentation
**URL:** https://infozone.atlassian.net/wiki/spaces/MD93/pages/205654017/SMPP+Agents
**Categories:** chunks_index.json

This section describes the SMPP Receiver and Transmitter agents. These are collection and forwarding agents for real-time workflow configurations. The SMPP Transmitter agent is listed among the processing agents in Desktop while the SMPP Receiver agent is listed among the collection agents. SMPP Protocol The Short Message Peer to Peer (SMPP) protocol is an open, industry standard protocol designed to provide a flexible data communications interface for the transfer of short message data between a Short Message Service Center (SMSC), or another type of Message center, and an SMS application system. SMPP Session Description An SMPP session between an SMSC and an ESME (External Short Message Entity) is initiated by the ESME first establishing a network connection with the SMSC and then issuing an SMPP Bind request to open an SMPP session. An ESME wishing to submit and receive messages is required to establish two network connections and two SMPP sessions (Transmitter and Receiver). During an SMPP session, an ESME may issue a series of requests to an SMSC and shall receive the appropriate responses to each request, from the SMSC. Likewise, the SMSC may issue SMPP requests to the ESME, which must respond accordingly. Prerequisites The user of this information must be familiar with: The SMPP protocol, version 3.4 The section contains the following subsections: SMPP Agents Configuration SMPP Agents Input/Output Data and MIM SMPP Agents Events SMPP UDRs SMPP Examples

---

# Document 1857: High Availability in PCC - MediationZone Documentation 9.3 - InfoZone

**Source:** ratanon/mz93-documentation
**URL:** https://infozone.atlassian.net/wiki/spaces/MD93/pages/204736380
**Categories:** chunks_index.json

This section describes different recommended high-availability setups and what is required in terms of hardware and software. Other options are, available but it is recommended that an expertise is consulted before a different deployment option is selected. Software and Network Requirements The PCC solution manages availability in different ways. [EZ] and [DR] manage availability by running several of them, while [CZ] requires a stand-by machine to fail over to. This chapter describes what is required for high availability and the possible consequences of not having full redundancy. Network In order to have full redundancy, the network needs to be equipped with redundant switches and all nodes in the solution need to have two network cards each. This is needed in order to manage a switch- or network card failure. Couchbase For information on high availability of Couchbase clusters, see CB v 6.0 or CB v 5.5 . Redis For information on the high availability of Amazon ElastiCache, see https://aws.amazon.com/documentation/elasticache/ .

---

# Document 1858: Spark, kafka and zookeeper - MediationZone Documentation 9.3 - InfoZone

**Source:** ratanon/mz93-documentation
**URL:** https://infozone.atlassian.net/wiki/spaces/MD93/pages/204645630
**Categories:** chunks_index.json

Kafka and zookeeper are required for sending data to and from the Spark cluster. Spark applications must be configured with a set of Kafka topics that are either shared between multiple applications or dedicated to specific applications. The assigned topics must be created before you submit an application to Spark. Before you can create the topics you must start the Kafka and Zookeeper services. See Preparing and Creating Scripts for KPI Management on how to start Spark, Kafka, and Zookeeper. The topics are for transferring data to the Spark Application, receiving calculated KPIs from Spark, and a third topic for alarms. The default names of the topics are kpi-input , kpi-output, and kpi-alarm , but the names can be altered in the KPI Management Profile. Ensure that the number of partitions must match the number of Kafka brokers. Retention Settings The default data retention period in Kafka is one day. You can change the length of this period to conserve disk space. Set the following properties in the file server.properties in the config-folder of Kafka: log.retention.bytes - Must be greater than value of the property log.segment.bytes log.segment.bytes - Must exceed the size of the input/output segments to and from Kafka log.retention.hours - Must be greater than the largest window size in the service model by at least factor 3. Hint! The instruction above will change the retention settings for all topics in the Kafka cluster. You can also override the retention setting for individual topics during creation. For further information see Starting Clusters and Creating Topics . For further information about Kafka, see 9.48 Kafka Agents in the Desktop User's Guide .

---

# Document 1859: Installation of the Data Repository for PCC - MediationZone Documentation 9.3 - InfoZone

**Source:** ratanon/mz93-documentation
**URL:** https://infozone.atlassian.net/wiki/spaces/MD93/pages/204604374
**Categories:** chunks_index.json

This section describes the installation of the data repository. Installing Data Repository for PCC This chapter includes the following sections and subsections: Installation of Couchbase Installation of Redis DirectoryStorage for Testing Installation of MySQL Cluster

---

# Document 1860: ECS Forwarding Workflow (UDR) - MediationZone Documentation 9.3 - InfoZone

**Source:** ratanon/mz93-documentation
**URL:** https://infozone.atlassian.net/wiki/spaces/MD93/pages/204641170
**Categories:** chunks_index.json

In order to send a UDR to the ECS, a workflow must contain an ECS forwarding agent. To perform a table lookup for all UDRs, an Analysis agent is used. If the lookup succeeded, the UDR is sent on the OK route to be saved on disk, while failing UDRs are sent to the ECS forwarding agent. Open A workflow sending UDRs to ECS UDRs may be sent to the ECS without any Error Code or MIM values associated with it. However, this will make browsing the ECS Inspector more difficult, and no auto-assignment to reprocessing groups using the Error Code is possible. ECS Inspector Error Codes can be associated with reprocessing groups via the ECS Inspector dialog ( Reprocessing Groups button). In this way, UDRs with an Error Code are automatically assigned to the respective reprocessing group. Otherwise, the UDRs have to be assigned manually to be available for collection. Open Add Error Code dialog - where a reprocessing group can be selected Analysis Agent The Analysis agent is used to validate and route UDRs, and to associate to a valid (existing) Error Code. The following example appends an Error Code and an Error Case to the UDR prior to sending it to the ECS forwarding agent. Example - appending an error code and an error case to the UDR prior to sending udrAddError( input, "AreaCode_ERROR", "Complete anumber: " + input.anum); udrRoute( input, "error" ); ECS Forwarding Agent In the ECS forwarding agent, the MIM values you want to associate with the UDR are appended. This is optional, however, it makes it easier to search for data and get additional information about the UDR from the ECS Inspector. Open The ECS forwarding agent

---

# Document 1861: mzcli - refreshdbmeta - MediationZone Documentation 9.3 - InfoZone

**Source:** ratanon/mz93-documentation
**URL:** https://infozone.atlassian.net/wiki/spaces/MD93/pages/547979665/mzcli+-+refreshdbmeta
**Categories:** chunks_index.json

Usage usage: refreshdbmeta [options] This command is used to refresh the metadata for existing Database profiles. Options: -p, --profile State a specific profile to be refreshed. The name should be entered in the following format: Folder.ProfileName If no profile is set, all existing profiles will be refreshed. Default: [] -v, --verbose More detailed output from the refreshdbmeta command. Default: [] This command is used to refresh the metadata for existing Database profiles. Options Option Description Option Description [-p, --profile] This option can be used if you want to state a specific profile to be refreshed. If this option is not used, all profiles will be refreshed. [ -v --verbose ] Use this flag for detailed output from the refreshdbmeta command. Example - Using the -v flag $ mzsh <username>/<password> refreshdbmeta -v Output: Database profile <db_profile> metadata has been refreshed Added table: mzadmin.table1 Added procedure: mzadmin.procedure1 Removed table: mzadmin.table2 Removed procedure: mzadmin.procedure2 Execution has been completed Return codes Listed below are the different return codes for the refreshdbmeta command: Code Description Code Description 0 Will be returned if the metadata was successfully refreshed. 1 Will be returned if the stated profile is not valid or could not be found.

---

# Document 1862: Encrypt Password - MediationZone Documentation 9.3 - InfoZone

**Source:** ratanon/mz93-documentation
**URL:** https://infozone.atlassian.net/wiki/spaces/MD93/pages/204737275
**Categories:** chunks_index.json

Encrypt Password allows you to encrypt any password and prints out the result onto the text field. To open Encrypt Password , go to Manage  Tools & Monitoring and then select Encrypt Password . Open Encrypt password configuration Setting Description Password The password to be encrypted will be entered here. All characters entered here will be masked. Open Click this icon to reveal the password. Click the icon again to mask the password. Generate with Alias Check this box to enable the option for the alias to be used when encrypting a password. Alias An alias to be used when encrypting a password. When this option is not used, the system default key will be used. If you want to use this option, the path and password to the Keystore has to be indicated by setting the Platform properties mz.cryptoservice.keystore.path and mz.cryptoservice.keystore.password . The keystore must also contain keys for all the aliases you want to use. For further information about these properties, see Platform Properties . Note! In order to use this option, an alias must have been generated with the Java key tool. Reset The reset button clears all data. Encrypt Displays the result of the encrypted password. To copy the value within, you must use the Copy button.

---

# Document 1863: Dynamic Fields Tab - MediationZone Documentation 9.3 - InfoZone

**Source:** ratanon/mz93-documentation
**URL:** https://infozone.atlassian.net/wiki/spaces/MD93/pages/204997586
**Categories:** chunks_index.json

In the Dynamic Fields tab you can configure fields that you may retrieve data from in the APL code. These fields can then be updated from the workflow table. The fields can be of either boolean , int , or string type. Open Example, The Dynamic Fields tab, using the APL function dynamicFieldGet Item Description Item Description Fields The Fields table displays all the dynamic fields that have been created. Name This column shows the name of the field. Description This column will show any description of the field that has been added. Type This column shows the type of the field. Default Value This column will show any default value that has been set for the field. To add a dynamic field: In the Dynamic Fields tab click the Add button. The Add new dynamic field definition dialog opens. Open Add new dynamic field definition dialog Select an existing category, or enter a new category in the Category field. If there is no existing category, you have to enter a new one. Enter a name for the field in the Name field. If you want, you can enter a brief description of the field in the Description field. Select what type the field should have; boolean , int , or string in the Type field. Enter/select a default value for the field in the Default Value field. This is mandatory for boolean and int fields, but optional for string fields. Click the Add button to add the field to the table in the Dynamic Fields tab. Repeat the steps above for all the fields you want add and then click the Close button. Your new fields are now added, and you can configure them to be either Final , Default , or Per Workflow in the Workflow Table tab.

---

# Document 1864: GCP Storage Collection Agent - MediationZone Documentation 9.3 - InfoZone

**Source:** ratanon/mz93-documentation
**URL:** https://infozone.atlassian.net/wiki/spaces/MD93/pages/205000416/GCP+Storage+Collection+Agent
**Categories:** chunks_index.json

The GCP Storage collection agent collects files from a specified bucket in the Google Cloud Platform and inserts them into a workflow. Initially, the source location is scanned for all files matching the current filter. In addition, the Filename Sequence and Sort Order settings may be used to further manage the matching of files, although they may not be used at the same time since it will cause the workflow to abort. All files found will be fed one after the other into the workflow. When a file has been successfully processed by the workflow, the agent offers the possibility of moving, renaming, removing or ignoring the original file. The agent can also be configured to keep files for a set number of days. In addition, the agent offers the possibility of decompressing compressed (gzip) files after they have been collected. When all the files are successfully processed, the agent stops to await the next activation, whether it is scheduled or manually initiated. Open Example workflow with a GCP Storage Collector Agent The section contains the following subsections: GCP Storage Collection Agent Configuration GCP Storage Collection Agent Events GCP Storage Collection Agent Input/Output Data and MIM GCP Storage Collection Agent Transaction Behavior

---

# Document 1865: packageexport - MediationZone Documentation 9.3 - InfoZone

**Source:** ratanon/mz93-documentation
**URL:** https://infozone.atlassian.net/wiki/spaces/MD93/pages/204743898/packageexport
**Categories:** chunks_index.json



---
**End of Part 78** - Continue to next part for more content.
