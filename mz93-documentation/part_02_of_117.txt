# RATANON/MZ93-DOCUMENTATION - Part 2/112

---
**Dataset:** ratanon/mz93-documentation
**Part:** 2 of 112
**GitHub:** https://github.com/ratan0n/docs/tree/main/mz93-documentation
**Size:** ~66.1 KB
---

A Web Service Provider workflow consists of a Web Service Provider agent (collection), and an Analysis agent. The Web Service Provider agent routes UDRs, that are of the type WSCycle_charge, to the Analysis agent. The Analysis agent then routes the UDRs, carrying a response, back to the Web Service Provider agent. Open The Web Service Provider workflow Configuring the Agents In the Workflow Editor , open the configuration views of both agents. In the Web Service Provider configuration dialog, click the Browse... button. The Configuration Selection dialog opens. Select example and click OK . In the Web Service profile text box, example.charge will appear. Set the Workflow Response Timeout to 3000 ms. In the HTTP tab, assign the HTTP Address with a value by clicking on the Extract Profile Settings button. Click OK . In the Analysis configuration view, enter the following APL code: import ultra.ws.example.charge.cycles; import ultra.ws.example.charge.x1; consume { // Verifying that the UDR type is matches the // UDR definition generated by the WS profile. if (instanceOf(input, WSCycle_charge)) { // Cast the input type to the WSCycle_charge UDR. WSCycle_charge udr = (WSCycle_charge) input; string errorMessage = null; int faultReason = -1; // debug debug("The ServiceType is " + udr.param.serviceType); debug("The amount to charge is " + udr.param.chargingEvent.id); debug("The amount to charge is " + udr.param.chargingEvent.amount); // Perform some business logic ... // In case an error occurred when performing // the business logic, send back a fault if (errorMessage != null) { FaultDetail fault = udrCreate(FaultDetail); fault.message = errorMessage; fault.reason = faultReason; udr.fault_FaultDetail = fault; udr.errorMessage = errorMessage; } else { ChargeResult result = udrCreate(ChargeResult); result.success = true; result.message = "OK"; udr.response = result; } // The UDR is routed back to the // Web Service Provider agent udrRoute(udr); } } The APL code first verifies that the UDRs that enter the workflow are of the WSCycle_charge type. If so, the UDRs are casted from the abstractWScycle type to the WSCycle_charge type. Click on the Compilation Test button. If the compilation fails check that the name of the folder in which you saved the WS profile is the same as in the path that the APL code specifies. Click on the Set To Input . Click OK .

---

# Document 27: Python Function Blocks - MediationZone Documentation 9.3 - InfoZone

**Source:** ratanon/mz93-documentation
**URL:** https://infozone.atlassian.net/wiki/spaces/MD93/pages/205034104/Python+Function+Blocks
**Categories:** chunks_index.json

Python code is divided into different function blocks, making it possible to control when to execute which code. For information on which function blocks are supported for each agent, see the relevant Python agent section. Some of the function blocks are applicable for all of the agents, while some are only relevant for Python agents in real-time workflows, and some for Python agents in batch workflows. Note! Function blocks are not relevant for the Python Connector agent. Top-level code such as global code and imported code will be executed just before the initialize function block. This section includes the following subsections: Function Blocks for Agents in Real-Time and Batch Workflows Function Blocks for Agents in Batch Workflows Function Blocks for Agents in Real-Time Workflows

---

# Document 28: Operating System - MediationZone Documentation 9.3 - InfoZone

**Source:** ratanon/mz93-documentation
**URL:** https://infozone.atlassian.net/wiki/spaces/MD93/pages/204612944/Operating+System
**Categories:** chunks_index.json

MediationZone can run on various Unix-like systems. It is recommended that the latest patch level is installed for the supported operating system. For further information about the supported environment, see System Requirements . File System Permissions At installation a Unix user must be created, usually mzadmin . This user will execute the installation and later on run the MediationZone instance. The mzadmin user must have read/write permissions for the directory MZ_HOME. Note! Read/write permissions should be restricted to the mzadmin user. Ensure that no other users have read/write permissions for MZ_HOME. Environment Variables

---

# Document 29: Table Component UDRs - MediationZone Documentation 9.3 - InfoZone

**Source:** ratanon/mz93-documentation
**URL:** https://infozone.atlassian.net/wiki/spaces/MD93/pages/205002487/Table+Component+UDRs
**Categories:** chunks_index.json

The following section explains the UDRs that can be used to create a component in a table. 1 Table UDR 2 TableColumn UDR 3 TableRow UDR Table UDR The Table UDR is used to create a table. This UDR is used together with TableRow UDR or a Table object. The table rows are default striped. Open To create the table shown above, you can use the following APL code: // Create a table row for the header row TableRow headerRow = udrCreate(TableRow); headerRow.columns = listCreate(TableColumn); // Create columns and add them to the header row listAdd(headerRow.columns, getTableColumn(getText("Decimal"), 0)); listAdd(headerRow.columns, getTableColumn(getText("Hexadecimal"), 0)); // Create the Table UDR Table myTable = udrCreate(Table); myTable.columnNames = headerRow; // Insert table rows that contain the table columns into the data field. myTable.data = listCreate(TableRow); listAdd(myTable.data, getTableRow([getTableColumn(getText("10"), 0), getTableColumn(getText("0xA"), 0)])); listAdd(myTable.data, getTableRow([getTableColumn(getText("11"), 0), getTableColumn(getText("0xB"), 0)])); listAdd(myTable.data, getTableRow([getTableColumn(getText("12"), 0), getTableColumn(getText("0xC"), 0)])); // Helper functions for table creation PlainText getText(string text) { PlainText pText = udrCreate(PlainText); pText.value = text; return pText; } TableColumn getTableColumn(ComponentUDR comp, int width){ TableColumn col = udrCreate(TableColumn); if(width > 0){ col.width = width; } col.components = listCreate(ComponentUDR, comp); return col; } TableRow getTableRow(list<TableColumn> columns){ TableRow row = udrCreate(TableRow); row.columns = listCreate(TableColumn); for (TableColumn column: columns) { listAdd(row.columns, column); } return row; } The following fields are included in the Table UDR : Field Description Field Description attributes (map<string,string>) This field may contain extra attributes to be added. columnNames (TableRow) This field may contain a TableRow UDR to define the header. cssClasses (list<string>) This field may contain a list of extra values added to class attribute. This is typically used to style the component. Please read more on Bootstrap . currentPage (int) This field may contain the current page, only used when usePagination is true. data (list<TableRow>) This field may contain the table data in form of a list of TableRow UDRs. Either this or dbTable field is required to show a table. dbTable (table) This field may contain a table object. Useful when showing a database table. Either this or data field is required to show a table. id (string) This field may contain the id of the component rowsPerPage (int) This field may contain the number of rows in the table, only used when usePagination is true. showBorders (boolean) This field may contain a boolean if borders on all sides of the table and cells should be added. Default is true showHeader (boolean) This field may contain a boolean if the table should have a header. Default is true url (string) This field is used to provide the url stub that will be used for pagination. If you provide e.g. "/table/mytable?page=" the url for page 5 will be "/table/mytable?page=5, only used when usePagination is true. usePagination (boolean) This field may contain a boolean if the table should use pagination, when true currentPage, rowsPerPage and url also needs to be set. TableColumn UDR The TableColumn UDR is used to create a table column see Table UDR for example. The following fields are included in the TableColumn UDR : Field Description Field Description attributes (map<string,string>) This field may contain extra attributes to be added. colspan (int) This field may contain a number of how many columns this column will span over. components (list<ComponentUDR>) This field contain a list of child components, the components that will present in the column. cssClasses (list<string>) This field may contain a list of extra values added to class attribute. This is typically used to style the component. Please read more on Bootstrap . id (string) This field may contain the id of the component width (int) This field may contain a width value. Possible values are 1-12. There are 12 template columns available per row, allowing you to create different combinations of elements that span any number of columns. Width indicate the number of template columns to span (e.g., 4 spans four out of 12, so this column will take 33.3% width of the total number of columns). Actual width on page are set in percentages so you always have the same relative sizing. Default is auto, the column will take as much as it get. TableRow UDR The TableRow UDR is used to create a table row, it is used together with TableColumn UDR, see Table UDR for example. The following fields are included in the TableRow UDR : Field Description Field Description columns (list<TableColumnUDR>) This field contain a list of TableColumn UDRs. cssClasses (list<string>) This field may contain a list of extra values added to class attribute. This is typically used to style the component. Please read more on Bootstrap .

---

# Document 30: Filters - MediationZone Documentation 9.3 - InfoZone

**Source:** ratanon/mz93-documentation
**URL:** https://infozone.atlassian.net/wiki/spaces/MD93/pages/204999508/Filters
**Categories:** chunks_index.json

Filters allow the user to filter out and locate erroneous UDRs and batch files in Data Veracity. The filter that created in this page, can be used in Data Veracity Search, for more details please refer to Search & Repair . Unsupported Data Type for Search Searching, filtering and repairing of UDRs with list and map data types are currently not supported by Data Veracity. In Filters, you can view and delete the saved filters. Open Data Veracity - Filters Filter Sort Order Sorting by Name column is based on Javas default sorting behavior for Strings(for example, sorting of alphabetical characters in Java is case sensitive). Warning! Existing filters can not be renamed. Deleting a Filter Filters can only be deleted from the Filters web UI. Deleting a filter will remove it completely from Data Veracity. To delete a filter, you can select one or many filters at once and then click on the Delete button. You will be prompted with a message to confirm the deletion of the selected filters. Click OK to proceed with the deletion. Open Data Veracity - Deleting filters

---

# Document 31: Excel Encoder Agent Events - MediationZone Documentation 9.3 - InfoZone

**Source:** ratanon/mz93-documentation
**URL:** https://infozone.atlassian.net/wiki/spaces/MD93/pages/204641214/Excel+Encoder+Agent+Events
**Categories:** chunks_index.json

Agent Message Events The Excel Encoder agent does not generate any message events. Debug Events There are no debug events for the Excel Encoder agent.

---

# Document 32: Automatic Scale Out and Rebalancing - MediationZone Documentation 9.3 - InfoZone

**Source:** ratanon/mz93-documentation
**URL:** https://infozone.atlassian.net/wiki/spaces/MD93/pages/301137967
**Categories:** chunks_index.json

Multiple workflows in the same Workflow configuration can be executed in parallel, and collect messages from the same topics, provided that there are several partitions configured for a topic, and the same consumer group is specified. If the number of running workflows changes, the Kafka cluster will automatically trigger rebalancing. You can only have one workflow per partition. If you start more workflows than partitions, the workflows not assigned any partition will run as active stand-by workflows. Open Multiple identical workflows can collect messages from the same topic. Example - Collect Messages from 2 Topics with 3 Configured Partitions You want to collect messages from 2 Kafka topics called example1 and example2 which have 3 configured partitions each. In the Kafka collection agent configuration, you only need to state the names of the topics and consumer group, and the agent will automatically manage the assignment of partitions within the consumer group. Open Kafka collection agent configuration You will get the following behavior and debug in the executing workflows: If only one workflow is started, it will collect messages from all three partitions. The debug output from the collector will look like this: *** Assignment *** Topic(s): example1, example2 Partition(s): 0-2 If a second workflow is started, an automatic rebalance is triggered, and the first workflow will collect messages from two partitions, and the second from the third partition. The debug output from the collectors of the two workflows will look like this: *** Rebalance *** Topic(s): example1, example2 Partition(s): 0-1 *** Assignment *** Topic(s): example1, example2 Partition(s): 2 If a third workflow is started, an automatic rebalance is triggered, and each workflow will collect messages from one partition. The debug output from the collectors of the three workflows: *** Rebalance *** Topic(s): example1, example2 Partition(s): 0 *** Rebalance *** Topic(s): example1, example2 Partition(s): 1 *** Assignment *** Topic(s): example1, example2 Partition(s): 2 If a fourth workflow is started, it will not be assigned any partitions since there are no partitions left and there can only be one workflow collecting from one partition. The fourth workflow will act as an active stand-by workflow. If a workflow aborts, a new automatic rebalance is triggered and the active stand-by workflow can be used.

---

# Document 33: GCP Storage Forwarding Agent Input/Output Data and MIM - MediationZone Documentation 9.3 - InfoZone

**Source:** ratanon/mz93-documentation
**URL:** https://infozone.atlassian.net/wiki/spaces/MD93/pages/204673364/GCP+Storage+Forwarding+Agent+Input+Output+Data+and+MIM
**Categories:** chunks_index.json

Input/Output Data The agent consumes bytearray or MultiForwardingUDR types. MIM For information about the MIM and a list of the general MIM parameters, see Administration and Management . Publishes MIM Value Description MultiForwardingUDR's FNTUDR This MIM parameter is only set when the agent expects input of MultiForwardingUDR type. The MIM value is a string representing the sub path from the output root directory on the target file system. The path is specified by the fntSpecification field of the last received MultiForwardingUDR . For further information about how to use input of MultiForwardingUDR type, see SCP Forwarding Agent MultiForwardingUDR Input . This parameter is of the string type and is defined as a batch MIM context type. File Transfer Timestamp This MIM parameter contains a timestamp, indicating when the target file was created in the temporary directory. File Transfer Timestamp is of the date type and is defined as a trailer MIM context type. Target Filename This MIM parameter contains the name of the target filename, as defined in Filename Template . Target Filename is of the string type and is defined as a trailer MIM context type. Target Template Pathname This MIM parameter contains the name of the target pathname, directories and filename, as defined in Filename Template . Target Template Pathname is of the string type and is defined as a trailer MIM context type. Target Pathname This MIM parameter contains the path to the output directory, as defined in the Disk tab. Target Pathname is of the string type and is defined as a global MIM context type. Accesses The agent accesses MIM parameters in the Filename Template configuration to construct the target filename.

---

# Document 34: Legacy KafkaOffsetUDR - MediationZone Documentation 9.3 - InfoZone

**Source:** ratanon/mz93-documentation
**URL:** https://infozone.atlassian.net/wiki/spaces/MD93/pages/301138729
**Categories:** chunks_index.json

The KafkaOffsetUDR is used to determine an offset that is not at the beginning or the end of the collection and that only applies if you have selected Start at requested in the Kafka Collection agent configuration. The Kafka Collection agent waits for the KafkaOffsetUDR and does not consume before the offset information. Messages can be persisted to a database or aggregation agent. Note! If you send a KafkaOffsetUDR from initialize without any content, messages are read from the beginning (from the first offset). The following fields are included in the KafkaOffsetUDR : Field Description Field Description offsets (map<int,long>) This field is populated with offset information. As offsets in Kafka are unique per partition, this maps partition identifiers (int) to an offset (long). offsetsAsString (string) This field contains a comma-separated key-value list and is available as a convenience. It is used for populating with offset information, as it provides a simple way to store the map with partitions and offset as a string. It reads and writes the same underlying data as the offsets (map<int,long>) field so that changing the value of offsetsAsString (string) changes the value of offsets (map<int,long>) and vice versa. Example An example of two partitions as string type: 1=2,2=3

---

# Document 35: Using External Reference in Agent Profile Fields - MediationZone Documentation 9.3 - InfoZone

**Source:** ratanon/mz93-documentation
**URL:** https://infozone.atlassian.net/wiki/spaces/MD93/pages/204998575
**Categories:** chunks_index.json

This section describes how to enable the use of External Reference profiles in an agent profile configuration. Note! You can use External Reference profiles with the following agent profiles: 5G Aggregation Archiving Azure Couchbase Database Duplicate UDR Elasticsearch File System GCP GCP PubSub Inter Workflow Open API Redis Workflow Bridge For further information see the relevant agent user's guide. Open an agent's profile configuration. Select External References to open the External References dialog. Open The External References dialog Setting Description Setting Description Enable External Reference Select this check box to enable external referencing of the agent profile fields. Clear to disable external referencing of any agent profile field. Profile Click Browse and select the agent profile you want to apply. Enable Select this check box to select the agent profile fields that you want to enable with External Referencing. Field Name The names of the agent profile fields External Reference Key The value Select the Enable External Reference check box, and click Browse to select your External Reference profile. In the table, select the external reference keys to use by selecting Enable and the External Reference Key field. Click OK . You have now enabled external references for the selected profile field(s).

---

# Document 36: Parquet Agent Configuration - MediationZone Documentation 9.3 - InfoZone

**Source:** ratanon/mz93-documentation
**URL:** https://infozone.atlassian.net/wiki/spaces/MD93/pages/205686338/Parquet+Agent+Configuration
**Categories:** chunks_index.json

The Parquet Encoder and Parquet Decoder agents are responsible for encoding and decoding Parquet documents, respectively. The section contains the following subsections: Parquet Decoder Agent Configuration Parquet Encoder Agent Configuration

---

# Document 37: Right to Use Documentation - MediationZone Documentation 9.3 - InfoZone

**Source:** ratanon/mz93-documentation
**URL:** https://infozone.atlassian.net/wiki/spaces/MD93/pages/204648020/Right+to+Use+Documentation
**Categories:** chunks_index.json

Billing Mediation Charging Function (CHF) Charging Gateway Function (CGF) 3G/4G Charging Gateway Function (CGF) 5G Offline Charging (OFCS) Online Charging Function (OCF) OSS Mediation 3G/4G OSS Mediation 5G Policy Control (PCRF) 4G Policy Control (PCF) 5G Routing Control (DRA) 3G/4G

---

# Document 38: Enhanced User Security - MediationZone Documentation 9.3 - InfoZone

**Source:** ratanon/mz93-documentation
**URL:** https://infozone.atlassian.net/wiki/spaces/MD93/pages/204613167
**Categories:** chunks_index.json

The user security can be enhanced by keeping the property install.security as true in install.xml before installation. After the installation, property mz.security.user.control.enabled would be set to true in platform.conf. Use STR to view platform configuration. If mz.security.user.control.enabled set to true after installation, all users are required to change the password during their first login after the property has take effect. If an admin should reset the password for a user, the user will also be required to change password when they re-login. Password Rules If enhanced user security is enabled, the default password rules are: The password must : Be at least eight characters long. Include at least one special character and one that is either a number or a capital letter. new user will have to reset password on first time login. The password must not : Contain more than two identical characters in an uninterrupted sequence. Such as "aaa". Include the username. Be in alphabetical sequence, such as Abcd. Be in numerical sequences, such as 1234. Be in any US keyboard pattern, such as Qwerty. Contain any whitespace. Be identical to any of the recent twelve (minimum) passwords used for the user ID. Info! Repetitive characters that are not consecutively sequenced are still valid. Such as "adadad". Other Password Rules If you have a custom password policy that you will want to include with the default policies listed above, you can modify or add new password rules with the Platform properties that are stated in the section Enhanced User Security Platform Properties of the Platform Properties .

---

# Document 39: Updating Pico Configurations - MediationZone Documentation 9.3 - InfoZone

**Source:** ratanon/mz93-documentation
**URL:** https://infozone.atlassian.net/wiki/spaces/MD93/pages/205657479/Updating+Pico+Configurations
**Categories:** chunks_index.json

Update existing configurations by manually editing the pico configuration file (<pico name>.conf) or use the mzsh topo set command. If you want to make changes for a set of pico configurations, you can do so by using templates. Attributes, i e properties, that that are set on container level (in container.conf ) or cell level ( cell.conf ) are inherited by pico configurations. Pico Level Attributes Run the following commands to add or update an attribute of a pico configuration in a container. $ mzsh topo set topo://container:<container>/pico:<pico>/val:<attribute> <attribute value> Example - Updating a system property $ mzsh topo set topo://container:main1/pico:platform/val:config.properties.mz.subfolder.enabled true Run the following command to add or update an object that contains one or more attributes. $ mzsh topo set topo://container:<container>/pico:<pico>/obj:<object name> '<config>' The <config> argument may contain a key-value pair that specifies a template or a pico configuration in HOCON format. Example - Updating a pico object $ mzsh topo set topo://container:main1/pico:ec2 '{ template:mz.standard-ec config { properties { ec.webserver.port=9092 } classpath { jars=["lib/picostart.jar"] } } }' Container Level Attributes Run the following command to add or update an attribute on container level. $ mzsh topo set topo://container:<container>/val:<attribute> <attribute value> Run the following command to add or update an object that contains one or more attributes. $ mzsh topo set topo://container:<container>/obj:<object name> '<config>' You cannot add JVM arguments or classpaths on the container level. If you need to add JVM arguments that are applied to all pico processes, it is recommended that you do so by using templates. Cell Level Attributes Run the following commands to add or update an attribute on cell level. $ mzsh topo set topo://val:common.<attribute> <attribute value> Run the following commands to add or update an object that contains one or more attributes. $ mzsh topo set topo://obj:common.<object name> '<config>' You cannot add JVM arguments or classpaths on the cell level. If you need to add JVM arguments or classpaths that are applied to all pico processes, it is recommended that you do so by using templates. Desktop Attributes Run the following commands to add or update a custom default attribute for Desktop instances. $ mzsh topo set topo://client:desktop/val:config.<attribute> <attribute value> Run the following commands to add or update an object that contains one or more attributes. $ mzsh topo set topo://obj:client:desktop.config.<object name> '<config>' Example - Updating default JVM arguments $ mzsh topo set topo://client:desktop/obj:config '{ jvmargs { xms=["-Xms128M"] xmx=["-Xmx256M"] client=["-client"] } }'

---

# Document 40: Random Number Generation Functions - MediationZone Documentation 9.3 - InfoZone

**Source:** ratanon/mz93-documentation
**URL:** https://infozone.atlassian.net/wiki/spaces/MD93/pages/204646319/Random+Number+Generation+Functions
**Categories:** chunks_index.json

Use the functions below to generate random integer values. randomInt Returns a pseudorandom, uniformly distributed int value from a random number generator initiated at workflow start. The values returned will be pseudorandomly generated and returned. All 231 possible int values are produced with (approximately) equal probability. This function uses the standard Java Random class. Refer to JDK documentation for exact details on the algorithm used for generating pseudorandom values. int randomInt(int bound) Parameter Description Parameter Description bound The upper bound (exclusive). Must be positive. Returns A random integer in the range 0 to bound-1 randomLong Returns a pseudorandom, uniformly distributed long value from a random number generator initiated at workflow start. The values returned will be pseudorandomly generated and returned. The algorithm uses a seed with only 48 bits, which means that not all possible long values will be returned. This function uses the standard Java Random class. Refer to JDK documentation for exact details on the algorithm used for generating pseudorandom values. long randomLong() Parameter Description Parameter Description Returns A random long

---

# Document 41: GTP' Agent MZSH Commands, Events and Limitations - MediationZone Documentation 9.3 - InfoZone

**Source:** ratanon/mz93-documentation
**URL:** https://infozone.atlassian.net/wiki/spaces/MD93/pages/204673383/GTP+Agent+MZSH+Commands+Events+and+Limitations
**Categories:** chunks_index.json

mzsh Commands In case you want to see the counters that are published as MIM values, you can use the mzsh wfcommand . See the Commandline Tool User's Guide for further information about this. Agent Message Events There are no agent message events for this agent. Debug Events Debug messages are dispatched in debug mode. During execution, the messages are displayed in the Workflow Monitor. You can configure Event Notifications that are triggered when a debug message is dispatched. For further information about the debug event type, see Debug Event . Limitations - GTP' Transported Over TCP Node Alive Request and Redirection Request are not transmitted to GSN nodes when using the TCP protocol. Loading

---

# Document 42: JMS Profile - MediationZone Documentation 9.3 - InfoZone

**Source:** ratanon/mz93-documentation
**URL:** https://infozone.atlassian.net/wiki/spaces/MD93/pages/205000796
**Categories:** chunks_index.json

In the JMS profile configuration, enter the details required to connect and acquire both the Connection Factory object and Destination object from a JNDI service. The JMS profile is loaded when you start a workflow that depends on it. Changes to the profile become effective when you restart the workflow. Configuration Open JMS profile configuration - JNDI Properties Setting Description Setting Description Connection Factory Name Enter the name of the connection factory object that is to be searched for within JNDI. This is used to create a connection with a JNDI provider (a messaging provider such as Weblogic, activeMQ, etc). Destination Name Enter the name of the destination object that is to be searched for within JNDI. This represents the target of messages that are produced and the source of messages that are consumed (e g, queue name or topic name). Properties List Enter <Name:Value> pairs that you want to use when creating the InitialContext. For a list of available options, refer to the JNDI implementation documentation and Context (Java SE 17 & JDK 17) (oracle.com) . Note! There may be instances where setting the username and password for the JNDI server in the JMS agents will result in an error where the agent will not be able to access the server. When this happens, you will have to set the username and password in the properties list, using the following security context: For username, use: java.naming.security.principal For password, use: java.naming.security.credentials

---

# Document 43: Data Masking Agent Events - MediationZone Documentation 9.3 - InfoZone

**Source:** ratanon/mz93-documentation
**URL:** https://infozone.atlassian.net/wiki/spaces/MD93/pages/204999357/Data+Masking+Agent+Events
**Categories:** chunks_index.json

Agent Message Events An information message from the agent, generated according to the configuration in the Event Notification Editor. For further information about the agent message event type, see Agent Event . Debug Events Debug messages are dispatched in debug mode. During execution, the messages are displayed in the Workflow Monitor. You can configure Event Notifications that are triggered when a debug message is dispatched. For further information about the debug event type, see Debug Event .

---

# Document 44: FTAM IOG Agent Configuration - MediationZone Documentation 9.3 - InfoZone

**Source:** ratanon/mz93-documentation
**URL:** https://infozone.atlassian.net/wiki/spaces/MD93/pages/205652657/FTAM+IOG+Agent+Configuration
**Categories:** chunks_index.json

You open the FTAM IOG collection agent configuration dialog from a workflow configuration. To open the configuration, click Build  New Configuration . Select Workflow from the Configurations dialog. When prompted to Select workflow type, select Batch . Click Add agent and select FTAM IOG from the Collection tab of the Agent Selection dialog. Switch Tab Open FTAM IOG agent configuration dialog - Switch tab Setting Description Setting Description Host Name The host alias of the IOG. This host alias, which is located in the <ROOT_DIR>/etc/host_def file. The matching entry in the file specify the corresponding ISO address. User Name User name as defined in the IOG. Password Password related to the User Name . Directory Control File 1 The name of the first directory control file is specified in the IOG. Additional directory control files can be specified in the Advanced tab. Main Filename Name of the main file as defined in the IOG. Stop at Subfile A subfile sequence number in the range of 0001-9999. Regular Expression A regular expression according to Java syntax, using the subfilename as input. The results are the names of the subfiles to be collected. Remove After Collection If enabled, the source files will be removed from the IOG after the collection. Note For further information about regular expressions in Java, please refer to http://docs.oracle.com/javase/8/docs/api/java/util/regex/Pattern.html . Interface Tab Open FTAM IOG agent configuration dialog - Interface tab. Setting Description Setting Description Host Host name or IP address of the host where the FTAM Interface service is running. Port Port number on the Host , on which the FTAM Interface service is listening. The default port number is 16702. Advanced Tab Open FTAM IOG agent configuration dialog - Advanced tab Setting Description Setting Description Account Optional account name, as defined in the IOG, if utilized. File Store Password Optional password for file access, as defined in the IOG, if utilized. Document Type A list from which the data format is selected; unstructured text, record-oriented text, or unstructured binary. Directory Control File [2-4] The names of up to three additional directory control files as defined in the IOG.

---

# Document 45: topo - MediationZone Documentation 9.3 - InfoZone

**Source:** ratanon/mz93-documentation
**URL:** https://infozone.atlassian.net/wiki/spaces/MD93/pages/204646579/topo
**Categories:** chunks_index.json

usage: topo <subcommand> <options> This command is used to register containers in STR and to create, update, remove, and view pico configurations. Note! This command is valid only for the MZ_HOME owner. When you make changes in pico configurations, using topo , these are automatically validated before they are copied to the active registry. If the command and its arguments can be parsed but fails the validation, you can update the configuration or use a reset command to undo the changes. An error message will appear if the validation fails. You can disable the validation by using the option --no-activation . Changes performed by the mzsh topo will then remain in the master registry until you submit a separate topo activate command. You can use the following subcommands with topo: activate container convert diff env get hash help migrate open rebase-configs register reset set setupremote show unset activate usage: activate [options] Options: -d, --allow-disconnected Allow the use of locally cached data (when platform unreachable) Default: false --dry-run Validates all changes to master, but stops before actually completing the activation Default: false --hash Perform activation, only if active registry hash matches the specified hash Default: <empty string> -v, --verbose Outputs information about the changes performed Default: false Use topo activate to move staged changes in the master registry to the active registry. Option Description Option Description [--dry-run] Use this option to validate the staged changes without performing the activation. [-d, --allow-disconnected] Use this option when the Platform is unreachable and you want to operate on cached data. [hash <hash value>] Compare the provided hash value with the actual hash that represents the current state of active registry. The activation fails if the values are not equal. For further information, see hash below, [-v, --verbose] Use this option for detailed information about the changes. Hint! The options --dry-run and --verbose are useful to learn the mzsh topo syntax. When you have edited the configuration manually, use the following command, to view the corresponding edits in a scripted syntax: mzsh topo activate --dry-run --verbose Example - Output from activate with verbose Option mzsh topo activate -v --dry-run mzsh topo set topo://container:main1/pico:ec1/val:config.properties.ec.httpd.port 9096 # (was: 9092) Dry-run: Validation successful Dry-run: Stopping without performing activation Dry-run: Active registry not changed You can then restore the master registry with the command mzsh topo reset . Example - Restart the Picos to Apply the Changes Changes to the STR are not applied on running pico instances or services. If you, for example, have updated the properties of the Platform and an EC, both must be restarted after activation. Example, after an mzsh topo activate of ec5, mzsh shutdown and startup needs to be done to apply the changes. mzsh shutdown ec5 mzsh startup ec5 container Outputs the current MZ_CONTAINER usage: container [options] Options: -d, --allow-disconnected Allow the use of locally cached data (when platform unreachable) Default: true Use topo container to display the name of the current container. Option Description Option Description [-d, --allow-disconnected] Use this option when the Platform is unreachable and you want to operate on cached data. convert Converts specified file of pico definitions from ("XML" -> STR) usage: convert [options] Options: -d, --allow-disconnected Allow the use of locally cached data (when platform unreachable) Default: false -c, --container -g, --container-group --dry-run Output the command that will do the conversion, but do not execut it Default: false * -f, --file Migrate picos from specified file Use topo convert to move the configuration of a specific XML file to STR. Option Description Option Description [-c, --container <container>] Use this option to specify a target container. [-d, --allow-disconnected] Use this option when the Platform is unreachable and you want to operate on cached data. [-g, --container-group <container group>] Use this option to specify a target container group. [--dry-run] Use this option to validate that the conversion and display the result of the conversion without updating the STR. [-f, --file <filename> Use this option to specify the source XML file. Example - Converting an XML File mzsh topo convert --container main1 diff Compare active registry with master or backup usage: diff [options] Options: -d, --allow-disconnected Allow the use of locally cached data (when platform unreachable) Default: false -q, --brief Output only whether files differ Default: false -f, --from Name of the registry to compare to the active registry Default: master -e, --show-entries Show a diff of all updated entries in the files Default: false Use topo diff to view differences between the master repository and the active repository in the STR. Option Description Option Description [-d, --allow-disconnected] Use this option when the Platform is unreachable and you want to operate on cached data. [-e, --show-entries] Use this option for viewing differences in an easy-to-read format. By default, the output from the command displays topo set commands that correspond to the staged changes. Example - Output from diff Command With -e option: UPDATE (containers/main1/picos/ec1.conf) config.properties.aaa:"2" # (was: "1") Without -e option: mzsh topo set topo://container:main1/pico:ec1/val:config.properties.aaa "2" # (was: "1") [ -f, --from <registry>] Use this option when you want to compare the active registry with the backup registry [-q, --brief] Use this option to only view the names of the updated registry files. The default value is false. Example - Comparing Registry Files Run the following command to view the differences between the active registry and the master registry. $ mzsh topo diff or $ mzsh topo diff --from master Run the following command to view the differences between the active registry and the backup registry. $ mzsh topo diff --from backup env Print (or update) the MZ environment values in a format that can be "sourced" in bash: "export NAME=VALUE" usage: env [options] Options: -d, --allow-disconnected Allow the use of locally cached data (when platform unreachable) Default: false -e, --effective Read the environment parameters from within the MZ process runtime, i.e. "effective values", accounting for overrides. The default behaviour is to read the values as they are defineds in the mzsh script, not accounting for the possibility to override these values with environment variables. Default: false --update-java-home Update the mzsh script value of JAVA_HOME --update-mz-container Update the mzsh script value of MZ_CONTAINER --update-mz-home Update the mzsh script value of MZ_HOME --update-mz-platform Update the mzsh script value of MZ_PLATFORM --update-mz-platform-token Update the mzsh script value of MZ_PLATFORM_TOKEN Use topo env to display or set environment variables that are used by the mzsh command. These variables are written to the script file $MZ_HOME/bin/mzsh . The three variables MZ_PLATFORM , MZ_CONTAINER and MZ_CONTAINER_TYPE are handled differently than the rest. In order to update the value in the script file you use the parameters starting with --update-<value> as per below table. In order to both update the value in the script file and use the value immediately you will have to combine the --update-<value> parameter with the -e parameter. Option Description Option Description [-d, --allow-disconnected] Use this option when the Platform is unreachable and you want to operate on cached data. [-e, --effective] Use this option to read the environment parameters in runtime, i e the "effective values" after accounting for overrides. The default behaviour is to read the values as they are defineds in the mzsh script file, not accounting for the possibility to override these values with environment variables. [--update-java-home <value>] Use this option to update the value of JAVA_HOME [ --update-mz-container <value>] Use this option to update the value of MZ_CONTAINER. [--update-mz-home <value> ] Use this option to update the value of MZ_HOME. [--update-mz-platform <value> ] Use this option to update the mzsh value of MZ_PLATFORM. Example - Reading the Environment Variables $ mzsh topo env export JAVA_HOME="/opt/jdk/jdk-17.0.2/jdk-17.0.2.jdk" export MZ_CONTAINER="main1" export MZ_CONTAINER_TYPE="platform" export MZ_PLATFORM="http://192.168.0.1:9000" export MZ_HOME="/opt/mz" Example - Setting the Environment Variable JAVA_HOME $ mzsh topo env --update-java-home /opt/jdk/jdk-17.0.2.jdk get Return the information specified by target-path from the System Topology Registry usage: get [options] target-path Options: -d, --allow-disconnected Allow the use of locally cached data (when platform unreachable) Default: false --default-val Value to output in place of a missing value for a target-path --exclude-dynamic Exclude dynamic information, such as _status { .... } from the output Default: false --format Format of returned data (full|data-only) Default: full -l, --local Implicitly use the local MZ_CONTAINER, unless specified in path Default: false -p, --perspective View of the returned path (default|resolved) Default: default -s, --strict-json Produce/Require strict JSON Default: false --timeout-seconds Maximum time to allow for gathering dynamic information (e.g. _status) Default: 10 Use topo get to retrieve pico configurations in the target path from STR. Paths in STR are structured as follows: topo://container:<container>/pico:<pico>/val:<attribute> Option Description Option Description [-d, --allow-disconnected] Use this option when the Platform is unreachable and you want to operate on cached data. [--default-val <value>] Use this option to replace a missing value in the target path with a default value. Example - Using default-val If the property aaa, is not defined for ec1, 123 is returned instead. $ mzsh topo get -l --default-val 123 topo://pico:ec1/val:config.properties.aaa [ --exclude-dynamic] Use this option to exclude non-static data in the output e g _status in a pico configuration. This is useful in case of errors that blocks the topo command. [--format <full|data-only>] Use this option to exclude metadata from the command output. full - Include meta data data-only - exclude meta data Default: full [-l, --local] Use this option to select the local container, unless another container is specified in the target path. Default: false [-p, --perspective <resolve | default>] Use this option to retrieve the attributes of templates instead of the template names. resolve - attributes default - template names Default: default [-s, --strict-json] Produce/Require strict JSON Default: false [--timeout-seconds] Maximum time to allow for gathering dynamic information (e.g. _status) Default: 10 Example - Viewing Pico Configurations Run the following command to view one or more pico configurations. $ mzsh topo get topo://container:main1/pico:ec2 You can view multiple pico configurations by replacing the full path with a regular expression. $ mzsh topo get topo://container:main1/pico:.* Example - Viewing Pico Attributes Run the following command to view a specific attribute in a pico configuration. $ mzsh topo get topo://container:main1/pico:ec2/val:_name You can retrieve the attributes of multiple pico processes by replacing the full path with a regular expression. $ mzsh topo get --format data-only topo://container:main1/pico:.*/val:_name hash Outputs a hash representing the current state of 'active' usage: hash [options] Options: -d, --allow-disconnected Allow the use of locally cached data (when platform unreachable) Default: false Use topo hash to retrieve a value that represents the current state of the active registry. This is useful when you need to handle concurrent changes of the STR. For instance, an application may need to retrieve a pico configuration to evaluate the required changes. In the meantime, a second application or a user may update the same configuration. Option Description Option Description [-d, --allow-disconnected] Use this option when the Platform is unreachable and you want to operate on cached data. Example - Using Hash Values Application 1 retrieves a new hash value. $ mzsh topo hash "3a2e373fa1653c7f0e757e2682c70317-2028777631" Application 1 retrieves the properties of ec1. $ mzsh topo get -l pico:ec1/obj:config.properties Application 1 updates a property but does not call topo activate . The hash is specified to ensure that changes by other users are not activated inadvertently later on. $ mzsh topo set -l --no-activation --hash 3a2e373fa1653c7f0e757e2682c70317-2028777631  topo://pico:ec1/val:config.properties.ec.httpd.port 9090 Application 2 updates the properties of ec1. The hash value is updated. $ mzsh topo set -l topo://pico:ec1/val:config.properties.ec.httpd.port 9090 Application 1 calls topo activate with hash value retrieved in step 1. $ mzsh topo activate --hash 3a2e373fa1653c7f0e757e2682c70317-2028777631 The activation fails since the hash values do not match. Specified hash does not match transaction id: d9cd38f3793647028bd7e5d64c354ad5-2055434210 != 3a2e373fa1653c7f0e757e2682c70317-2028777631) This may indicate concurrent modification of registry: Operation aborted! Application 1 resets the master registry, retrieves a new hash and starts over. $ mzsh topo reset $ mzsh topo hash help Usage: topo help [<subcommand>] Use topo help to retrieve a description of a subcommand. Run the following command for an overview of the various topo subcomands $ mzsh topo help Run the following command for a description of a specific subcomand $ mzsh topo help <command> migrate Move pico process definitions in $MZ_HOME/etc/*.xml into System Topology Registry usage: migrate [options] Options: -d, --allow-disconnected Allow the use of locally cached data (when platform unreachable) Default: false -a, --no-archive Do not archive the existing xml configs (will create duplicates) Default: false Use topo migrate to move pico configurations from $MZ_HOME to STR. The upgrader runs this command during upgrade. Option Description Option Description [-d, --allow-disconnected] Use this option when the Platform is unreachable and you want to operate on cached data. open Opens an STR configuration file (in an editor) usage: open [options] target Options: -d, --allow-disconnected Allow the use of locally cached data (when platform unreachable) Default: false -n, --no-activation Write changes to master registry, but skip activation Default: false Use topo open to open a cell, container- or pico configuration file in a text editor. When you save and close the editor, the command will call topo activate to move the staged changes in the master registry to the active registry. Option Description Option Description [-d, --allow-disconnected] Use this option when the Platform is unreachable and you want to operate on cached data. [-n, --no-activation] Use this option to skip activation after changes in master registry. Run the following command to open a cell configuration: $ mzsh topo open cell:<cell> Example - Opening a Cell Configuration $ mzsh topo open cell:default Run the following command to open a container configuration: $ mzsh topo open <container> Example - Opening a Container Configuration $ mzsh topo open main1 Run the following command to open a pico configuration: $ mzsh topo open <pico> Example - Opening a Pico Configuration $ mzsh topo open ec1 or $ mzsh topo open container:main1/pico:ec1 If the pico name is not unique in the system, you will be prompted to specify the container. Example - Multiple Pico Configurations Sharing the Same Name $ mzsh topo open ec2 (/home/main1/common/config/cell/default/master/containers/main1/picos/ec2.conf,ec2,topo://container:main1/pico:ec2) (/home/main1/common/config/cell/default/master/containers/exec1/picos/ec2.conf,ec2,topo://container:exec1/pico:ec2) Multiple entries, select one: (1) topo://container:main1/pico:ec2 (2) topo://container:exec1/pico:ec2 [1] : To avoid ambiguous references, specify the name of the container and the pico configuration. Run the following command to open the custom or the standard services configuration: $ mzsh topo open services:<custom|standard> Example - Opening a Service Configuration $ mzsh topo open services:custom Hint! When you save the configuration, topo activate is called with the --verbose option and the saved changes are displayed in a scripted syntax. By default, the command opens the vi editor. To use a different editor set the environment variable EDITOR . Example - Setting nano as the Default Editor $ export EDITOR=nano rebase-configs Removes duplicate configuration entries from configuration files that exist in a template. usage: rebase-configs [options] [topology-ref] Options: -a, --activate Activate immediately Default: false -d, --allow-disconnected Allow the use of locally cached data (when platform unreachable) Default: false Use topo rebase to inset a standard template in a pico configuration and remove attributes that are identical to attributes in the template. The command automatically detects the pico configuration type and applies one of the following templates: mz.standard-platform.conf mz.standard-ec.conf mz.standard-sc This command is useful to reduce the size of the pico configurations and thereby facilitate maintenance. The changes are written to the master registry. To validate and activate the changes you can either use the --activate option or run topo activate after the topo rebase-configs command. For further information about templates, see STR File Structure . Option Description Option Description [-a, --activate] Use this option to immediately activate after changes in master registry. [-d, --allow-disconnected] Use this option when the Platform is unreachable and you want to operate on cached data. Example - Rebasing an EC Configuration $ mzsh topo rebase-configs topo://container:main1/pico:ec1$ mzsh topo active --verbose or mzsh topo rebase-configs --actoivate topo://container:main1/pico:ec1 register Usage: topo register [-a, --address] [-c, --container] [-d, --allow-disconnected] [-g, --container-group <container group>] [--mz-home <mz home>] [-u] When you install an execution container, and the Platform is running, it is automatically registered in the Platform Container. If the platform is not running during the installation, use topo register to register the Execution Container manually. Option Description Option Description [-a, --address <ip/host>] Use this when you need to set a different host address for the container than the one that is specified in the common property pico.rcp.server.host , which is the default value. This option is typically used together with the -u option. [-c, --container <container>] Use this option when you need to change the existing container name. This option is typically used together with the -u option. [-d, --allow-disconnected] Use this option when the Platform is unreachable and you want to operate on cached data. [-g, --container-group <container group>] Use this option when you need to change the existing container group. This option is typically used together with the -u option. [--mz-home <path>] Use this option when you need to set a different home directory for the container than the one that is specified in the environment variable MZ_HOME, which is the default value. [-u] Use this option to allow updates of an already registered container. By default, updates are not allowed and the command will attempt to register a new container. reset Usage: topo reset [-d, --allow-disconnected] [-f, --from <registry>] Use topo reset to remove any changes to the master registry in STR since the activation. Option Description Option Description [-d, --allow-disconnected] Use this option when the Platform is unreachable and you want to operate on cached data. [-f, --from <registry>] Use this option to state the name of the registry to reset from. Valid registries are: active, backup. set Usage: topo set [-d, --allow-disconnected] [-l, --local] [-n, --no-activation] [-s, --strict-json] <target path> <config> Use topo set to create and update pico configurations in the specified target-path of STR. Option Description Option Description [-d, --allow-disconnected] Use this option when the Platform is unreachable and you want to operate on cached data. [-l, --local ] Use this option to select the local container, unless another container is specified in the target path. [--no-activation, -n] Use this option to skip activation after changes in master registry. [-s, --strict-json] Use this option when you want to specify the configuration in JSON format instead of HOCON format. Run the following command to create a new pico configuration. $ mzsh topo set topo://container:<container>/pico:<pico> <config> The <config> argument may contain a key-value pair that specifies a template or a pico configuration in HOCON format. Example - Creating a New Pico Configuration Based on a Template $ mzsh topo set topo://container:main1/pico:ec2 template:mz.standard-ec Example - Creating Pico Configuration When you specify a pico configuration that consists of multiple attributes, it is recommended that you use multi-line strings. HOCON Format: $ mzsh topo set --local pico:ec2 ' { template:mz.standard-ec config { properties { ec.httpd.port : 9092 } classpath { jars=["lib/picostart.jar"] } } }' JSON Format: mzsh topo set -l --strict-json pico:ec2 ' { "template": "mz.standard-ec", "config": { "properties": { "ec": { "httpd": { "port": 9092 } } }, "classpath": { "jars": ["lib/picostart.jar"] } } }' Add the pico group setting by using the following topo command mzsh topo set topo://container:main1/pico:ec1/val:config.properties.pico.groups "ec1, ec2" This command makes the Execution context "EC1" a member of the "ec1" and "ec2" groups. This is the HOCON example format adding in ECs to a pico group. config { classpath {} jvmargs { args=[] } properties { mz.webserver.xframeoptions=DENY pico.groups="ec1, ec2" ec.backlog.dir="/opt/mz/tmp" ec.webserver.port=9137 } vendor-jvmargs { hp {} sun {} } } Run the following command to add or update an attribute of a pico configuration. mzsh topo set topo://container:<container>/pico:<pico>/val:<attribute> <attribute value> Example - Updating a Pico Attribute $ mzsh topo set topo://container:main1/pico:ec2/val:ec_type ec Run the following command to add or update an object that contains one or more attributes. $ mzsh topo set topo://container:<container>/pico:<pico>/obj:<object name> '<config>' The <config> argument may contain a pico configuration in HOCON format. Example - Updating a Pico Object This command adds the properties value1 and value2 : $ mzsh topo set topo://container:main1/pico:ec2/obj:config.properties.example_object '{ value1=1 value2=2 }' The following commands does not overwrite the properties value1 and value2 in example_object but adds value3 : $ mzsh topo set topo://container:main1/pico:ec2/obj:config.properties.example_object '{ value3=3 }' setupremote Usage: topo setupremote [-c, --container <container>] [-g, --container-group <container group>] [--host-key <path>] [--javahome <path>] [--no-authorized-key] [--no-host-key] [-- no-ssh-details] [--ssh-address <ip/host>] [--ssh-port <port>] [--ssh-username <username>] Use the command topo setupremote to enable remote access via SSH to an Execution Container, e g from the Platform container. Option Description Option Description [-c, --container <container>] Use this option to specify a different container than the local one, which is the default value. [-g, --container-group <container group>] Use this option to setup remote access to a container in specific container group. This is useful when you have multiple containers with identical names in different containers groups. [--host-key <path>] Use this option to use a pre-generated host key instead of the one that is generated when you run topo setupremote . [--java-home <path>] Use this option when the target container is located on a different host. The default value is specified by the environment variable JAVA_HOME in the current shell. [--no-authorized-key] By default, the topo setupremote command will obtain a public authorization key from the user home directory on the Platform Container host and store it in the STR, i e the file mz.conf . Use the option --no-authorized-key to skip this operation. [--no-host-key] By default, the topo setupremote command will store the public host key of the Execution Container in the STR, i e the file mz.conf . Use the option --no-host-key to skip this operation. [--no-ssh-details] Use this option to exclude ssh-username and ssh-address from STR. These attributes are required for remote access. If you use this option you will need to update the STR manually. [--ssh-address <ip/host>] Use this option when the target container is located on a different host or when you want to bind to a specific IP address or hostname. The default value is specified by the address attribute for container in mz.conf . [--ssh-port <port>] Use this option when you want to use a different port than 22 for SSH. [--ssh-username <username>] Use this option when the target container is located on a different host or when a specific username is required for SSH. The default SSH user is the OS user that runs the topo setupremote command. show Use topo show to retrieve various types of information about pico instances that are defined in the STR. Usage: topo show [-d, --allow-disconnected] [ --exclude-dynamic] [--format <format>] [-l, --local] [--timeout-seconds <time>] <view> Option Description Option Description [-d, --allow-disconnected] Use this option when the Platform is unreachable and you want to operate on cached data. [ --exclude-dynamic] Exclude non-static data in the output e g _status in a pico configuration. This is useful in case of errors that blocks the topo command. [ --format <format>] Set the format of the returned data: csv json table (default) [ -l, --local ] Use this option to view pico instances in the local container only. By default, all containers are included. [--timeout-seconds <time>] Use this option to limit the time for retrieving dynamic information, e g _status .The default value is 10 seconds. The following views are available: jvm-args - Displays the JVM arguments that are used by the pico instances in the system. JVM arguments that are set in templates are included. status - Displays the container name, pico name, pico type and running state. status-sc - Displays similar view as status but only includes SCs. status-ec - Displays similar view as status but only includes ECs. status-long - Displays similar view as status but also includes the status of replication between Platform Container and Execution Containers. pico-view - Displays similar view as status but also includes memory usage and the pico response time. pico-view2 - Displays similar view as pico-view but also includes uptime. ports - Displays the ports that are used by the pico instances in the system. Ports that are set in templates and on cell- and container level, are included. If both webserver and httpd ports are displayed, then webserver ports take precedence. Example - Views $ mzsh topo show jvm-args +------------------------------------------------------------- | container | name | config.jvmargs | +-----------+----------+-------------------------------------+ | main1 | platform | args=[ | | | | "-XX:MaxMetaspaceSize=256M", | | | | "-Xms192M", | | | | "-Xmx1024M" | | | | ] | +-----------+----------+-------------------------------------+ | main1 | ec1 | args=[ | | | | "-server" | | | | ] | | | | maxDirect=[ | | | | "-XX:MaxDirectMemorySize=4096M" | | | | ] | | | | maxMetaspace=[ | | | | "-XX:MaxMetaspaceSize=196M" | | | | ] | | | | xms=[ | | | | "-Xms64M" | | | | ] | | | | xmx=[ | | | | "-Xmx256M" | | | | ] | +-----------+----------+-------------------------------------+ | main1 | psc1 | args=[ | | | | "-server" | | | | ] | | | | maxDirect=[ | | | | "-XX:MaxDirectMemorySize=4096M" | | | | ] | | | | maxMetaspace=[ | | | | "-XX:MaxMetaspaceSize=196M" | | | | ] | | | | xms=[ | | | | "-Xms64M" | | | | ] | | | | xmx=[ | | | | "-Xmx256M" | | | | ] | +-----------+----------+-------------------------------------+ | exec1 | ec2 | args=[ | | | | "-server" | | | | ] | | | | maxDirect=[ | | | | "-XX:MaxDirectMemorySize=4096M" | | | | ] | | | | maxMetaspace=[ | | | | "-XX:MaxMetaspaceSize=196M" | | | | ] | | | | xms=[ | | | | "-Xms64M" | | | | ] | | | | xmx=[ | | | | "-Xmx256M" | | | | ] | +------------------------------------------------------------- $ mzsh topo show status +--------------------------------------------------------------- | container | name | type | state | config-state | +-----------+----------+----------+-------------+--------------+ | main1 | platform | platform | running | in-sync | | main1 | ec1 | ec. | not-started | | | main1 | psc1 | sc | not-started | | | exec1 | ec2 | ec | not-started | | +--------------------------------------------------------------- $ mzsh topo show ports +---------------------------------------------------------------------------- | container | name | type | ports | +-----------+----------+----------+-----------------------------------------+ | main1 | platform | platform | "mz.pcc.restful.port"="9090" | | | | | "mz.servicehost.port.range"="5451-5500" | | | | | "mz.wi.port"="9000" | | | | | "pico.rcp.platform.port"="6790" | | | | | "pico.synchronizer.port"="6791" | +-----------+----------+----------+-----------------------------------------+ | main1 | ec1 | ec | "ec.httpd.port"="9093" | | | | | "pico.rcp.platform.port"="6790" | | | | | "pico.synchronizer.port"="6791" | +-----------+----------+----------+-----------------------------------------+ | main1 | psc1 | sc | "mz.servicehost.port.range"="5801-5850" | | | | | "pico.rcp.platform.port"="6790" | | | | | "pico.synchronizer.port"="6791" | +-----------+----------+----------+-----------------------------------------+ | exec1 | ec2 | ec | "ec.httpd.port"="9090" | | | | | "pico.rcp.platform.port"="6790" | | | | | "pico.synchronizer.port"="6791" | +---------------------------------------------------------------------------- unset Usage: topo unset [-d, --allow-disconnected] [-l, --local] [-n, --no-activation] <target path> Use topo unset to remove pico configurations in the specified target-path of STR. Option Description Option Description [-d, --allow-disconnected] Use this option when the Platform is unreachable and you want to operate on cached data. [-l, --local] Use this option to select the local container, unless another container is specified in the target path. [-n, --no-activation] Use this option to skip activation after changes in master registry. Run the following command to remove a pico configuration. mzsh topo unset topo://container:<container>/pico:<pico> Example - Removing a Pico Configuration $ mzsh topo unset topo://container:main1/pico:ec2 Example - Removing a Pico Attribute $ mzsh topo unset topo://container:main1/pico:ec2/val:ec_type ec File Paths in Attributes When you enter a path that is relative to $MZ_HOME in the value of an attribute, it is recommend that you use ${mz.home} as a substitution. In the following example $MZ_HOME will be resolved to its current value e g /home/user/mz. Example - Resolved Path $ mzsh topo set topo://container:main1/val:common.pico.rcp.tls.keystore $MZ_HOME/keys/platform.keys The next example uses a path that is always relative to $MZ_HOME. Example - Substituted Path $ mzsh topo set topo://container:main1/obj:common.pico.rcp.tls.keystore '{ keystore=${mz.home}"/keys" }' When you are using ${mz.home} as a substitution, ensure to set attributes as part of an object, using the obj keyword. Conflicting Attributes The name of an attribute may contain the full name of another attribute. For instance, mz.httpd.security.keystore is a system property but its name is also a part of mz.httpd.security.keystore.password. In this case you must ensure that the name of both properties are surrounded by quotes, or one of the properties will be overwritten at activation. Example - Handling Conflicting Attributes, Manual Editing common : { "pico.rcp.tls.keystore" : "home/mz/keys", "pico.rcp.tls.keystore.password" : "..." } When there are conflicting properties and you are using the mzsh topo command, also add single quotes, surrounding the target path (topo://..). Example - Handling Conflicting Attributes, Scripted Editing $ mzsh topo set 'topo://container:<platform container>/val:common."pico.rcp.tls.keystore"' "home/mz/keys" $ mzsh topo set 'topo://container:<platform container>/val:common."pico.rcp.tls.keystore.password"' "..." Updating IP, Hostname, and Ports in JDBC URL You can update the IP address, hostname, and ports int he JDBC URL using the mzsh topo get and mzsh topo set commands as shown in the examples below. Example - Get Current Config $ mzsh topo get -s --format data-only topo://container:platform1/pico:platform/obj:config.properties.mz.jdbc { "password": "DR-4-48851644227183C2041D838568E117EC", "oracle": { "ons": "" }, "type": "oracle", "user": "mzadmin", "url": "jdbc:oracle:thin:@//127.0.0.1:1521/orcl" } Example - Update URL with set $ mzsh topo set topo://container:mz/pico:platform/val:config.properties.mz.jdbc.url "jdbc:oracle:thin:@//192.168.1.10:1522/orcl" [ set: topo://container:mz/pico:platform/val:config.properties.mz.jdbc.url => jdbc:oracle:thin:@//192.168.1.10:1522/orcl] Updating file: $MZ_HOME/common/config/cell/default/master/containers/mz/picos/platform.conf Topology activation completed (master->active) Caution! When you have set the new JDBC URL, run shutdown and startup on the platform to ensure that your changes take effect properly. If you added the incorrect config and the platform did not start, you can run your mzsh command again with the --allow-disconnected option Return Codes Listed below are the different return codes for the topo command: Code Description Code Description 0 Will be returned if the command is successful. 1 Will be returned if the argument count is incorrect or argument(s) are invalid. 3 Will be returned if the target path argument for the subcommand get does not exist.

---

# Document 46: Parquet Encoder Example - MediationZone Documentation 9.3 - InfoZone

**Source:** ratanon/mz93-documentation
**URL:** https://infozone.atlassian.net/wiki/spaces/MD93/pages/205653453/Parquet+Encoder+Example
**Categories:** chunks_index.json



---
**End of Part 2** - Continue to next part for more content.
