# RATANON/MZ93-DOCUMENTATION - Part 72/112

---
**Dataset:** ratanon/mz93-documentation
**Part:** 72 of 112
**GitHub:** https://github.com/ratan0n/docs/tree/main/mz93-documentation
**Size:** ~68.6 KB
---

The Desktop is an intuitive and powerful tab-based management user interface that covers all aspects of the systems configuration. The following figure shows the main Desktop window. In the Desktop menus, various types of configurations, tools, and inspectors are available depending on the type of license you have. For example, if you dont have a Diameter license none of the Diameter agents or profiles will be available in the Desktop. Desktop Menus There are three types of menus available for you when you click on the new button in the desktop menu as shown in the figure below: Configuration menu, Inspection menu, and Tools menu. Open Composite-picture showing Desktop menus. The content of each menu is non-exhaustive and may vary per system environment. Configuration Menu Option Description Option Description Aggregation Profile Used for registration of aggregation criteria configurations that are used in an Aggregation Agent. Alarm Detection Enables you to define criteria for generation of alarm messages. You select a condition, or combine a set of conditions, that within specific limits generate an alarm message. Amazon Profile The Amazon Profile is a generic profile used for setting up Amazon S3 credentials and properties that can be used by various other profiles or agents. APL Code Used for registration of APL scripts that are used in Analysis and Aggregation agents. APL Collection Strategy Enables specific selection logic to be created for Disk, FTP, SCP and SFTP agents. Archive Profile Used for registration of archiving configurations that are used in Archiving agents. Audit Profile Used for registration of Audit table configurations that are used in workflows. Categorized Grouping Profile Used for registration of a Categorized Grouping Agent configuration used by a Categorized Grouping Agent. Couchbase Profile Used for registration of Couchbase configurations, which can be selected in Distributed Storage profiles in order to access buckets in a Couchbase cluster. Data Masking Profile Used for configuring the masking method that you want the Data Masking agent to use, which UDR types and field you want to obscure/reveal, and any masking method specific settings. Database Profile Used for registration of database configurations, both external and internal, that are used in the workflows. Diameter Application Profile Used for registration of supported Diameter Application IDs, Diameter AVPs and Diameter Commands that are used in Diameter Stack (server) / Request (client) agents. Diameter Routing Profile Used for registration of the peer table, realm routing table, and DNS settings for Diameter Stack/Request agents. Distributed Storage Profile Used for registration of distributed storage configurations that are used in workflows. Duplicate Batch Profile Used for registration of Duplicate Batch criteria configurations that are used in Duplicate Batch agents. Duplicate UDR Profile Used for registration of Duplicate UDR (record) criteria configurations that are used in Duplicate UDR agents. Elasticsearch Profile An Elasticsearch profile is used to read and write data in an Elasticsearch Service in AWS and can be accessed by batch workflows using Aggregation agents. Encryption Key Profile The Encryption Profile is a generic profile used for making encryption configurations that can be used by various agents. Encryption Profile The Encryption Profile you make encryption configurations to be used by the Encryptor agent. Event Notification Used for registration of notification and event setups that are used in workflows. External Reference Profile Used for mapping of external reference sources into MediationZone external reference targets. File System Profile The File System Profile are used for making file syste- specific configurations, currently used by the Amazon S3 collection and forwarding agents. Inter Workflow Profile Used for registration of parameter configurations for passing data between workflows using Inter Workflow. JMS Profile Used for registration of JMS specific configurations that are used in the JMS agents. Kafka Profile Used to configure which topic to use, and to select to use embedded Kafka or external Kafka, and configure the profile according to selection. Nordpool Profile The NordPool profile configure the token and server path, as well as login details. OpenAPI Profile The Open API profile can be used for automatically generating UDR structures based on an entered REST API schema in the profile. Python Interpreter Profile Interpreter profiles configure which executable to to use and also which working directory to use. Python Module Python Module configurations share Python code that can be imported by multiple Python agents. Redis Profile Used for registration of Redis profiles that are used in the workflows. Rest Server Profile The REST Server Profile is used to define the endpoint URI for any particular REST server agent in MediationZone. Reference Data Profile Used to query and edit specific table sets in relational databases while schema permissions remain unaltered. SAP RFC Profile Used for dynamic generation of UDRs based on the selected SAP RFC functions that are part of an SAP system. Shared Table Profile Used for registration of shared memory table SQL queries. SNMP Collection Profile Used by the SNMP Request and SNMP Trap collection agents. SNMP OID Profile SNMP OID profile configure which OIDs, i e UDR types and fields to poll, outside of the SNMP Request agent itself, which enables several agents to use the same configuration. Suspend Execution Profile The Suspend Execution profile enables you to apply a restriction that prevents specific workflows and/or Workflow Groups from running in specific periods of time. System Insight Profile Used to create, edit or remove profiles and filters that you want to use to display or store statistics using the System Insight service. TLS Profile The TLS profile enables you to make more detailed configurations for which cipher suites to accept. Ultra Format Used for registration of data configurations using the Ultra Formatting Subsystem. Please refer to the section Ultra Format Definition Language (UFDL) for more information about Ultra. Workflow Used for access to configure and/or change workflows. A workflow is identified as a set of agents connected to each other to represent a data flow. Workflows are the cornerstones of the MediationZone system. Workflow Bridge Profile Used for registration of parameter configurations for passing data between workflows using Workflow Bridge. Workflow Group Enables you to configure several workflows as a single entity WS Profile Used for registration of parameter configurations used in Web Services Inspection Menu Option Description Option Description Aggregation Session Inspector Allows the user to view and edit aggregation sessions Alarm Inspector An alarm can be searched and filtered via the Alarm Inspector tab. The result is presented in a table showing alarm name, description and severity configured using the Alarm Detection configuration. Archive Inspector Allows the user to view and purge Archive entries. Duplicate Batch Inspector Allows the user to view and delete duplicate batch entries. Duplicate UDR Inspector Allows the user to view and delete duplicate UDR entries. ECS Inspector Allows the user to view and manage entries in the Error Correction System (ECS). ECS Statistics Allows the user to view statistics about entries in the Error Correction System (ECS). See Error Correction System (ECS) for more information about ECS. Tools Menu Option Description Option Description Access Controller Used for management of access security to the system Configuration Browser Allows the user to view the configurations for which they have authorization Configuration Diff Allows the user to view two configurations, or two versions of the same configuration side-by-side. The configuration types that can be viewed and compared are APL and Ultra. Configuration Monitor Contains a list of all operations in queue and their progress, e.g. the workflow state. Documentation Generator Allows the user to generate documentation from the configurations in the system. Encrypt Password Encrypt Password allows to encrypt any password and prints out the result onto the text field. Execution Manager With Execution Manager you enable, activate and monitor multiple Workflow groups. Key Manager The Key Manager enables you to configure key exchange required by the protocols for several different agents. Pico Manager Used for management of servers with the system to include Execution Contexts (i.e., the processing servers) Pico Viewer Allows the user to view the servers with the system to include Execution Contexts (i.e., the processing servers). See Overview of MediationZone for more information about the system architecture. Python Language Service Must be running while you are writing your Python code to allow for Code Completion, Validation or Compilation Test to the Python packages that you have installed. System Exporter Used for exporting part or the entire configuration of the system. System Importer Used for importing part or the entire configuration of the system. System Log Allows the user to view and purge System Log entries System Monitor Allows the user to access and read the JMX MBeans for services running on pico hosts (instead of using external tools like jconsole or visualvm). System Statistics Allows the user to view system processing statistics UDR File Editor Allows the user to view and correct the contents of records and files Ultra Format Converter For converting UDRs from one Ultra format to another Help Menu Option Description Option Description User Documentation Allows the user access to an offline version of the user manuals Online Help Directs the user to login to the online user manuals About Allows the user to view the list of software packages and versions, and pico versions for the current instance of Mediation Zone.

---

# Document 1706: Data Veracity Forwarding Agent Configuration - MediationZone Documentation 9.3 - InfoZone

**Source:** ratanon/mz93-documentation
**URL:** https://infozone.atlassian.net/wiki/spaces/MD93/pages/205684832/Data+Veracity+Forwarding+Agent+Configuration
**Categories:** chunks_index.json

To open the Data Veracity forwarding agent configuration dialog from a workflow configuration, you can do either one of the following: double-click the agent icon select the agent icon and click the Edit button The Agent Configuration consists of the following tabs: 1 Data Veracity Tab 2 Thread Buffer Tab Data Veracity Tab Open Data Veracity Forwarding Agent Configuration - Data Veracity Tab Setting Description Setting Description Profile Click Browse to select a predefined Data Veracity Profile. The profile contains the configuration about the Data Veracity connection details and the Data Veracity table schema sql generation. For further information, see Data Veracity Profile . MIM Mapping MIM values to be associated with a UDR when sent to Data Veracity. The MIM values added in the Data Veracity Profile should be listed in the table. Commit Window Size The number of UDRs (rows) to be inserted or removed between each database commit command. This value may be used to tune the performance. If tables are small and contain no Binary Objects, the value may be set to a higher value than the default. Default is 500. The window size can be set to any value between 1-60000, where setting 1 means that commit is performed after 1 UDR, and setting 60000 means that commit is performed after 60000 UDRs. Rows are inserted for each UDR that is fed to the agent. All UDRs are stored in memory between each database commit command, to enable rollback. Rows are removed at the next workflow startup in case of a crash recovery. Should the check box be unchecked, the commit will be performed at every end batch of the workflow. Thread Buffer Tab The use and settings of private threads for an agent, enabling multi-threading within a workflow, is configured in the Thread Buffer tab. For further information, see the section Thre ad Buffer Tab in Workflow Template . Open Data Veracity Forwarding Agent Configuration -Thread Buffer tab

---

# Document 1707: APL - PCC Provisioning Plugins - MediationZone Documentation 9.3 - InfoZone

**Source:** ratanon/mz93-documentation
**URL:** https://infozone.atlassian.net/wiki/spaces/MD93/pages/204645921/APL+-+PCC+Provisioning+Plugins
**Categories:** chunks_index.json

The provisioning functions include: Note! These functions can be used to interact with the PCC provisioning interface from APL. pccGetData Retrieves a specific UDR from the provisioning interface based on the stated UDR type and key. drudr pccGetData( string typename, string key ) Parameters Parameter Description typename The fully qualified typename of the requested UDR. For information about available UDR types, see APL - PCC Provisioning Plugins . key The unique identifier of the requested UDR. Returns: The matching UDR or null, if no matching UDR was found. Example drudr notification = pccGetData ("PCC.Routing.Provisioning.Routing_Details", "3"); will retrieve a UDR of the type PCC.Routing.Provisioning.Routing_Details with the key 3 . pccListData Retrieves a list with all the UDRs from the provisioning interface with the stated UDR type. list<drudr> pccListData( string typename ) Parameters Parameter Description typename The fully qualified typename of the requested UDRs. For information about available UDR types, see APL - PCC Provisioning Plugins . Returns: A list containing all the UDRs of the requested type. Example list<drudr> notificationsList = pccListData ("PCC.Routing.Provisioning.Routing_Details"); will return a list named notificationsList with all the UDRs that have the type PCC.Routing.Provisioning.Routing_Details . pccCreateData This function inserts a new UDR through the provisioning interface. drudr pccCreateData( drudr udr ) Parameters Parameter Description udr The new UDR to insert. For information about available UDR types, see APL - PCC Provisioning Plugins . Returns: The created UDR or null if there was an error. Example drudr created = pccCreateData(input); will insert a new UDR named created through the provisioning interface. pccUpdateData This function updates a UDR through the provisioning interface. drudr pccUpdateData( drudr udr ) Parameters Parameter Description udr The UDR to update. For information about available UDR types, see APL - PCC Provisioning Plugins . Returns: The updated UDR, specified in the argument, or null if there was an error. Example drudr udr = pccUpdateData(created); will update the UDR named created through the provisioning interface. pccDeleteData This function deletes a UDR in the provisioning interface drudr pccDeleteData( drudr udr ) Parameters Parameter Description udr The UDR to delete. For information about available UDR types, see APL - PCC Provisioning Plugins . Returns: The deleted UDR, specified by the argument, or null if there was an error. Example drudr udr = pccDeleteData(created); will delete the UDR named created through the provisioning interface. pccLastErrorCode If any of the create, delete or update operations should fail, the error code can be retrieved with this method. int pccLastErrorCode() Return code Explanation 200 Will be returned if the last operation was successful. 400 Will be returned if the object just created/updated is referring to one or more objects that are missing. 401 Will be returned if the delete operation failed because the object contains references from other objects. 402 This error code is only applicable for the pccCreateData function, and will be returned if the object already exists. 403 Will be returned if any of the functions pccGetData, pccUpdateData, or pccDeleteData are referring to a missing object. 500 Will be returned if there was an error trying to read/write to storage. Example int errorCode = pccLastErrorCode(); will return 500. pccLastErrorMessage If any of the create, delete or update operations should fail, a more detailed description of the error can be retrieved with this method. string pccLastErrorMessage() Parameters Parameter Description Returns: A description of the last error. Example If the last error code was 403, string errorMsg = pccLastErrorMessage(); will return a description of error code 403 e g Cannot find PCC.Routing.Provisioning.Use_Case with id 1001 . Example If the last error code was 500, string errorMsg = pccLastErrorMessage(); will return a description of error code 500 e g Failed to verify Couchbase . pccSetProvisioningArea Sets a provisioning working area for the workflow. There are two areas available, TEST and PROD. void pccSetProvisioningArea( string area ) Parameters Parameter Description area The name of the area to work against. All delete, update, get and create operations will use this area. Must be one of the either TEST or PROD. Example pccSetProvisioningArea("TEST"); will set area TEST as working area for the workflow. pccGetProvisioningArea Retrieves the currently active area for the workflow. string pccGetProvisioningArea() Parameters Parameter Description Returns: The name of the currently active provisioning area. Example If the currently active area for the workflow is TEST, string area = pccGetProvisioningArea(); will return "TEST". pccCopyAreaData Copies configurations from one area to another. Warning! This function will also clear the target area from all previous configurations before the new configurations are inserted. string pccCopyAreaData ( string source , string destination , string configurations ) Parameters Parameter Description source The name of the source area. destination The name of the destination area. configurations The configurations that you want to copy, e g PCC (for all PCC configurations), PCC.Routing_Destination (for only Routing configurations), PCC.Use_Case (for only Use Case configurations), etc. Returns: Null if the command succeeded or the error message if there was an error. Example pccCopyAreaData("TEST","PROD","PCC.RoutingControl"); will copy all the provisioned RoutingControl data from the area TEST to the area PROD. If you want to copy all PCC related data, you can enter ("TEST","PROD","PCC") . pccClearArea Clears an area. All content in the area will be deleted. string pccClearArea( string area ) Parameters Parameter Description area The name of the area to clear. Returns: Null if the command succeeded or the error message if there was an error. Example pccClearArea("TEST", "PCC.Periods"); will clear the area TEST from old PCC configurations for periods. If you want to delete all PCC related data, you can enter ("TEST","PCC") .

---

# Document 1708: logger - MediationZone Documentation 9.3 - InfoZone

**Source:** ratanon/mz93-documentation
**URL:** https://infozone.atlassian.net/wiki/spaces/MD93/pages/315031553/logger
**Categories:** chunks_index.json

Usage logger -pico platform Usage: logger -pico name [-reset] Reset logging to default. This will log to any package/class at the default level. Cannot be used in combination with other optional parameters. [-stacktrace ON | OFF ] Turn stacktrace on/off. Default is on. [-level OFF | ERROR | WARN | INFO | CONFIG | DEBUG | TRACE | FINEST | ALL ] [-file filename ] Send logging to additional file. If used, the command applies only to the specified filename. [-package package/class,.. ] Only log specific package/class. Default is any package/class. The command applies only to the specified package. With this command, you can edit log settings for the picos and update the logging dynamically. Options Option Description Option Description [-reset] Resets the logging to default settings, for example: mzsh <user name>/<password> logger -pico <ec> -reset This option cannot be used in combination with any other option. [-stacktrace] Turns stacktrace on or off, for example: mzsh <user name>/<password> logger -pico <ec> -stacktrace OFF The default value is on. [-level] Determines for which severity levels events should be logged; OFF, ERROR, WARN, INFO, CONFIG, DEBUG, TRACE, FINEST, or ALL, for example: mzsh <user name>/<password> logger -pico <ec> -level WARN Caution! If you set a detailed log level, such as DEBUG, TRACE, or FINEST, logging will be done for all classes in the selected pico(s), including APL logging, which may have a negative impact on performance. To avoid excessive logging when using these log levels, you can add the -package flag, described below, to state a package, for example, the aplLogger package, like this: mzsh <user name>/<password> logger -pico <ec> -level debug -package aplLogger to only do logging for APL. [-file] Will log to an additional file stated with filename, for example: mzsh <user name>/<password> logger -pico <ec> -file mylogfile.txt [-package] Will only log events for the stated package or class, for example: mzsh <user name>/<password> logger -pico <ec> -level debug -package aplLogger Note! When you use the -package option and state the aplLogger package, you can also specify a specific workflow like this: mzsh <user name>/<password> logger -pico <ec> -level debug -package aplLogger.<workflow name> Return Codes Listed below are the different return codes for the logger command: Code Description Code Description 0 Will be returned if the command was successful. 1 Will be returned if there are missing arguments: Pico not running Pico name missing Unknown failure 2 Will be returned if the level is missing or invalid. 3 Will be returned if the file is missing. 4 Will be returned if the package is missing or invalid. 7 Will be returned if the stacktrace is missing or invalid. 8 Will be returned if reset has been incorrectly used.

---

# Document 1709: REST HTTP Interface - MediationZone Documentation 9.3 - InfoZone

**Source:** ratanon/mz93-documentation
**URL:** https://infozone.atlassian.net/wiki/spaces/MD93/pages/204611691/REST+HTTP+Interface
**Categories:** chunks_index.json

Provisioning is supported via a REST HTTP Interface which is implemented using the standard HTTP methods GET , PUT , POST and DELETE . The interface supports XML and JSON formats, and enables external systems to provision and update Rules. The REST HTTP Interface runs on the EC Web Interface and is started when the EC process is started. Authentication is performed against the Platform, if possible. If the Platform is unreachable, the user is authenticated against the locally defined user (configured in EC web interface properties). The UDRs available in the Rules REST Interface are: RulesMapping PCC_Rule QoS_Information Charging_Rule Static_Rule To retrieve one UDR: http://<host>:<port>/PCRF/Rules/<area>/<udr-type>/<udr-id> To retrieve all UDR of a certain type: http://<host>:<port>/PCRF/Rules/<area>/<udr-type> Note! In the examples in this chapter, HTTP/1.0 have been used, but REST supports HTTP/1.1 as well. Creating a UDR A UDR can be created by sending data to the HTTP Interface using POST to the base URL for the UDR. The response will be the created UDR. Default format for the response is XML if nothing is specified. The format for the response is decided by the Accept HTTP header. Example Creating a Qos_Information UDR in area PROD using XML POST http://localhost:9090/PCRF/Rules/PROD/QoS_Information HTTP/1.0 Content-Type: application/xml Content-Length: 251 The xml-data should be structured as follows: <QoS_Information> <APN_Agg_MBR_DL>0</APN_Agg_MBR_DL> <APN_Agg_MBR_UL>0</APN_Agg_MBR_UL> <Allocation_Retention_Priority>0 </Allocation_Retention_Priority> <Bearer_Identifier>1</Bearer_Identifier> <GBR_DL>100</GBR_DL> <GBR_UL>100</GBR_UL> <ID>100</ID> <MBR_DL>1000</MBR_DL> <MBR_UL>1000</MBR_UL> <QCI>1</QCI> </QoS_Information> Example Creating a QoS Information_UDR in area PROD using JSON POST http://localhost:9090/PCRF/Rules/PROD/QoS_Information HTTP/1.0 Content-Type: application/json Content-Length: 196 The json-data should be structured as follows: { "QoS_Information":{ "APN_Agg_MBR_DL":0, "APN_Agg_MBR_UL":0, "Allocation_Retention_Priority":0, "Bearer_Identifier":1, "GBR_DL":100, "GBR_UL":100, "ID":100, "MBR_DL":1000, "MBR_UL":1000, "QCI":1 } } Retrieving a UDR The format for the response is determined by the Accept HTTP header. Retrieving a specific RulesMapping UDR in area PROD as JSON GET http://localhost:9090/PCRF/Rules/PROD/RulesMapping/1001 HTTP/1.0 Accept: application/json Example output: { "ID": 1001, "Priority": 1, "Arguments": ["Arg1","Arg2"], "Targets": [1001], "StopFallthrough": false } Retrieving all RulesMapping UDRs in area PROD as JSON GET http://localhost:9090/PCRF/Rules/PROD/RulesMapping HTTP/1.0 Accept: application/json Example output: { "RulesMappings": [ { "ID": 1001, "Priority": 1, "Arguments": ["Arg1","Arg2"], "Targets": [1001], "StopFallthrough": false }, { "ID": 1002, "Priority": 2, "Arguments": ["Arg 3","Arg 4"], "Targets": [1002], "StopFallthrough": false } ] } Retrieving a specific PCC_Rule UDR in area PROD as JSON GET http://localhost:9090/PCRF/Rules/PROD/PCC_Rule/1001 HTTP/1.0 Accept: application/Json Example output: { "ID": 1001, "Rule_Name": "Rule 1", "Charging_Rules": [1001], "Period": 1, "QoS": 2 } Retrieving all PCC_Rule UDRs in area PROD as JSON GET http://localhost:9090/PCRF/Rules/PROD/PCC_Rule HTTP/1.0 Accept: application/json Example output: { "PCC_Rules": [ { "ID": 1001, "Rule_Name": "Rule 1", "Charging_Rules": [1001], "Period": 1, "QoS": 2 }, { "ID": 1002, "Rule_Name": "Rule 2", "Charging_Rules": [1001], "Period": 5, "QoS": 12 } ] } Retrieving a specific QoS_Information UDR in area PROD as JSON GET http://localhost:9090/PCRF/Rules/PROD/QoS_Information/1001 HTTP/1.0 Accept: application/json Example output: { "ID": 1001, "Name": "QoS 1Mbps", "ARP": 0, "APN_Agg_MBR_DL": 1000, "APN_Agg_MBR_UL": 1000, "GBR_DL": 0, "GBR_UL": 0, "MBR_DL": 1000, "MBR_UL": 1000, "QCI": 9 } Retrieving all QoS_Information UDRs in area PROD as JSON GET http://localhost:9090/PCRF/Rules/PROD/QoS_Information HTTP/1.0 Accept: application/json Example output: { "QoS_Informations": [ { "ID": 1001, "Name": "QoS 1Mbps", "ARP": 0, "APN_Agg_MBR_DL": 1000, "APN_Agg_MBR_UL": 1000, "GBR_DL": 0, "GBR_UL": 0, "MBR_DL": 1000, "MBR_UL": 1000, "QCI": 9 }, { "ID": 1002, "Name": "QoS 7/2Mbps", "ARP": 0, "APN_Agg_MBR_DL": 7000, "APN_Agg_MBR_UL": 2000, "GBR_DL": 0, "GBR_UL": 0, "MBR_DL": 7000, "MBR_UL": 2000, "QCI": 9 } ] } Retrieving a specific Charging_Rule UDR in area PROD as JSON GET http://localhost:9090/PCRF/Rules/PROD/Charging_Rule/1001 HTTP/1.0 Accept: application/json Example output: { "ID": 1001, "Name": "Charging Rule 1", "Dynamic_Rule": 0, "Final_Indication_Rule": 0, "Static_Rule": 1 } Retrieving all Charging_Rule UDRs in area PROD as JSON GET http://localhost:9090/PCRF/Rules/PROD/Charging_Rule HTTP/1.0 Accept: application/json Example output: { "Charging_Rules": [ { "ID": 1001, "Name": "Charging Rule 1", "Dynamic_Rule": 0, "Final_Indication_Rule": 0, "Static_Rule": 1001 }, { "ID": 1002, "Name": "Charging Rule 2", "Dynamic_Rule": 1001, "Final_Indication_Rule": 1001, "Static_Rule": 0 } ] } Retrieving a specific Static_Rule UDR in area PROD as JSON GET http://localhost:9090/PCRF/Rules/PROD/Static_Rule/1001 HTTP/1.0 Accept: application/json Example output: { "ID": 1001, "Rule_Name": "Static Rule 1", "Rule_Base_Name": "rb-default" } Retrieving all Static_Rule UDRs in area PROD as JSON GET http://localhost:9090/PCRF/Rules/PROD/Static_Rule HTTP/1.0 Accept: application/json Example output: { "Static_Rules": [ { "ID": 1001, "Rule_Name": "Static Rule 1", "Rule_Base_Name": "rb-default" }, { "ID": 1002, "Rule_Name": "Static Rule 2", "Rule_Base_Name": "rb-redirect" } ] } Updating a UDR Updates are made using PUT . Example Updating QoS Information UDRs in area PROD using XML PUT http://localhost:9090/PCRF/Rules//PROD/QoS_Information/<id> HTTP/1.0 Content-Type: application/xml Content-Length: 251 The format of the xml-data should be structured as follows: <QoS_Information> <APN_Agg_MBR_DL>0</APN_Agg_MBR_DL> <APN_Agg_MBR_UL>0</APN_Agg_MBR_UL> <Allocation_Retention_Priority>0 </Allocation_Retention_Priority> <Bearer_Identifier>1</Bearer_Identifier> <GBR_DL>100</GBR_DL> <GBR_UL>100</GBR_UL> <ID>100</ID> <MBR_DL>1000</MBR_DL> <MBR_UL>1000</MBR_UL> <QCI>1</QCI> </QoS_Information> Deleting a UDR Deleting a resource is done by using the DELETE method. Example Deleting Rules UDR 2101 in area PROD DELETE http://localhost:9090/PCRF/Rules/PROD/PCC_Rule/2101 HTTP/1.0 Clearing an area Clearing an area is done with a HTTP DELETE call to <host>:<port>/PCRF/Rules/<source area>/admin/clear . Example Clearing area TEST DELETE http://localhost:9090/PCRF/Rules/TEST/admin/clear HTTP/1.0 Copy one area to another Copying one area to another is done with a HTTP PUT call to <host>:<port>/PCRF/Rules/<source area>/admin/copyArea?dest=<destination area> . Example Copying data from TEST to PROD PUT http://localhost:9090/PCRF/Rules/TEST/admin/copyArea?dest=PROD HTTP/1.0 Content-Length: 0 Error codes There are several different codes that can be returned for the different operations. For admin commands: http://<host>:<port>/PCRF/Rules/<area>/admin/clear http://<host>:<port>/PCRF/Rules/<area>/admin/copyArea http://<host>:<port>/PCRF/Rules/<area>/admin/refresh Error code Description Error code Description 200 Will be returned if the last operation was successful. 500 Will be returned if there was an error. When creating a UDR: http://<host>:<port>/PCRF/Rules/<area>/<udr-type> Error code Description Error code Description 201 Will be returned if the UDR was created. 409 Will be returned if a UDR with the stated key already exists, or if there are dependencies missing. 415 Will be returned if the UDR key is of type string and the key is missing, or if the key type is incorrect. 500 Will be returned if the UDR requires references that are missing, or if there was an error. When retrieving one UDR: http://<host>:<port>/PCRF/Rules/<area>/<udr-type>/<id> Error code Description Error code Description 200 Will be returned if the requested UDR was found. 204 Will be returned if there is no UDR with the stated ID. 500 If there was an error. When retrieving all UDRs: http://<host>:<port>/PCRF/Rules/<area>/<udr-type> Error code Description Error code Description 200 Will be returned with an empty list or with a list containing the UDRs. When updating a UDR: http://<host>:<port>/PCRF/Rules/<area>/<udr-type>/<id> Error code Description Error code Description 200 Will be returned if the UDR was updated successfully. 408 Will be returned if the keys in the URL and the XML are different, or the key in the URL is set to "0".. 409 Will be returned if the UDR requires references that are missing, or if there is not UDR with the stated key. 500 Will be returned if there was an error. When deleting a UDR: http://<host>:<port>/PCRF/Rules/<area>/<udr-type>/<id> Error code Description Error code Description 200 Will be returned if the UDR was deleted successfully. 204 Will be returned if there is no UDR with the stated ID. 409 Will be returned if the UDR is referenced by another UDR. 500 Will be returned if there was an error.

---

# Document 1710: Audit Functions - MediationZone Documentation 9.3 - InfoZone

**Source:** ratanon/mz93-documentation
**URL:** https://infozone.atlassian.net/wiki/spaces/MD93/pages/204646217/Audit+Functions
**Categories:** chunks_index.json

For the audit related functions to take effect, you must select the Enable Audit option in the Audit tab in the Workflow Properties dialog, see Audit Tab . Note! The key or combination of keys are only unique within a batch. If a second batch is executed, a new row looking exactly the same as one from the previous batch might be received. The purpose of the key is to be able to save more than one row per batch. For further information about Audit, see Audit Profile in the Desktop User's Guide . The following functions for Audit described here are: AuditAdd The auditAdd function increases or decreases a column value in any table specified. Note that the table must be configured in the Audit Profile Editor window first, and the column must be defined as a 'Counter'. void auditAdd ( string profile, string tableAlias, string columnAlias, any value, any key1, //Optional any key2 ) //Optional Parameter Description profile The name of a defined Audit Profile . This declaration is case-sensitive. The profile declaration must include the directory name: myFolder.myProfile tableAlias Name of the table to update. It is case-sensitive and can be in uppercase or lowercase depending on the type of database used. It must also exist in the specified Audit Profile . columnAlias Name of the column to update. The name is case-sensitive and can be in uppercase or lowercase depending on the type of database used. value The value to increase/decrease the existing value with. key<n> The key columns in the order as entered in the Audit Profile Editor . Returns Nothing. AuditSet The auditSet function sets a column value in any table specified. Note that the table must be configured in the Audit Profile window first, and the column must be defined as being of type 'Value'. void auditSet ( string profile, string tableAlias, string columnAlias, any value, any key1, //Optional any key2 ) //Optional Parameter Description profile The name of a defined Audit Profile . This declaration is case-sensitive. The profile declaration must include the directory name: myFolder.myProfile tableAlias Name of the table to update. It is case-sensitive and can be in uppercase or lowercase depending on the type of database used. It must also exist in the specified Audit Profile . columnAlias Name of the column to update. The name is case-sensitive and can be in uppercase or lowercase depending on the type of database used. value The value to set. key<n> The key columns in the order as entered in the Audit Profile . Returns nothing.

---

# Document 1711: exit - MediationZone Documentation 9.3 - InfoZone

**Source:** ratanon/mz93-documentation
**URL:** https://infozone.atlassian.net/wiki/spaces/MD93/pages/204743822/exit
**Categories:** chunks_index.json

usage: exit [ N ] Exits the command line tool. The argument N is the final exit code returned to the calling process. If no argument is supplied, the result of the previous operation will be returned to the calling process. Return Codes Listed below are the different return codes for the exit command: Code Description Code Description N The value of the supplied argument or the final exit code from the last command.

---

# Document 1712: Format Management Overview - MediationZone Documentation 9.3 - InfoZone

**Source:** ratanon/mz93-documentation
**URL:** https://infozone.atlassian.net/wiki/spaces/MD93/pages/204646665
**Categories:** chunks_index.json

MediationZone is capable of handling various Usage Detail Record (UDR) formats provided that their structure is known. Vendor UDR formats are often complex and hard to work with in agents that view or manipulate data. Therefore, the system converts the external UDR formats to an internal representation, and vice versa when UDRs are leaving the system. In order to make this conversion, both internal and external format definitions have to be defined. When the definitions exist, there must be a mapping description that maps each external field of interest to an internal field. Ultra does not require a one-to-one relationship between external and internal field names. Normally, only fields of interest or those that are needed when leaving the system are declared in the internal format definition. Often the internal definition holds additional fields that are initially empty and then populated on the way through a workflow. MediationZone does not constrain how these fields are used. Example - Format management In this example, the external field E1C is not needed and is not mapped at all. Internally IFA and IFB are manipulated. IFE is given a value, probably depending on values defined in IFC and IFD during the UDRs way through the workflow. At the exit, the two original fields are mapped into E2A and E2B plus the new (IFE) into E2C. Open MediationZone introduces a language called Ultra Format Definition Language (UFDL) that is used when describing UDR formats and mappings. Apart from describing external formats, internal formats, and mappings, the UFDL requires separate decoder and encoder specifications. A decoder or encoder refers to one or several mappings that are used for the actual translation. Format Storage In order to operate on UDRs, there must be a compiled version (Java class) of the internal format definition available in the Code or Ultra server. Such Java classes are introduced into the servers in two different ways: Format definitions entered in the Ultra Format Editor are compiled and inserted in the Ultra server when saved. Precompiled format definitions (for instance; Radius, NetFlow, and SNMP protocols) are inserted in the Code server during package commit. A format can be recompiled while workflows using it are running. In this case, the changes to the format will take effect the next time the workflow is activated. All Java classes generated by the Ultra server are kept in the system. This is to make UDRs, for instance stored in ECS and using the old format version, processable. For further information, see Ultra Format Converter . Note! Saving a format in the Ultra Format Editor may take some time, since the system may have to re-validate and regenerate many dependent configurations. If an Ultra format is moved to another directory or is renamed, the configurations using the format become invalid. Built-in Formats There are four different built-in external formats that can be used between workflows; MZ Tagged, MZ Tagged (compressed), JSON, and CSV. These can be used by the Decoder and Encoder agents as well as by the real-time collection agents for Inter Workflow, TCP/IP, and GTP'. MZ Tagged Formats The MZ Tagged format is available in all supported agents, while the MZ Tagged (compressed) format is only available in the Encoder agent. Using the compressed format reduces the size of the UDRs significantly. However, since compression requires more CPU, you should consider the trade-off between I/O and CPU when choosing an encoder. No Decoder or Encoder needs to be defined in Ultra to handle these formats. The MZ Tagged formats contain header data that is based on the time zone settings of the host on which it was generated. This is important to consider when you compare output from identical workflows that are running on hosts with different time zone settings. The binary data may differ due to the header content. JSON Format The JSON Format is available in the Decoder, Inter Workflow, TCP/IP, and GTP' agents. With this built-in format, you can also choose to use a DynamicJsonUDR where you can add the payload to the UDR. The format is validated according to the specified JSON schema. CSV Format The CSV Format is available in the Decoder, Inter Workflow, TCP/IP, and GTP' agents. The following predefined CSV formats are supported; Unix, Mac, Windows, and Excel, but you can also create your own custom format. Decoding of a UDR The Ultra engine is designed to decode only the necessary parts of a Usage Detail Record, UDR, to keep workflow performance as high as possible. By default (that is, provided that Full Decode is not selected), the decoder only decodes enough to calculate the size of the UDRs. The UDR content is decoded as the field values are accessed. Hence, if there is a decoding error, this may not be discovered by the decoder but by the agent accessing a specific field. Note! Full decoding of complicated nested UDR structures can be time-consuming. In most cases, the performance cost of this option is however small.

---

# Document 1713: KPI Agent - MediationZone Documentation 9.3 - InfoZone

**Source:** ratanon/mz93-documentation
**URL:** https://infozone.atlassian.net/wiki/spaces/MD93/pages/204611397
**Categories:** chunks_index.json

The KPI agent sends incoming performs KPI calculations based on the data in the incoming KDR UDRs and the Service Model of the selected KPI profile. The agent routes the output to the workflow as KPIAggregatedOutput UDRs. Open KPI Management workflow Configuration Open KPI agent configuration Setting Description Setting Description KPI Profile Click Browse to select a predefined KPI profile. The profile contains the service model configuration. Delay The delay setting specifies a time period that is added to the upper limit of each KPI output period. If the timestamp of a KDR UDR exceeds the upper limit with the added delay, it is matched with the next period and the current period is closed. For further information about periods, see KPI Management UDR Types . Input/Output Data The Input/Output data is the type of data an agent expects and delivers. The KPI Cluster In agent expects KDR UDRs and delivers KPIAggregatedOutput UDRs. MIM For information about the MIM and a list of the general MIM parameters, see Administration and Management in Legacy Desktop in the Desktop User's Guide . Publishes MIM Parameter Description MIM Parameter Description Error Counter This MIM parameter contains the number of errors that have occurred since the workflow was started. Error Counter is of the long type and is defined as a global MIM context type. Discarded KPIs This MIM parameter contains the number of calculated KPIs that were discarded since they belong to a previously closed period. Discarded KPIs is of the long type and is defined as a global MIM context type. Model Config This MIM parameter contains the name of the KPI Profile in the agent configuration. Model Config is of the string type and is defined as a global MIM context type. Model Version This MIM parameter contains the version of the KPI Profile in the agent configuration. Model Version is of the int type and is defined as a global MIM context type. Accesses This agent does not access any MIM parameters. Agent Message Events There are no message events for these agents. Debug Events Debug messages are dispatched in debug mode. During execution, the messages are displayed in the Workflow Monitor . Example - Debug events Failed to match dimension: At least one node is missing in /tree1/AMERICAS/country/Country.AvgSales for input Map(region -> AMERICAS, amount -> 563.75, xcountry -> Mexico) Failed metric calculation: Failed to evaluate KPI(Region.AvgSales), EXPR(Some(Expr(amount))) INPUT: Map(xamount -> 505.0) You can configure Event Notifications that are triggered when a debug message is dispatched. For further information about the debug event type, see 4.3.23 Debug Event .

---

# Document 1714: Python Agents in Batch Workflows - MediationZone Documentation 9.3 - InfoZone

**Source:** ratanon/mz93-documentation
**URL:** https://infozone.atlassian.net/wiki/spaces/MD93/pages/205686590/Python+Agents+in+Batch+Workflows
**Categories:** chunks_index.json

This section describes how to configure Python agents in batch workflows. The following general information applies: Threading Model In batch workflows, the workflow logic is adapted to data execution, in sequential and single-threaded mode. The collection agent controls the main execution thread, and when the thread returns from the collection agent, the workflow will stop. Garbage Collection A UDR that is routed to a Python agent is kept in both the Python and Java heaps as long as it is referenced. When the UDR is no longer referenced in Python, an automatic message is sent to Java saying that it may be released from the Java heap. If you need to route many large UDRs to Python and keep them alive for a longer period of time, a good solution could be to copy the relevant information into a suitable Python structure in order to allow the UDR to be released. If this is not the case, you should not have to take any specific measures in order for garbage collection to work as it should. This section includes the following subsections: Python Collection Agent - Batch Python Processing Agent - Batch Python Agents Example - Batch

---

# Document 1715: Performance Tuning with Couchbase Storage - MediationZone Documentation 9.3 - InfoZone

**Source:** ratanon/mz93-documentation
**URL:** https://infozone.atlassian.net/wiki/spaces/MD93/pages/204639837/Performance+Tuning+with+Couchbase+Storage
**Categories:** chunks_index.json

This section describes how to tune the Aggregation agent with Couchbase storage. Unless stated otherwise, the properties referred to in this section are set in the Advanced tab in the Aggregation profile. For further information on performance tuning with Couchbase storage, you can refer to Couchbase's own advice on Tuning & Performance in the Couchbase Documentation. Queries and Indexes When Couchbase is selected as the storage type in an Aggregation profile, a bucket is automatically created during the execution of a workflow. The bucket is named according to the configuration of the assigned Couchbase profile. The bucket is populated with documents that contain the aggregation session data. This makes it possible to index the timeout information of aggregation sessions in Couchbase. The aggregation session data is fetched using an N1QL query. Note! N1QL queries are used by default. If you want to use views instead, use the following mzsh topo command to set the property mz.cb.use.n1ql to false in ECs: mzsh topo set topo://container:<container>/pico:<pico>/val:config.properties.mz.cb.use.n1ql false The data returned by the query is split into chunks of a configurable size. The size of each partial set of data can be configured by setting the property view.iteratorpageSize in the Advanced tab of the assigned Couchbase profile. Setting a higher value than the default 1000, may increase throughput performance but it depends on the available RAM of the Execution Context host. You can choose to update the result set from a query before or after it has been called. Or you can choose to retrieve the existing result set from a query. In this case the results are possibly out of date, or stale. To control this behavior, you can set the property view.index.stale in the Advanced tab of the assigned Couchbase profile. The following settings are available: FALSE - The index is updated before the query is executed. This ensures that any documents updated (and persisted to disk) are included in the query. The client waits until the index has been updated before the query is executed, and therefore the response is delayed until the updated index is available. OK - The index is not updated. If an index exists for the given query, the information in the current index is used as the basis for the query and the results are returned accordingly. This value is seldom used and only if automatic index updates are enabled in Couchbase. UPDATE_AFTER - This is the recommended setting when using a Couchbase profile with Aggregation. The existing index is used as the basis of the query, but the index is marked for updating once the results have been returned to the client. For more information about queries and indexes, you can refer to Couchbase's own documentation on indexes. Timeout There are by default, two timeout threads per workflow that periodically check the Couchbase aggregation storage for timed out sessions. You can control how often this check is performed by setting mz.cb.agg.timeoutwait.sec . The default value is 10 seconds. You can also increase the number of threads that perform this check by setting the property mz.cb.agg.timeout_no_of_thread . Setting a higher value than default may speed up detection of timeouts. However, the number of CPUs and the time that it takes for Couchbase to index accessed documents (session data) are limiting factors. Hint! You can use the MIM parameter Session Timeout Latency as an indicator of the timeout handling performance. The sessions that are fetched from the Couchbase query are shuffled randomly in temporary buffers, one for each workflow. This is done to minimize the probability that multiple workflows attempt to time out the same sessions simultaneously. You can control the size of these buffers by setting the property mz.cb.agg.randombuffer . The default value is 1000 sessions. You use the Operation Timeout (ms) setting in the Connectivity tab of the assigned Couchbase profile to control the timeout of Couchbase "CRUD" operations, i e create, read, update, and delete. Setting a lower value than the default 1000 ms may have a positive impact on throughput performance. However, if the value is set too low, indicated by a large number of operation timeouts errors in the EC logs, a lower throughput can be expected. Queries operate over a different protocol than CRUD operations and have a separate timeout property named view.timeout in the Advanced tab of the Couchbase profile. The default value is set to 75000 (ms). It is generally not recommended to decrease this value. However, if you frequently receive the error Failed to iterate through timeout sessions in the EC logs, increasing this value may have a positive impact on throughput performance. Session Storage Format The aggregation sessions are stored in JSON format. However, some of the data within the JSON strings can be stored in binary format instead of plain text (default). You can change the stored format by setting the property mz.cb.agg.json_serializer.format . The valid values are: MZ-BIN - The session data is serialized into JSON strings with binary content. JSON - The session data is serialized into JSON strings with plain text content. Example - Binary Format { "drType": "MZ-BIN", "drFormatVersion": 2, "data": "Af+cAAAAR2NvbS5tZWRpYXRpb256b25lLnVsdHJhLmluLmFnZ3Jl Z2F0aW9uX2NvbW1vbl9zZXNznaW9uX3Nlc3Npb25fMTk1MzI3MTEwAAABT C19yJgAAAAAAAAAAAEAAAAGAQAAAAExAQAAAAExAQAAnAAExAAAABgEAAA AHY29uc3VtZQ==", "SessionTimeout": 1426692360344, "initialized": true } Example - Plain text format { "drType": "JSON", "drFormatVersion": 2, "data": { "Type": "udr", "StorableId": "aggregation_common.session.session", "TypeName": "aggregation_common.session.session", "Version": 1, "Content": { "CRCValue": 0, "v_bnum": "1", "SessionID": null, "initialized": true, "SessionTimeout": 1426691920461, "v_response": "consume", "v_anum": "1", "v_total_duration": 5 } }, "SessionTimeout": 1426691920461, "initialized": true } The Aggregation agent can read stored session data in both formats, regardless of the selected value. In order to obtain the best possible performance in the Aggregation agent, you should use the binary format. Hint You can use an Aggregation agent with Force Read Only selected to read the stored sessions. You can then encode the binary content to JSON with the APL function jsonEncodeUdr . This is useful for debugging, or when you want to view the sessions in an external system. For more information about jsonEncodeUdr , see the APL Reference Guide . Replication and Persistence You can use the properties mz.cb.awaitPersistenceTo and mz.cb.awaitReplicationTo in the Advanced tab of the selected Couchbase profile to minimize the risk of data loss. However, setting a higher value than the default 0 will reduce the throughput performance. Automated Index Updates Note! This section only applies if you are using view instead of queries. In order to obtain the best possible performance in the Aggregation agent, you should disable automatic index updates in Couchbase. From a terminal window, update the index settings using the curl tool. curl -u <Couchbase administrator user>:<password>:<IP address or hostname>:8091/settings/viewUpdateDaemon -d updateMinChanges=0 You may specify the IP address or hostname of any available node in the Couchbase cluster. If the updates are successful, the changes will be applied to all nodes. For more information about automated index updates, you can refer to Couchbase's own documentation on views.

---

# Document 1716: Analysis Agent Input and Output Types - MediationZone Documentation 9.3 - InfoZone

**Source:** ratanon/mz93-documentation
**URL:** https://infozone.atlassian.net/wiki/spaces/MD93/pages/204640064/Analysis+Agent+Input+and+Output+Types
**Categories:** chunks_index.json

UDRs entering an Analysis agent are referred to as input types, while UDRs leaving the agent are referred to as output types. The input types must be specified, while the output types are calculated from the input types and the AP L code. Example - Input and Output types Suppose there is a workflow with one Analysis agent, one input route streaming two different input types (typeA and typeB), and two output routes. The two output routes take two different UDR types - the first equaling one of the input types (typeA), and the second is a new UDR type (typeC) which is created out of information fetched from the other input type (typeB). Open The APL code: if (instanceOf(input, typeA)) { udrRoute((typeA)input,"r_2"); } else { typeC newUDR = udrCreate(typeC); newUDR.field = ((typeB)input).field; // Additional field assignments... udrRoute(newUDR, ,"r_3"); } The first udrRoute statement explicitly typecasts to the typeA type, while there is no typecasting at all for the second udrRoute statement. This is because the input variable does not have a known type (it can be either typeA or typeB), while newUDR is known by the compiler to be of typeC. Without any typecasting, the output type on r_2 would have been reported as an undefined UDR, drudr, and the workflow would not have been valid.

---

# Document 1717: ECS Maintenance System Task - MediationZone Documentation 9.3 - InfoZone

**Source:** ratanon/mz93-documentation
**URL:** https://infozone.atlassian.net/wiki/spaces/MD93/pages/205032851/ECS+Maintenance+System+Task
**Categories:** chunks_index.json

The ECS Maintenance system task removes outdated ECS data, provided that the state is Reprocessed . The number of days to keep data is set in the ECS Maintenance configuration dialog (see ECS Maintenance System Task Configuration ). It is also possible to fully turn off the cleanup of UDRs, Batches, Statistics, or all of them. The Statistics can be reported by email. This is configured in the Report tab of the task. When the ECS Maintenance System Task is executed, a number of things happen: UDRs, batches, and ECS statistics are removed from the ECS according to the settings in the Cleanup tab. See Cleanup Tab in ECS Maintenance System Task Configuration . An ECS Statistics Event is generated containing information about the number of UDRs associated with every error code. This occurs at time intervals configured in the ECS Maintenance System Task Configuration . See ECS Statistics Event for further information about how to configure notifications for the ECS Statistics Event. Statistical information is sent to the ECS Statistics, according to what is configured in the Report Tab in ECS Maintenance System Task Configuration . An email containing statistical information is sent to the email recipient specified in the Report Tab in ECS Maintenance System Task Configuration . For further information on how to configure mail server and port, see Platform in the System Administrator's Guide. Note! The ECS is designed to store a fairly limited amount of erroneous UDRs and batches. It is therefore important that the data is extracted, reprocessed, or deleted from the ECS on a regular basis. Loading

---

# Document 1718: GCP Profile - MediationZone Documentation 9.3 - InfoZone

**Source:** ratanon/mz93-documentation
**URL:** https://infozone.atlassian.net/wiki/spaces/MD93/pages/204673280/GCP+Profile
**Categories:** chunks_index.json

The GCP Profile is used for setting up the access credentials and properties to be used to connect to a Google Cloud Platform service. Currently, the profile can be used with the following profile and agents: GCP PubSub Agents GCP PubSup Profile GCP BigQuery Agent Menus The contents of the menus in the menu bar may change depending on which configuration type has been opened in the currently displayed tab. The GCP Profile uses the standard menu items and buttons that are visible for all configurations, and these are described in Build View . The Edit menu is specific for the GCP Profile configurations. Setting Description Setting Description External References Select this menu item to enable the use of External References in the GCP Profile configuration. This can be used to configure the following fields: Use JSON File Credentials File Form Project Id Private Key Id Private Key Client Email Client Id Other Information For further information, see Using External Reference in Agent Profile Fields and External Reference Profile . Note! If there is a proxy in your network environment, the GCP agents will work with a proxy that does not require authentication. Currently, the GCP agents do not work with a proxy that requires authentication. Refer to HTTP Proxy Support for more details. Configuration JSON File The following settings are available when you have selected Use Json File as the Input Option in the GCP Profile. Open GCP Profile - Use Json File Configuration Setting Description Setting Description Environment-Provided Service Account When MediationZone is deployed in the GCP environment, such as in Compute Engine, enable this option to retrieve the Service Account credentials provided by the environment. Input Option Allows you to select the method for connecting to the GCP service. For the Use JSON File option, you need to create the GCP Service Account Key as a JSON file and download it into the Platform and EC servers. Credentials File The location of the GCP Service Account JSON file containing the credential keys. Note! The JSON file option is not recommended for production dgcp_profile_jsoneployments. It is meant to facilitate ease of testing of the GCP Profile by the workflow designer during development. Form The following settings are available when you have selected Form as the Input Option in the GCP Profile. Open GCP Profile - Form Configuration Setting Description Setting Description Environment-Provided Service Account When MediationZone is deployed in the GCP environment, such as in Compute Engine, enable this option to retrieve the Service Account credentials provided by the environment. Input Option Allows you to select the method for connecting to the GCP service. For Form , the GCP Profile will take the role of the Service Account Key file. It will parse all the credentials in order to connect to the GCP service. Project Id The GCP Project Id that hosts the GCP service that MediationZone should access. Private Key Id The Private Key Id to be used for the service account. Private Key The full content of the private key, or use Secret Profile. Client Email The email address given to the service account. Client Id The Id for the service account client. Other Information The Auth URI, Token URI and info about the certs are to be added into this field.

---

# Document 1719: IP Address Functions - MediationZone Documentation 9.3 - InfoZone

**Source:** ratanon/mz93-documentation
**URL:** https://infozone.atlassian.net/wiki/spaces/MD93/pages/205656697/IP+Address+Functions
**Categories:** chunks_index.json

All functions support both IPv4 and IPv6. The results from some functions may however depend on the underlying system configuration. The following functions for IP Address described here are: getHostname Returns the fully qualified domain name of the host on which the workflow is active. This is the best effort method, meaning we may not be able to return the FQDN depending on the underlying system configuration. string getHostname() Parameter Description Parameters: None. Returns The hostname as a string. getIPAddress Returns the IP address of the local host. string getIPAddress() Parameter Description Parameters: None Returns The raw IP address as a string ipAddressString Extracts the IP address part from a variable of type ipaddress. string ipAddressString(ipaddress ipa ) Parameter Description ipa An IP address Returns The IP address as a string, e g "10.0.3.22" ipFromAddress Converts the bytearray representation into an ipaddress type. Refer to Data types for further information about ipaddress type. ipaddress ipFromAddress ( bytearray address ) Parameter Description address The IP address as a bytearray. IPv4 address bytearray must be 4 bytes long and IPv6 bytearray must be 16 bytes long. Returns The IP address as an ipaddress type. ipFromHostname Given a string containing the IP address (numerical presentation), or hostname, a variable of type ipaddress is returned. Note! This function can be time consuming if DNS has to be accessed. ipaddress ipFromHostname ( string host ) Parameter Description host The name of the host Returns The IP address provided by the DNS server ipIsV6Address Evaluate if the IP address represents an IPv6 address. boolean ipIsV6Address()(ipaddress ipa ) Parameters: Parameter Description ipa The IP address to evaluate Returns true if the address is IPv6, false otherwise. ipLocalHost Returns the IP address of the local host. ipaddress ipLocalHost() Parameter Description Returns The IP address of the local host ipToAddress Returns the numerical representation of an IP address for example (10.0.3.22) as elements of a bytearray. bytearray ipToAddress ( ipaddress ipa ) Parameter Description ipa An IP address Returns A bytearray representation of the IP address; for example [ 10 0 3 22 ]. ipToHostname Extracts the fully qualified domain name part from a variable of type ipaddress. The host running the EC must have DNS setup. Note that this method may be time consuming. string ipToHostname( ipaddress ipa ) Parameter Description ipa An IP address. Returns The hostname corresponding to the given IP address.

---

# Document 1720: Pulse Agent Events - MediationZone Documentation 9.3 - InfoZone

**Source:** ratanon/mz93-documentation
**URL:** https://infozone.atlassian.net/wiki/spaces/MD93/pages/204608643/Pulse+Agent+Events
**Categories:** chunks_index.json

Agent Message Events There are no agent message events for this agent. Debug Events Debug messages are dispatched in debug mode. During execution, the messages are displayed in the Workflow Monitor. You can configure Event Notifications that are triggered when a debug message is dispatched. For further information about the debug event type, see Debug Event . Loading

---

# Document 1721: ECS Statistics Event - MediationZone Documentation 9.3 - InfoZone

**Source:** ratanon/mz93-documentation
**URL:** https://infozone.atlassian.net/wiki/spaces/MD93/pages/204605243/ECS+Statistics+Event
**Categories:** chunks_index.json

The ECS Statistics event is triggered when the ECS_Maintenance system task is executed, see Error Correction System for further information about this system task. Filtering In the Event Setup tab, the values for all the event fields are set by default to All in the Match Value(s) column, which will generate event notifications every time the ECS_Maintenance system task is executed. Double-click on the field to open the Match Values dialog where you can click on the Add button to add which values you want to filter on. If there are specific values available, these will appear in a drop-down list. Alternatively, you can enter a hard coded string or a regular expression. The following fields are available for filtering of ECS Statistics events in the Event Setup tab: ECS Statistics event specific fields errorCodeCountNewUDRs - This field enables you create a regular expression based filter for UDRs in state New in order to only generate notifications for UDRs passing the filter. This may be useful for specifying that notifications should only be generated for certain error codes and/or when a certain amount of UDRs have be registered, for example. Specifying error codes errorCodeCountReprocessedUDRs - This field enables you create a regular expression based filter for UDRs in state Reprocessed in order to only generate notifications for UDRs passing the filter. This may be useful for specifying that notifications should only be generated for certain error codes and/or when a certain amount of UDRs have be registered, for example. Fields inherited from the Base event The following fields are inherited from the Base event, and can also be used for filtering, described in more detail in Base Event : category - If you have configured any Event Categories, you can select to only generate notifications for ECS Statistics events with the selected categories. See Event Category for further information about Event Categories. contents - The contents field contains a hard coded string with event specific information. If you want to use this field for filtering you can enter a part of the contents as a hard coded string. However, for ECS Statistics events, everything in the content is available for filtering by using the other event fields, i e eventName, errorCodeCountForNewUDRs, etc. eventName - This field can be used to specify which event types you want to generate notifications for. This may be useful if the selected event type is a parent to other event types. However, since the ECS Statistics event is not a parent to any other event, this field will typically not be used for this event. origin - If you only want to generate notifications for events that are issued from certain Execution Contexts, you can specify the IP addresses of these Execution Contexts in this field. receiveTimeStamp - This field contains the date and time for when the event was inserted into the Platform database. If you want to use timeStamp for filtering, it may be a good idea to enter a regular expression, for example, "2012-06.*" for catching all ECS Statistics events from 1st of June, 2012, to 30th of June, 2012. severity - With this field you can determine to only generate notifications for events with a certain severity; Information, Warning, Error or Disaster. However, since ECS Statistics events only have severity Information, this field may not be very useful for filtering. timeStamp This field contains the date and time for when the Execution Context generated the event. If you want to use timeStamp for filtering, it may be a good idea to enter a regular expression, for example, "2012-06-15 09:.*" for catching all ECS Statistics events from 9:00 to 9:59 on the 15th of June, 2012. Note! The values of these fields may also be included in the notifications according to your configurations in the Notifier Setup tab.

---

# Document 1722: wfgroupenable - MediationZone Documentation 9.3 - InfoZone

**Source:** ratanon/mz93-documentation
**URL:** https://infozone.atlassian.net/wiki/spaces/MD93/pages/205657167
**Categories:** chunks_index.json

This command enables one or more workflow groups. usage: wfgroupenable <pattern match expression for workflow group names> ... [ -mode < a >] With this command you compare a single pattern match expression, or several, with the full workflow group name of all the workflow groups. Example- wfgroupenable <folder>.<workflowgroupconfigurationname>.<workflowgroupname> The command accepts standard wild cards, such as '*' and '?'. For further information see Textual Pattern Matches . It also accepts the following options: Option Description Option Description [ -mode < a > ] Enable only workflow groups marked with a specified mode: a - Only Autostart groups are enabled. Return Codes Listed below are the different return codes for the wfgroupenable command: Code Description Code Description 0 Will be returned if the command is successful. 1 Will be returned if the argument count is incorrect. 2 Will be returned if the user is not found or not logged in. 3 Will be returned if no matching workflow group is found. 4 Will be returned if the user does not have permission to access the workflow group.

---

# Document 1723: Data Masking Agent - MediationZone Documentation 9.3 - InfoZone

**Source:** ratanon/mz93-documentation
**URL:** https://infozone.atlassian.net/wiki/spaces/MD93/pages/204640439
**Categories:** chunks_index.json

This section describes the Data Masking profile and the Data Masking agent. The agent is a processing agent for batch and real-time workflow configurations. The Data Masking agent can be used to either mask or unmask specified fields in different UDRs in order to protect the data. It can be used when data is going to be processed in the cloud without involving personal data, for example. The agent enables compliance with regulations around data protection, ensuring personal data is accessed in a controlled manner. Open The agent uses a profile in which you can define the masking method; Crypto, Database, or Hash, as well as which fields to mask/unmask along with additional settings specific for each masking method. When selecting Database, Oracle, Postgres, and SAP HANA can be used. In the agent itself, you can select which of the UDR types configured in the used profile(s) that you want the agent to process, as well as how you want the agent to handle unmatching data. Supported features: Encryption/decryption with AES-128 and AES-256 Reading a key from a specific JCEKS keystore Generation and storage of replacement data in a Database Converting input data to random data based on SHA-256 hash Use of multiple profiles in the agent Error handling Logging Unsupported Data Type for Search Searching, filtering, repairing and masking of UDRs with list and map data types are currently not supported by Data Veracity. The section contains the following subsections: Data Masking Profile Masking Methods Data Masking Agent Configuration Data Masking UDRs Data Masking Agent Input/Output Data and MIM Data Masking Agent Events

---

# Document 1724: ECS Restricted Fields Configuration - MediationZone Documentation 9.3 - InfoZone

**Source:** ratanon/mz93-documentation
**URL:** https://infozone.atlassian.net/wiki/spaces/MD93/pages/204607365/ECS+Restricted+Fields+Configuration
**Categories:** chunks_index.json



---
**End of Part 72** - Continue to next part for more content.
