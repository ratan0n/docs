# RATANON/MZ93-DOCUMENTATION - Part 63/112

---
**Dataset:** ratanon/mz93-documentation
**Part:** 63 of 112
**GitHub:** https://github.com/ratan0n/docs/tree/main/mz93-documentation
**Size:** ~69.9 KB
---

To open the FTPS collection agent configuration, click Build  New Configuration . Select Workflow from the Configurations dialog. When prompted to Select workflow type , select Batch . Click Add agent and select Ftps from the Agent Selection dialog. Double-click the agent icon or right-click the icon and select Edit agent , to display the Agent Configuration dialog. Part of the configuration may be done in the Filename Sequence or Sort Order tabs described in Workflow Template . Connection Tab The Connection tab contains configuration data that is relevant to a remote server. Open The FTPS collection agent configuration - Connection tab Setting Description Setting Description Server Information Provider The standard behavior is Single Server. If your system is installed with the Multi Server File functionality, you can configure the FTPS agent to collect from more than one server. For further information, contact your System Administrator. Host Primary host name or IP address of the remote host to be connected. If a connection cannot be established to this host, the Additional Hosts specified in the Advanced tab, are tried. Username Username for an account on the remote host, enabling the FTPS session to login. Password Password related to the Username. Transfer Type Data transfer type to be used during file retrieval. Binary - The agent uses binary transfer type. Default setting. ASCII - The agent uses ASCII transfer type. Encryption Type You can select an encryption type: Implicit - Full encryption of FTP connection from the start of the session. Explicit - Explicitly define any required security/encryption mechanisms. File System Type Type of file system on the remote host. Unix - Remote host using Unix file system. Default setting. Windows NT - Remote host using Windows NT file system. VAX/VMS - Remote host using VAX/VMS file system. Client Authentication If you select this checkbox, you must enter the keystore file location (JKS format) and password to connect to the FTPS Server. The connection fails if the file is invalid or not found, or if the key in the file is not the same as the file stored in the FTPS server. Keystore Location Enter the keystore file location in JKS format. You must populate this field if you have selected the Client Authentication checkbox. Keystore Password Enter the keystore password. You must populate this field if you have selected the Client Authentication checkbox. Reuse SSL/TTL Session Select this checkbox to reuse the SSL/TTL session. Collection Retries Settings Enable Select this checkbox to enable repetitive attempts to connect and start a file transfer. When this option is selected, the agent attempts to connect to the host as many times as is stated in the Max Retries field. If the connection fails, a new attempt is made after the number of seconds entered in the Retry Interval(s) field. Retry Interval(s) Enter the time interval in seconds, between retries. If a connection problem occurs, the time interval before the first attempt to reconnect is the time set in the Timeout field in the Advanced tab plus the time set in the Retry Interval(s) field. For the remaining attempts, the time interval is the number seconds entered in this field. Max Retries Enter the maximum number of retries to connect. If more than one connection attempt is made, this number is reset as soon as a file transfer is completed successfully. Note! This number does not include the original connection attempt. Restart Retries Settings Enable Select this checkbox to enable the agent to send a RESTART command if the connection has been broken during a file transfer. The RESTART command contains information about where in the file you want to resume the file transfer. Before selecting this option, ensure that the FTPS server supports the RESTART command. When this option is selected, the agent attempts to re-establish the connection, and resumes the file transfer from the point in the file stated in the RESTART command, as many times as is entered in the Max Restarts field. When a connection has been re-established, a RESTART command is sent after the number of seconds entered in the Retry Restarts Interval(s) field. Note! The Restart Retries settings will not work if you have selected to decompress the files in the Source tab, see he section Source Tab below. Note! RESTART is not always supported for transfer type ASCII. For further information about the RESTART command, see http://www.w3.org/Protocols/rfc959/ . Retry Restarts Interval(s) Enter the time interval, in seconds, you want to wait before initiating a restart in this field. This time interval are applied for all restart retries. If a connection problem occurs, the time interval before the first attempt to send a RESTART command is the time set in the Timeout field in the Advanced tab plus the time set in the Retry Restarts Interval(s) field. For the remaining attempts, the time interval is the number seconds entered in this field. Max Restarts Enter the maximum number of restarts per file you want to allow. In case more than one attempt to send the RESTART command is made, the number of used retries is reset as soon as a file transfer is completed successfully. Source Tab The Source tab contains configurations related to the remote host, source directories, and source files. The following text describes the configuration options available when no custom strategy has been chosen. Open The FTPS collection agent configuration - Source tab Setting Description Setting Description Collection Strategy If there is more than one collection strategy available in the system, a Collection Strategy drop-down list is also visible. For more information, see Appendix 4 - Collection Strategies . Directory Absolute path of the source directory on the remote host, where the source files reside. If the FTPS server is of UNIX type, the path name can also be given relative to the home directory of the User Name account. Include Subfolders Select this checkbox to include the subfolders of the path specified in the Directory setting. Filename Name of the source files on the remote host. Use regular expressions according to Java syntax. See also http://docs.oracle.com/javase/8/docs/api/java/util/regex/Pattern.html . Example To match all filenames beginning with TTFILE , type: TTFILE.* Note! When collecting files from VAX file systems, the names of the source files include both path and filename, which has to be considered when entering the regular expression. Compression Compression type of the source files: No Compression - The agent does not decompress the files before passing them on in the workflow. Gzip - The agent decompresses the files using gzip before passing them on. Move to Temporary Directory Select this checkbox to move the source files to the automatically created subdirectory DR_TMP_DIR in the source directory, before collection. This option supports safe collection when source files repeatedly use the same name. Append Suffix to Filename Enter a suffix that you want to add to the filename prior to collecting it. Important! Before you execute your workflow, make sure that none of the filenames in the collection directory include this suffix. Inactive Source Warning (h) Enter number of hours after which to display a warning message (event) in the System Log and Event Area if no file has been available for collection for the configured number of hours: The source has been idle for more than <n> hours, the last inserted file is <file>. Move to If enabled, the source files will be moved from the source directory (or from the directory DR_TMP_DIR if using Move to Temporary Directory ), to the directory specified in the Destination field, after collection. Note! The Directory has to be located in the same file system as the collected files at the remote host. Also, absolute pathnames must be defined (relative pathnames cannot be used). If a file with the same filename, but with a different content, already exists in the target directory, the workflow will abort. If a file with the same filename, AND the same content, already exists in the target directory, this file will be overwritten and the workflow will not abort. Destination Enter the full path of the remote host directory into which the source files should be moved after the collection. This field is only available if Move to is enabled. Rename Select this checkbox to rename the source file after the collection, and let them remain (or be moved back from the directory DR_TMP_DIR if using Move to Temporary Directory ) in the source directory from which they were collected. Note! When the File System Type for VAX/VMS is selected, the following must be considered. If a file is renamed after collection on a VAX/VMS system, the filename might become too long. In that case the following rules apply: A VAX/VMS filename consists of <filename>.<extension>;<version>, where the maximum number of characters for each variable is: <filename>: 39 characters <extension>: 39 characters <version>: 5 characters If the new filename turns out to be longer than 39 characters, the agent moves part of the filename to the extension. If the total sum of the filename and extension exceeds 78 characters, the last characters are truncated. Example: A_VERY_LONG_FILENAME_WITH_MORE_THAN_39_ CHARACTERS.DAT;5 Is converted to: A_VERY_LONG_FILENAME_WITH_MORE_THAN_39_. CHARACTERSDAT;5 Note! If a new file is created on the FTPS server, with the same filename as the original file but with different content, the workflow aborts. If a new file with the same filename AND content is created, the file is overwritten. Enter the prefix and/or suffix to append to the beginnings and/or ends of the source filenames, respectively, after the collection. These fields are only available if Move to or Rename is enabled. Warning! If Rename is enabled, the source files are renamed in the current (source or DR_TMP_DIR ) directory. Be sure not to assign a Prefix or Suffix that gives the files new names that match the Filename regular expression, as this will cause the files to be collected over and over again. Search and Replace Select either Move to or Rename to enable Search and Replace . Search : Enter the section of the filename to replace. Replace : Enter the replacement text. Search and Replace operate on entries in a way similar to the Unix sed utility. The identified filenames are modified and forwarded to the following agent in the workflow. This functionality enables you to perform advanced filename modifications: Use a regular expression in the Search field to specify the section of the filename that you want to extract. Enter characters and meta characters that define the pattern and content of the replacement text into the Replace field. Search and Replace Examples To rename the file file1.new to file1.old , use: Search : .new Replace : .old To rename the file JAN2011_file to file_DONE , use: Search : ([A-Z]*[0-9]*)_([a-z]*) Replace : $2_DONE Note that the search value divides the filename into two parts by using parentheses. The replace value applies to the second part by using the placeholder $2 . Remove Select this checkbox to remove the source files from the source directory (or from the directory DR_TMP_DIR , if using Move to Temporary Directory ), after the collection. Keep (days) This field is only available if Move to or Rename is enabled. Enter the number of days to keep moved or renamed source files on the remote host after the collection. To delete the source files, the workflow has to be executed (scheduled or manually) again, after the configured number of days. Note! A date tag is added to the filename, which determines when the file can be removed. Ignore Select this checkbox to let the source files remain in the source directory after the collection. This field is not available if Move to Temporary Directory is enabled. Route FileReferenceUDR Select this checkbox to forward the data to an SQL Loader agent. See SQL Loader Agent for further information. Advanced Tab The Advanced tab contains configurations related to the use of the FTPS service. For example, in case the used FTPS server does not return the file listed in a well-defined format the Disable File Detail Parsing option can be useful. For information refer to that section. The FTPS collection agent configuration - Advanced tab Setting Description Setting Description Command Port Enter the port number that the FTPS service should use to connect to the remote host. Timeout (s) Enter the maximum time, in seconds, to wait for a response from the server. Zero (0) means to wait forever. Passive Mode (PASV) This checkbox must be selected if FTPS passive mode is used for data connection. In passive mode, the channel for data transfer between client and server is initiated by the client instead of by the server. This is useful when a firewall is situated between the client and the server. Disable File Detail Parsing Select this checkbox to disable file detail parsing for information received from the FTPS server. This enhances the compatibility with unusual FTPS servers but disables some functionality. If file detail parsing is disabled, file modification timestamps are not available to the collector. The collector cannot distinguish between directories and simple files. For this reason, sub-directories in the input directory must not match the Filename regular expression. The agent assumes that a file named DR_TMP_DIR is a directory because a directory named DR_TMP_DIR is used when Move to Temporary Directory in the Source tab is selected. Therefore, you cannot name a regular file DR_TMP_DIR in the collection directory. Note! When collecting files from a VAX file system, this checkbox must be selected. Additional Hosts Select Add to enter additional hosts or IP addresses from where to collect the source files. If the agent fails to connect to the remote Host specified in the Connection tab, it tries to connect to the hosts listed here, in sequence from top to bottom. Use the Add , Edit , Remove , U p , and Down buttons to configure the host list.

---

# Document 1479: Azure OAuth Token UDR - MediationZone Documentation 9.3 - InfoZone

**Source:** ratanon/mz93-documentation
**URL:** https://infozone.atlassian.net/wiki/spaces/MD93/pages/204743638/Azure+OAuth+Token+UDR
**Categories:** chunks_index.json

The Azure OAuth Token APL Plugin produces one type of UDR; AzureOAuthToken . AzureOAuthToken This UDR is used for describing a specific attachment. Field Description Field Description Expires (date) At which time the generated token becomes invalid. Token (string) The generated token in string format. OriginalData (bytearray) The original data in bytearray format.

---

# Document 1480: Provisioning of PCC Buckets - MediationZone Documentation 9.3 - InfoZone

**Source:** ratanon/mz93-documentation
**URL:** https://infozone.atlassian.net/wiki/spaces/MD93/pages/205656292/Provisioning+of+PCC+Buckets
**Categories:** chunks_index.json

There are three different interfaces for handling the provisioning of buckets, subscribers, and products. One is implemented as APL functions, the other as a REST web service, and the third is the regular user interface. Provisioning always targets a specific, internally predefined, area. Changes in one area are not reflected in the other. There are two different areas (TEST and PROD) the provisioning can target. A typical use case would be to provision data to the TEST area and, when considered ready, copy the content of TEST to PROD where a workflow can access them. Using two different areas - one for provisioning and one for runtime - makes it possible to test the configurations before moving them into production. This chapter includes the following sections: APL - PCC Provisioning Plugins - Buckets REST HTTP Interface - Buckets REST HTTP Interface - Products Provisioning Products for Buckets in Desktop

---

# Document 1481: Syslog Collection Agent - MediationZone Documentation 9.3 - InfoZone

**Source:** ratanon/mz93-documentation
**URL:** https://infozone.atlassian.net/wiki/spaces/MD93/pages/204643359/Syslog+Collection+Agent
**Categories:** chunks_index.json

This section describes the Syslog Collection agent. This agent is available in real-time workflow configurations. Overview The Syslog Collection agent allows data to be collected and inserted into a real-time workflow, using the standard Syslog protocol via UDP. The agent does not decode the incoming messages but distributes this task to subsequent APL agents. An incoming Syslog message is decoded when an APL agent accesses the fields in a consumed SyslogMessageUDR . Decoding errors are logged in the System Log. The agent supports IPv4 and IPv6 environments and is compliant with the specifications RFC5424 and RFC3164. Prerequisites The reader of this document should be familiar with: Syslog Protocol https://tools.ietf.org/html/rfc5424 https://www.ietf.org/rfc/rfc3164.txt (obsoleted by RFC5424) The section contains the following subsections: Syslog Collection Agent Configuration Syslog Collection UDR Types Syslog Collection Agent Input/Output Data and MIM Syslog Collection Agent Events Syslog Collection Agent Example

---

# Document 1482: Websocket Client Agent Configuration - MediationZone Documentation 9.3 - InfoZone

**Source:** ratanon/mz93-documentation
**URL:** https://infozone.atlassian.net/wiki/spaces/MD93/pages/204675457/Websocket+Client+Agent+Configuration
**Categories:** chunks_index.json

The Websocket Client agent configuration dialog is displayed when right-clicking on the Websocket Client agent and selecting the Configuration option, or when double-clicking on the agent in the Workflow Editor. These configurations only need to be made if you want to use TLS, or change the name of the agent, otherwise the agent will work as it is. Open The Websocket Client agent configuration dialog Setting Description Setting Description Servers Define the WS or WSS server. The agent will automatically connect to these servers and receive data from them. Connect Timeout (s) The timeout used when opening new connections. Ping Timeout (s) Timeout for the connections configured in Servers. When no data is received on the websocket, a ping will regularly be sent to detect if connection has been lost. Enable TLS Select this checkbox if you want to use TLS. The field beneath will then be activated.

---

# Document 1483: Control File Collection Strategy - MediationZone Documentation 9.3 - InfoZone

**Source:** ratanon/mz93-documentation
**URL:** https://infozone.atlassian.net/wiki/spaces/MD93/pages/204675773/Control+File+Collection+Strategy
**Categories:** chunks_index.json

This section includes a description of the complementary Control File collection strategy that is applied for the Disk, FTP, SFTP, and SCP Collection agents. The Control File collection strategy enables collection of file(s) for which a corresponding control file exists. If the control file does not exist, the file is ignored. Configuration The Control File Collection Strategy controls which further configuration options that are available in the Source tab. If no strategy is selected, the default strategy is used. Open Collection Strategy - Control File Note! The Collection Strategy drop down list will only be visible if there are other collection strategies available in the system, apart from the default collection strategy available. Setting Description Setting Description Collection Strategy Select the Control File option in this list. Directory Enter the absolute path name of the source directory on the remote host, where the source files reside. The path name may also be entered relative to the home directory of the User Name account. Include Subfolders Select this checkbox to also include subfolders within the specified directory. Filename Enter the name of the source files on the remote host. Regular expressions according to Java syntax can be used. For further information, see http://docs.oracle.com/javase/8/docs/api/java/util/regex/Pattern.html . Example To match all file names beginning with TTFILE , enter: TTFILE.* Compression Select compression type for the source files. This selection determines if the agent will decompress the files before passing them on in the workflow. No Compression : The agent will not decompress the file(s). Gzip : The agent will decompress the file(s) using gzip. Position The control filename consists of an extension added either before or after the shared filename part. Select one of the choices: Prefix or Suffix. Prefix means that the text entered inte the Control File Extension field will be searched for before the shared filename part, and Suffix means that the text entered in the Control File Extension field, will be searched for after the shared filename part. Control File Extension The Control File Extension is used to define when the data file should be collected. A data file with filename FILE will only be collected if the corresponding control file exists. A possible control filename can be FILE.ok . The text entered in this field is the expected extension of the shared filename. The Control File Extension will be attached to the beginning or the end of the shared filename, depending on the selection made in the Position list, above. Data File Extension The Data File Extension will only be applicable if Position is set to Suffix. There can be cases where a more strict definition of which files should be collected is needed. This is defined in the Data File Extension field. Consider a data file called FILE.dat . If .dat is entered in the Data File Extension field the corresponding Control file will be called FILE.ok if .ok is entered in the Control File Extension field. Note! Consider a directory containing 5 files: FILE1.dat FILE2.dat FILE1.ok ok.FILE1 FILE1 The Position field is set to Prefix and the Control File Extension field is set to .ok . The control file is ok.FILE1 and FILE1 will be the file collected. The Position field is set to Suffix and the Control File Extension field is set to .ok . The control file is FILE1.ok and FILE1 will be be the file collected. The Position field is set to Suffix and the Control File Extension field is set to .ok and the Data File Extension field is set to .dat . The control file is FILE1.ok and FILE1.dat will be the file collected. After collection, the control file is handled in the same way as the collected file is configured to be handled, that is the system should delete/rename/move/ignore it. Move to Temporary Directory If this option is selected, the source files will be moved to the automatically created subdirectory DR_TMP_DIR in the source directory, before collection. This option supports safe collection when source files repeatedly use the same name. Inactive Source Warning (h) If this option is selected, a warning message (event) will appear in the System Log and Event Area when the configured number of hours have passed without any file being available for collection: The source has been idle for more than <n> hours, the last inserted file is <file>. Move to If this option is selected, the source files will be moved from the source directory (or from the directory DR_TMP_DIR if using Move to Temporary Directory), to the directory specified in the Destination field, after collection. Note! The Destination must be located in the same file system as the collected files at the remote host. Additionally, absolute path names must be defined (relative path names cannot be used). Rename If this option is selected, the source files will be renamed after the collection, and remain (or moved back from the directory DR_TMP_DIR if using Move to Temporary Directory ) in the source directory from which they were collected. Remove If this option is selected, the source files will be removed from the source directory (or from the directory DR_TMP_DIR , if using Move to Temporary Directory ), after the collection. Ignore If this option is selected, the source files will remain in the source directory after the collection. This field is not available if Move to Temporary Directory is enabled. Destination If the Move to option has been selected, enter the full path name of the directory on the remote host into which the source files will be moved after the collection in this field. If any of the other After Collection options have been selected, this option will not be available. Prefix and Suffix If any of the Move to or Rename options have been selected, enter the prefix and/or suffix that will be appended to the beginning and/or end of the name of the source files, respectively, after the collection, in these fields. If any of the other After Collection options have been selected, this option will not be available. Note! If Rename is enabled, the source files will be renamed in the current (source or DR_TMP_DIR ) directory. Ensure that you do not assign a Prefix or Suffix , giving files new names that still match the Filename regular expression. That will cause the files to be collected over and over again. Keep (days) If any of the Move to or Rename options have been selected, enter the number of days to keep moved or renamed source files on the remote host after the collection in this field. In order to delete the source files, the workflow has to be executed (scheduled or manually) again, after the configured number of days. If any of the other After Collection options have been selected, this option will not be available. Note! A date tag is added to the filename, determining when the file may be removed. Route FileReferenceUDR Select this checkbox to route File Reference UDR instead of raw data.

---

# Document 1484: FTAM EWSD Agent Events - MediationZone Documentation 9.3 - InfoZone

**Source:** ratanon/mz93-documentation
**URL:** https://infozone.atlassian.net/wiki/spaces/MD93/pages/205652623/FTAM+EWSD+Agent+Events
**Categories:** chunks_index.json

Agent Message Events An information message from the agent, stated according to the configuration done in the Event Notification Editor . For further information about the agent message event type, see Agent Event . Ready with file: filename Reported along with the name of the source file, when the file given in Filename has been collected and inserted into the workflow. File cancelled: filename Reported along with the name of the source file, each time a Cancel Batch message is received. This assumes the workflow is not aborted. For further information, see FTAM EWSD Agent Transaction Behavior . Debug Events There are no debug events for this agent.

---

# Document 1485: APL Code Editor - MediationZone Documentation 9.3 - InfoZone

**Source:** ratanon/mz93-documentation
**URL:** https://infozone.atlassian.net/wiki/spaces/MD93/pages/204999066
**Categories:** chunks_index.json

The A PL Code E ditor, as opposed to the Aggregation and Analysis agents' code areas, is used to create generic APL code, that is, code that can be imported and used by several agents and workflows. To open the APL Code Editor, click the New Configuration button in the upper left part of the Desktop window, and then select APL Code from the menu. Open The menu items that are specific to APL Code Editor are described in the following table: Button Description Button Description Edit Edits the entered APL code. New Creates a new APL code entry. Open Opens the list of saved APL code entries. Save As Opens the Save As dialog box where you can save the APL code entry. You must enter the mandatory parameters to save the entry. Specify the Folder by using the Browse button and navigating to the destination, then confirm the selection by pressing the OK button. Specify the APL code name in the Name field and you can type an optional Version Comment. Open Save As Dialog Box Permissions View/edit the APL code permissions. Open Permissions Dialog Box References View the External References available for the APL code entry. History View the version history for the APL code entry. Help Open the online documentation. The generic code is imported by adding the following code in the agent code area, using the import keyword: import apl.<foldername>.<APL Code configurationname> If generic code is modified in the APL Code Editor, the change is automatically reflected in all agents that contain this code the next time each workflow is executed. Since function overloading is not supported, make sure not to import functions with equal names, since this causes the APL code to become invalid, even if the functions are located in different APL modules. This also applies if the functions have different input parameters, for example, a(int x) and a(string x) . Note! Not all functions work in a generic environment, for example, functions related to specific workflows or MIM-related functions. This type of functionality must be included in the agent code area instead. Example - An APL code definition An APL code definition, saved as MyGenericCode in the Default directory, is available to an agent by adding the following into its code area: import apl.Default.MyGenericCode;

---

# Document 1486: picoversion - MediationZone Documentation 9.3 - InfoZone

**Source:** ratanon/mz93-documentation
**URL:** https://infozone.atlassian.net/wiki/spaces/MD93/pages/205657018/picoversion
**Categories:** chunks_index.json

usage: picoversion Displays the version information from the picostart.jar file. MZ >> picoversion 8.0.0.0 [compatibility: 7.0.4.0] Return Codes Listed below are the different return codes for the picoversion command: Code Description Code Description 0 Will be returned if the command was successful, which it always is.

---

# Document 1487: JMS Agents - MediationZone Documentation 9.3 - InfoZone

**Source:** ratanon/mz93-documentation
**URL:** https://infozone.atlassian.net/wiki/spaces/MD93/pages/205033686/JMS+Agents
**Categories:** chunks_index.json

This section describes the JMS agents. The agents are collection and processing agents for real-time workflow configurations. The JMS agents enable MediationZone to communicate with other JMS application components. Following the JMS 1.1 specification, the agents look up the configured ConnectionFactory and Destination objects using JNDI. Therefore, it is required that a JNDI server is configured and can be accessed by the agents. The following JMS vendors are currently supported: Weblogic SonicMQ ActiveMQ JBossMQ HornetQ Solace Note! Solace has a known limitation when the JMS processing agent and Solace VMR server are temporarily disrupted. When the agent successfully reconnects, it freezes when forwarding the next JMS message via a Solace JMS API. The issue is observed when using Solace JMS APIs lib version 10.1.1. Prerequisites The user of this information should be familiar with: JNDI JMS This section contains the following subsections: JMS Profile JMS Collector Agent JMS Request Agent JMS Agents Preparations JMS UDRs

---

# Document 1488: SCP Forwarding Agent Configuration - MediationZone Documentation 9.3 - InfoZone

**Source:** ratanon/mz93-documentation
**URL:** https://infozone.atlassian.net/wiki/spaces/MD93/pages/205653956/SCP+Forwarding+Agent+Configuration
**Categories:** chunks_index.json

You open the SCP forwarding agent configuration dialog from a workflow configuration. To open the SCP forwarding agent configuration, click Build  New Configuration . Select Workflow from the Configurations dialog. When prompted to Select workflow type , select Batch . Click Add agent and select SCP from the Forwarding tab of the Agent Selection dialog. Part of the configuration may be done in the Filename Template service tab described in Workflow Template . Connection Tab Open The SCP forwarding agent configuration - Connection tab For information about the Connection tab, see the figure, The SCP Collection Agent Configuration - Connection Tab in SCP Collection Agent Configuration . Target Tab Open The SCP forwarding agent configuration - Target Tab The Target tab contains configuration settings related to the remote host, target directories, and target files. Setting Description Setting Description Input File Handling Input Type The agent can act on two input types. Depending on which one the agent is configured to work with, the behavior differs. The default input type is bytearray, that is the agent expects bytearrays. If nothing else is stated the documentation refers to input of bytearray. If the input type is MultiForwardingUDR , the behavior is different. For further information about the agent's behavior in MultiForwardingUDR input, see SCP Forwarding Agent MultiForwardingUDR Input . File Information Directory Enter the absolute pathname of the target directory on the remote host, where the forwarded files will be placed. The pathname may also be given relative to the home directory of the user's account. The files will be temporarily stored in the automatically created subdirectory DR_TMP_DIR in the target directory. When an End Batch message is received, the files are moved from the subdirectory to the target directory. Create Directory When enabled, this will create the directory, or the directory structure, of the path that you specify in Directory. Note! The directories are created when the workflow is executed. Compression Select the compression type of the destination files. Determines whether the agent will compress the output files as it writes them. No Compression - the agent will not compress the files. Gzip - the agent will compress the files using gzip. Note! No extra extension will be appended to the target filenames, even if compression is selected. Target File Handling Produce Empty Files If enabled, the agent will create empty output files for empty batches rather than omitting those batches. Handling of Already Existing Files Select the behavior of the agent when the file already exists, the alternatives are: Overwrite - The old file will be overwritten and a warning will be logged in the System Log. Add Suffix - If the file already exists the suffix ".1" will be added. If this file also exists the suffix ".2" will be tried instead and so on. Abort - This is the default selection and is the option used for upgraded configurations, that is workflows from an upgraded system. Temporary File Handling Use Temporary Directory If this option is selected, the agent will move the file to a temporary directory before moving it to the target directory. After the whole file has been transferred to the target directory, and the endBatch message has been received, and the temporary file is removed from the temporary directory. Use Temporary File If there is no write access to the target directory and, hence, a temporary directory cannot be created, the agent can move the file to a temporary file that is stored directly in the target directory. After the whole file has been transferred, and the endBatch message has been received, the temporary file will be renamed. The temporary filename is unique for every execution of the workflow. It consists of a workflow and agent ID, and a file number. Abort Handling Select how to handle the file in case of cancelBatch or rollback, either Delete Temporary File or Leave Temporary File. Note! When a workflow aborts, the file will not be removed until the next time the workflow is run. Advanced Tab Open The SCP forwarding agent configuration - Advanced tab The Advanced tabs contain configurations related to a more specific use of the SCP service, which might not be frequently utilized. Setting Description Setting Description Advanced Settings Port Enter the port number the SCP service will use on the remote host. Timeout (s) Enter the maximum time, in seconds, to wait for a response from the server. 0 (zero) means to wait forever. Accept New Host Keys If selected, the agent overwrites the existing host key when the host is represented with a new key. The default behavior is to abort when the key mismatches. Caution! Selecting this option causes a security risk since the agent will accept new keys regardless if they possibly belong to another machine. Enable Key Re-Exchange Used to enable and disable automatic re-exchange of session keys during ongoing connections. This can be useful if you have long lived sessions since you may experience connection problems for some servers if one of the sides initiates a key re-exchange during the session. Buffered Mode Select this check box if you want to enable buffered mode on the SCP client. Additional Hosts Additional Hosts List of additional host names or IP addresses that may be used to establish a connection. These hosts are tried, in sequence from top to bottom, if the agents fail to connect to the remote host set in the Connection tab. Use the Add , Edit , Remove , Up, and Down buttons to configure the host list. After Treatment Execute Select between the two options: Before Move : Execute the following command and its arguments prior to transfer. After Move : Execute the following command and its arguments on the local copy of the transferred UDR, after transfer. Command Enter a command or a script Arguments This field is optional. Each entered parameter value has to be separated from the preceding value with a space. The temporary filename is inserted as the second last parameter, and the final filename is inserted as the last parameter, automatically. This means that if, for instance, no parameter is given in the field, the arguments will be as follows: $1=<temporary_filename> $2=<final_filename> If three parameters are given in the Arguments field, the arguments are set as: $1=<parameter_value_#1> $2=<parameter_value_#2> $3=<parameter_value_#3> $4=<temporary_filename> $5=<final_filename> Backlog Tab The Backlog tab contains configurations related to backlog functionality. If the backlog is not enabled, the files will be moved directly to their final destination when an end batch message is received. If the backlog however is enabled, the files will first be moved to a directory called DR_POSTPONED_MOVE_DIR and then to their final destination. For further information about transaction behavior, see the section, Retrieves in SCP Forwarding Agent Transaction Behavior . When the backl og is initialized and when backlogged files have transferred a note is registered in the System Log. Open The SCP forwarding agent configuration - Backlog tab Setting Description Setting Description Enable Backlog When selected, this will enable the backlog functionality. When not selected the agent's behavior is similar to the standard SFTP forwarding agent. Directory Base directory in which the agent will create sub-directories to handle backlogged files. Absolute or relative path names can be used. Type Files is the maximum number of files allowed in the backlog folder. Bytes is the total sum (size) of the files that reside in the backlog folder. If a limit is exceeded the workflow will abort. Size Enter the maximum number of files or bytes that the backlog folder can contain. Processing Order Determine the order by which the backlogged data will be processed once the connection is reestablished, and select between First In First Out (FIFO) or Last In First Out (LIFO). Duplicate File Handling Specifies the behavior if a file with the same file name as the one being transferred is detected. The options are Abort or Overwrite and the action is taken both when a file is transferred to the target directory or to the backlog. Security Tab Open The SCP forwarding agent configuration - Security tab For information about the Security tab, see the description under SCP Collection Agent Configuration Note! Due to an upgrade of the Maverick library for MediationZone version 8.1.5.0, the default handling of the advanced security has changed. Users should take note of the behaviour change for the Advanced Security Option for the SCP agents. The Advanced Security Option will be disabled by default. Users will have to enable it on their own accord from the Security Tab in the SCP agents configuration. With Advanced Security Option disabled, Maverick will manage the connection between the SCP agent and the server. Maverick will attempt to connect with the STRONG security level. Failing to do so, it will auto downgrade the security level to WEAK and attempt to connect, this behaviour will allow our agents to work well with backwards compatibility for servers with older instances of the Maverick library. Furthermore, having STRONG security level will result in a performance degradation. However, when a user manually enables the Advanced Security Option from the security tab, Maverick will instead assign the WEAK security level, which will not be as strict or resource intensive as the STRONG security level. For more information about security levels, you can refer to this page: https://www.jadaptive.com/managed-security-in-our-java-ssh-apis/

---

# Document 1489: HTTP/2 Server Agent - MediationZone Documentation 9.3 - InfoZone

**Source:** ratanon/mz93-documentation
**URL:** https://infozone.atlassian.net/wiki/spaces/MD93/pages/204608014/HTTP+2+Server+Agent
**Categories:** chunks_index.json

The HTTP/2 Server agent enables you to configure an HTTP server in a real-time workflow. The agent receives requests, converts them into UDRs routed into the workflow, and then sends responses back over a TCP/IP connection. The agent can be used for both HTTP/1 and HTTP/2. Prerequisites The reader of this information should be familiar with: Hypertext Transfer Protocol version 2 (RFC 7540: https://tools.ietf.org/html/rfc7540 ) Hypertext Transfer Protocol version 1.1 (RFC 2616: http://www.ietf.org/rfc/rfc2616.txt ) The Transport Layer Security (TLS) Protocol version 1.2 (RFC 5246: https://www.ietf.org/rfc/rfc5246.txt ) This section contains the following subsections: HTTP/2 Server Agent Configuration HTTP/2 Server Agent Input/Output Data and MIM

---

# Document 1490: High Availability Properties - MediationZone Documentation 9.3 - InfoZone

**Source:** ratanon/mz93-documentation
**URL:** https://infozone.atlassian.net/wiki/spaces/MD93/pages/205657573
**Categories:** chunks_index.json

This section describes the different high availability properties that you can use in the STR. For further information about high availability, see High Availability Setup . All Pico Types These properties are applicable to all pico types. Property Description mz.ha.enabled Default value: false This property enables the HA Monitoring Server on a pico instance. mz.ha.log_file Default value: "" This property determines the directory where the HA Monitor Server will store log files. The log file contains the property assignments, that is, counter limits as well as debug and statistics information. The default setting is an empty value, meaning that the HA logging is disabled. mz.ha.host Default value: 127.0.0.1 This property determines the address of the interface that the HA Monitor Server will bind to. The HA Client typically runs on the same host as the HA Monitor server that it connects to. mz.ha.port Default value: "" This property determines the port that the server will bind to. This parameter must be set if an HA monitor server is used. Execution Contexts These properties are applicable to ECs. If multiple properties are specified, the ping returns FAILED if any of the properties do not comply with their respective threshold. Property Description mz.ha.interval Default value: 40 This property defines the time interval, in seconds, for the counters specified below, i.e. mz.ha.min_number_of_transactions, mz.ha.max_aborts. mz.ha.min_activations, mz.ha.min_activations_for_aborts, and mz.ha.min_consumes. The time interval must be at least 40 seconds. If a lower number is stated, the used value will be 40 seconds. mz.ha.min_activations Default value: -1 This property defines the minimum number of workflow activations required before the number of aborts are counted. The default value "-1" means that the counter is disabled. mz.ha.min_activations_for_aborts Default value: -1 This property must be used in combination with the mz.ha.max_aborts property to get a notion of the maximum number of aborts allowed within the mz.ha.interval. The default value "-1" means that the counter is disabled. mz.ha.min_consumes Default value: -1 This property defines the minimum number of consumed UDRs required within the mz.ha.interval. This property is mainly used for realtime workflows. The default value "-1" means that the counter is disabled. mz.ha.min_number_of_transactions Default value: -1 Defines the minimum number of closed transactions required within the mz.ha.interval. Used for batch workflows on an EC, since realtime workflows do not generate transactions. The default value "-1" means that the counter is disabled. mz.ha.max_aborts Default value: -1 This property defines the maximum number of aborts allowed within the mz.ha.interval. The default value "-1" means that the counter is disabled.

---

# Document 1491: ADLS2 File Collection Agent - MediationZone Documentation 9.3 - InfoZone

**Source:** ratanon/mz93-documentation
**URL:** https://infozone.atlassian.net/wiki/spaces/MD93/pages/204671862/ADLS2+File+Collection+Agent
**Categories:** chunks_index.json

The ADLS2 file collection agent collects files from an Azure Data Lake Storage Gen2 using the access credentials defined in an Azure profile and inserts them into a workflow. Initially, the source location is scanned for all files matching the current filter. In addition, the Filename Sequence and Sort Order settings may be used to further manage the matching of files, although they may not be used at the same time since it will cause the workflow to abort. All files found will be fed one after the other into the workflow. When a file has been successfully processed by the workflow, the agent offers the possibility of moving, renaming, removing or ignoring the original file. The agent can also be configured to keep files for a set number of days. In addition, the agent offers the possibility of decompressing compressed (gzip) files after they have been collected. When all the files are successfully processed, the agent stops to await the next activation, whether it is scheduled or manually ini tiate d. ADLS2 File Collection Agent Configuration ADLS2 File Collection Agent Input/Output Data and MIM ADLS2 File Collection Agent Events ADLS2 File Collection Agent Transaction Behavior

---

# Document 1492: Desktop Launcher - MediationZone Documentation 9.3 - InfoZone

**Source:** ratanon/mz93-documentation
**URL:** https://infozone.atlassian.net/wiki/spaces/MD93/pages/205655011/Desktop+Launcher
**Categories:** chunks_index.json

This section describes how you start and manage the Desktop Launcher, and includes the following subsections: Installing the Desktop Launcher Adding Instances and Login Updating Instance Settings Removing Instances and Runtime Data Adding a Launcher Service Updating Launcher Services Settings Removing and Refreshing Launcher Services

---

# Document 1493: Example of SQL Processing Agent in Real-Time Workflow - MediationZone Documentation 9.3 - InfoZone

**Source:** ratanon/mz93-documentation
**URL:** https://infozone.atlassian.net/wiki/spaces/MD93/pages/205002219/Example+of+SQL+Processing+Agent+in+Real-Time+Workflow
**Categories:** chunks_index.json

This example shows a workflow configured to collect Diameter requests from Diameter Stack, and route them to an Analysis Agent. In the Analysis Agent, it maps Diameter requests to the configured UDR in the SQL processing agent, and then routes to the SQL forwarding agent to insert the data into a database. Upon commit, the SQL processing agent routes a commitUDR to the second Analysis agent. It then forms a Diameter Response UDR that is routed back to the Diameter Client. Open Example of a real-time workflow with an SQL processing agent This is an example of how the SQL processing agent may be configured for this workflow. Open Example configuration of an SQL processing agent

---

# Document 1494: SNMP OID Profile - MediationZone Documentation 9.3 - InfoZone

**Source:** ratanon/mz93-documentation
**URL:** https://infozone.atlassian.net/wiki/spaces/MD93/pages/204674811
**Categories:** chunks_index.json

Open With the SNMP OID profile, you can configure which OIDs, that is UDR types and fields to poll, outside of the SNMP Request agent itself. This way, several agents can use the same configuration. Configuration To create a new SNMP OID profile configuration, click the New Configuration button in the upper left part in Desktop, and then select SNMP OID Profile from the menu. The SNMP OID profile configuration contains the following settings: Setting Description Setting Description SNMP Collection Profile Select which SNMP Collection profile the OID profile should use. Poll/Field/Instances Add the UDR types and fields you want to have available for polling in this section, and select the Poll check box for the ones you want to poll. Continuous requests for the specified OIDs will be sent out. Do not enable this if you want to send out dynamic requests from APL to the OID by using the generated structure.

---

# Document 1495: Amazon S3 Forwarding Agent Configuration - MediationZone Documentation 9.3 - InfoZone

**Source:** ratanon/mz93-documentation
**URL:** https://infozone.atlassian.net/wiki/spaces/MD93/pages/204639956/Amazon+S3+Forwarding+Agent+Configuration
**Categories:** chunks_index.json

To open the Amazon S3 collection agent configuration dialog from a workflow configuration, you can do the following: right-click the agent icon and select Configuration... select the agent icon and click the Edit button Note! If you are using the Amazon S3 collection agent in a Batch workflow, part of the configuration may be done in the Filename Template tab in Workflow Template . For Real-Time workflow, additional configurations in File Closing Criteria tab are available in Batch-Based Real-Time Agents - Agent Configuration . Open Amazon S3 forwarding agent configuration dialog - Amazon S3 tab Setting Description Setting Description Profile Select the File System profile you want the agent to use, see File System Profile for further information about this profile. Input Type The agent can act on two input types. Depending on which one the agent is configured to work with, the behavior will differ. The default input type is bytearray, that is the agent expects bytearrays. If nothing else is stated the documentation refer to input of bytearray. If the input type is MultForwardingUDR , the behavior is different. For further information about the agent's behavior in MultiForwardingUDR input, see Amazon S3 Forwarding MultiForwardingUDR Input . File Information Directory Enter the absolute pathname of the target directory on the location stated in the referenced File System profile, where the forwarded files will be stored. The files will be temporarily stored in the automatically created subdirectory DR_TMP_DIR , in the target directory. When an End Batch message is received, the files are moved from the subdirectory to the target directory. Create Directory Select this setting to create the directory, or the directory structure, of the path that you specify in the Directory field. Note! The directories are created when the workflow is executed. Compression Select the compression type of the target files: No Compression - agent does not compress the files. This is the default setting. Gzip - agent compresses the files using gzip. This determines if the agent will compress the files or not. Note! No extra extension will be appended to the target filenames, even if compression is selected. The configuration of the filenames is managed in the Filename Template tab only. After Treatment Command If a UNIX command is supplied, it will be executed on each successfully closed temporary file, using the parameter values declared in the Arguments field. Note! At this point the temporary file is created and closed, however the final filename has not yet been created. The entered command has to exist in the execution environment, either including an absolute path, or to be found in the PATH for the execution environment. Arguments This field is optional. Each entered parameter value has to be separated from the preceding value with a space. The temporary filename is inserted as the second last parameter, and the final filename is inserted as the last parameter, automatically. This means that if, for instance, no parameter is given in the field, the arguments will be as follows: $1=<temporary_filename> $2=<final_filename> If three parameters are given in the field Arguments, the arguments are set as: $1=<parameter_value_#1> $2=<parameter_value_#2> $3=<parameter_value_#3> $4=<temporary_filename> $5=<final_filename> Produce Empty Files If enabled, files will be produced although containing no data.

---

# Document 1496: A Sequential Format Example - MediationZone Documentation 9.3 - InfoZone

**Source:** ratanon/mz93-documentation
**URL:** https://infozone.atlassian.net/wiki/spaces/MD93/pages/204678348/A+Sequential+Format+Example
**Categories:** chunks_index.json

The example illustrated in this appendix is a format definition for decoding a shortened version of EWSD AMA (Automatic Message Accounting). All incoming records are of the same record type, however their content varies. The first four fields are present in all records, the fifth field varies depending on the content of the field RecordOwnerTypePresent . The last three fields are optional. Open A schematic representation of the example discussed in this section external Since the last three optional fields (including RecordOwnerType and RecordOwnerDN ) consist of several fields, each one is defined as its own type. That is, an external sequential format. Note! The FillerRecord_0x00_EXT construct. This is the padding which may be present between records. Hence, it is defined as a record type identified by the decoder, however not routed on to the subsequent agent (see the in_map definitions). If the format is only used for decoding (which is the normal case for switch output formats), the encoding instructions ( encode_value ) in the following code is skipped. external AMARecord_EXT: identified_by(RecordIdentifier == 0x84), dynamic_size(RecordLength) { int(little_endian) RecordIdentifier :static_size(1), external_only, encode_value(0x84); int(little_endian) RecordLength :static_size(2), external_only, encode_value(udr_size); This byte contains several flags, from which only one is of interest. Therefore, if RecordOwnerTypePresent is set, then the RecordOwnerType is present, or else the RecordOwnerDN data is. See the presence specifications in the following code. bit_block :static_size(1) { int(little_endian) RecordOwnerTypePresent: msb(7),lsb(7), external_only, encode_value( (field_present(RecordOwnerType)?1:0)); }; Since three bytes of unwanted data is present, it is specified as external_only to stop the field from getting automatically generated in the target internal. No encoding is specified (0 padding is used). byte ignoredFields: static_size(3), external_only; Either RecordOwnerType or RecordOwnerDN is present. To encode them, it is important to note that exactly one of these fields must be present in the output data. int(little_endian) RecordOwnerType: static_size(1), present if(RecordOwnerTypePresent == 1); RecordOwnerDN_EXT RecordOwnerDN: present if(RecordOwnerTypePresent == 0); The rest of the record consists of optional packages with additional information. The full AMA format contains lots of other packages (and additional information in the header), however in this example, only three packages are included. Any unrecognized package leads to failure of the decoding, since the size of the set is specified (all the remaining data must be handled by the set decoding). set: dynamic_size(remaining_size) { Package_100_EXT DateTimeDuration : optional; Package_101_EXT PartnerDirectoryNumber : optional; Package_102_EXT ServiceInfo : optional; }; }; external RecordOwnerDN_EXT { bit_block : static_size(1) { int LACLength : msb(7), lsb(4); int OwnerIDLength : msb(3), lsb(0), external_only, encode_value( strLength( LACAndDN )); }; The following is a typical construction for BCD data with a nibble length specification. Both nibble size ( native_size ) and field size ( dynamic_size ) must be specified. bcd LACAndDN : dynamic_size((OwnerIDLength+1)>>1), // Alternative syntax: // dynamic_size((OwnerIDLength+1)/2) native_size(OwnerIDLength); }; //Package with PackageNumber 100 (0x64): external Package_100_EXT: identified_by(PackageNumber == 0x64) { int(little_endian) PackageNumber : static_size(1), external_only, encode_value( 0x64 ); int(little_endian) Year : static_size(1); int(little_endian) Month : static_size(1); int(little_endian) Day : static_size(1); int(little_endian) Hour : static_size(1); int(little_endian) Minutes : static_size(1); int(little_endian) Seconds : static_size(1); int(little_endian) Flags : static_size(1); int(little_endian) Duration : static_size(3); }; // Package with PackageNumber 101 (0x65). external Package_101_EXT: identified_by(PackageNumber == 0x65) { int(little_endian) PackageNumber: static_size(1), external_only, encode_value( 0x65 ); int(little_endian) NumberOfDigits: static_size(1), external_only, encode_value( strLength( Digits )); // Again the typical BCD decoding specification bcd Digits: dynamic_size((NumberOfDigits+1)/2), native_size(NumberOfDigits); }; // Package with PackageNumber 102 (0x66). external Package_102_EXT: identified_by(PackageNumber == 0x66) { int(little_endian) PackageNumber : static_size(1), external_only, encode_value( 0x66 ); int(little_endian) ServiceIndicator : static_size(1); int(little_endian) AdditionalInformation : static_size(1); int(little_endian) Flags : static_size(1); }; Note! The identified_by expression, which must be specified for any format used in a set construct. / Filler needed to be able to recognize on the input stream: external FillerRecord_0x00_EXT: identified_by(RecordIdentifier == 0x00), static_size(32) { int(little_endian) RecordIdentifier : static_size(1), external_only, encode_value(0x00); // Note that no other fields are specified. // The UDR size (32) will be consumed and discarded (see in_map). }; Alternative Syntax An alternative to use the set construct, in the external definition for AMARecord_ext , switched_set could be used. This impacts the syntax for the Package_*_EXT types. Only the syntax differing from the original example is shown. The main reason for using switched_set instead of set is when performance must be increased. external AMARecord_EXT: // ... // All preceding fields according to the original specification. // Only the set construct is replaced with switched_set. // ... switched_set(PackageNumber): dynamic_size(remaining_size) { case( 0x64 ) { Package_100_EXT DateTimeDuration; }; case( 0x65 ) { int(little_endian) NumberOfDigits_101: static_size(1), external_only, encode_value( strLength( Digits_101 )); // Again the typical BCD decoding specification. bcd Digits_101: dynamic_size((NumberOfDigits_101+1)/2), native_size(NumberOfDigits_101); }; case( 0x66 ) { int(little_endian) ServiceIndicator_102 : static_size(1); int(little_endian) AdditionalInformation_102 : static_size(1); int(little_endian) Flags_102 : static_size(1); }; }; }; external RecordOwnerDN_EXT { bit_block : static_size(1) { int LACLength : msb(7), lsb(4); int OwnerIDLength : msb(3), lsb(0), external_only, encode_value( strLength( LACAndDN )); }; The following is a typical construction for BCD data with a nibble length specification. Both nibble size ( native_size ) and field size ( dynamic_size ) must be specified. bcd LACAndDN : dynamic_size((OwnerIDLength+1)>>1), native_size(OwnerIDLength); }; // Package with PackageNumber 100 (0x64). external Package_100_EXT { int(little_endian) Year : static_size(1); int(little_endian) Month : static_size(1); int(little_endian) Day : static_size(1); int(little_endian) Hour : static_size(1); int(little_endian) Minutes : static_size(1); int(little_endian) Seconds : static_size(1); int(little_endian) Flags : static_size(1); int(little_endian) Duration : static_size(3); }; Note! No identified_by or PackageNumber is present, since this is handled in the containing switched_set . internal No internal is used. In this case, the target_internal is sufficient; all field names and field types are in order and there is only one type of record present in the input, and no additional fields are required. in_map The padding in the records is recognized by the decoder, however it is not actually mapped in to the system due to the use of the discard_output flag. The AMARecord_Map contains sub-automatic specifications (the target_internal specifications within the automatic block), which give five additional internal formats (other than the AMARecord ). This is useful when you want to route them as individual records. in_map FillerRecord_0x00_Map : external(FillerRecord_0x00_EXT), target_internal(FillerRecord_0x00), discard_output { automatic; }; in_map AMARecord_Map : external(AMARecord_EXT), target_internal( AMARecord ) { automatic { RecordOwnerType_EXT : target_internal( RecordOwnerType ); RecordOwnerDN_EXT : target_internal( RecordOwnerDN ); Package_100_EXT : target_internal( Package_100 ); Package_101_EXT : target_internal( Package_101 ); Package_102_EXT : target_internal( Package_102 ); }; }; decoder The padding pseudo-records and data records can arrive in any order, therefore there is no need to define a constructed decoder. decoder AMAFile : in_map( AMARecord_Map ), in_map( FillerRecord_0x00_Map );

---

# Document 1497: Shut Down Workflows and Desktops - MediationZone Documentation 9.3 - InfoZone

**Source:** ratanon/mz93-documentation
**URL:** https://infozone.atlassian.net/wiki/spaces/MD93/pages/204996941
**Categories:** chunks_index.json

To shut down workflow groups, workflows and Desktops: Open Execution Manager , and check the status of all Workflow Groups groups (Enabled / Disabled). This step is necessary to identify which groups need to be resumed after the upgrade is completed. If there is a mix of enabled and disabled groups, make sure to record all  Enabled  groups, as you will need this information during the Resume Workflow Execution process. Otherwise if all groups are enabled, you can proceed to the next step. Note! Make sure to check the status of System Task-related groups to determine if they also need to be resumed after the upgrade. The Workflow Groups can be disabled using either the Execution Manager in Desktop or via the command line. The example below shows how to disable all Workflow Groups via command line wfgroupdisable . $ mzsh mzadmin/<password> wfgroupdisable * Stop all workflows that are not disconnected and let them finish execution. Ensure that all users shut down all connected Desktops. If you want to see which Desktops that are connected, you can use the following command: $ mzsh mzadmin/<password> pico -view Note! This command will also display other pico instances, such as Execution Contexts.

---

# Document 1498: Connecting Workflows - MediationZone Documentation 9.3 - InfoZone

**Source:** ratanon/mz93-documentation
**URL:** https://infozone.atlassian.net/wiki/spaces/MD93/pages/205816681/Connecting+Workflows
**Categories:** chunks_index.json

Kafka The Apache Kafka framework uses a high-throughput, distributed, publish-subscribe messaging model. The framework is scalable and it can be elastically and transparently expanded without downtime. Data streams are partitioned and spread over a cluster of machines to allow data streams larger than the capability of a single machine and to allow clusters of coordinated consumers. The real-time Kafka agents enable MediationZone to act as a Kafka cluster. Kafka producer agents publish messages (containing UDRs) and these are subscribed to by any number of Kafka collector agents in the workflows that are to be connected. These agents can also be used to connect to external Kafka interfaces. Open Connecting real-time workflows with Kafka All messages are persisted and the publishers are decoupled from the subscribers. This means that the forwarding agent will keep writing to the queue (i e the Kafka log) even if the receiving processing agents terminate. The amount of data that can be queued, also called queue depth, is only limited by storage. If there is enough storage, the queue depth is unlimited. It is highly recommended to use the Kafka agents to connect workflows when: There is a need to connect real-time workflows that are running on the same, or in different MediationZone installations. Minimization of data loss is prioritized. One-way communication is sufficient (one-to-one or one-to-many). Workflow Bridge A Workflow Bridge agent acts as a bridge for communication between real-time workflows, or between batch and real-time workflows, within the same MediationZone system. There are several benefits of using Workflow Bridge: Using real-time-processing capabilities while keeping transaction safety when using the bridge between batch and real-time workflows Scaling the processing of high volume streaming data by distributing the processing load between execution contexts when bridging between an upstream data collection workflow and one or more downstream real-time workflow(s). When sending data to multiple workflows, the UDRs can be sent in a load-balancing scenario, where specific data can be distributed to a specific workflow. Data can also be broadcast to all downstream workflows. Open Batch to real-time Workflow Bridge Communication The Workflow Bridge agents communicate with each other using a dedicated set of UDRs. Communication is done in-memory when workflows are executing within the same Execution Context. TCP or Aeron are used when the workflows are running on different Execution Contexts. This provides for efficient transfer of data. To maintain transactional integrity across multiple workflows, the workflow state changes will be communicated over the workflow bridge. This enables downstream workflows to take action when upstream workflow state changes, and upstream workflows can maintain transaction integrity if downstream workflows fail to execute. For every transaction, a session context with arbitrary data can be kept in the real-time collection agent. This can be used as a session object during the transaction. In order to optimize performance, it is possible to collect and send data in a bulk from the forwarding agent. When the Workflow Bridge real-time collection agent has received the data bulk, it is unpacked and forwarded as separate UDRs by the agent. The bulk is created by the Workflow Bridge forwarding agent after a configured number of UDRs has been reached, or after a configured time interval. This is specified in the Workflow Bridge profile.

---

# Document 1499: TCP/IP Collection Agent Configuration - MediationZone Documentation 9.3 - InfoZone

**Source:** ratanon/mz93-documentation
**URL:** https://infozone.atlassian.net/wiki/spaces/MD93/pages/205654316/TCP+IP+Collection+Agent+Configuration
**Categories:** chunks_index.json

To open the TCP/IP collection agent configuration, click Build  New Configuration . Select Workflow from the Configurations dialog. When prompted to Select workflow type , select Realtime . Click Add agent and select Tcp Ip from the Agent Selection dialog. Double-click the agent icon or right-click the icon and select Edit agent , to display the Agent Configuration dialog. TCP/IP Tab Open TCP/IP collection agent configuration dialog - TCP/IP tab Setting Description Setting Description Host The IP address or hostname to which the TCP collector connects. If the host is connected the port must also be connected. If left empty, the TCP collector connects to all IP-addresses available in the system. Note! This setting can be dynamically updated. Port The port number from which the data is received. Make sure the port is not used by other applications. Note! The port can also be dynamically updated while the agent is running. Double-click the agent in the Workflow Editor in monitor mode and modify it. Save the workflow to trigger the agent to use the new port. For further information about updating agent configurations while a workflow is running, see Dynamic Update in Administration and Management in Legacy Desktop . Allow Multiple Connections Select this checkbox to allow several TCP/IP connections simultaneously. If cleared, only one connection is allowed. Number of Connections Allowed If Allow Multiple Connections is selected, enter a number between 2 and 65000 to specify the number of allowed connections. Send Response Select this checkbox to have the collector send a response back to the source. If Allow Multiple Connections is selected, the collector expects a UDR extended with the default TCPIPUDR as a reply. If the checkbox is cleared, it expects a bytearray. Note! Drag and drop in the opposite direction in the workflow to create a response route between the agents. The TCP/IP agent must be connected to an agent utilizing APL, since responses are created using APL commands. Open For a description of the differences between single or multiple connections, see A TCP/IP Example . Send TCPIPStateUDR Select this checkbox to track the connection state of the client and have the collection agent send a UDR indicating the status of the client connection each time it changes state. See TCPIPStateUDR in TCP/IP Related UDR Types . Note! This information is not detected if a client is powered down or if its network cable is removed. Decoder Tab The Decoder tab contains settings related to decoding of the collected data. Open TCP/IP collection agent configuration dialog - Decoder tab Extra System Properties This section describes the extra system properties that you can use to configure the TCP/IP Collection Agent. Setting Description Setting Description mz.tcpip.logginginterval_ms This property allows you to limit the number of exceptions from the TCP Collection Agent to one exception per specified interval (in milliseconds). Only change the property if support has expressly recommended it. It is normally not recommend to set this property.

---

# Document 1500: Command Line Tool Reference Guide - MediationZone Documentation 9.3 - InfoZone

**Source:** ratanon/mz93-documentation
**URL:** https://infozone.atlassian.net/wiki/spaces/MD93/pages/204646337
**Categories:** chunks_index.json

Search this document: This section describes the command line tools available in MediationZone 9.3. Both provide command-line access for system administration and workflow managementbut they are not the same tool. mzsh mzsh is a shell that serves as both a system administration tool and a platform client tool. Its functionality depends on whether the platform is running and whether you are logged in, allowing access to different parts of the system accordingly. mzcli mzcli is a command-line interface (CLI) that allows you to execute system commands independently on multiple hosts, providing flexible remote management capabilities. This section contains the following subsections: mzsh mzcli

---

# Document 1501: GCP PubSub Publisher Agent - MediationZone Documentation 9.3 - InfoZone

**Source:** ratanon/mz93-documentation


---
**End of Part 63** - Continue to next part for more content.
