# RATANON/MZ93-DOCUMENTATION - Part 3/112

---
**Dataset:** ratanon/mz93-documentation
**Part:** 3 of 112
**GitHub:** https://github.com/ratan0n/docs/tree/main/mz93-documentation
**Size:** ~67.7 KB
---

This example illustrates typical use of the Parquet Encoder agent in a batch workflow. The following configurations will be created: An Ultra Format A Parquet Profile A Batch Workflow that makes use of the Parquet Encoder agent to create Parquet documents Define an Ultra Format A simple Ultra Format needs to be created for the incoming UDRs. For more information about the Ultra Format Editor and the UFDL syntax, refer to the Ultra Format Management User's Guide . Example - Ultra Create an Ultra Format as defined below: external BOOK_HEADER : identified_by(strREContains(HEADER, "title,name,organization,copyrightYear")), terminated_by(0xA) { ascii HEADER : terminated_by(0xA); }; external BookRecord { ascii title : terminated_by(","); ascii authorName : terminated_by(","); ascii organization : terminated_by(","); ascii copyrightYearString : terminated_by(","); ascii numberOfPages : terminated_by(0xA); }; internal BookRecord { string title; string authorName; string organization; string copyrightYearString; int numberOfPages; // enriched date copyrightYear; }; // decoder in_map BOOK_HEADER_InMap : external(BOOK_HEADER), target_internal(BOOK_HEADER), discard_output { automatic; }; in_map BookRecord_InMap : external(BookRecord), internal(BookRecord) { automatic; }; decoder BOOK_HEADER_Decode : in_map(BOOK_HEADER_InMap); decoder BookRecord_Decode : in_map(BookRecord_InMap); decoder DECODER { decoder BOOK_HEADER_Decode; decoder BookRecord_Decode *; }; // encoder out_map BookRecord_OutMap : external(BookRecord), internal(BookRecord) { automatic; }; encoder ENCODER : out_map(BookRecord_OutMap); Define a Parquet Profile The Parquet Profile is used to define the Schema as well as define advanced properties for encoding. See .2.1 Parquet Profile Configuration for information on how to open the Parquet Profile editor. Profile - Schema Tab Profile Configuration Example - Schema Tab The Schema Tab contains a single dialog box to specify the Parquet Schema. Example - Parquet Schema The structured text block shows an example Parquet schema for a book asset. Copy and paste this text to your schema. message book { required binary title (UTF8); required group author { optional binary name (UTF8); optional binary organization (UTF8); } optional int32 copyrightYear (DATE); optional int64 numberOfPages; } Profile - Advanced Tab Open Profile Configuration Example - Advanced Tab The Advanced Tab includes a number of dialogs with default values retained. Create a Batch Workflow In this workflow, CSV records in a disk are retrieved that are then encoded into a Parquet document. The workflow is illustrated here: Open Example workflow with Parquet Encoder Walking through the example workflow from left to right, we have: A Disk Agente that reads in the source file as a byte array. A Decoder Agent that parses the bytes from the file and decodes the CSV records, passing BookRecord UDRs to the Analysis agent. An Analysis agent that transforms these incoming BookRecord UDRs into ParquetEncoderUDRs in accordance with the schema specified in the Parquet Profile. The Parquet Encoder agent that receives the ParquetEncoderUDRs, encodes the data with Parquet, and forwards the data as a byte-array. The Disk Collection forwarding agent receives the byte-array data and writes out a Parquet document. This section walks through the steps of creating such a batch workflow. Disk Disk_Source is a Disk C ollection agent that collects data from an input file and forwards it to the Decoder agent. Double-click on the Disk_Source agent to display the configuration dialog for the agent: Open Example of a Disk agent configuration Decoder The Decoder agent receives the input data from the Disk agent, translates it into UDRs and forwards them to the Analysis agent. Double-click on the Decoder agent to display the configuration dialog. Example of an Decoder agent configuration In this dialog, choose the Decoder that you defined in your Ultra Format. Analysis The Analysis Agent transforms the data from each BookDecoder UDR into a ParquetEncoderUDR. In particular, the ParquetEncoderUDR includes a map with contents that mirror the Parquet schema defined in the profile. Double-click on the Analysis agent to display the configuration dialog. Open The Analysis agent dialogue with the APL code defined. In this dialog, the APL code for handling input data is written. In the example, each BookRecord UDR is transformed into a ParquetEncoderUDR. Adapt the code according to your requirements. You can also see the UDR type used in the UDR Types field, in this example it is a BookRecord . Example - Parquet APL The APL code below shows an example of constructing a ParquetEncoderUDR : import ultra.Sandbox_Parquet_Autotest.Autotest_Ultra; import ultra.Parquet; consume { switch (input) { case (AutotestRecord record) { // normalize strToDate(record.optionalTimestampMillisField, record.optionalTimestampMillisFieldString, "yyyyMMddHHmmss", "Europe/Stockholm"); // // payload // map<string,any> payload = mapCreate(string,any); mapSet(payload, "requiredInt32Field", record.requiredInt32Field); mapSet(payload, "requiredInt64Field", record.requiredInt64Field); mapSet(payload, "requiredDoubleField", record.requiredDoubleField); mapSet(payload, "requiredStringField", record.requiredStringField); mapSet(payload, "optionalStringField", record.optionalStringField); mapSet(payload, "missingOptionalStringField", record.missingOptionalStringField); mapSet(payload, "optionalTimestampMillisField", record.optionalTimestampMillisField); // // encode // ParquetEncoderUDR encoderUDR = udrCreate(ParquetEncoderUDR); encoderUDR.payload = payload; // // route // udrRoute(encoderUDR); } } } Note in the code that the data in the payload map in the ParquetEncoderUDR mirrors the schema configured in the profile. Non-matching structures will result in errors at runtime. Parquet Encoder The Parquet Encoder agent creates a Parquet document based on the ParquetEncoderUDRs it receives from upstream agents. Double-click on the Parquet Encoder agent to display the configuration dialog. Open The Parquet Encoder agent with the Parquet Profile defined. In this dialog, choose the Parquet Profile that you defined earlier. Disk Forwarder Disk_Destination is a Disk Forwarding agent that writes bytes to an output file on disk. Double-click on the Disk_Destination agent to display the configuration dialog for the agent: Open Example of a Disk agent configuration Running the Workflow When you run the Workflow, it processes the CSV file from the input directory and writes out a corresponding Parquet file in the configured output directory.

---

# Document 47: Aggregation Session Inspector - MediationZone Documentation 9.3 - InfoZone

**Source:** ratanon/mz93-documentation
**URL:** https://infozone.atlassian.net/wiki/spaces/MD93/pages/204998928/Aggregation+Session+Inspector
**Categories:** chunks_index.json

The Aggregation Session Inspector enables viewing and editing of existing sessions. The data is displayed in a table where each row represents a session, with the session data ordered in columns. It is also possible to edit the contents of the sessions, that is, to change the timeout and the values of the session variables. Aggregation Session Inspector only inspects sessions stored on disk and SQL. Note! Aggregation Session Inspector is only available in the Desktop interface. Open The Aggregation Session Inspector Note! To use the Aggregation Session Inspector, the EC specified as the Storage Host in the Storage tab of the Aggregation profile configuration must be up and running. Searching for sessions Initially, the table is empty and must be populated with data using the Search Sessions dialog. When you select the Search button, the Search Sessions dialog opens where you can select which group of sessions you want to view. The Search Sessions dialog Setting Description Setting Description Profile Select the Aggregation profile that corresponds to the data of interest. Timeout Period If you select this check box you can select a timeout period from which you want to display data. You can either select the User Defined option in the Period Type drop-down list and then enter date and time in the From and To fields, or you can select one of the predefined time intervals in the drop-down list; Last Hour , Today , Yesterday , This Week , Previous Week , Last 7 Days , This Month or Previous Month . UDR View Allows a more detailed view of the UDRs in the session list. For further information about UDR Views, see the Ultra Reference Guide . Table Toolbar The table toolbar for the Aggregation Session Inspector presents the users with more options to manipulate the session data within the table. The following are the buttons found on the bar: With no sessions selected With no sessions selected Open Option Description Search Displays the Search Sessions a dialog where search criteria may be defined to identify the group of sessions to be displayed, see Searching for sessions for more information. Refresh Refreshes the table. Validate Storage When you select the Validate Storage button, after performing a search, all the aggregation storage session files are validated. This is done by attempting to read the session data to establish what can and cannot be read. If the storage contains references to corrupt sessions, an option to remove them is given. Delete All Deletes all sessions. With one session selected Open Option Description Edit Timeout You can modify the session timeout value here. Changing the value to any time before the current time will have the session timeout during the next execution cycle on its corresponding workflow. Info! This field is only available when you are searching for sessions stored on disk. Sessions stored on SQL will not have this field enabled. Info! The session will acquire a lock from editing when you have opened this field to modify the timeout, preventing other users from modifying the information while you are editing it. The lock is released when you quit the dialog. Open Explore Session Displays a new dialog where the session variables may be viewed and if Read Only was disabled in the Search Session dialog, the session variables may be edited as well. Note! This field will be read-only for SQL Storage sessions. You will be able to explore the session, but you will not be able to edit it. Info! The session will acquire a lock from editing when you have opened this field to modify the session, preventing other users from modifying but not reading the information while you are editing it. The lock is released when you quit the dialog. An example of a UDR Viewer dialog: Open With one or more sessions selected Open Option Description Clear Selection(s) Unselects any highlighted sessions. Delete Permanently removes any selected sessions.

---

# Document 48: Kafka Real-Time Collection Agent - MediationZone Documentation 9.3 - InfoZone

**Source:** ratanon/mz93-documentation
**URL:** https://infozone.atlassian.net/wiki/spaces/MD93/pages/301138346/Kafka+Real-Time+Collection+Agent
**Categories:** chunks_index.json

The Kafka real-time collection agent consumes messages from Kafka. Several workflows can collect messages from the same set of topics in parallel but from different partitions. Starting and stopping workflows will automatically rebalance which partitions the workflows collect from, see Automatic Scale Out and Rebalancing . Workflow Example A simple workflow with a Kafka real-time collection agent can look like this: Open Workflow with Kafka real-time collection agent This workflow example has been created as follows: Workflow Design Create the workflow with the following agents: Agent Configuration Kafka Collects messages from Kafka. Analysis Receives KafkaRecord UDRs and creates output UDRs based on the contents of the input UDR. The offset is used to create a unique id. Encoder Encodes the data to the format the files will be forwarded in. Disk Creates files with the defined format and stores them in the stated directory. Kafka Collector Configure the Kafka real-time collector agent to minimize potential data loss by setting Offset management to At Least Once . Open Kafka Collection Agent. Analysis Agent Configure the Analysis agent to create an output UDR and then map the content of the Kafka message. A unique id is created by using the offset from the input UDR. consume { Default.UFL_test.test_TI myUDR = udrCreate(Default.UFL_test.test_TI); myUDR.offSet = (string)input.offset; myUDR.value = baToStr(input.value); udrRoute(myUDR); }

---

# Document 49: HTTP Client Helper Functions - MediationZone Documentation 9.3 - InfoZone

**Source:** ratanon/mz93-documentation
**URL:** https://infozone.atlassian.net/wiki/spaces/MD93/pages/204677939/HTTP+Client+Helper+Functions
**Categories:** chunks_index.json

The HTTP client helper functions are used for error handling. The following functions for HTTP Client Helper described here are: 1 httpGetLastErrorCode 2 httpGetLastErrorMessage 3 httpGetLastErrorResponse 4 httpGetLastResponseHeader httpGetLastErrorCode This function gets the last error code set. int httpGetLastErrorCode() Parameter Description Parameter Description Returns The HTTP status code. It will be -1 if no error occurred. Note that calling the httpGetLastErrorCode() function should only be done when the previous POST/GET request returned null. httpGetLastErrorMessage This function gets the last error message. string httpGetLastErrorMessage() Parameter Description Parameter Description Returns The HTTP status message. It will be null if no error occurred. Note that calling the httpGetLastErrorMessage() function should only be done when the previous POST/GET request returned null. httpGetLastErrorResponse This function gets the last response if the connection failed but the server sent useful data nonetheless. string httpGetLastErrorResponse() Parameter Description Parameter Description Returns A document from the HTTP server. It will be an empty string if no error occurred. Note that calling the httpGetLastErrorResponse() function should only be done when the previous POST/GET request returned null. httpGetLastResponseHeader This function retrieves the header from the last HTTP response. map<string,string> httpGetLastResponseHeader() Parameter Description Parameter Description Returns A map containing the response header

---

# Document 50: Terminology - MediationZone Documentation 9.3 - InfoZone

**Source:** ratanon/mz93-documentation
**URL:** https://infozone.atlassian.net/wiki/spaces/MD93/pages/205816269/Terminology
**Categories:** chunks_index.json

Search this document: Below are the terms and acronyms used throughout the MediationZone documentation. Terms Term Definition Agent An application that executes a specific task in a workflow. There are three types of agents: collection, processing and forwarding agents. Analysis Programming Language A structured programming language, used by the Analysis and Aggregation agents to analyze or manipulate UDR fields. Asynchronous agent An asynchronous agent enables the workflow to process multiple UDRs simultaneously by using a queue for each output route. Batch A file, containing external data records, that can only be collected by offline workflows. Offline workflows are also referred to as batch workflows. Begin Batch Indicates the start of a data batch to be fed into a workflow. All collection agents emit Begin Batch messages at the beginning of a data batch. Cancel Batch A message initiated by any agent that wants to cancel the current batch. Cell Cells contain a set of Container Groups. At the time of writing, only one predefined cell ( default ) is available. Collection Agent An agent that collects and inserts data into workflows, including file based and UDR based collectors. Configuration Configurations in the system include all the objects that you find in the Configuration Browser, for example, workflow configurations, agent profiles, workflow groups, Ultra formats, or alarm detectors. Data Batch The data transferred through a Workflow between a Begin Batch and End Batch message. In file based mediation, a data batch often contains a complete file. End Batch Indicates the end of a data batch fed into a Workflow. Error Correction System A central repository for erroneous records and batches. Execution Container In addition to the Platform Container, a MediationZone system may have several Execution Containers. Each container supports running any number of Execution Contexts (ECs) and Service Contexts (SC). Execution Context Execution Contexts are responsible for executing workflows. Execution Contexts may run both in the Platform Container and in any number of Execution Containers. Forwarding Agent An agent that distributes data from workflows. System A MediationZone system, refers to a Platform Container and any number of Execution Containers. System Installation The result of one or more Container installations, including the Platform Container. Meta Information Model MIM - Some agents in a workflow need information from the workflow or other agents in order to operate. For example, an agent that produces a file might need the source file name and the number of processed UDRs to be used in the outgoing file name. MediationZone uses the Meta Information Model to enable this. MIM resource An identifier for a specific resource, published by the Workflow or an agent. MIM resources are static during the workflow execution. MIM value The current value of a MIM resource. MIM resources can be assigned their values either statically, or when receiving Begin Batch or End Batch messages. MZ_HOME The installation directory of a container. Pico Configuration A set of attributes in the STR that defines a pico instance. Pico Instance A segment of MediationZone that is also a Java Virtual Machine (JVM). Pico Instances can be of the different types: Execution Context (EC) Command Line Platform Desktop Service Context (SC) Platform A core part of MediationZone that is responsible for providing services to other pico instances. Platform Container Each MediationZone system must have one Platform Container that includes the Platform. Additional Platform Containers may exist in a system, for high availability, but only one is active at a time. The Platform Container may also have Execution Contexts (EC) and Service Contexts (SC). Processing Agent An agent that processes data in a workflow. In a workflow, a processing agent can either have one incoming and one outgoing data stream, or just one incoming data stream. Profile A global configuration that is used by the agents. Some agents require a profile to finalize the configuration of the agent. Related UDRs Partial UDRs that originate from the same long-duration data exchange between two devices. Session An information record that MedationZone samples at any time during execution of a workflow. This record enables a recovery of the exact status of the workflow, when a failover occurs. In MediationZone, a session is considered to be closed either when a timeout occurs or when a predefined closing criteria (an APL if condition) is met. A session remains active until it is removed with the sessionRemove() function. Service Context Service Contexts are responsible for providing running distributed services that are required by various components in the system. Service Contexts may run both in the Platform Container and in any number Execution Containers. STR Container Each MediationZone installation is assigned a container name, to identify it uniquely within a MediationZone system. Put differently, the container name is an identifier for an MZ_HOME directory on a particular host. One host (physical or virtual) may hold several Containers, each one with a unique name and installed in separate MZ_HOME directories. Containers are used by STR to reference a MediationZone installation on a host. Pico instances can be defined for one or more containers. STR Container installation The result of running the MedationZone setup scripts to install the software in a (MZ_HOME) directory on a physical or virtual host. STR Container Group A Container Group contains a set of containers. At the time of writing, only one predefined Container Group ( default ) is available. Synchronous Agent A synchronous agent finishes processing of each UDR before it retrieves the next UDR in the queue. System A MediationZone system, refers to a Platform Container and any number of Execution Containers. System Installation The result of one or more Container installations, including the Platform Container. System Topology Registry A data structure that holds configurations, service configurations, and attributes that control the behavior of MediationZone. The data in STR can be edited in the System Administration GUI, text editor, or via the Command Line Tool (mzsh). Ultra The MediationZone format management system. Ultra Format Definition Language UFDL - An enriched programming language used to describe the physical structure of incoming and outgoing (external) data, internal (working) formats, as well as decoding and encoding rules. Usage Detail Record UDR - the MediationZone translation of what otherwise is known as CDR, Call Detail Record. Workflow A workflow is an executable object that is represented by a Workflow Table row in a Workflow configuration, an Execution Manager row, and a Workflow Monitor view. A workflow is included in a w orkflow configuration . You define a Workflow in the w orkflow configuration , further described in the Desktop User's Guide. Workflow Configuration A Workflow configuration consists of: A process-definition of agents and the routes between them (referred to as a template) Workflow Properties One or several workflow table rows (see Workflow) Workflow Group A group of workflows that are configured as a single entity and share criteria for scheduling and execution. Acronyms Acronym Definition APL Analysis Programming Language CRC Cyclic Redundancy Check DB Database EC Execution Context ECS Error Correction System FTP File Transfer Protocol GTP GPRS Tunneling Protocol GUI Graphical User Interface HA High Availability HOCON Human Optimised Config Notation HTTP Hypertext Transfer Protocol IP Internet Protocol IPDR Internet Protocol Data Record JAR Java Archive JMX Java Management Extensions JVM Java Virtual Machine MIB Management Information Base MIM Meta Information Model MZ MediationZone OS Operating System RAC (Oracle) Real Application Clusters RCP Remote Communication Protocol REST Representational State Transfer RTBS Real-Time Billing System SC Service Context SCP Secure Copy Protocol SFTP SSH File Transfer Protocol SID (Oracle) System ID STR System Topology Registry SQL Structured Query Language TCP Transmission Control Protocol TLS Transport Layer Security UDR Usage Detail Record UFDL Ultra Format Definition Language XML Extensible Markup Language

---

# Document 51: Data Veracity in Data Management - MediationZone Documentation 9.3 - InfoZone

**Source:** ratanon/mz93-documentation
**URL:** https://infozone.atlassian.net/wiki/spaces/MD93/pages/204672534/Data+Veracity+in+Data+Management
**Categories:** chunks_index.json

The Data Veracity feature in Data Management allows the user to inspect and maintain Data Veracity records which includes erroneous UDRs and batch files located in Data Veracity. Operators can view and remove Error Codes, Filters, Repair Rules, inspect UDRs as well as Approve or Reject Data Veracity records that have been marked for deletion and edit the content of UDRs. Apart from simply sending a Data Veracity record to Data Veracity, a workflow can be configured to associate user-defined information with the Data Veracity data such as Error Code and MIM information. For cancelled batches, the Error UDR and Cancel Message may contain additional user defined information. Note! Take special precaution when updating the Ultra formats. It is not possible to collect data from Data Veracity if the corresponding UDR has been renamed. If the format definition has changed, you can still collect the data. Changes to the formats are handled as follows: Added or renamed fields will be assigned default values. Removed fields will be ignored. Fields that have changed data types will be assigned default values. Note! Operations that modifies the Data Veracity tables via Data Veracity Data Management will only be allowed by users with appropriate application write access. Data Veracity Dashboard From the Manage view, click on Data Veracity and this will lead you to the Data Veracity dashboard where you can select the action to perform on the UDRs. Open Data Veracity Dashboard The section contains the following subsections: Search & Repair Approve Delete Repair Jobs Error Codes Filters Repair Rules Restricted Fields Data Masking Fields

---

# Document 52: Ultra Format Converter - MediationZone Documentation 9.3 - InfoZone

**Source:** ratanon/mz93-documentation
**URL:** https://infozone.atlassian.net/wiki/spaces/MD93/pages/204744190/Ultra+Format+Converter
**Categories:** chunks_index.json

When an Ultra Format Definition is updated, the system automatically converts, or updates, persistent data by default when it is accessed, in order to reflect changes. You can either completely disable this automatic update or enable it for only a selection of formats. You can also set default values for added fields. The following agents and applications can handle persistent data: Application Handling Application Handling Database Collection Agent Collected UDRs are updated. Decoder (using MZ Tagged ) Processed UDRs are updated. Aggregation Sessions All UDRs belonging to the same format definition - historic and updated - are considered valid for comparison. If historic UDRs exist within old sessions, or the session format itself has been updated, the session and its content is updated the next time it is accessed. ECS UDRs are updated whenever they are read from the ECS by the ECS collection agent or accessed through the ECS Inspector . Note! Attempts to collect, process, or update historic UDR data when the automatic conversion for a specific format is disabled causes the workflow to abort (or return an exception, when done outside workflow processing). Conversion Rules If you remove fields from the format definition, they are deleted and cannot be retrieved. If you add fields, they are set to either 0 (zero), true ( numeric types), false ( boolean types), or null (all other types), by default. If you change the type of an existing field, it can cause the field content to be deleted. For example, if you change the type from string to int , the field is set to 0 (zero), provided that no valid default value is defined. Only numerical types ( int , long , etc) are directly interchangeable. If a numeric value exceeds the number of bytes allowed in the new type, it is truncated. Disabling Automatic Conversion In the Ultra Format Converter , you can disable the automatic conversion to new format versions, and instead define default values for UDR fields added in the new version. Open the Ultra Format Converter by selecting Manage  Ultra Format Converter . Open Ultra Format Converter Setting Description Setting Description Convert Select for which UDR types to enable conversion. There are two options: All - All formats are considered, regardless of the types listed (default). Selected Only - Only the formats listed in this window are considered. UDR Types If you have selected to convert Selected Only in the Convert drop-down list, you need to add UDR types in this section. Field/Value section (Default Values) If you have added UDR types in the UDR Types section, it is possible to add default field values of the selected UDR type(s). This may be useful if fields are added to the format, or the type of an existing field is changed. The latter case is especially useful since the old field values are reset if the types are not interchangeable. Note! It is not possible to assign values to old, already existing fields. This can be configured but will not take effect.

---

# Document 53: Single Sign On (OIDC) - MediationZone Documentation 9.3 - InfoZone

**Source:** ratanon/mz93-documentation
**URL:** https://infozone.atlassian.net/wiki/spaces/MD93/pages/204678589
**Categories:** chunks_index.json

Single sign-on (SSO) is a way to log in only once and access different applications using the same login details. It is convenient, efficient, and secure. You just need to change the password once and not have to worry about updating it across other applications. Open Login with SSO MediationZone supports SSO using an OpenID Connect ( OIDC) compliant Identity Provider. Microsoft Active Directory can be configured to act as such an Identity Provider. The system can act as a Relaying Party in the OIDC 1.0 flow. Refer for more details: https://openid.net/specs/openid-connect-core-1_0.html . The conceptual diagram below describes the details of the OIDC SSO authentication flow toward Active Directory. Open OIDC SSO Authentication Diagram Configuration To turn on SSO several properties need to be added to the platform and will take effect after a platform restart. The following properties are mandatory. Property Description Property Description auth .oidc.rp.c lient.id Default value "" Cl ient ID provi ded by Identity Provider. If it is not present, the SSO functionality is disabled. auth.oidc.rp.provider.url Default value "" Provide the Base URL to the associated Identity Provider. This URL, concatenated with `/.well-known/openid-configuration`, must retrieve the OpenID Provider's configuration as per the OpenID Connect Discovery specification. Example: https://login.microsoftonline.com/<tenant_ID>/v2.0 auth.oidc.rp.provider.name Default value "" The name of the provider needs to b e Azure if it is used and groups are returned as uids. auth.oidc.rp.groupPath Default value "roles" Path in ID Token or UserInfo object to find an array of users Access groups as defined by the Access Controller , separated with a dot (.). The groups should be an array of Strings. Example: Groups array in an object Here the groups array is inside an object . { myObject : { myGroups : [ "myGroup1", "mygroup2" ] } } The path should then be: groupPath: myObject.myGroups When the group's array is directly under UserInfo then groupPath is just the name of the group's array. auth.oidc.rp.auth.method Default value "CLIENT_SECRET_BASIC" Available authentication methods are CLIENT_SECRET_BASIC and PRIVATE_KEY_JWT The following property is mandatory when CLIENT_SECRET_BASIC is used as an authentication method: Property Description Property Description auth.oidc.rp.client.secret Default value "" This property sets the relevant Client Secret. Needs to be encrypted. You need to add the following values to the OIDC provider as redirect URLs: Property Description Property Description User Interface http(s)://<hostname>:<ui-webserver-port>/desktop/sso Desktop Launcher http(s)://<hostname>:<platform-webserverport>/launch/api/desktop/v1/sso The following properties are mandatory when PRIVATE_KEY_JWT is used as an authentication method: Property Description Property Description auth.oidc.rp.auth.jwt.keystorePath Default value "" Path to JKS keystore when PRIVATE_KEY_JWT is used auth.oidc.rp.auth.jwt.alias Default value "" Alias for key in keystore when PRIVATE_KEY_JWT is used auth.oidc.rp.auth.jwt.keystorePassword Default value "" Keystore password when PRIVATE_KEY_JWT is used, needs to be Encrypted by MediationZone. auth.oidc.rp.auth.jwt.keyPassword Default value "" Key password when PRIVATE_KEY_JWT is used, needs to be Encrypted by eMediationZone. The following properties are optional: Property Description Property Description auth.oidc.rp.scopes Default value "" Optional additional scopes. Default scopes are openid, profile, and email. auth.oidc.rp.claims.username Default value "" Claim to use as the user name, if not specified sub will be used. This value should be unique. auth.oidc.rp.auth.jwt.keyId Default value "" Optional Key ID for JWT header when PRIVATE_KEY_JWT is used auth.oidc.rp.group.syncDisabled Default value false. Disable group synchronization from Identity Provider. When this is true groups are set manually on each SSO User. auth.oidc.rp.group.default Default value "" When Group Sync is disabled a default group can be added to users logged in through SSO auth.oidc.rp.multigroupsync.defaultGroup Default value "" This property assigns a default group to the user who is a member of multiple groups when the user logs in for the first time . It takes effect only when the group synchronization is enabled. The default group can be changed after logging in and must be one of the member groups. Changes made to the default group after logging in will persist in the next login. auth.oidc.rp.auth.debug Default value false. Set this to true during the implementation of SSO Access to get more information. Use the following command to add the properties: Example - topo mzsh topo open platform Azure as Identity Provider When Azure is used as an ID provider, be sure to set the property auth.oidc.rp.provider.name to Azure to be able to fetch the groups. Then the groups are fetched from Microsoft Graph REST API. A request to the user's endpoint to get the group membership is performed. Make sure to add API Permission GroupMember.Read.All in Azure. Private Key Authentication When the method: "PRIVATE_KEY_JWT" is used, you need to create a Java Keystore in JKS format using an EC or RSA algorithm. The signing algorithm of the JWT used to authenticate to the Token Endpoint will be RS256 for RSA keys and ES256 for EC keys. The script below shows how these can be generated. Note that this will generate a self-signed certificate, which is not suitable for use in publicly exposed interfaces. Make sure to set the parameters at the beginning of the script before execution. This script produces the ssokeystore.jks . It also produces the file publicCert.pem , this file should be uploaded to the ID provider in advance. Example - How to generate a self-signed certificate #!/bin/bash KEY_PASSWORD=DefaultKeystorePWD STORE_PASSWORD=DefaultKeystorePWD DNAME=CN=exampledomain.com,O=Example  rm -f ssokeystore.jks publicCert.pem  keytool -genkey -keystore ssokeystore.jks -storepass $STORE_PASSWORD -keypass $KEY_PASSWORD -alias certificate -keyalg RSA -keysize 2048 -dname $DNAME keytool -keystore ssokeystore.jks -exportcert -alias certificate -rfc -file publicCert.pem -deststorepass $STORE_PASSWORD

---

# Document 54: SCP Collection Agent Transaction Behavior - MediationZone Documentation 9.3 - InfoZone

**Source:** ratanon/mz93-documentation
**URL:** https://infozone.atlassian.net/wiki/spaces/MD93/pages/205001928/SCP+Collection+Agent+Transaction+Behavior
**Categories:** chunks_index.json

This section includes information about the SCP collection agent transaction behavior. For information about the general transaction behavior, see Workflow Monitor . Input/Output Data The agent transmits commands that change the state of the file currently processed. Command Description Begin Batch Will be emitted just before the first byte of each collected file is fed into a workflow. End Batch Will be emitted just after the last byte of each collected file has been fed into the system. The agent acquires commands from other agents and based on them generates a state change of the file currently processed. Command Description Cancel Batch If a Cancel Batch message is received, the agent sends the batch to ECS. Note! If the Cancel Batch behavior defined on the workflow level is configured to abort the workflow, the agent will never receive the last Cancel Batch message. In this situation, ECS will not be involved, and the file will not be moved, however, left at its current place. APL code where Hint End Batch is followed by a Cancel Batch will always result in workflow abort. Make sure to design the APL code to first evaluate the Cancel Batch criteria to avoid this sort of behavior. Hint End Batch If a Hint End Batch message is received, the collector splits the batch at the end of the currently processed block (as received from the server), provided that no UDR is split. If the block end occurs within a UDR, the batch will be split at the end of the preceding UDR. After a batch split, the collector emits an End Batch Message, followed by a Begin Batch message (provided that there is more data in the subsequent block).

---

# Document 55: Disk Forwarding Agent - Batch - MediationZone Documentation 9.3 - InfoZone

**Source:** ratanon/mz93-documentation
**URL:** https://infozone.atlassian.net/wiki/spaces/MD93/pages/204738571
**Categories:** chunks_index.json

The Disk forwarding agent creates files on the local file system containing the received data. Files are created when a Begin Batch message is received and closed when an End Batch message is received. In addition, the Filename Template service offers the possibility to compress (gzip) the files or to further process them, using commands. To ensure that downstream systems will not use the files until they are closed, they are stored in a temporary directory until the End Batch message is received. This behavior also applies to Cancel Batch messages. If a Cancel Batch is received, file creation is canceled. The section contains the following subsections: Disk Forwarding Agent Configuration - Batch Disk Forwarding Agent Transaction Behavior - Batch Disk Forwarding Agent Events - Batch Disk Forwarding MultiForwardingUDR Input - Batch Disk Forwarding Agent Input/Output Data and MIM - Batch

---

# Document 56: GTP' LGU ReCollection Agent Configuration - MediationZone Documentation 9.3 - InfoZone

**Source:** ratanon/mz93-documentation
**URL:** https://infozone.atlassian.net/wiki/spaces/MD93/pages/205685789/GTP+LGU+ReCollection+Agent+Configuration
**Categories:** chunks_index.json

To open the GTP' LGU ReCollection agent configuration, click Build  New Configuration . Select Workflow from the Configurations dialog. When prompted to select workflow type, select Realtime . Click Add Agent and select GTP LGU ReCollection from the Collection tab of the Agent Selection dialog. Open The GTP' ReCollection Agent Configuration Setting Description Setting Description Listening Port Enter the listening port for the GTP' LGU ReCollection agent. This port must be located on the host where the Execution Context is running. Host Enter the IP address of the network element. Port Enter the server port number of the network element. Timeout (ms) Enter the period of time (in milliseconds) before the GTP' LGU ReCollection agent attempts to resend a failed request. If Max Attempts is reached and the timeout has expired, the agent sends a GTPRecollectionResponseUDR with the ResponseState field set to 3 (timeout). Max Attempts Enter the maximum number of attempts to send a request to the network element.

---

# Document 57: Creating Server Keystore and Certificate - MediationZone Documentation 9.3 - InfoZone

**Source:** ratanon/mz93-documentation
**URL:** https://infozone.atlassian.net/wiki/spaces/MD93/pages/204675233/Creating+Server+Keystore+and+Certificate
**Categories:** chunks_index.json

After generating the CA, the next step is to generate a key pair for the server/service. Run the following command: $ keytool -genkey -alias server -keyalg RSA -keystore ./Server.jks -storetype PKCS12 alias = name of the key, for example, server keystore = name of the keystore, for example, server.jks Note! When prompted for first and last name, the hostname where the certificate is valid should be entered, for example, localhost. Other values can be anything. Generate a Certificate Signing Request (CSR) so that we can get server's certificate signed using a CA. $ keytool -certreq -alias server -keystore Server.jks -file Server.csr Get the certificate signed by our the CA, Test CA in this example. See Setting Up a Certificate Authority on how to set up a CA. $ openssl x509 -CA caroot.cer -CAkey cakey.pem -CAserial serial.txt -req -in Server.csr -out Server.cer -days 365 Note! CA , CAkey and CAserial are files generated when setting up the CA. Import the Test CA root self signed certificate in server key store as a trusted certificate. $ keytool -import -alias TestCA -file caroot.cer -keystore Server.jks Import server's certificate signed by Test CA in server key store with the same alias name that was used to generate the key pair during genkey. $ keytool -import -alias server -file Server.cer -keystore Server.jks

---

# Document 58: System Log - MediationZone Documentation 9.3 - InfoZone

**Source:** ratanon/mz93-documentation
**URL:** https://infozone.atlassian.net/wiki/spaces/MD93/pages/204639211
**Categories:** chunks_index.json

Events and errors encountered in the system are saved in the System Log. The System Log handles duplicate events within a time frame, and therefore every event and error has a first and last occurred date, as well as information on how many times it was repeated. You can select to filter out which events you want to see as well as delete selected events from the log. The System Log table will display a maximum of 500 000 entries. If you want to modify the maximum number of entries, add the Platform property mz.systemlog.maxresults to the platform.conf and modify the value, see Platform Properties . To open the System Log, go to Manage  Tools & Monitoring and then select System Log . Open The System Log If you have had the System Log open for a while, you can refresh the view by clicking on the Refresh button in the table action bar. System Log Table The System Log table displays the following options and values Column Description Column Description Open Selection Checkbox The selection check boxes can be used for selecting specific entries that you want to delete. If you select one or several check boxes, the table action bar will change to display a Clear and a Delete button. Last Occurred This column shows the date and time when the event last occurred. Severity This column shows the severity of the event: Info - An event with severity Info is an informative message, for example when a user logs in or a workflow is activated. Warning - An event with severity Warning is also an informative message but is considered to be slightly more serious than a regular information message, for example when a workflow sends data to ECS. Error - An error is logged when any part of the system fails, for example when a workflow aborts. If you display Event Details for an event with severity Error, you will see a stack trace that must always be included when contacting support. Fatal - Fatal is a severity that is never used by default, but may be used for user-defined agents. Type This column shows the event type: System Workflow User Message This column shows the message heading. If you display Event Details you will see the full message. First Occurred This column shows the date and time when the event first occurred. Repeated This column shows how many times this event has occurred. Area Indicates which part of the system the message originates from; user, system or workflow. Workflow/Agent The name of the workflow/agent from which the message originates. Message Area If an entry is selected from the list, further details about it is displayed in this area. Event Details If you click on the entry in the System Log table, you will see additional details about the event: Open Apart from the Last occurred, Message heading you will also see the following information: Information Description Information Description Creation date The date and time when the entry was registered. Origin The origin of the event, for example an IP address and port for a user event, or the host and port for a workflow event. Agent name Name of any agent involved. User name The user name of the user being the origin of the event. This information is only displayed for user events. Stack trace The full stack trace for errors. This information is only displayed for workflow events. Filter Open You can click on the Filter button to set filters for a more curated list of entries in the System Log. The Filter dialog will then open where you can configure your filter. Open System Log Filter An entry has to match all configured filter settings to be displayed in the System Log table. Item Description Item Description Severity The severity of the log entry; Info, Warning, Error, Fatal Type The affected entity. Date Range Within which period entries will be viewed. A few predefined options are available. If none are selected, all are considered. The default period is Today . The available options are: User-defined All Last hour Today Yesterday This week This month If you select User-defined , enter the Start date and time and End date and time . If neither are specified, all entries will match. Workflow Select to only view events relating to a selected workflow. All workflows for which entries have been registered are selectable in this drop-down-list. Only one workflow can be selected. Workflow Group Select to only view events relating to a selected workflow group. All workflow groups for which entries have been registered are selectable in this drop-down-list. Only one workflow group can be selected. Agent Select to only view events relating to a selected agent. All agents for which entries have been registered are selectable in this drop-down-list. Only one agent can be selected. Note! The System Log does not display agent events by default, in order for agent events to be presented in the System Log you have to configure agent events in an Event Notifications . Username Select to only view events relating to a selected user. All users for which entries have been registered are selectable in this drop-down-list. Only one user can be selected. Note! This filter will only apply to user events and not any other events with user name stated, and can therefore not be used for filtering out workflows created by specific users. Message Enter a free text search string to be matched by the messages in the entries you want to display. When you are finished, click OK to apply your filter settings. If you want to clear all filters, you can open the Filter dialog again and click on the Reset button. Deleting Entries You can delete either all entries in the System Log, or specific entries. To delete all entries, click on the Delete button in the table action bar. You will be prompted to confirm that you want to delete all entries. Click on the Delete button to confirm. If you want to only delete specific entries, select the check boxes for the entries you want to delete. The table action bar will change and display a Clear button and a Delete button. Click on the Clear button to clear all your selections, or on the Delete button if you want to delete selected entries. You will be prompted to confirm that you want to delete all entries. Click on the Delete button to confirm.

---

# Document 59: Data Collection Reports - MediationZone Documentation 9.3 - InfoZone

**Source:** ratanon/mz93-documentation
**URL:** https://infozone.atlassian.net/wiki/spaces/MD93/pages/205658294/Data+Collection+Reports
**Categories:** chunks_index.json

Below is an example of a customized data collection report executed either with a predefined schedule or on-demand. Open Data collection report

---

# Document 60: Creating Pico Configurations - MediationZone Documentation 9.3 - InfoZone

**Source:** ratanon/mz93-documentation
**URL:** https://infozone.atlassian.net/wiki/spaces/MD93/pages/204647137/Creating+Pico+Configurations
**Categories:** chunks_index.json

Create new pico configurations by manually creating a new configuration file in the container ( <pico name>.conf) or use the mzsh topo set command . Run the following commands to create a new pico configuration. $ mzsh topo set topo://container:<container>/pico:<pico> <conf> The <config> argument may contain a key-value pair that specifies a template or a pico configuration in HOCON format. Example - Creating a new pico configuration based on a template $ mzsh topo set topo://container:main1/pico:ec2 template:mz.standard-ec When the target container is in the local MZ_HOME, you can add the local flag and omit the container name. Example. Creating a new pico configuration in the local container $ mzsh topo set --local pico:ec2 template:mz.standard-ec When you specify a pico configuration with multiple attributes, it is recommended that you use multi-line strings. Example - Creating pico configuration in HOCON format $ mzsh topo set --local pico:ec2 '{ template:mz.standard-ec config { properties { ec.httpd.port : 9092 } classpath { jars=["lib/picostart.jar"] } } }' If you do not specify a template, you need to ensure that the pico type is specified in the configuration: mzsh topo set --local pico:ec2 '{ type:ec config { properties { ec.httpd.port : 9092 } classpath { jars=["lib/picostart.jar"] } } }' Note! It is possible to create identical pico configurations with the same name in multiple containers. However, only one of these can run at a time. When you want to set the value of a property so that it is shared by all pico instances in a container, you can set it on the container level instead. Similarly, if the value should be shared by all pico instances in all containers, your can set properties on the cell level. Example - Setting a property in a container $ mzsh topo set topo://container:<container>/val:common.pico.tmpdir '${mz.home}/"tmp"' Example - Setting a property in a cell $ mzsh topo set topo://cell:default/val:common.pico.rcp.platform.host examplehost Note! Properties in the pico configuration overrides properties on the container level. Properties that are set on the container level overrides properties on the cell level. For further information about how to set properties on container- and cell level, see Updating Pico Configurations .

---

# Document 61: MSMQ UDR - MediationZone Documentation 9.3 - InfoZone

**Source:** ratanon/mz93-documentation
**URL:** https://infozone.atlassian.net/wiki/spaces/MD93/pages/204608388/MSMQ+UDR
**Categories:** chunks_index.json

This section describes the structure and properties of the MSMQ UDR type. Open The properties in MSMQ UDR type The table below describes the MSMQ UDR properties used in the MSMQ Collection and Processing agents: Field Description Field Description appSpecific (int) The application-generated information, such as single integer values or application-defined message classes. arrivedTime (date) The data and time at which the message arrives at the destination queue. body (string) The body of the message. context (any) A free field that can be used to store contextual information regarding the request. error (string) The error received by the MSMQ collection or processing agents. label (string) An application-defined label for the message. priority (int) The priority that is assigned to the message when en route to a queue and when inserted into the destination queue. queue (string) This field contains the queue name. OriginalData (bytearray) This field contains the original data in bytearray format.

---

# Document 62: ConsumeCycleUDR - MediationZone Documentation 9.3 - InfoZone

**Source:** ratanon/mz93-documentation
**URL:** https://infozone.atlassian.net/wiki/spaces/MD93/pages/204644189/ConsumeCycleUDR
**Categories:** chunks_index.json

The ConsumeCycleUDR is the UDR that the Workflow Bridge forwarding agent populates with data and routes to the Workflow Bridge real-time collection agent. The ConsumeCycleUDR must always be acknowledged and sent back from an Analysis agent to the Workflow Bridge real-time collection agent if the ConsumeCycleUDR was initially sent by a Workflow Bridge batch forwarding agent. See the section, Analysis, for the real-time collection Workflow in Workflow Bridge Example Batch to Real-Time Scenario with Action UDR for an example.

---

# Document 63: importrollback - MediationZone Documentation 9.3 - InfoZone

**Source:** ratanon/mz93-documentation
**URL:** https://infozone.atlassian.net/wiki/spaces/MD93/pages/204743887
**Categories:** chunks_index.json

usage: importrollback <rollback file> This command reverses the effects of the systemimport command by removing the imported configuration and reverting to an older configuration. Note! Use the importrollback command only to revert the systemimport command and not for the purpose of a general system rollback. To be able to properly rollback the entire system, make sure that you occasionally create a backup file with systemexport . This way, you can revert to an earlier system configuration by simply using systemimport . Note! The ECS Reprocessing Groups and ECS error codes are not removed by the importrollback command. The rollback file parameter provides importrollback with information that enables the system to reconstruct the status of your system prior to applying the systemimport command. For further information about systemimport see systemimport . Return Codes Listed below are the different return codes for the importrollback command: Code Description 0 Will be returned if the command was successful. 1 Will be returned if the argument count is incorrect. 2 Will be returned if the rollback file does not exist. 3 Will be returned if the import rollback could not be started due to locked import. 1-> If import rollback is started, a return code greater than zero is returned if the rollback of any of the configurations fail. The exit code is then the number of failed rollbacks, i e return code is 1 if one rollback fails, 2 if two rollback fails, etc.

---

# Document 64: MQTT Agent Configuration - MediationZone Documentation 9.3 - InfoZone

**Source:** ratanon/mz93-documentation
**URL:** https://infozone.atlassian.net/wiki/spaces/MD93/pages/205686194/MQTT+Agent+Configuration
**Categories:** chunks_index.json

To open the MQTT agent configuration dialog from a workflow configuration, you can do the following: right-click the agent icon and select Configuration... select the agent icon and click the Edit button Configuration The MQTT Agent Configuration consists of the following tabs: 1 General Tab 2 Subscribe Tab 3 Advanced Tab General Tab The General tab contains configurations related to the MQTT Connection Details. Open MQTT Agent Configuration - General tab Setting Description Setting Description General Username Enter the user name to be used for the connection to the MQTT server. Password Enter the password to be used for the connection to the MQTT server. Security Use TLS Select this checkbox to have the MQTT agent use TLS. The fields beneath will then be activated. Security Profile Note! This field is enabled when the Use TLS checkbox is selected. Only the Java Keystore Type, Keystore Path, and Keystore Password fields in the Security profile are used by MQTT agent. A new security profile is automatically generated when importing the MQTT agent workflow configuration of an earlier version prior to MediationZone 9. Broker Details Broker Connection Enter the IP address or hostname of the target broker. Broker Port Enter the port value of the target broker. Subscribe Tab The Subscribe tab contains configurations related to topic subscription, where the MQTT agent will subscribe to 1 or many topics in the subscriber/publisher. Open MQTT Agent Configuration - Subscribe tab Setting Description Setting Description Topic Enter the value for the MQTT topic in this field. QoS Select the value for the Quality of Service. The three available options are: At Most Once (0) At Least Once (1) Exactly Once (2) Advanced Tab The Advanced tab contains additional properties for the MQTT agent. Open MQTT Agent Configuration - Advanced tab Setting Description Setting Description Keep Alive Keep Alive (s) Enter a Keep Alive (in seconds) value for the MQTT agent. The Keep Alive is set to 60 seconds by default. Session Use Clean Session Select this checkbox to have the MQTT agent set to use clean session. MQTT agent is set to use persistent session by default. Client ID Enter the value for the Client ID of the MQTT agent. The Last Will and Testament Use Will Message Select this check box to have the MQTT agent use Will Message. By selecting this checkbox will enable the following fields. Will Message The following parameters are used to set up a Will Message as specified in the OASIS Standard MQTT Version 3.1.1 Specification Enable Will Message Retain Select this checkbox to have the MQTT agent to set retain Will Message to true in the MQTT server. Note! This field is enabled when the Use Will Message checkbox is selected. Will Message Topic Enter the value for the topic to be used in the Will Message. Note! This field is enabled when the Use Will Message checkbox is selected. Will Message Enter the message to be included in the Will Message. Note! This field is enabled when the Use Will Message checkbox is selected. Will Message Quality of Service Select the value for the Quality of Service to be used by Will Message. The three available options are: At Most Once (0) At Least Once (1) Exactly Once (2) Note! This field is enabled when the Use Will Message checkbox is selected.

---

# Document 65: encryptpassword - MediationZone Documentation 9.3 - InfoZone

**Source:** ratanon/mz93-documentation
**URL:** https://infozone.atlassian.net/wiki/spaces/MD93/pages/204612469
**Categories:** chunks_index.json

usage: encryptpassword [[<password>] | [-a|-alias <alias> [<password> | -e <encryptedpassword>]]] Encrypts a password and prints out the result. Use this command to create an encryption of a password. When you run encryptpassword in non-interactive mode, special shell characters must be escaped or the password may become truncated. You can use backslash () to escape a special character. Example - Escaping special character $ mzsh encryptpassword example$password You can escape all special characters in a string by surrounding it with single quotes ('). Example - Escaping all characters in a string $ mzsh encryptpassword '`examplepassword!#$&()|";'<> ' If single quote characters are part of the password, these can be escaped with backslash (). Example - Escaping single quote characters $ mzsh encryptpassword '&example#''password Hint! You can use the encrypted password as a password value in an external reference or in a password cell of a workflow table. Options The command accepts the following options: Option Description Option Description [<password>] The password you want to encrypt. [-a|-alias] Use this option to encrypt a password with an alias. Note! In order to use this option, an alias must have been generated with the Java keytool. When this option is not used, the system default key will be used.If you want to use this option, the path and password to the keystore has to be indicated by setting the Platform properties mz.cryptoservice.keystore.path and mz.cryptoservice.keystore.password . The keystore must also contain keys for all the aliases you want to use. For further information about these properties, see 2.6.4 Platform Properties in the System Administrator's Guide . [-e] Use this option to encrypt a password with another alias. Note! The Platform has to be started, and you have to log in to be able to use the -a and -e options. Return Codes Listed below are the different return codes for the encryptpassword command: Code Description Code Description 0 Will be returned if the command was successful. 1 Will be returned if the argument count is incorrect. 3 Will be returned if the encryption went wrong.

---

# Document 66: Searching the ECS - MediationZone Documentation 9.3 - InfoZone

**Source:** ratanon/mz93-documentation
**URL:** https://infozone.atlassian.net/wiki/spaces/MD93/pages/204641101
**Categories:** chunks_index.json

The Search ECS dialog allows the user to filter out and locate erroneous UDRs and batches in the ECS. Any search settings you make can also be saved as filters that you can use for future searches. The Search ECS dialog is displayed when the Search option is selected in the ECS Inspector. Select UDRs or Batches to display UDR or batch specific options. Open Search ECS dialog Search Options The entries in the ECS can be either UDRs or batches. Depending on the selected type, different search options are available. Common Search Options The following settings are available for both UDRs and batches in the ECS. Search Option Description Search Option Description Saved Filters This is the column to the left in the dialog. This column lists any previously saved filters. For more information about how to create a filter, see section Saving Search Settings as a Filter below. Workflow The name of the workflow that sent the entry to the ECS. Agent The name of the agent that sent the entry to the ECS. Error Code An Error Code that has been defined in the ECS Inspector. See ECS Error Codes for further information. Error Case A list displaying the Error Cases associated with the selected Error Code. If the entry is too long to fit in the field, the field can be expanded by enlarging the ECS Inspector in order to display the entire error case text. An Error Case is a string, associated with a defined Error Code. Error Cases can only be appended via APL code: udrAddError( <UDR>, <Error Code>, <Error Case> ); Note! When Batches is selected, the <UDR> parameter is the error UDR. MIM It is possible to configure a workflow to send descriptive MIM values with the actual data (in the Workflow Properties window). This can be used to refine the search in the ECS. Insert Period Select this checkbox to search for UDRs or batches that have been inserted into the ECS during a specific time period. Choose User Defined and specify start time ( From ) and end time ( To ), or use one of the predefined intervals, e.g. Last Hour , Today , This Week . Reprocessing Group Contains a list of all reprocessing groups. Unassigned UDRs or Batches list all entries not associated with any reprocessing group. Reprocessing State Filter based on state, which can be New or Reprocessed . Only entries in state New may be collected. Search Options for Batches The following settings are only available when searching for batches in the ECS Search Option Description Search Option Description Cancel Agent The name of the agent that cancelled the batch. Cancel Message The error message sent as an argument with the cancelBatch function. Error UDR Type The type of Error UDR that can optionally be sent with a batch, containing important MIM information (or any other desired information when the UDR is populated via APL). Search Options for UDRs The following settings are only available when searching for UDRs in the ECS. Search Option Description Search Option Description UDR Type The type of UDR you want to search for. Tag If you have tagged UDRs, this option can be used for displaying only UDRs with the stated tag. Reprocessing State Change Period Select this checkbox to search for UDRs that last changed state (to New or Reprocessed ) during a specific time period. Choose User Defined and specify start time ( From ) and end time ( To ), or use one of the predefined intervals, e.g. Last Hour , Today , This Week . Search Fields If you have selected to search for UDRs , there is an Advanced tab, where you can select to Search Fields . Here, you can enter specific values for different UDR labels that you have configured, see Configuring Searchable Fields in the ECS . Only UDRs containing the specified values will be displayed in the ECS Inspector. Example For example, with the following setting: Open Only UDRs with IMSI 2446888776 are displayed in the ECS Inspector, provided that the label IMSI has been mapped to the IMSI field in the UDRs. Wild cards and intervals can also be used when entering the values for the fields; " * " can be used for matching any or no characters, and intervals can be set by using brackets " [ ] ". When using the * or [ ] , the following rules apply: Only one wild card and one interval can be used per value. An interval is defined with a start value and an end value. If the interval consists of the same number of digits as start and end values, the match is made based on the specified number of digits, e.g. (a[001-002]) matches a001 but not a01 . If the interval consists of different numbers of digits as start and end values, the match is made based on an appropriate number of digits in the UDR, e.g. (a[1-20]) matches a1 and a20 , but not a01 or a020 . Only one interval can be stated within the " [ ] ". The start and end values have to consist of numbers. The start value cannot be larger than the end value. The start value cannot have a larger amount of numbers than the end value, e.g. [0001-3] . If a setting for a value is not correct, an error message is displayed as a tooltip. In order for a UDR to pass the filter, all the defined values have to match. Example For example, with the following setting: Open Only UDRs with: A Number starting with 468 AND B Number starting with 47 AND Location Area Code 10 to 20 will be displayed. Saving Search Settings as a Filter When the search settings have been made, you can select to save these settings as a filter. Warning! If you have included search criteria that refer to parameters previously defined in your system, such as error codes, tags, search fields, etc, such filters will not work properly if you delete any of the defined parameters. To save a filter: Set the search options you want and click Save (bottom left corner button). A dialog opens asking you to enter a name for the filter. Open Entering Filter Name Enter a name in the Filter Name field and click OK . The dialog closes and the new filter appears in the Saved Filters list. The next time you want to use the same search settings, click the filter name in the Saved Filters list and the saved search settings are displayed. Hint! Any saved filters can be renamed or deleted by selecting the filter and clicking the Rename or Delete buttons.

---

# Document 67: SAP CTS+ Export - MediationZone Documentation 9.3 - InfoZone

**Source:** ratanon/mz93-documentation
**URL:** https://infozone.atlassian.net/wiki/spaces/MD93/pages/318308390
**Categories:** chunks_index.json

The CTS+ integration in MediationZone uses a "loose coupling" approach for handling exports. This means that the export process is performed within MediationZone , and then the exported file is manually made available to CTS+ for transport and import into target systems. To make a CTS+ export: Create the System Export: Use the System Export tool in Desktop, or the mzsh command line tool to generate the export file in MediationZone. Make the System Export available to TMS: Once the export file is created, follow the steps in the SAP CTS+ documentation on the SAP Help Portal - SAP Online Help to upload the file to TMS. When it is available, the export can be imported into target systems via the SAP CTS+ API. Note! When setting up your configurations and system exports, the entire export content will be imported into the target system. To ensure smooth integration we recommend that you: Use External References for system-specific variables. This ensures configurations are valid for both the source and target systems, with only the External References being system-specific. For more details, see External Reference Profile . Limit your exports to include only the use cases you intend to import into other systems.

---

# Document 68: Email Agent MIM - MediationZone Documentation 9.3 - InfoZone

**Source:** ratanon/mz93-documentation
**URL:** https://infozone.atlassian.net/wiki/spaces/MD93/pages/205652440/Email+Agent+MIM
**Categories:** chunks_index.json

MIM For information about the MIM and a list of the general MIM parame ters, see Administration and Management . Publishes MIM Value Description Email Count This MIM parameter contains a integer, indicating the number of emails the agent will process. Email Count is of the integer type and is defined as a header MIM context type. Note! This count is not a exact number if you use " Filter on subject" in the Agent Configuration Rules Tab, as the subject filtering is done after fetching the number of messages. Source Files Left This MIM parameter contains a long, indicating how many emails are left to process. Source Files Left is of the integer type and is defined as a header MIM context type. Note! This count is not a exact number if you use " Filter on subject" in the Agent Configuration Rules Tab, as the subject filtering is done after fetching the number of messages. Note! The name Source Files Left is so that the execution manager will be able to use this MIM for the Backlog column (even though we are using emails, not files). Accesses The agent does not itself access any MIM resources.

---

# Document 69: Workflow Configuration - MediationZone Documentation 9.3 - InfoZone

**Source:** ratanon/mz93-documentation
**URL:** https://infozone.atlassian.net/wiki/spaces/MD93/pages/204647603
**Categories:** chunks_index.json



---
**End of Part 3** - Continue to next part for more content.
