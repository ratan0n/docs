# RATANON/MZ93-DOCUMENTATION - Part 73/112

---
**Dataset:** ratanon/mz93-documentation
**Part:** 73 of 112
**GitHub:** https://github.com/ratan0n/docs/tree/main/mz93-documentation
**Size:** ~64.4 KB
---

The purpose of the restricted fields configuration is to make it possible to mark certain fields as read-only in the ECS Inspector. For instance you might want to guard some UDR fields from being edited to avoid losing traceability. The ECS Restricted Fields configuration is viewable (read-only) for all users with access to the ECS Inspector. Only users belonging to the administrator group are allowed to edit the configuration. Restrictions can be set on any UDR type, also within sub-UDRs. The restrictions are applied recursively so if there are restrictions on a UDR field of a certain type, all sub-fields are blocked from editing as well. The restrictions defined in the ECS Restricted Fields configuration are valid only in the ECS. I.e. the UDRs are still possible to modify outside the ECS (unless they have been explicitly defined as read-only in the UDR definition). It is possible to import and export the ECS Restricted Fields configuration if needed. The configuration is located in the System Exporter file tree viewer under System  ECS  Restricted Fields . Note! The access rights described above apply also to importing and exporting. This means that any user can export the ECS Restricted Fields configuration (as long as they have ECS Inspector access) but only members of the administrator group can import the ECS Restricted Fields configuration. To restrict certain UDR type fields from being edited in the ECS Inspector, specify those fields in the ECS Restricted Fields dialog (opened from the ECS Inspector  Restricted Fields button). Note! Only users belonging to the administrator group are allowed to configure restricted fields. However, all users can view the configured restrictions. Open Restricted Fields dialog To configure restricted fields: Click the Add button beneath the Restricted UDR Types section. The UDR Internal Format Browser dialog opens. Open UDR Internal Format Select the UDR Type for which you want to restrict fields from being edited and click Apply . The UDR type is added to the Restricted UDR Types list. Repeat the previous step for all the UDR Types you want to add, and then click OK to close the dialog. Select one of the UDR Types that you have added and click the Add button beneath the Restricted Fields section. The UDR Internal Format Browser dialog opens. Open UDR Internal Format Browser Select a field you want to restrict from being edited and click Apply . The UDR type is added to the Restricted Fields list. Repeat the previous step for all the fields you want to restrict from being edited, and then click OK to close the dialog. When you are finished, click Save in the ECS Restricted Fields dialog. The configured fields are now blocked from editing in the ECS Inspector.

---

# Document 1725: TCP/IP Collection Agent Events - MediationZone Documentation 9.3 - InfoZone

**Source:** ratanon/mz93-documentation
**URL:** https://infozone.atlassian.net/wiki/spaces/MD93/pages/205034839/TCP+IP+Collection+Agent+Events
**Categories:** chunks_index.json

Agent Message Events There are no message events for this agent. Agent Debug Events There are no debug events for this agent.

---

# Document 1726: status - MediationZone Documentation 9.3 - InfoZone

**Source:** ratanon/mz93-documentation
**URL:** https://infozone.atlassian.net/wiki/spaces/MD93/pages/204677995/status
**Categories:** chunks_index.json

usage: status [ -q ] [ -verbose ] <server process> ... This command is used to retrieve the running status of pico instances that are defined in the local container. The states are: running not running not responding but the process is still running. (Shown if the local server process is not responding.) running without contact with the platform RCP service. (Shown if information can not be collected from the platform.) Note! If the code server (a server closely connected to the platform with the ability to function independently) is not available the status command will wait for the RCP communication to time out, this requires some extra time. Options The command accepts the following options: Option Description Option Description [-q] Generates less or no information messages. [-verbose] Enables verbose mode. Return Codes Listed below are the different return codes for the status command: Code Description Code Description 0 Will be returned if a command was successful and all defined processes are running, or if there are picos defined in the system. 1 Will be returned if any of the processes is not responding but its JVM is running. 2 Will be returned if there is no server process with the specified name, or if any of the defined processes are not running.

---

# Document 1727: Data Masking Fields - MediationZone Documentation 9.3 - InfoZone

**Source:** ratanon/mz93-documentation
**URL:** https://infozone.atlassian.net/wiki/spaces/MD93/pages/205032499/Data+Masking+Fields
**Categories:** chunks_index.json

Data Masking Fields allows users create a data masking rule to prevent the data of certain fields from being seen by other users when they search for the Data Veracity UDRs on the web interface. Fields that have been masked will display data in asterisk form rather than the original data itself. Unsupported Data Type for Search Searching, filtering, repairing and masking of UDRs with list and map data types are currently not supported by Data Veracity. The Data Masking Fields web interface is where data masking rules could be viewed or removed. Open Data Veracity - Data Masking Fields Data Masking Fields Sort Order Sorting by UDR column is based on Javas default sorting behavior for Strings(for example, sorting of alphabetical characters in Java is case sensitive). The example below shows the three fields, myStringField, subUDR.sub_date1 and subUDR.sub_long1 that have been masked for the UDR. Open Masked Fields in Search Query Results Note! Only users with write access to Data Veracity will be able to manage the Data Masking Fields rules and be able to view the masked data. Adding New Data Masking Rules In the Data Veracity  Data Masking Fields page, click the New button on the right. You will be prompted to select the UDR Typ e and Masked Fields . Open Data Veracity - Masked Fields Fields Description Fields Description UDR Type Allows you to choose from a list of UDRs that are configured in your Data Veracity profile. From the example below, we have multiple UDR Types, namely MainUDR, anotherUDR, MySubUDR and SecondNested. Open Data Veracity - Selecting UDR Types Masked Fields Upon selecting a UDR Type , the Masked Fields will be populated with all the UDR fields that are in the UDR type . You can choose to add a single field, multiple fields or even all the fields available in the UDR by clicking from the dropdown list. You will also be able to select the fields within any nested UDRs that are available in the chosen UDR Type . Note! When selecting fields for one UDR Type , the masking will only apply to the field within that selected UDR Type . When performing a Data Veracity Search using MainUDR , you will find the fields to be properly masked. However, if you search using the subUDR , the fields will not be masked. To mask the fields in subUDR, you are required to create a Data Mask entry by selecting the subUDR as the UDR Type. Primitive List / Map are not supported for masking, ie list of String. Once you have added all required fields for data masking, click on the Save button. An entry will appear on the Mask Field(s) dashboard. Note! Only one Data Masking rule can be created per UDR type at any one time. Editing a Data Masking Rule Data masking rules can be edited when there are new fields to be added into the Masked Fields list. To edit a data masking rule, you can select one entry and then click on the Edit button. You will be prompted with the pop-up where you can add more masked fields or remove already masked fields from the entry. Open Data Veracity - Editing Masked Fields Click Save , to update the selected entry. Deleting a Data Masking Rule Data masking rules can only be deleted from the Data Masking Fields web interface. Deleting a Data masking rule here will remove masking rule from Data Veracity. To delete a rule, you can select one or many rules at once and then click on the Delete button on the top right corner of the table. Open Data Veracity - Data Masking Rule Deletion Upon deletion, you will be prompted with a message asking if you would want to delete the selected rules. If you click Delete , the selected rules will be deleted. Open Data Veracity - Data Masking Rule Deletion confirmation dialog

---

# Document 1728: SAP CC Online Agent Events - MediationZone Documentation 9.3 - InfoZone

**Source:** ratanon/mz93-documentation
**URL:** https://infozone.atlassian.net/wiki/spaces/MD93/pages/205686854/SAP+CC+Online+Agent+Events
**Categories:** chunks_index.json

Agent Message Events There are no agent message events for this agent. Debug Events Debug messages are dispatched in debug mode. During execution, the messages are displayed in the Workflow Monitor. You can configure Event Notifications that are triggered when a debug message is dispatched. For further information about the debug event type, see Debug Event . The agent produces the following debug events: Input charging request in XML format Invalid charging request in XML format Successful charging answer in XML format Charging error in XML format

---

# Document 1729: Process Modeling and Configuration - MediationZone Documentation 9.3 - InfoZone

**Source:** ratanon/mz93-documentation
**URL:** https://infozone.atlassian.net/wiki/spaces/MD93/pages/205783542/Process+Modeling+and+Configuration
**Categories:** chunks_index.json

MediationZone provides flexibility through configuration. Its high-level graphical environment delivers a complete set of configurable tools to meet the challenging requirements of a service provider. Workflows are the cornerstones of process modeling and configuration in MediationZone A workflow is a set of nodes that are referred to as agents. Processing models are visualized by connecting the agents to each other using drag and drop. Workflows contain three types of agents: Collection agents are responsible for gathering data into the workflow from data sources or the client of a bi-directional real-time flow. An example of a simple collection agent could be one that reads a file from disk and sends its contents into the workflow. Processing agents delivers data on one or many outgoing routes. A processing agent could be as simple as a counter that counts the throughput. It could also be more complex in that it evaluates the data and depending on the result, delivers it on different routes. Amongst the processing agents, so-called transformer agents can be identified. A transformer agent is responsible for translating an incoming byte stream into a UDR object or the opposite. For file distribution the Encoder Agent can be used to create header/trailer records containing meta-data of the file, e.g. record counter, check sum etc. This is commonly referred to as Decoding and Encoding, which the MediationZone Ultra format system will handle. Forwarding agents are responsible for distributing the data from the workflow to other systems or devices. An example of a forwarding agent could be one that creates a file from a data stream and transfers it to another system using FTP. For a list of interface agents, see Appendix A - MediationZone Interfaces . Open MediationZone Agents Workflows may be interlinked into mediation tasks of virtually any complexity, where the output of one Workflow is the input of another. Agents specifically designed for this purpose minimize the overhead related to inter-workflow processing; this contributes to the superior performance of MediationZone. There are three different types of workflows, that each have a slightly different execution behavior, but their modeling and configuration structure is the same. Batch workflows  Are used to collect, process and distribute file-based data, also referred to as an Offline model. Batch Workflows can be configured for multi-threaded execution, and enforces a first-in-first-out processing order and a strict transaction boundary based on each batch processed. Real-time workflows  Enables online processing of requests/answers with other systems. These Workflows use multi-threading to enable execution of large numbers of independent execution paths simultaneously. Task workflows  Used to execute common activities such as cleanup or maintenance tasks. A number of System Tasks are pre-configured in MediationZone and can be complemented with any user-defined activity. Task Workflows are further described in Types of Workflows . The workflow configuration is used to design and configure workflows, by adding agents and connecting them to each other. This is further described in Workflow Configuration . The following illustration shows an example of a simple Batch workflow: Open Example of Batch Workflow Configuration Workflows that are conceptually related can be grouped together. This enables the setting of common execution or monitoring characteristics on all elements in a group, such as execution scheduling for Workflow Groups or selection of execution environment for Workflows and Workflow Groups. See Workflow Configuration for more information. Workflow and Workflow Group functions include, among other things: Function Description Function Description Scheduling Workflows Groups can be scheduled for execution periodically, on specific occasions or as a result of an event within the MediationZone system. Distributed execution A workflow or a group of workflows can be directed to execute on a particular execution node, or it can automatically be distributed to a node with the lowest load or lowest number of active Workflows. Suspend execution For a period of time a workflow or a group can be suspended from executing as scheduled. Version handling All versions of workflows and groups are saved during configuration, and it is possible to view and rollback to any previous version. Table configuration Workflows with the same structure can easily be multiplied in a table-based view, where the user selects which parameters that should be possible to define per workflow. External References Workflow configuration can be managed via property files called external references, providing the facility for external control of Workflow execution from outside the Desktop. Meta Information Model (MIM) Upon configuration, the workflow and its agents provide runtime attributes  MIMs, which can be fetched and distributed to other parts of the system. MIMs can be both static and dynamic. Examples of MIM values are, for example, agent names and names of collected files. Encryption As with all configurations, also Workflows and groups can be saved encrypted. In such a case, read or write access to encrypted configurations is only possible if a correct password is provided.

---

# Document 1730: Offline Charging (OFCS) - MediationZone Documentation 9.3 - InfoZone

**Source:** ratanon/mz93-documentation
**URL:** https://infozone.atlassian.net/wiki/spaces/MD93/pages/205882037/Offline+Charging+OFCS
**Categories:** chunks_index.json

Definition Offline Charging System (OFCS) is defined using the Charging architecture and principles outlined by 3GPP TS32.240 (Ref 1) as the baseline. It is constructed as a set of capabilities to facilitate charging for telecom network connectivity services delivered by the CSP characterized by, and limited to: Interoperability with the core network The ability to interoperate with network elements via the Diameter Rf interface Charging Domain components Charging Data Function (CDF)  with or without a coupled CGF Charging Gateway Function (CGF)  when coupled with the CDF to provide full OFCS functionality. Not to be used as a stand-alone CGF. Interoperability between the CDF and the CGF via a supported interface, to facilitate CDR generation and data flow to downstream Billing Domain (BD) systems Commercial Models and purposes Direct B2C connectivity Direct B2B connectivity Telecom network inbound roaming Telecom network outbound roaming This Right to Use (RTU) grants the licensee the right to use DigitalRoutes MediationZone software in accordance with this definition.

---

# Document 1731: Python Interpreter Profile - MediationZone Documentation 9.3 - InfoZone

**Source:** ratanon/mz93-documentation
**URL:** https://infozone.atlassian.net/wiki/spaces/MD93/pages/204739912/Python+Interpreter+Profile
**Categories:** chunks_index.json

With Python Interpreter profiles, you can configure which Python interpreter to use. Open Interpreter profile configuration The Interpreter profile is loaded when you start a workflow that depends on it. Changes to the profile become effective when you restart the workflow. To open the editor, click the New Configuration button in the upper left part of the Desktop window, and then select Python Interpreter Profile from the menu. Setting Description Setting Description Use Default Select this checkbox if you want to use the default interpreter as defined in the Python Manager tool. Use Named Select this checkbox to select a predefined interpreter listed in the Python Manager tool. Use This Select this checkbox to specify the actual location and working directory of a Python interpreter executable directly.

---

# Document 1732: UDP Related UDR Types - MediationZone Documentation 9.3 - InfoZone

**Source:** ratanon/mz93-documentation
**URL:** https://infozone.atlassian.net/wiki/spaces/MD93/pages/204643470/UDP+Related+UDR+Types
**Categories:** chunks_index.json

There is only one UDP related UDR Type; Packet. Packet UDR The Packet UDR is the UDR type created by default in the UDP agent. It can be viewed in the UDR Internal Format Browser. To open the browser, open an APL Editor, right click in the editing area and select UDR Assistance... and the browser will open . Packet UDR Packet UDR Field Description Field Description data (bytearray) This field contains the data sent to the UDP agent. Can be assigned in case a packet is sent to the designated host and port. host (string) This field contains the hostname or IP address to the remote host. port (int) This field contains the port to the remote host.

---

# Document 1733: premove - MediationZone Documentation 9.3 - InfoZone

**Source:** ratanon/mz93-documentation
**URL:** https://infozone.atlassian.net/wiki/spaces/MD93/pages/204646522/premove
**Categories:** chunks_index.json

usage: premove <package-name> Removes the selected package from the system. The command should only be used by system administrators with authority to maintain the MediationZone software. For further information about managing packages, see the System Administrator's Guide . Return Codes Listed below are the different return codes for the premove command: Code Description Code Description 0 Will be returned if the command was successful. 1 Will be returned if there is no package with the specified name.

---

# Document 1734: Installation Instructions - MediationZone Documentation 9.3 - InfoZone

**Source:** ratanon/mz93-documentation
**URL:** https://infozone.atlassian.net/wiki/spaces/MD93/pages/204996705/Installation+Instructions
**Categories:** chunks_index.json

Loading Prerequisites The reader of this document should be familiar with: System Administrator's Guide For information about Terms and Abbreviations used in this document, see the Terminology documentation. Loading

---

# Document 1735: IPDR SP Agent - MediationZone Documentation 9.3 - InfoZone

**Source:** ratanon/mz93-documentation
**URL:** https://infozone.atlassian.net/wiki/spaces/MD93/pages/205000724/IPDR+SP+Agent
**Categories:** chunks_index.json

This section describes the IPDR SP (Internet Protocol Detail Record Streaming Protocol) agent. The agent is a collection agent for real-time workflow configurations. Prerequisites The user of this information should be familiar with: IPDR Streaming Protocol TMF8000-IPDR-IIS-PS version 2.8 DOCSIS 2.0 SAMIS DOCSIS 3.0 SAMIS-TYPE-1 DOCSIS 3.0 SAMIS-TYPE-2 IPDR Protocol The Internet Protocol Detail Record (IPDR) is used to provide IP based service usage information, performance and usage measurement of cable modems, multimedia terminal adapters and others. The IPDR is used by Operations Support Systems (OSS) and Business Support Systems (BSS) applications. IPDR SP Specification Description The requirements for IPDR SP collection, encoding and transport protocols for the exchange of IPDR SP records are all included in the IPDR SP Specifications. The IPDR SP DOCSIS definitions is used as maintained by CableLabs. This section contains the following subsections: IPDR SP Agent Configuration IPDR SP Agent Input/Output Data and MIM IPDR SP Agent Events IPDR SP UDRs IPDR SP Examples

---

# Document 1736: Inter Workflow Forwarding Agent in a Batch Workflow - MediationZone Documentation 9.3 - InfoZone

**Source:** ratanon/mz93-documentation
**URL:** https://infozone.atlassian.net/wiki/spaces/MD93/pages/205653042/Inter+Workflow+Forwarding+Agent+in+a+Batch+Workflow
**Categories:** chunks_index.json

To open the Inter Workflow forwarding agent configuration, click Build  New Configuration . Select Workflow from the Configurations dialog. When prompted to select a workflow type , click Batch . Click Add agent  Forwarding tab and select Inter Workflow from the Agent Selection dialog. Double-click the agent icon or right-click the icon and select Edit agent , to display the Agent Configuration dialog. Open Inter Workflow forwarding agent configuration - batch workflow Setting Description Setting Description Profile The name and most recent version of the profile as defined in the Inter Workflow profile configuration. All workflows in the same workflow configuration can use separate Inter Workflow profiles, if that is preferred. In order to do that the profile must be set to Default in the Workflow Table tab found in the Workflow Properties dialog. After that each workflow in the table can be appointed different profiles. Named MIM The user defined MIM names according to the definitions in the selected profile. MIM Resource Selected, existing MIM values of the workflow that the Named MIMs are mapped to. This way, MIM values from this workflow are passed on to the collection workflow. Produce Empty Batches If enabled, empty files will be created even if no UDRs are forwarded from a batch. Use Custom Stream Select this checkbox to enable Stream ID-based connections across multiple workflows using the same profile. When checked, collector and forwarding agents establish connections based on both the profile and a Stream ID, allowing workflows to link dynamically. In cases where a real-time workflow connects to a batch workflow, they scale as a unit, ensuring backend/frontend pairs stay linked via the Stream ID. Note! If this checkbox is cleared, the Inter Workflow profile is fixed at design time and cannot be changed dynamically, preventing chained workflows from scaling. Example - Configuring a Stream ID in Inter Workflow Forwarder and Collection Agents Scenario: You have multiple processing workflows that each need to send data to a specific collection workflow. Instead of creating separate Inter Workflow profiles for each pair, you can configure a stream ID to manage these connections within a single profile. For example, if three processing workflows (A, B, and C) need to send data to three corresponding collection workflows (X, Y, and Z), you can define stream IDs like "A-X", "B-Y", and "C-Z". This ensures each processing workflow sends data to the correct collection workflow while maintaining a simpler, more scalable configuration. Stream ID If you have checked the Use Custom Stream checkbox add a Stream ID.

---

# Document 1737: Session Iterator Functions - MediationZone Documentation 9.3 - InfoZone

**Source:** ratanon/mz93-documentation
**URL:** https://infozone.atlassian.net/wiki/spaces/MD93/pages/204612236/Session+Iterator+Functions
**Categories:** chunks_index.json

This section describes the four different APL sessionIterator functions. They can be used both for Real Time and Batch workflows. An iterator is started with sessionIteratorCreate, and is ended by using sessionIteratorNext or aborted using sessionIteratorDestroy. Iterating over all sessions in storage does not take any locks. This means that if a workflow updates the storage at the same time as the iteration is ongoing, sessions can be missed in the search or the same sessions can be returned twice. There is an "Error Count" on the iterator that can be used when this type of inconsistency has been detected. This is the same as the type of inconsistencies that can be detected in the Aggregation Session Inspector where sessions are not accessible. The following functions for Session Iterator described here are: 1 sessionIteratorCreate 2 sessessionIteratorNext 3 sessionIteratorErrorCount 4 sessionIteratorDestroy sessionIteratorCreate Creates a new iterator that can be used in the other three functions. any sessionIteratorCreate( string profileName ) sessessionIteratorNext Returns the next session or null if the full session storage has been traversed. drudr sessionIteratorNext( any iterator ) sessionIteratorErrorCount Returns the number of detected errors during the iteration. This is a fairly normal condition when the storage is updated or removed while the iteration is ongoing. Each error will typically mean that one session was missed, but it can also mean a larger number of missed sessions if the storage was moved. If the session iterator starts iterating over the storage on one ec, and at the same time a workflow using the profile starts on another ec, the storage is removed from the first ec and started up at the second ec and the iterator will abort. This will be logged in system log as well as the error count being increased. int sessionIteratorErrorCount( any iterator ) sessionIteratorDestroy Destroy the iterator to release resources to avoid a memory leak due to iterators being left in live state. This is not needed if the iteration is run to the end. void sessionIteratorDestroy( any iterator ) Best practice to implement sessionIterators in APL An example below of searching for a session that matches an "intField" value. "QueryData" is here the session type of the "Default.queryagg" profile. QueryData findSession(int intFieldValue) { int retries = 0; any iter = null; // For a real scenario, consider limiting number of retries while (true) { iter = sessionIteratorCreate("Default.queryagg"); QueryData qd = (QueryData) sessionIteratorNext(iter); while (qd != null) { if (qd.intField == intFieldValue) { // Done! sessionIteratorDestroy(iter); return qd; } qd = (QueryData) sessionIteratorNext(iter); } if (sessionIteratorErrorCount(iter) > 0) { // We did not find the session and had errors -> retry ++retries; } else { // No errors, but it does not seem to exist return null; } } } We simply retry the search whenever an error is detected. Note also the use of sessionIteratorDestroy which should be used whenever an iterator is not run to the end. Performance Note! Considerably better performance will be achieved by running the lookups on the same EC as the storage service. This means that if you run the lookup at the same time as a workflow using the storage is running on a different EC, then it will be slower. It will still be better performance than using the Aggregation Session Inspector, and there will be no load on the platform.

---

# Document 1738: Ultra Format Configuration - MediationZone Documentation 9.3 - InfoZone

**Source:** ratanon/mz93-documentation
**URL:** https://infozone.atlassian.net/wiki/spaces/MD93/pages/205657244/Ultra+Format+Configuration
**Categories:** chunks_index.json

The Ultra Format configuration introduces format definitions in the system to be used by agents in workflows. Use the Ultra Format Definition Language (UFDL) to describe format definitions. Apart from selecting Decoder, Encoder, and UDR Type definitions, formats can be imported from APL code, as well as directly from other Ultra definitions: import ultra.folder_name.module_name; // From APL code import folder_name.module_name; // From UFDL code To open an Ultra Format configuration, click Build  New Configuration . Select Ultra Format in the Configurations dialog. Open Ultra Format Editor The configuration contains the standard configuration buttons as described in Common Configuration Buttons . Syntax Highlighting In the code area, the different parts of the code are color coded according to type, for easier identification, and when right-clicking in the code area, a context sensitive popup menu appears, enabling easy access to the most common actions you may want to perform. The text is color-coded according to the following definitions: Blue - Functions Green - Types Orange - Comments Purple - Keywords Yellow/Green - Values Ultra Format Buttons The buttons available in the Ultra Format configuration are the general ones as described in Common Configuration Buttons . Configuration Diff If you want to compare the current version of an Ultra configuration with a previous version of the same configuration, you can use Configuration Diff to compare the two versions side by side. However, this tool is only available in Legacy Desktop. See Configuration Diff for more information.

---

# Document 1739: Netflow Input/Output Data - MediationZone Documentation 9.3 - InfoZone

**Source:** ratanon/mz93-documentation
**URL:** https://infozone.atlassian.net/wiki/spaces/MD93/pages/204673962/Netflow+Input+Output+Data
**Categories:** chunks_index.json

The Input/Output data is the type of data an agent expects and delivers. Depending on the incoming flow records, the agent may produce one of the following UDR types. Their names reflect the NetFlow versions: V1UDR (netflow) V5UDR (netflow) V7UDR (netflow) V8ASMatrixUDR (netflow) V8DestinationPrefixMatrixUDR (netflow) V8PrefixMatrixUDR (netflow) V8ProtocolPortMatrixUDR (netflow) V8SourcePrefixMatrixUDR (netflow) V9UDR (netflow) V10UDR (netflow)

---

# Document 1740: Batch Request - MediationZone Documentation 9.3 - InfoZone

**Source:** ratanon/mz93-documentation
**URL:** https://infozone.atlassian.net/wiki/spaces/MD93/pages/205001837/Batch+Request
**Categories:** chunks_index.json

AcquireUDR This UDR is dedicated to requesting the connected SAP Convergent Charging Server to collect a list of chargeable items included in an acquisition parameter. The SAP Convergent Charging Server processes these chargeable items and stores them in temporary files. For field definitions, refer to the section below, AcquisitionParametersUDR. Field Description Field Description parameters Contained within this field is a list of chargeable items stored as an AcquisitionParametersUDR AcquisitionParametersUDR This UDR represents the data for the batch acquisition operation of a chargeable item or a collection of chargeable items in the charging client. Field Description Field Description chargeableItem (ChargeableItemUDR (sapcc)) A ChargeableItem represents the information that the client needs to perform the charge process. It consists of a name and a list of properties . consumptionDate (date) The date of the consumption event. The value should be a string representing a numerical value in the following format: 1, 0.1, 0.01, 0.001 etc. serviceid (string) The serviceId part of the access object linked to the customer master data defined in SAP Convergent Charging userid (string) The userId part of the access object linked to the customer master data defined in SAP Convergent Charging BlankChargeUDR (sapcc.batch.BlankChargeUDR) This UDR is used by the SAP CC Batch agents to submit a blank charge request to the SAP Convergent Charging server. The sapcc.batch.BlankChargeUDR extends from sapcc.BlankChargeUDR. For field definitions, refer to the section ChargeUDR in Charging Request UDRs . ChargeUDR (sapcc.batch.ChargeUDR) This UDR is used by the SAP CC Batch agents to submit a charge request to the SAP Convergent Charging server. The sapcc.batch.ChargeUDR extends from sapcc.ChargeUDR and contains one additional field. For sapcc.ChargeUDR files, refer to Charging Request UDRs . The additional field for sapcc.batch.ChargeUDR is provided below: Field Description Field Description reratingLockCode (string) The rerating operation lock code

---

# Document 1741: Database Properties - MediationZone Documentation 9.3 - InfoZone

**Source:** ratanon/mz93-documentation
**URL:** https://infozone.atlassian.net/wiki/spaces/MD93/pages/205783237
**Categories:** chunks_index.json

This section describes the properties related to Oracle, PostgreSQL, and SAP HANA that you can set. Derby The following properties are applicable to the Derby database. Property Description Property Description derby.restore.path Default value: "MZ_HOME/dbrestore" Set this property to set the Derby restore directory. Oracle The following properties are applicable to the Oracle database. These settings are used by the Platform for the connection towards the Platform database, and for ECs for connections towards external databases. Property Description Property Description oracle.pool.connectionwaittimeout Default value: 900 The number of seconds to wait for a free connection if the pool has reached max-connections used. oracle.pool.maxlimit Default value: -1 Maximum number of connections in the pool. It should be set to no less than "3". A usual setting would be about 10 to 100. The default value "-1" means that the number of connections is unlimited. Oracle Advanced Security Support The following properties are supported for Oracle 12.2, which includes support for Oracle Advanced Security. Set the properties below if you want to enable encryption for Platform for the connection towards the Platform database and for ECs for connections towards external databases. More information about Oracle Advanced Security can be found in the Oracle Database Advanced Security Administrator's Guide . Note! MediationZone only supports Oracle Advanced Security for Oracle 12.2. Property Description Property Description oracle.net.encryption_client The level of security of the client that will connect to the Oracle database is determined with this parameter. Accepted values include, REJECTED, ACCEPTED, REQUESTED, and REQUIRED. Example oracle.net.encryption_client="REQUIRED" oracle.net.encryption_types_client The encryption algorithm to be used is determined with this parameter. oracle.net.crypto_checksum_client The level of security regarding data integrity for the connection with the Oracle database is determined with this parameter. Accepted values include, REJECTED, ACCEPTED, REQUESTED, and REQUIRED. Example oracle.net.crypto_checksum_client="REQUIRED" oracle.net.crypto_checksum_types_client The data integrity algorithm to be used is determined with this parameter. PostgreSQL The following properties are applicable to the PostgreSQL database. These settings are used by the Platform for the connection towards the Platform database, and for ECs for connections towards external databases. Property Description Property Description postgresql.connectionpool.defaultQueryTimeout Default value: 300 Sets the maximum allowed duration in ms of any statement. postgresql.connectionpool.maxlimit Default value: 10 Maximum number of connections in the pool for the PostgreSQL database. It should be set to no less than the sum of the values of postgresql.connectionpool.maxlimit configured for Platform and database profiles connecting to this database. These settings are used by the Platform for the connection towards the Platform database and can also be used for ECs connections towards external databases and it is set on Database profile level. The following settings are used by the PostgreSQL Database for the connection to MediationZone, and are stored in the postgresql.conf file in the server that is hosting the PostgreSQL database. These settings are updated from the Psql Terminal using the ALTER SYSTEM sql command. Changes to the settings will require a restart of the PostgreSQL service. $ psql postgres=# ALTER SYSTEM SET max_connections = 110; ALTER SYSTEM Property Description Property Description max_connections Default value: 100 Maximum number of connections in the pool for the PostgreSQL database. It should be set to no less than the value set for postgresql.connectionpool.maxlimit. shared_buffers Default value: 32 Amount of memory (in MB) for caching data that should be dedicated to the PostgreSQL database. effective_cache_size Default value: 128 Amount of memory (in MB) for disk caching. The recommended effective size should be set to 1/2 of the total memory of the server. work_mem Default value: 1 Memory (in MB) for performing in-memory complex sorts in the database. random_page_cost Default value: 4.0 Multiplier value for determining the length of time it takes for the disk to seek a random disk page. SAP HANA The following properties are applicable to the SAP HANA database. These settings are used by the Platform for the connection towards the MediationZone database, and by ECs for connections towards external databases. Property Description Property Description saphana.connectionpool.maxlimit Default value: 10 This property specifies the maximum number of connections in the pool. It is recommended that the value is set to 3 or greater. A usual setting would be between 10 and 100.

---

# Document 1742: Debug Event - MediationZone Documentation 9.3 - InfoZone

**Source:** ratanon/mz93-documentation
**URL:** https://infozone.atlassian.net/wiki/spaces/MD93/pages/204605260
**Categories:** chunks_index.json

Dispatched when debug is used. The event is of Workflow type and therefore includes the following fields: agentMessage - Message issued by the agent. agentName - The name of the agent issuing the event. The following fields are inherited from the Base event, and described in more detail in Base Event : category contents eventName origin receiveTimeStamp severity timeStamp The following fields are inherited from the Workflow event, and described in more detail in Workflow Event : workflowKey workflowName workflowGroupName

---

# Document 1743: Error Codes - MediationZone Documentation 9.3 - InfoZone

**Source:** ratanon/mz93-documentation
**URL:** https://infozone.atlassian.net/wiki/spaces/MD93/pages/204606841
**Categories:** chunks_index.json

With the Error Codes option, errors can be specified in Data Veracity and associated with the erroneous UDRs or batch files. Error Codes could be used as an option when configuring the Data Veracity Collection Agent as it is used as an identifier for the workflow to collect certain Data Veracity record UDRs with the corresponding Error Codes. There are two predefined Error Codes within the system, AGGR_UNMATCHED_UDR and DUPLICATE_UDR , which are automatically set by the Aggregation and Duplicate UDR Detection agents when the corresponding error condition is detected. All other Error Codes are defined by the user. Open Data Veracity - Error Codes Error Code Sort Order Sorting by Name column is based on Javas default sorting behavior for Strings(for example, sorting of alphabetical characters in Java is case sensitive). To create an Error Code, click on the New button. This will display the Data Veracity Create Error Code dialog. This is where assignments of new Error Codes are made. Open Data Veracity Create Error Code dialog Item Description Item Description Error Code The Error Code that will be attached to UDRs or batches. Description A description of the error code. A user may send optional information to Data Veracity from an Analysis or an Aggregation agent, as long as an Error Code has been defined. To this Error Code, any information may be appended using APL. See the example below. Example An Error Case can be appended using APL code. udrAddError( input, "CALL ID ERROR", "The callId: " + input.callId + ", Calling number: " + input.anum ); In this example the "CALL ID ERROR" is defined in the Data Veracity Error Code dialog, found in the Error Code Web UI Note! To clear the errors for a UDR the udrClearErrors function should be used.

---

# Document 1744: ECS Changing State - MediationZone Documentation 9.3 - InfoZone

**Source:** ratanon/mz93-documentation
**URL:** https://infozone.atlassian.net/wiki/spaces/MD93/pages/204738720/ECS+Changing+State
**Categories:** chunks_index.json

You can change the state of a selected number of entries, or if no entries are selected, all entries. Possible states are New or Reprocessed . Reprocessed means that the entry has been collected by an ECS agent and been reprocessed with errors. Already processed data can be reset to New to enable recollection. Note! If the number of matches is larger than the maximum number of UDRs that can be displayed (see Maximum Number of Displayed UDR Entries in the ECS Inspector ), the state change is still applied to all matching entries. To change state of selected or all entries: Select the entries you want to change in the table, or click the Select All button to apply changes to all matching entries. Then right-click and select Set State... The Set State dialog opens where you can see the total number of entries that will be affected. Note! If the number of matching entries exceeds the maximum number of entries that can be displayed in the ECS Inspector, the dialog only tells you that all matching entries will be affected. If you proceed, another dialog opens up with information about the total number of entries that will be affected, asking you if you want to continue. Select state New or Reprocessed and click OK . If the number of matching entries exceeds the maximum number of entries that can be displayed you will get a question if you want to continue. Click Yes if you want to continue. If the number of matching entries exceeds the maximum number of entries that can be displayed, a progress bar will show the progress of the state change. This may be useful if you are changing the state for a large number of entries. Otherwise, the state simply changes in the table and the timestamp in the Last RP State Change column is updated.

---

# Document 1745: Installation Overview PCC - MediationZone Documentation 9.3 - InfoZone

**Source:** ratanon/mz93-documentation
**URL:** https://infozone.atlassian.net/wiki/spaces/MD93/pages/204997065
**Categories:** chunks_index.json

The Policy Charging and Control solution depends on a set of components. The order in which these are installed is defined here: Installing MediationZone to provide the majority of the functions in [CZ] and [EZ], see Installation of Control Zone and Execution Zone for PCC . Installing the Data Repository. [DR] for storage and [CZ] for management, see Installation of the Data Repository for PCC .

---

# Document 1746: A Diameter Example - MediationZone Documentation 9.3 - InfoZone

**Source:** ratanon/mz93-documentation
**URL:** https://infozone.atlassian.net/wiki/spaces/MD93/pages/204738547/A+Diameter+Example
**Categories:** chunks_index.json

This section describes an example based on two workflow configurations that include Diameter agents and profiles. The configurations perform the following tasks: The Diameter client workflow creates a request based on input from a TCP/IP agent and routes it to the Diameter server workflow. The Diameter server workflow creates an answer to the received request and routes it back to to the Diameter client workflow. The Diameter client workflow forwards the response to the TCP/IP agent. Follow these steps to run the example: Open the System Importer and select diameter_example.zip . Import all configurations. Add dia1 and dia2 to /etc/hosts . Example. /etc/hosts 127.0.0.1 localhost 127.0.0.1 dia1,dia2 Start the imported workflows. Connect to the TCP/IP agent in the client workflow via netcat (or nc). Enter a string and an integer, separated by a comma. Example. Input to client workflow $ netcat localhost 3210 user,10 If the workflows successfully processed the input, 1 (one) will be sent to the terminal.

---

# Document 1747: Single Sign On (OIDC) - MediationZone Documentation 9.3 - InfoZone

**Source:** ratanon/mz93-documentation
**URL:** https://infozone.atlassian.net/wiki/spaces/MD93/pages/204678589/Single+Sign+On+OIDC
**Categories:** chunks_index.json

Single sign-on (SSO) is a way to log in only once and access different applications using the same login details. It is convenient, efficient, and secure. You just need to change the password once and not have to worry about updating it across other applications. Open Login with SSO MediationZone supports SSO using an OpenID Connect ( OIDC) compliant Identity Provider. Microsoft Active Directory can be configured to act as such an Identity Provider. The system can act as a Relaying Party in the OIDC 1.0 flow. Refer for more details: https://openid.net/specs/openid-connect-core-1_0.html . The conceptual diagram below describes the details of the OIDC SSO authentication flow toward Active Directory. Open OIDC SSO Authentication Diagram Configuration To turn on SSO several properties need to be added to the platform and will take effect after a platform restart. The following properties are mandatory. Property Description Property Description auth .oidc.rp.c lient.id Default value "" Cl ient ID provi ded by Identity Provider. If it is not present, the SSO functionality is disabled. auth.oidc.rp.provider.url Default value "" Provide the Base URL to the associated Identity Provider. This URL, concatenated with `/.well-known/openid-configuration`, must retrieve the OpenID Provider's configuration as per the OpenID Connect Discovery specification. Example: https://login.microsoftonline.com/<tenant_ID>/v2.0 auth.oidc.rp.provider.name Default value "" The name of the provider needs to b e Azure if it is used and groups are returned as uids. auth.oidc.rp.groupPath Default value "roles" Path in ID Token or UserInfo object to find an array of users Access groups as defined by the Access Controller , separated with a dot (.). The groups should be an array of Strings. Example: Groups array in an object Here the groups array is inside an object . { myObject : { myGroups : [ "myGroup1", "mygroup2" ] } } The path should then be: groupPath: myObject.myGroups When the group's array is directly under UserInfo then groupPath is just the name of the group's array. auth.oidc.rp.auth.method Default value "CLIENT_SECRET_BASIC" Available authentication methods are CLIENT_SECRET_BASIC and PRIVATE_KEY_JWT The following property is mandatory when CLIENT_SECRET_BASIC is used as an authentication method: Property Description Property Description auth.oidc.rp.client.secret Default value "" This property sets the relevant Client Secret. Needs to be encrypted. You need to add the following values to the OIDC provider as redirect URLs: Property Description Property Description User Interface http(s)://<hostname>:<ui-webserver-port>/desktop/sso Desktop Launcher http(s)://<hostname>:<platform-webserverport>/launch/api/desktop/v1/sso The following properties are mandatory when PRIVATE_KEY_JWT is used as an authentication method: Property Description Property Description auth.oidc.rp.auth.jwt.keystorePath Default value "" Path to JKS keystore when PRIVATE_KEY_JWT is used auth.oidc.rp.auth.jwt.alias Default value "" Alias for key in keystore when PRIVATE_KEY_JWT is used auth.oidc.rp.auth.jwt.keystorePassword Default value "" Keystore password when PRIVATE_KEY_JWT is used, needs to be Encrypted by MediationZone. auth.oidc.rp.auth.jwt.keyPassword Default value "" Key password when PRIVATE_KEY_JWT is used, needs to be Encrypted by eMediationZone. The following properties are optional: Property Description Property Description auth.oidc.rp.scopes Default value "" Optional additional scopes. Default scopes are openid, profile, and email. auth.oidc.rp.claims.username Default value "" Claim to use as the user name, if not specified sub will be used. This value should be unique. auth.oidc.rp.auth.jwt.keyId Default value "" Optional Key ID for JWT header when PRIVATE_KEY_JWT is used auth.oidc.rp.group.syncDisabled Default value false. Disable group synchronization from Identity Provider. When this is true groups are set manually on each SSO User. auth.oidc.rp.group.default Default value "" When Group Sync is disabled a default group can be added to users logged in through SSO auth.oidc.rp.multigroupsync.defaultGroup Default value "" This property assigns a default group to the user who is a member of multiple groups when the user logs in for the first time . It takes effect only when the group synchronization is enabled. The default group can be changed after logging in and must be one of the member groups. Changes made to the default group after logging in will persist in the next login. auth.oidc.rp.auth.debug Default value false. Set this to true during the implementation of SSO Access to get more information. Use the following command to add the properties: Example - topo mzsh topo open platform Azure as Identity Provider When Azure is used as an ID provider, be sure to set the property auth.oidc.rp.provider.name to Azure to be able to fetch the groups. Then the groups are fetched from Microsoft Graph REST API. A request to the user's endpoint to get the group membership is performed. Make sure to add API Permission GroupMember.Read.All in Azure. Private Key Authentication When the method: "PRIVATE_KEY_JWT" is used, you need to create a Java Keystore in JKS format using an EC or RSA algorithm. The signing algorithm of the JWT used to authenticate to the Token Endpoint will be RS256 for RSA keys and ES256 for EC keys. The script below shows how these can be generated. Note that this will generate a self-signed certificate, which is not suitable for use in publicly exposed interfaces. Make sure to set the parameters at the beginning of the script before execution. This script produces the ssokeystore.jks . It also produces the file publicCert.pem , this file should be uploaded to the ID provider in advance. Example - How to generate a self-signed certificate #!/bin/bash KEY_PASSWORD=DefaultKeystorePWD STORE_PASSWORD=DefaultKeystorePWD DNAME=CN=exampledomain.com,O=Example  rm -f ssokeystore.jks publicCert.pem  keytool -genkey -keystore ssokeystore.jks -storepass $STORE_PASSWORD -keypass $KEY_PASSWORD -alias certificate -keyalg RSA -keysize 2048 -dname $DNAME keytool -keystore ssokeystore.jks -exportcert -alias certificate -rfc -file publicCert.pem -deststorepass $STORE_PASSWORD

---

# Document 1748: Preparing the Installer File for the Execution Container - MediationZone Documentation 9.3 - InfoZone

**Source:** ratanon/mz93-documentation
**URL:** https://infozone.atlassian.net/wiki/spaces/MD93/pages/204996904/Preparing+the+Installer+File+for+the+Execution+Container
**Categories:** chunks_index.json

To unpack the software, get the install.xml file: Create a directory to use when unpacking this release and future releases. For the purpose of these instructions, this designated directory is referred to as the staging directory . Note! The staging directory should not be the same directory as the one you created and set up as the MZ_HOME directory. The MZ_HOME directory still needs to be empty for the installation to succeed. Place the *.tgz file and the license file from your release delivery into the staging directory . Use a command line tool, go to the staging directory , and unpack the *.tgz file by running the following command: $ tar xvzf <filename>.tgz A directory with the software to be installed is then created in the staging directory . For the purpose of these instructions, this directory is referred to as the release content directory . Now copy the MZ license file into the release content directory . $ cp mz.license <release content directory Enter the release content directory and prepare the install.xml file by running the following command: $ cd <release content directory> $ ./setup.sh prepare The *.mzp packages are now extracted into <release content directory>/internal/packages , and the install.xml is extracted into the release content directory . To extract the release content directory and the installation parameters: Hint! For more information about the installation procedure, use the following command to view a description of the steps in the different installation and upgrade scenarios: ./setup.sh help

---

# Document 1749: Supervision Event - MediationZone Documentation 9.3 - InfoZone

**Source:** ratanon/mz93-documentation
**URL:** https://infozone.atlassian.net/wiki/spaces/MD93/pages/205030587/Supervision+Event
**Categories:** chunks_index.json

When using the Supervision Service for real-time workflows, you can configure Supervision events to be generated when certain combinations of conditions are met. These conditions are based on the current values for specified MIM parameters. For example, you can configure a Supervision event to be generated when the throughput goes above a certain value, or when the heap size goes above a certain level, etc. See the section Services Tab in Workflow Properties for further information about how data is inserted into ECS. Filtering In the Event Setup tab, the values for all the event fields are set by default to All in the Match Value(s) column, which will generate event notifications every time a Supervision event is generated. Double-click on the field to open the Match Values dialog where you can click on the Add button to add which values you want to filter on. If there are specific values available, these will appear in a drop-down list. Alternatively, you can enter a hardcoded string or a regular expression. The following fields are available for filtering of Supervision events in the Event Setup tab: Supervision event specific fields action - With this field you can configure notifications to be sent only for certain actions. Actions are configured in Action Lists for the Decision Tables you have created for the Supervision Service in the Workflow Properties. Use regular expressions to filter on this field. cause - With this field, you can specify to generate notifications only for events with certain descriptions. The descriptions are added when configuring your actions for the Supervision Service. See t he section Supervision Service in Workflow Properties for further information. Use regular expressions to filter on this field. value - This field enables you to configure notifications to be sent only for events with certain content. The content is added when you configure your actions for the Supervision Service. See t he section Supervision Service in Workflow Properties for further information. Use regular expressions to filter on this field. Fields inherited from the Base event The following fields are inherited from the Base event, and can also be used for filtering, described in more detail in Base Event : category - If you have configured any Event Categories, you can select to only generate notifications for Supervision events with the selected categories. See Event Category for further information about Event Categories. contents - This field contains the action type configured in the Supervision Service, i e Supervision Event, and the cause, i e the name of the action, as well as the value. eventName - This field can be used to specify which event types you want to generate notifications for. This may be useful if the selected event type is a parent to other event types. However, since the Supervision event is not a parent to any other event, this field will typically not be used for this event. origin - If you only want to generate notifications for events that are issued from certain Execution Contexts, you can specify the IP addresses of these Execution Contexts in this field. receiveTimeStamp - This field contains the date and time for when the event was inserted into the Platform database. If you want to use timeStamp for filtering, it may be a good idea to enter a regular expression, for example, "2012-06.*" for catching all Supervision events from 1st of June, 2012, to 30th of June, 2012. severity - With this field you can determine to only generate notifications for events with a certain severity; Information, Warning, Error or Disaster. However, since Supervision events only have severity Information, this field may not be very useful for filtering. timeStamp This field contains the date and time for when the Execution Context generated the event. If you want to use timeStamp for filtering, it may be a good idea to enter a regular expression, for example, "2012-06-15 09:.*" for catching all Supervision events from 9:00 to 9:59 on the 15th of June, 2012. Fields inherited from the Workflow event The following fields are inherited from the Workflow event, and can also be used for filtering, described in more detail in Workflow Event : workflowGroupName - This field can be used for configuring Supervision event notifications to be generated only for specific workflow groups. Simply select the workflow groups you want to generate Supervision events for in the drop-down-list, or enter a regular expression. workflowKey - This filed can be used for configuring Supervision event notifications to be generated only for specific Workflow Keys. You can browse for the workflow keys you want to add, or enter a regular expression. workflowName - This field can be for configuring Supervision event notifications to be generated only for specific Workflow Names. You can browse for the workflow names you want to add, or enter a regular expression. Note! The values of these fields may also be included in the notifications according to your configurations in the Notifier Setup tab.

---

# Document 1750: ECS Restricted Fields Configuration - MediationZone Documentation 9.3 - InfoZone

**Source:** ratanon/mz93-documentation
**URL:** https://infozone.atlassian.net/wiki/spaces/MD93/pages/204607365
**Categories:** chunks_index.json

The purpose of the restricted fields configuration is to make it possible to mark certain fields as read-only in the ECS Inspector. For instance you might want to guard some UDR fields from being edited to avoid losing traceability. The ECS Restricted Fields configuration is viewable (read-only) for all users with access to the ECS Inspector. Only users belonging to the administrator group are allowed to edit the configuration. Restrictions can be set on any UDR type, also within sub-UDRs. The restrictions are applied recursively so if there are restrictions on a UDR field of a certain type, all sub-fields are blocked from editing as well. The restrictions defined in the ECS Restricted Fields configuration are valid only in the ECS. I.e. the UDRs are still possible to modify outside the ECS (unless they have been explicitly defined as read-only in the UDR definition). It is possible to import and export the ECS Restricted Fields configuration if needed. The configuration is located in the System Exporter file tree viewer under System  ECS  Restricted Fields . Note! The access rights described above apply also to importing and exporting. This means that any user can export the ECS Restricted Fields configuration (as long as they have ECS Inspector access) but only members of the administrator group can import the ECS Restricted Fields configuration. To restrict certain UDR type fields from being edited in the ECS Inspector, specify those fields in the ECS Restricted Fields dialog (opened from the ECS Inspector  Restricted Fields button). Note! Only users belonging to the administrator group are allowed to configure restricted fields. However, all users can view the configured restrictions. Open Restricted Fields dialog To configure restricted fields: Click the Add button beneath the Restricted UDR Types section. The UDR Internal Format Browser dialog opens. Open UDR Internal Format Select the UDR Type for which you want to restrict fields from being edited and click Apply . The UDR type is added to the Restricted UDR Types list. Repeat the previous step for all the UDR Types you want to add, and then click OK to close the dialog. Select one of the UDR Types that you have added and click the Add button beneath the Restricted Fields section. The UDR Internal Format Browser dialog opens. Open UDR Internal Format Browser Select a field you want to restrict from being edited and click Apply . The UDR type is added to the Restricted Fields list. Repeat the previous step for all the fields you want to restrict from being edited, and then click OK to close the dialog. When you are finished, click Save in the ECS Restricted Fields dialog. The configured fields are now blocked from editing in the ECS Inspector.

---

# Document 1751: Exceeded Time Interval Detection Reports - MediationZone Documentation 9.3 - InfoZone

**Source:** ratanon/mz93-documentation
**URL:** https://infozone.atlassian.net/wiki/spaces/MD93/pages/205783951/Exceeded+Time+Interval+Detection+Reports
**Categories:** chunks_index.json

MediationZone can be configured to deliver Audit Data generated reports when the time interval between two consecutive UDRs has exceeded the threshold specified by the customer. This type of Audit is beneficial as it can: Alert (by linking to alarms) network departments about disturbances Provide traffic insight Below is the table layout for time gap detection mechanism. Parameter Type Description Parameter Type Description ID NUMBER Type of technology FILE_NAME VARCHAR Name of processed file PROCESSED_DATE DATE SYSDATE DELAY NUMBER Delay in seconds TIME_LIMIT NUMBER Limit in seconds ANSWER_TIME_1 DATE Answer time for the first UDR ANSWER_TIME_2 DATE Answer time for the second UDR Below is a report tracking consecutive UDRs that have exceeded the time interval criteria for different call flows. This kind of reporting eases the detection of network and switch problems by showing the lack of activity during periods of time. ID FILE_NAME PROCESS_DATE DELAY LIMIT ANSWER_TIME_1 ANSWER_TIME_2 ID FILE_NAME PROCESS_DATE DELAY LIMIT ANSWER_TIME_1 ANSWER_TIME_2 01 U070416200595GCDR 17-04-07 05:59 31 10 16-04-2007 00:12:20 16-04-2007 00:12:51 01 U070416200595GCDR 17-04-07 05:59 20 10 16-04-2007 00:30:10 16-04-2007 00:30:30 01 U070416200595GCDR 17-04-07 05:59 12 10 16-04-2007 01:40:05 16-04-2007 01:40:17 02 U070416194294GCDR 17-04-07 05:56 35 30 16-04-2007 02:25:05 16-04-2007 02:25:22 02 U070416192093GCDR 17-04-07 05:53 42 30 16-04-2007 04:05:30 16-04-2007 04:05:35 01 U070416190092GCDR 17-04-07 05:50 20 10 16-04-2007 05:59:51 16-04-2007 06:00:10 01 U070416184291GCDR 17-04-07 05:47 22 10 16-04-2007 06:10:02 16-04-2007 06:10:25

---

# Document 1752: Analysis Agent Input/Output Data and MIM - MediationZone Documentation 9.3 - InfoZone

**Source:** ratanon/mz93-documentation
**URL:** https://infozone.atlassian.net/wiki/spaces/MD93/pages/204672103/Analysis+Agent+Input+Output+Data+and+MIM
**Categories:** chunks_index.json

Input/Output Data The input/output data is the type of data an agent expects and delivers. Produced types are dependent on input type and the APL code. The agent consumes byte arrays and any UDR type selected from the UDR Types list. MIM The agent does not publish or access any additional MIM parameters. However, MIM parameters and values/Agent Message events/Debug events can be produced/accessed/dispatched through APL. For further information about available functions, see the section MIM Related Functions in the APL Reference Guide .

---

# Document 1753: Parquet Profile Configuration Advanced - MediationZone Documentation 9.3 - InfoZone

**Source:** ratanon/mz93-documentation
**URL:** https://infozone.atlassian.net/wiki/spaces/MD93/pages/205001151/Parquet+Profile+Configuration+Advanced
**Categories:** chunks_index.json

The Advanced tab includes additional properties for optimizing the performance of the Parquet encoding. Note that these parameters are only used by the Parquet Encoder. None of these are choices when decoding. The Parquet profile's Advanced tab Setting Description Setting Description Compression Codec The compression algorithm used to compress pages when encoding. Valid choices are Uncompressed , Snappy , Gzip , Lzo , Brotli , Lz4 , and Zstd . Default is Uncompressed . Block Size The Block Size is the size of a row group buffered in memory. Block size limits the memory usage when writing. Larger values improve I/O when reading, but consumes more memory when writing. The Default Block Size is 134217728 . Page Size The page is the smallest unit that must be read fully to access a single record. When reading, each page can be decompressed independently. If this value is too small, the compression deteriorates. The Default Page Size is 1048576 . Dictionary Page Size There is one dictionary page per column per row group when dictionary encoding is used. Dictionary page size works like the page size, but for dictionary encoding. Default is 1048576 . Enable Dictionary Select this checkbox to include the dictionary compression strategy in the generated Parquet document. Enable Dictionary allows for building a dictionary of values encountered in columns. Validating Select this checkbox to enable schema validation. Writer Version Parquet format version to use when writing. Version 1.0 (v1) ensures compatibility with older readers. Default is v1 . There is also the option to set v2 .

---

# Document 1754: AMQP UDRs - MediationZone Documentation 9.3 - InfoZone

**Source:** ratanon/mz93-documentation
**URL:** https://infozone.atlassian.net/wiki/spaces/MD93/pages/204606332/AMQP+UDRs
**Categories:** chunks_index.json



---
**End of Part 73** - Continue to next part for more content.
