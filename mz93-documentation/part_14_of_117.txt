# RATANON/MZ93-DOCUMENTATION - Part 14/112

---
**Dataset:** ratanon/mz93-documentation
**Part:** 14 of 112
**GitHub:** https://github.com/ratan0n/docs/tree/main/mz93-documentation
**Size:** ~63.9 KB
---

usage: topo <subcommand> <options> This command is used to register containers in STR and to create, update, remove, and view pico configurations. Note! This command is valid only for the MZ_HOME owner. When you make changes in pico configurations, using topo , these are automatically validated before they are copied to the active registry. If the command and its arguments can be parsed but fail the validation, you can update the configuration or use a reset command to undo the changes. An error message will appear if the validation fails. You can disable the validation by using the option --no-activation . Changes performed by the mzcli topo will then remain in the master registry until you submit a separate topo activate command. You can use the following subcommands with topo: activate container convert diff get hash help migrate rebase-configs register reset set setupremote show unset activate Usage: topo activate [--dry-run] [-v, --verbose] Use topo activate to move staged changes in the master registry to the active registry. Option Description Option Description [--dry-run] Use this option to validate the staged changes without performing the activation. [hash <hash value>] Compare the provided hash value with the actual hash that represents the current state of active registry. The activation fails if the values are not equal. For further information, see hash below, [-v, --verbose] Use this option for detailed information about the changes. Hint! The options --dry-run and --verbose are useful to learn the mzcli topo syntax. When you have edited the configuration manually, use the following command, to view the corresponding edits in a scripted syntax: $ mzcli topo activate --dry-run --verbose Example - Output from activate with verbose Option $ mzcli topo activate -v --dry-run mzcli topo set topo://container:main1/pico:ec1/val:config.properties.ec.httpd.port 9096 # (was: 9092) Dry-run: Validation successful Dry-run: Stopping without performing activation Dry-run: Active registry not changed You can then restore the master registry with the command mzcli topo reset . Example - Restart the Picos to Apply the Changes Changes to the STR are not applied on running pico instances or services. If you, for example, have updated the properties of the Platform and an EC, both must be restarted after activation. Example, after an mzcli topo activate of ec5, mzcli shutdown and startup needs to be done to apply the changes. $ mzcli shutdown ec5 $ mzcli startup ec5 container Usage: topo container Use topo container to display the name of the current container. convert Usage: topo convert [-c, --container <container>] [-g, --container-group <container group>] [--dry-run] [-f, --file <filename>] Use topo convert to move the configuration of a specific XML file to STR. Option Description Option Description [-c, --container <container>] Use this option to specify a target container. [-g, --container-group <container group>] Use this option to specify a target container group. [--dry-run] Use this option to validate that the conversion and display the result of the conversion without updating the STR. [-f, --file <filename> Use this option to specify the source XML file. Example - Converting an XML File $ mzcli topo convert --container main1 diff Usage: topo diff [-e, --show-entries] [-f, --from <registry>] [-q, --brief] Use topo diff to view differences between the master repository and the active repository in the STR. Option Description Option Description [-e, --show-entries] Use this option for viewing differences in an easy-to-read format. By default, the output from the command displays topo set commands that correspond to the staged changes. Example - Output from diff Command With -e option: UPDATE (containers/main1/picos/ec1.conf) config.properties.aaa:"2" # (was: "1") Without -e option: mzcli topo set topo://container:main1/pico:ec1/val:config.properties.aaa "2" # (was: "1") [ -f, --from <registry>] Use this option when you want to compare the active registry with the backup registry [-q, --brief] Use this option to only view the names of the updated registry files. The default value is false. Example - Comparing Registry Files Run the following command to view the differences between the active registry and the master registry. $ mzcli topo diff or $ mzcli topo diff --from master Run the following command to view the differences between the active registry and the backup registry. $ mzcli topo diff --from backup get Usage: topo get [--default-val <value>] [ --exclude-dynamic] [--format <full | data-only>] [-l, --local] [-p, --perspective] <target path>] Use topo get to retrieve pico configurations in the target path from STR. Paths in STR are structured as follows: topo://container:<container>/pico:<pico>/val:<attribute> Option Description Option Description [--default-val <value>] Use this option to replace a missing value in the target path with a default value. Example - Using default-val If the property aaa, is not defined for ec1, 123 is returned instead. $ mzcli topo get -l --default-val 123 topo://pico:ec1/val:config.properties.aaa [ --exclude-dynamic] Use this option to exclude non-static data in the output e g _status in a pico configuration. This is useful in case of errors that blocks the topo command. [--format <full|data-only>] Use this option to exclude metadata from the command output. full - Include meta data data-only - exclude meta data Default: full [-l, --local] Use this option to select the local container, unless another container is specified in the target path. Default: false [-p, --perspective <resolve | default>] Use this option to retrieve the attributes of templates instead of the template names. resolve - attributes default - template names Default: default Example - Viewing Pico Configurations Run the following command to view one or more pico configurations. $ mzcli topo get topo://container:main1/pico:ec2 You can view multiple pico configurations by replacing the full path with a regular expression. $ mzcli topo get topo://container:main1/pico:.* Example - Viewing Pico Attributes Run the following command to view a specific attribute in a pico configuration. $ mzcli topo get topo://container:main1/pico:ec2/val:_name You can retrieve the attributes of multiple pico processes by replacing the full path with a regular expression. $ mzcli topo get --format data-only topo://container:main1/pico:.*/val:_name hash Usage: topo hash Use topo hash to retrieve a value that represents the current state of the active registry. This is useful when you need to handle concurrent changes of the STR. For instance, an application may need to retrieve a pico configuration to evaluate the required changes. In the meantime, a second application or a user may update the same configuration. Example - Using Hash Values Application 1 retrieves a new hash value. $ mzcli topo hash "3a2e373fa1653c7f0e757e2682c70317-2028777631" Application 1 retrieves the properties of ec1. $ mzcli topo get -l pico:ec1/obj:config.properties Application 1 updates a property but does not call topo activate . The hash is specified to ensure that changes by other users are not activated inadvertently later on. $ mzcli topo set -l --no-activation --hash 3a2e373fa1653c7f0e757e2682c70317-2028777631  topo://pico:ec1/val:config.properties.ec.httpd.port 9090 Application 2 updates the properties of ec1. The hash value is updated. $ mzcli topo set -l topo://pico:ec1/val:config.properties.ec.httpd.port 9090 Application 1 calls topo activate with hash value retrieved in step 1. $ mzcli topo activate --hash 3a2e373fa1653c7f0e757e2682c70317-2028777631 The activation fails since the hash values do not match. Specified hash does not match transaction id: d9cd38f3793647028bd7e5d64c354ad5-2055434210 != 3a2e373fa1653c7f0e757e2682c70317-2028777631) This may indicate concurrent modification of registry: Operation aborted! Application 1 resets the master registry, retrieves a new hash and starts over. $ mzcli topo reset $ mzcli topo hash help Usage: topo help [<subcommand>] Use topo help to retrieve a description of a subcommand. Run the following command for an overview of the various topo subcomands $ mzcli topo help Run the following command for a description of a specific subcomand $ mzcli topo help <command> migrate Usage: topo migrate Use topo migrate to move pico configurations from $MZ_HOME to STR. The upgrader runs this command during upgrade. rebase-configs Usage: topo rebase-configs [-a, --activate] <target path> Use topo rebase to inset a standard template in a pico configuration and remove attributes that are identical to attributes in the template. The command automatically detects the pico configuration type and applies one of the following templates: mz.standard-platform.conf mz.standard-ec.conf mz.standard-sc This command is useful to reduce the size of the pico configurations and thereby facilitate maintenance. The changes are written to the master registry. To validate and activate the changes you can either use the --activate option or run topo activate after the topo rebase-configs command. For further information about templates, see https://infozone.atlassian.net/wiki/x/MyUzD . Option Description Option Description [-a, --activate] Use this option to immediately activate after changes in master registry. Example - Rebasing an EC Configuration mzcli topo rebase-configs topo://container:main1/pico:ec1$ mzcli topo active --verbose or mzcli topo rebase-configs --activate topo://container:main1/pico:ec1 register Usage: topo register [-a, --address] [-c, --container] [-g, --container-group <container group>] [--mz-home <mz home>] [-u] When you install an execution container, and the Platform is running, it is automatically registered in the Platform Container. If the platform is not running during the installation, use topo register to register the Execution Container manually. Option Description Option Description [-a, --address <ip/host>] Use this when you need to set a different host address for the container than the one that is specified in the common property pico.rcp.server.host , which is the default value. This option is typically used together with the -u option. [-c, --container <container>] Use this option when you need to change the existing container name. This option is typically used together with the -u option. [-g, --container-group <container group>] Use this option when you need to change the existing container group. This option is typically used together with the -u option. [--mz-home <path>] Use this option when you need to set a different home directory for the container than the one that is specified in the environment variable MZ_HOME, which is the default value. [-u] Use this option to allow updates of an already registered container. By default, updates are not allowed and the command will attempt to register a new container. reset Usage: topo reset [-f, --from <registry>] Use topo reset to remove any changes to the master registry in STR since the activation. Option Description Option Description [-f, --from <registry>] Use this option to state the name of the registry to reset from. Valid registries are: active, backup. set Usage: topo set [-l, --local] [-n, --no-activation] [-s, --strict-json] <target path> <config> Use topo set to create and update pico configurations in the specified target-path of STR. Option Description Option Description [-l, --local ] Use this option to select the local container, unless another container is specified in the target path. [--no-activation, -n] Use this option to skip activation after changes in master registry. [-s, --strict-json] Use this option when you want to specify the configuration in JSON format instead of HOCON format. Run the following command to create a new pico configuration. $ mzcli topo set topo://container:<container>/pico:<pico> <config> The <config> argument may contain a key-value pair that specifies a template or a pico configuration in HOCON format. Example - Creating a New Pico Configuration Based on a Template $ mzcli topo set topo://container:main1/pico:ec2 template:mz.standard-ec Example - Creating Pico Configuration When you specify a pico configuration that consists of multiple attributes, it is recommended that you use multi-line strings. HOCON Format: $ mzcli topo set --local pico:ec2 ' { template:mz.standard-ec config { properties { ec.httpd.port : 9092 } classpath { jars=["lib/picostart.jar"] } } }' JSON Format: mzcli topo set -l --strict-json pico:ec2 ' { "template": "mz.standard-ec", "config": { "properties": { "ec": { "httpd": { "port": 9092 } } }, "classpath": { "jars": ["lib/picostart.jar"] } } }' Add the pico group setting by using the following topo command mzcli topo set topo://container:main1/pico:ec1/val:config.properties.pico.groups "ec1, ec2" This command makes the Execution context "EC1" a member of the "ec1" and "ec2" groups. This is the HOCON example format adding in ECs to a pico group. config { classpath {} jvmargs { args=[] } properties { mz.webserver.xframeoptions=DENY pico.groups="ec1, ec2" ec.backlog.dir="/opt/mz/tmp" ec.webserver.port=9137 } vendor-jvmargs { hp {} sun {} } } Run the following command to add or update an attribute of a pico configuration. mzcli topo set topo://container:<container>/pico:<pico>/val:<attribute> <attribute value> Example - Updating a Pico Attribute $ mzcli topo set topo://container:main1/pico:ec2/val:ec_type ec Run the following command to add or update an object that contains one or more attributes. $ mzcli topo set topo://container:<container>/pico:<pico>/obj:<object name> '<config>' The <config> argument may contain a pico configuration in HOCON format. Example - Updating a Pico Object This command adds the properties value1 and value2 : $ mzcli topo set topo://container:main1/pico:ec2/obj:config.properties.example_object '{ value1=1 value2=2 }' The following commands does not overwrite the properties value1 and value2 in example_object but adds value3 : $ mzcli topo set topo://container:main1/pico:ec2/obj:config.properties.example_object '{ value3=3 }' setupremote Usage: topo setupremote [-c, --container <container>] [-g, --container-group <container group>] [--host-key <path>] [--javahome <path>] [--no-authorized-key] [--no-host-key] [-- no-ssh-details] [--ssh-address <ip/host>] [--ssh-port <port>] [--ssh-username <username>] Use the command topo setupremote to enable remote access via SSH to an Execution Container, e g from the Platform container. Option Description Option Description [-c, --container <container>] Use this option to specify a different container than the local one, which is the default value. [-g, --container-group <container group>] Use this option to setup remote access to a container in specific container group. This is useful when you have multiple containers with identical names in different containers groups. [--host-key <path>] Use this option to use a pre-generated host key instead of the one that is generated when you run topo setupremote . [--java-home <path>] Use this option when the target container is located on a different host. The default value is specified by the environment variable JAVA_HOME in the current shell. [--no-authorized-key] By default, the topo setupremote command will obtain a public authorization key from the user home directory on the Platform Container host and store it in the STR, i e the file mz.conf . Use the option --no-authorized-key to skip this operation. [--no-host-key] By default, the topo setupremote command will store the public host key of the Execution Container in the STR, i e the file mz.conf . Use the option --no-host-key to skip this operation. [--no-ssh-details] Use this option to exclude ssh-username and ssh-address from STR. These attributes are required for remote access. If you use this option you will need to update the STR manually. [--ssh-address <ip/host>] Use this option when the target container is located on a different host or when you want to bind to a specific IP address or hostname. The default value is specified by the address attribute for container in mz.conf . [--ssh-port <port>] Use this option when you want to use a different port than 22 for SSH. [--ssh-username <username>] Use this option when the target container is located on a different host or when a specific username is required for SSH. The default SSH user is the OS user that runs the topo setupremote command. show Use topo show to retrieve various types of information about pico instances that are defined in the STR. Usage: topo show [ --exclude-dynamic] [--format <format>] [-l, --local] [--timeout-seconds <time>] <view> Option Description Option Description [ --exclude-dynamic] Exclude non-static data in the output e g _status in a pico configuration. This is useful in case of errors that blocks the topo command. [ --format <format>] Set the format of the returned data: csv json table (default) [ -l, --local ] Use this option to view pico instances in the local container only. By default, all containers are included. [--timeout-seconds <time>] Use this option to limit the time for retrieving dynamic information, e g _status .The default value is 10 seconds. The following views are available: jvm-args - Displays the JVM arguments that are used by the pico instances in the system. JVM arguments that are set in templates are included. status - Displays the container name, pico name, pico type and running state. status-sc - Displays similar view as status but only includes SCs. status-ec - Displays similar view as status but only includes ECs. status-long - Displays similar view as status but also includes the status of replication between Platform Container and Execution Containers. pico-view - Displays similar view as status but also includes memory usage and the pico response time. pico-view2 - Displays similar view as pico-view but also includes uptime. ports - Displays the ports that are used by the pico instances in the system. Ports that are set in templates and on cell- and container level, are included. If both webserver and httpd ports are displayed, then webserver ports take precedence. Example - Views $ mzcli topo show jvm-args +------------------------------------------------------------- | container | name | config.jvmargs | +-----------+----------+-------------------------------------+ | main1 | platform | args=[ | | | | "-XX:MaxMetaspaceSize=256M", | | | | "-Xms192M", | | | | "-Xmx1024M" | | | | ] | +-----------+----------+-------------------------------------+ | main1 | ec1 | args=[ | | | | "-server" | | | | ] | | | | maxDirect=[ | | | | "-XX:MaxDirectMemorySize=4096M" | | | | ] | | | | maxMetaspace=[ | | | | "-XX:MaxMetaspaceSize=196M" | | | | ] | | | | xms=[ | | | | "-Xms64M" | | | | ] | | | | xmx=[ | | | | "-Xmx256M" | | | | ] | +-----------+----------+-------------------------------------+ | main1 | psc1 | args=[ | | | | "-server" | | | | ] | | | | maxDirect=[ | | | | "-XX:MaxDirectMemorySize=4096M" | | | | ] | | | | maxMetaspace=[ | | | | "-XX:MaxMetaspaceSize=196M" | | | | ] | | | | xms=[ | | | | "-Xms64M" | | | | ] | | | | xmx=[ | | | | "-Xmx256M" | | | | ] | +-----------+----------+-------------------------------------+ | exec1 | ec2 | args=[ | | | | "-server" | | | | ] | | | | maxDirect=[ | | | | "-XX:MaxDirectMemorySize=4096M" | | | | ] | | | | maxMetaspace=[ | | | | "-XX:MaxMetaspaceSize=196M" | | | | ] | | | | xms=[ | | | | "-Xms64M" | | | | ] | | | | xmx=[ | | | | "-Xmx256M" | | | | ] | +------------------------------------------------------------- $ mzcli topo show status +--------------------------------------------------------------- | container | name | type | state | config-state | +-----------+----------+----------+-------------+--------------+ | main1 | platform | platform | running | in-sync | | main1 | ec1 | ec. | not-started | | | main1 | psc1 | sc | not-started | | | exec1 | ec2 | ec | not-started | | +--------------------------------------------------------------- $ mzcli topo show ports +---------------------------------------------------------------------------- | container | name | type | ports | +-----------+----------+----------+-----------------------------------------+ | main1 | platform | platform | "mz.pcc.restful.port"="9090" | | | | | "mz.servicehost.port.range"="5451-5500" | | | | | "mz.wi.port"="9000" | | | | | "pico.rcp.platform.port"="6790" | | | | | "pico.synchronizer.port"="6791" | +-----------+----------+----------+-----------------------------------------+ | main1 | ec1 | ec | "ec.httpd.port"="9093" | | | | | "pico.rcp.platform.port"="6790" | | | | | "pico.synchronizer.port"="6791" | +-----------+----------+----------+-----------------------------------------+ | main1 | psc1 | sc | "mz.servicehost.port.range"="5801-5850" | | | | | "pico.rcp.platform.port"="6790" | | | | | "pico.synchronizer.port"="6791" | +-----------+----------+----------+-----------------------------------------+ | exec1 | ec2 | ec | "ec.httpd.port"="9090" | | | | | "pico.rcp.platform.port"="6790" | | | | | "pico.synchronizer.port"="6791" | +---------------------------------------------------------------------------- unset Usage: topo unset [-l, --local] [-n, --no-activation] <target path> Use topo unset to remove pico configurations in the specified target-path of STR. Option Description Option Description [-l, --local] Use this option to select the local container, unless another container is specified in the target path. [-n, --no-activation] Use this option to skip activation after changes in master registry. Run the following command to remove a pico configuration. mzcli topo unset topo://container:<container>/pico:<pico> Example - Removing a Pico Configuration $ mzcli topo unset topo://container:main1/pico:ec2 Example - Removing a Pico Attribute $ mzcli topo unset topo://container:main1/pico:ec2/val:ec_type ec File Paths in Attributes When you enter a path that is relative to $MZ_HOME in the value of an attribute, it is recommend that you use ${mz.home} as a substitution. In the following example $MZ_HOME will be resolved to its current value e g /home/user/mz. Example - Resolved Path $ mzcli topo set topo://container:main1/val:common.pico.rcp.tls.keystore $MZ_HOME/keys/platform.keys The next example uses a path that is always relative to $MZ_HOME. Example - Substituted Path $ mzcli topo set topo://container:main1/obj:common.pico.rcp.tls.keystore '{ keystore=${mz.home}"/keys" }' When you are using ${mz.home} as a substitution, ensure to set attributes as part of an object, using the obj keyword. Conflicting Attributes The name of an attribute may contain the full name of another attribute. For instance, mz.httpd.security.keystore is a system property but its name is also a part of mz.httpd.security.keystore.password. In this case you must ensure that the name of both properties are surrounded by quotes, or one of the properties will be overwritten at activation. Example - Handling Conflicting Attributes, Manual Editing common : { "pico.rcp.tls.keystore" : "home/mz/keys", "pico.rcp.tls.keystore.password" : "..." } When there are conflicting properties and you are using the mzcli topo command, also add single quotes, surrounding the target path (topo://..). Example - Handling Conflicting Attributes, Scripted Editing $ mzcli topo set 'topo://container:<platform container>/val:common."pico.rcp.tls.keystore"' "home/mz/keys" $ mzcli topo set 'topo://container:<platform container>/val:common."pico.rcp.tls.keystore.password"' "..." Updating IP, Hostname, and Ports in JDBC URL You can update the IP address, hostname, and ports int he JDBC URL using the mzcli topo get and mzcli topo set commands as shown in the examples below. Example - Get Current Config $ mzcli topo get -s --format data-only topo://container:platform1/pico:platform/obj:config.properties.mz.jdbc { "password": "DR-4-48851644227183C2041D838568E117EC", "oracle": { "ons": "" }, "type": "oracle", "user": "mzadmin", "url": "jdbc:oracle:thin:@//127.0.0.1:1521/orcl" } Example - Update URL with set $ mzcli topo set topo://container:mz/pico:platform/val:config.properties.mz.jdbc.url "jdbc:oracle:thin:@//192.168.1.10:1522/orcl" [ set: topo://container:mz/pico:platform/val:config.properties.mz.jdbc.url => jdbc:oracle:thin:@//192.168.1.10:1522/orcl] Updating file: $MZ_HOME/common/config/cell/default/master/containers/mz/picos/platform.conf Topology activation completed (master->active) Caution! When you have set the new JDBC URL, run shutdown and startup on the platform to ensure that your changes take effect properly. If you added the incorrect config and the platform did not start, you can run your mzcli command again with the --allow-disconnected option Return Codes Listed below are the different return codes for the topo command: Code Description Code Description 0 Will be returned if the command is successful. 1 Will be returned if the argument count is incorrect or argument(s) are invalid. 3 Will be returned if the target path argument for the subcommand get does not exist.

---

# Document 291: KPI Management - External Software - MediationZone Documentation 9.3 - InfoZone

**Source:** ratanon/mz93-documentation
**URL:** https://infozone.atlassian.net/wiki/spaces/MD93/pages/204677074/KPI+Management+-+External+Software
**Categories:** chunks_index.json

To use KPI Management, you must install and start Spark, Kafka, and Zookeeper. The following chapters will explain the basic procedures for this, but please refer to the respective pages for details. The versions these instructions and KPI Management have been tested with are: Spark 3.5.0 for Scala 2.13 (the package name is spark-3.5.0-bin-hadoop3-scala2.13.tgz ) Kafka 3.3.2 for Scala 2.13 (the package is kafka_2.13-3.3.2.tgz and that also includes ZooKeeper) This section includes the following subsections: Spark, kafka and zookeeper Starting Clusters and Creating Topics Using Multiple Service Models

---

# Document 292: Python Module - MediationZone Documentation 9.3 - InfoZone

**Source:** ratanon/mz93-documentation
**URL:** https://infozone.atlassian.net/wiki/spaces/MD93/pages/204739939
**Categories:** chunks_index.json

With the Python Module configurations, you can write shared Python code that can be imported by multiple Python agents. This allows you to organize your Python code into different modules that can be reused. Open Python Module To access the Python Module, click the New Configuration button and then select Python Module from the menu. The entire Python Module configuration is a code area where you can write code that you want Python agents to be able to import. See the code section for the relevant agent for further information. The imported modules are referenced by the workflows, but as each agent has its own memory space, global variables will not be shared between agents or workflows. Python Code Editor Assistance To provide assistance when you are writing code in the Python code area, there are several features in place: Syntax Highlighting - Different parts of the code are color-coded according to type Right-click Menu - A menu that provides editor options. Code Completion - Helps you to write Python code in the Python Code Editor by providing context-sensitive proposals. For further information on these features, see Python Code Editor Assistance .

---

# Document 293: Inter Workflow Real-Time Collection Agent Transaction Behavior - MediationZone Documentation 9.3 - InfoZone

**Source:** ratanon/mz93-documentation
**URL:** https://infozone.atlassian.net/wiki/spaces/MD93/pages/205000674/Inter+Workflow+Real-Time+Collection+Agent+Transaction+Behavior
**Categories:** chunks_index.json

Although the Inter Workflow real-time collection agent is not transaction safe, it checks if the workflow queue is empty prior to removing the current batch from the storage. If the agent is stopped while there is still data in the workflow queue, the last batch will be collected again once the agent becomes active.

---

# Document 294: Operations REST Interface - MediationZone Documentation 9.3 - InfoZone

**Source:** ratanon/mz93-documentation
**URL:** https://infozone.atlassian.net/wiki/spaces/MD93/pages/205031043/Operations+REST+Interface
**Categories:** chunks_index.json

Operations such a workflow configuration, workflow execution plan, external references etc are exposed as an OpenAPI. A live instance of this OpenAPI can be accessed here for any given running Platform: Workflows http(s)://<platform server>:<platform port>/ops/mz/wf/v1/api-docs Workflow Groups http(s)://<platform server>:<platform port>/ops/mz/wfg/v1/api-docs External References http(s)://<platform server>:<platform port>/ops/extref/v1/api-docs Host http(s)://<platform server>:<platform port>/ops/mz/host/v1/api-docs Pico http(s)://<platform server>:<platform port>/ops/mz/pico/v1/api-docs Note! For Host and Pico , users must have Execute permission from the Pico Viewer application to access the API. This permission can be viewed and granted in Access Controller. This allows for exploration of the OpenAPI and it is also possible to place live requests against the running Platform granted that valid credentials are provided.

---

# Document 295: ADLS2 File Collection Agent Configuration - MediationZone Documentation 9.3 - InfoZone

**Source:** ratanon/mz93-documentation
**URL:** https://infozone.atlassian.net/wiki/spaces/MD93/pages/205031436/ADLS2+File+Collection+Agent+Configuration
**Categories:** chunks_index.json

You open the ADLS2 collection agent configuration dialog from a workflow configuration. To open the ADLS2 collection agent configuration, click Build  New Configuration . Select Workflow from the Configurations dialog. When prompted to Select workflow type, select Batch . Click Add agent and select ADLS2 from the Collection tab of the Agent Selection dialog. To open the ADLS2 file forwarding agent configuration dialog from a workflow configuration, you can do the following: double-click the agent icon, or, select the agent icon and click on the button Part of the configuration may be done in the Filename Sequence or Sort Order tab described in Workflow Template . The ADLS File tab contains settings related to the placement and handling of the source files to be co llecte d by the agent. Open ADLS2 File collection agent configuration - ADLS2 File tab Setting Description Setting Description Profile Select the Azure profile you want the agent to use, see Azure Profile for further information about this profile. Container Name Enter the name of the container where the files will be collected from. The container name can be found in the Containers section of the storage account that has been configured in the Azure Profile. Example An example container na me. Open Collection Strategy If there is more than one collection strategy available in the system a Collection Strategy drop-down list will also be visible. For more information about the nature of the collection strategy, refer to Appendix 4 - Collection Strategies . Directory The absolute pathname of the source directory on the location where the source files reside. Include Subfolders Select this check box if you have subfolders in the source directory from which you want files to be collected. If you select Enable Sort Order in the Sort Order tab, the sort order selected will also apply to subfolders. Filename Name of the source files in the location stated in the File System profile. Regular expressions according to Java syntax applies. For further information, see http://docs.oracle.com/javase/8/docs/api/java/util/regex/Pattern.html . Example To match all filenames beginning with TTFILE , type: TTFILE.* Compression Compression type of the source files. Determines if the agent will decompress the files before passing them on in the workflow. - No Compression - agent does not decompress the files. This is the default setting. - Gzip - agent decompresses the files using gzip. Move to Temporary Directory If enabled, the source files will be moved to the automatically created subdirectory DR_TMP_DIR in the source directory, prior to collection. This option supports safe collection of a source file reusing the same name. Append Suffix to Filename Enter the suffix that you want to be added to the file name prior to collecting it. Important! Before you execute your workflow, make sure that none of the file names in the collection directory include this suffix. Inactive Source Warning (hours) If the specified value is greater than zero, and if no file has been collected during the specified number of hours, the following message is logged: The source has been idle for more than <n> hours, the last inserted file is <file>. Move to If enabled, the source files will be moved from the source directory (or from the directory DR_TMP_DIR , if using Move to Temporary Directory ) to the directory specified in the >Destination field, after the collection. If the Prefix or Suffix fields are set, the file will be renamed as well. Note! It is only possible to move files within the same bucket. Destination The absolute pathname of the directory on the location specified in the referenced File System profile into which the source files will be moved after collection. This field is only enabled if Move to is selected. Rename If enabled, the source files will be renamed after the collection, remaining in the source directory from which they were collected (or moved back from the directory DR_TMP_DIR , if using the Move To Temporary Directory setting). Prefix/Suffix Prefix and/or suffix that will be appended to the beginning respectively the end of the name of the source files, after the collection. These fields are only enabled if Move to or Rename is selected. Note! If Rename is enabled, the source files will be renamed in the current directory (source or DR_TMP_DIR ). Be sure not to assign a prefix or suffix, giving files new names, still matching the filename regular expression, or else the files will be collected over and over again. Search and Replace To apply Search and Replace , select either the Move to or Rename setting. Search : Enter the part of the filename that you want to replace. Replace : Enter the replacement text. Search and Replace operate on your entries in a way that is similar to the Unix sed utility. The identified filenames are modified and forwarded to the following agent in the workflow. This functionality enables you to perform advanced filename modifications, as well: Use regular expression in the Search entry to specify the part of the filename that you want to extract. Note! A regular expression that fails to match the original file name will abort the workflow. Enter Replace with characters and meta characters that define the pattern and content of the replacement text. Search and Replace Examples To rename the file file1.new to file1.old , use: Search : .new Replace : .old To rename the file JAN2011_file to file_DONE , use: Search : ([A-Z]*[0-9]*)_([a-z]*) Replace : $2_DONE Remove If enabled, the source files will be removed from the source directory (or from the directory DR_TMP_DIR , if using the Move To Temporary Directory setting), after the collection. Ignore If enabled, the source files will remain in the source directory after collection. Keep (days) Number of days to keep source files after the collection. In order to delete the source files, the workflow has to be executed (scheduled or manually) again, after the configured number of days. Note! A date tag is added to the filename, determining when the file may be removed. This field is only enabled if Move to or Rename is selected. Route FileReferenceUDR Select this check box if you want to forward the data to an SQL Loader agent. See SQL Loader Agent for further info rmat ion.

---

# Document 296: Configuration Diff - MediationZone Documentation 9.3 - InfoZone

**Source:** ratanon/mz93-documentation
**URL:** https://infozone.atlassian.net/wiki/spaces/MD93/pages/204742043/Configuration+Diff
**Categories:** chunks_index.json

The Configuration Diff tool allows you to view two configurations or two versions of the same configuration side by side . You can choose from a list of two types of configurations to view and compare: APL and Ultra. The differences between the two configurations are highlighted in blue. To open Configuration Diff, click the Tools button in the upper left part of the Desktop window. Then double-click on Configuration Diff . You can also open the Configuration Diff tool from the APL Code editor, Ultra Format editor, Unit Test editor, or Python Module editor by selecting the Diff button located in the upper right part of the the Desktop window. Two panes are displayed when Configuration Diff opens. Select values for each pane: Field Description Field Description Configuration To select the configurations that you want to compare, select the Browse... button to the right of the Configuration field for each display pane. You can also display and view encrypted configurations. If you select an encrypted configuration, you are prompted to enter the relevant password to decrypt the configuration. History To select a different version of the same configuration, use this drop-down box to select the version you want to display. You can also display and view encrypted configurations. If you select an encrypted configuration, you are prompted to enter the relevant password to decrypt the configuration. Navigate through the differences by scrolling both panes in parallel using the scroll bar to the right of either pane. To scroll through each pane separately, hover over the pane that you want to scroll through, and use the scroll wheel on your mouse. To skip through each difference, use the navigation buttons displayed at the top left of the dialog: Button Description Button Description Previous Click this button to skip to the previous difference in the configurations. The previous difference is highlighted in green. Next Click this button to skip to the next difference in the configurations. The next difference is highlighted in green. Refresh Click this button to display the updated version of the configuration. Configurations are not locked when you display them in Configuration Diff. If another user has modified and saved a configuration that you are viewing in this tool, you can click this button to view the latest updated version.

---

# Document 297: Log Forwarding - MediationZone Documentation 9.3 - InfoZone

**Source:** ratanon/mz93-documentation
**URL:** https://infozone.atlassian.net/wiki/spaces/MD93/pages/378241048/Log+Forwarding
**Categories:** chunks_index.json

You can send MediationZone log files to an external log collector by configuring the properties described in this section. All log files generated in MediationZone will be forwarded when log forwarding is enabled, including System, Platform, and EC logs. The log structure, fields, and severity follow the JSON and RFC5424 specifications and it is a prerequisite to know one of these specifications to use the log forwarding functionality. The following properties should be added to the platform configuration file to forward the logs to the external log collector: Properties Description Default Value Properties Description Default Value mz.syslog.logging.enable This property is used to enable or disable the logging. false mz.syslog.protocol This property defines the protocol to use, either UDP or TCP. UDP mz.syslog.hostname This property defines the hostname or IP address of the target log collector. localhost mz.syslog.port This property defines the port of the target log collector. 514 mz.syslog.layouttype This property defines the layout type based on the supported specifications. You can select either RFC5424 or JSON. RFC5424 mz.syslog.includestacktrace This property is used to include a full stack trace in your log messages. false mz.syslog.debuglogfile.enable This property is used to generate a debug log file, useful when you need to determine any issues when configuring the log forwarding. false mz.syslog.debuglogfile.filename This property defines the name of the debug log file. syslog-debug.log mz.syslog.debuglogfile.filedir This property defines the location of the debug log file. /tmp/syslog mz.syslog.debuglogfile.filenum This property defines the number of debug log file to be generated. 5 Platform Configuration To enable syslog logging to connect to external log collector. mzsh topo set topo://container:main1/pico:platform/val:config.properties.mz.syslog.logging.enable true To set external log collector connection port. For instance, port 5140 is connection port for Fluent-bit mzsh topo set topo://container:main1/pico:platform/val:config.properties.mz.syslog.port 5140 The rest of the properties that are not set explicitly will follow their default value in the tables. Changes made to the properties above only take effect after platform restarted. mzsh restart platform Log Forwarding With Fluent-bit: Fluent-bit is one of the external log collector that is widely used by major cloud providers, banks, and companies world-wide. Fluent-bit can read from local files and network devices, and can scrape metrics in the Prometheus format from your server. Furthermore, Fluent Bit supports a vendor-neutral approach, seamlessly integrating with other ecosystems such as Prometheus and OpenTelemetry. Click here to install Fluent-bit for your environment if you have not. Fluent-bit Configuration File Fluent-bit configuration file allows user to configure what kind of data source (input) to read from and where to forward the data to, i.e., data destination (output). Edit Fluent-bit configuration file with the following contents. [SERVICE] Flush 1 Log_Level info Parsers_File parsers.conf [INPUT] Name syslog Mode udp Buffer_Chunk_Size 32000 Buffer_Max_Size 64000 Receive_Buffer_Size 512000 [OUTPUT] Name stdout Match * [OUTPUT] Name file Match * Path <your-directory-path> [OUTPUT] name syslog match * host <your-host-name-or-ip-address> port 514 mode udp syslog_format rfc5424 syslog_maxsize 2048 syslog_severity_key severity syslog_facility_key facility syslog_hostname_key host syslog_appname_key appname syslog_procid_key procid syslog_msgid_key msgid syslog_sd_key sd syslog_message_key message then startup Fluent-bit with configuration file manually fluent-bit -c /opt/homebrew/etc/fluent-bit/fluent-bit.conf on Linux environment with Systemd, startup Fluent-bit with systemctl sudo systemctl start fluent-bit then do a status check, you should see a similar output like this: $ systemctl status fluent-bit  fluent-bit.service - Fluent Bit Loaded: loaded (/usr/lib/systemd/system/fluent-bit.service; disabled; vendor preset: disabled) Active: active (running) since Thu 2016-07-07 02:08:01 BST; 9s ago Main PID: 3820 (fluent-bit) CGroup: /system.slice/fluent-bit.service 3820 /opt/fluent-bit/bin/fluent-bit -c etc/fluent-bit/fluent-bit.conf ... Fluent-bit started up manually with these output on the screen Fluent Bit v3.1.9 * Copyright (C) 2015-2024 The Fluent Bit Authors * Fluent Bit is a CNCF sub-project under the umbrella of Fluentd * https://fluentbit.io ______ _ _ ______ _ _ _____ __ | ___| | | | | ___ (_) | |____ |/ | | |_ | |_ _ ___ _ __ | |_ | |_/ /_| |_ __ __ / /`| | | _| | | | | |/ _  '_ | __| | ___  | __|   / /   | | | | | | |_| | __/ | | | |_ | |_/ / | |_  V /.___/ /_| |_ _| |_|__,_|___|_| |_|__| ____/|_|__| _/ ____(_)___/ [2024/11/05 18:31:45] [ info] [fluent bit] version=3.1.9, commit=, pid=17946 [2024/11/05 18:31:45] [ info] [storage] ver=1.5.2, type=memory, sync=normal, checksum=off, max_chunks_up=128 [2024/11/05 18:31:45] [ info] [cmetrics] version=0.9.6 [2024/11/05 18:31:45] [ info] [ctraces ] version=0.5.6 [2024/11/05 18:31:45] [ info] [input:syslog:syslog.0] initializing [2024/11/05 18:31:45] [ info] [input:syslog:syslog.0] storage_strategy='memory' (memory only) [2024/11/05 18:31:45] [ info] [in_syslog] UDP server binding 0.0.0.0:5140 [2024/11/05 18:31:45] [ info] [output:syslog:syslog.2] setup done for 192.168.64.2:514 (TLS=off) [2024/11/05 18:31:45] [ info] [output:stdout:stdout.0] worker #0 started [2024/11/05 18:31:45] [ info] [output:file:file.1] worker #0 started [2024/11/05 18:31:45] [ info] [sp] stream processor started Fluent-bit Outputs Fluent-bit can be configured to route collected data to multiples destinations. The fluent-bit configuration file listed in previous section routes collected data to standard output, local file and remote rsyslog server. Refer to official documentation to know more about output plugins supported by Fluent-bit. Standard Output [0] syslog.0: [[1730863047.926000000, {}], {"pri"=>"14", "time"=>"2024-11-06T11:17:27.926+08:00", "host"=>"server-host.local", "ident"=>"DRX-9.3.1.0", "pid"=>"3795", "msgid"=>"System", "extradata"=>"[2@32473 UUID="3ff217ee-d18c-45ca-9a3b-7907923e9e26" host="localhost:6790" picoName="platform" severity="Information" type="System"]", "message"=>"The pico instance platform (platform) at host localhost has connected."}] [1] syslog.0: [[1730863047.927000000, {}], {"pri"=>"14", "time"=>"2024-11-06T11:17:27.927+08:00", "host"=>"server-host.local", "ident"=>"DRX-9.3.1.0", "pid"=>"3795", "msgid"=>"System", "extradata"=>"[2@32473 UUID="e3ac6725-23cf-4e56-b483-803e3dfaaf90" host="localhost:6790" severity="Information" type="System"]", "message"=>"System message: The system started"}] [0] syslog.0: [[1730863057.633000000, {}], {"pri"=>"14", "time"=>"2024-11-06T11:17:37.633+08:00", "host"=>"server-host.local", "ident"=>"DRX-9.3.1.0", "pid"=>"3795", "msgid"=>"System", "extradata"=>"[2@32473 UUID="2b4d0683-3a6d-442e-9d45-c5089159d6e0" host="localhost:6790" picoName="platform" severity="Information" type="System"]", "message"=>"The pico instance ec1 (ec) at host localhost has connected."}] [0] syslog.0: [[1730863068.462000000, {}], {"pri"=>"14", "time"=>"2024-11-06T11:17:48.462+08:00", "host"=>"server-host.local", "ident"=>"DRX-9.3.1.0", "pid"=>"3795", "msgid"=>"System", "extradata"=>"[2@32473 UUID="819b616b-504a-42fc-a271-907fa9e801b6" host="localhost:6790" picoName="platform" severity="Information" type="System"]", "message"=>"The pico instance ec2 (ec) at host localhost has connected."}] [0] syslog.0: [[1730863179.066000000, {}], {"pri"=>"14", "time"=>"2024-11-06T11:19:39.066+08:00", "host"=>"server-host.local", "ident"=>"DRX-9.3.1.0", "pid"=>"3795", "msgid"=>"System", "extradata"=>"[2@32473 UUID="9b3191a2-d90b-441e-9602-8a2d99371301" host="localhost:6790" picoName="platform" severity="Information" type="System"]", "message"=>"The pico instance desktop-0 (desktop) at host 192.168.100.3 has connected."}] [1] syslog.0: [[1730863179.085000000, {}], {"pri"=>"14", "time"=>"2024-11-06T11:19:39.085+08:00", "host"=>"server-host.local", "ident"=>"DRX-9.3.1.0", "pid"=>"3795", "msgid"=>"User", "extradata"=>"[3@32473 UUID="3ebb0e90-a3db-40b3-b11a-f7cd23fb6ff1" host="192.168.100.3:52018" severity="Information" type="User" user="mzadmin"]", "message"=>"mzadmin, Desktop user logged in"}] [0] syslog.0: [[1730863752.812000000, {}], {"pri"=>"14", "time"=>"2024-11-06T11:29:12.812+08:00", "host"=>"server-host.local", "ident"=>"DRX-9.3.1.0", "pid"=>"3795", "msgid"=>"User", "extradata"=>"[3@32473 UUID="6e360bcb-fee7-433e-a964-cb3e547786fe" host="diameter-client.digitalroute.com:52018" severity="Information" type="User" user="mzadmin" workflow="perf_http2_client_server.wf_http2_server_perf.workflow_1"]", "message"=>"mzadmin, Debug has been enabled on workflow perf_http2_client_server.wf_http2_server_perf.workflow_1."}] [1] syslog.0: [[1730863752.822000000, {}], {"pri"=>"14", "time"=>"2024-11-06T11:29:12.822+08:00", "host"=>"server-host.local", "ident"=>"DRX-9.3.1.0", "pid"=>"3795", "msgid"=>"System", "extradata"=>"[2@32473 UUID="c19103ec-bbe9-48b2-9c79-7f0f03de9727" host="localhost:6790" severity="Information" type="System"]", "message"=>"System message: Workflow perf_http2_client_server.wf_http2_server_perf.workflow_1 is being manually started by user: mzadmin"}] [2] syslog.0: [[1730863752.823000000, {}], {"pri"=>"14", "time"=>"2024-11-06T11:29:12.823+08:00", "host"=>"server-host.local", "ident"=>"DRX-9.3.1.0", "pid"=>"3795", "msgid"=>"User", "extradata"=>"[3@32473 UUID="955166fe-87ac-4ced-8a51-c17888431bd3" host="diameter-client.digitalroute.com:52018" severity="Information" type="User" user="mzadmin" workflow="perf_http2_client_server.wf_http2_server_perf.workflow_1"]", "message"=>"mzadmin, Workflow perf_http2_client_server.wf_http2_server_perf.workflow_1 (1) started."}] Local File syslog.0: [1730863047.926000000, {"pri":"14","time":"2024-11-06T11:17:27.926+08:00","host":"server-host.local","ident":"DRX-9.3.1.0","pid":"3795","msgid":"System","extradata":"[2@32473 UUID="3ff217ee-d18c-45ca-9a3b-7907923e9e26" host="localhost:6790" picoName="platform" severity="Information" type="System"]","message":"The pico instance platform (platform) at host localhost has connected."}] syslog.0: [1730863047.927000000, {"pri":"14","time":"2024-11-06T11:17:27.927+08:00","host":"server-host.local","ident":"DRX-9.3.1.0","pid":"3795","msgid":"System","extradata":"[2@32473 UUID="e3ac6725-23cf-4e56-b483-803e3dfaaf90" host="localhost:6790" severity="Information" type="System"]","message":"System message: The system started"}] syslog.0: [1730863057.633000000, {"pri":"14","time":"2024-11-06T11:17:37.633+08:00","host":"server-host.local","ident":"DRX-9.3.1.0","pid":"3795","msgid":"System","extradata":"[2@32473 UUID="2b4d0683-3a6d-442e-9d45-c5089159d6e0" host="localhost:6790" picoName="platform" severity="Information" type="System"]","message":"The pico instance ec1 (ec) at host localhost has connected."}] syslog.0: [1730863068.462000000, {"pri":"14","time":"2024-11-06T11:17:48.462+08:00","host":"server-host.local","ident":"DRX-9.3.1.0","pid":"3795","msgid":"System","extradata":"[2@32473 UUID="819b616b-504a-42fc-a271-907fa9e801b6" host="localhost:6790" picoName="platform" severity="Information" type="System"]","message":"The pico instance ec2 (ec) at host localhost has connected."}] syslog.0: [1730863179.066000000, {"pri":"14","time":"2024-11-06T11:19:39.066+08:00","host":"server-host.local","ident":"DRX-9.3.1.0","pid":"3795","msgid":"System","extradata":"[2@32473 UUID="9b3191a2-d90b-441e-9602-8a2d99371301" host="localhost:6790" picoName="platform" severity="Information" type="System"]","message":"The pico instance desktop-0 (desktop) at host 192.168.100.3 has connected."}] syslog.0: [1730863179.085000000, {"pri":"14","time":"2024-11-06T11:19:39.085+08:00","host":"server-host.local","ident":"DRX-9.3.1.0","pid":"3795","msgid":"User","extradata":"[3@32473 UUID="3ebb0e90-a3db-40b3-b11a-f7cd23fb6ff1" host="192.168.100.3:52018" severity="Information" type="User" user="mzadmin"]","message":"mzadmin, Desktop user logged in"}] syslog.0: [1730863752.812000000, {"pri":"14","time":"2024-11-06T11:29:12.812+08:00","host":"server-host.local","ident":"DRX-9.3.1.0","pid":"3795","msgid":"User","extradata":"[3@32473 UUID="6e360bcb-fee7-433e-a964-cb3e547786fe" host="diameter-client.digitalroute.com:52018" severity="Information" type="User" user="mzadmin" workflow="perf_http2_client_server.wf_http2_server_perf.workflow_1"]","message":"mzadmin, Debug has been enabled on workflow perf_http2_client_server.wf_http2_server_perf.workflow_1."}] syslog.0: [1730863752.822000000, {"pri":"14","time":"2024-11-06T11:29:12.822+08:00","host":"server-host.local","ident":"DRX-9.3.1.0","pid":"3795","msgid":"System","extradata":"[2@32473 UUID="c19103ec-bbe9-48b2-9c79-7f0f03de9727" host="localhost:6790" severity="Information" type="System"]","message":"System message: Workflow perf_http2_client_server.wf_http2_server_perf.workflow_1 is being manually started by user: mzadmin"}] syslog.0: [1730863752.823000000, {"pri":"14","time":"2024-11-06T11:29:12.823+08:00","host":"server-host.local","ident":"DRX-9.3.1.0","pid":"3795","msgid":"User","extradata":"[3@32473 UUID="955166fe-87ac-4ced-8a51-c17888431bd3" host="diameter-client.digitalroute.com:52018" severity="Information" type="User" user="mzadmin" workflow="perf_http2_client_server.wf_http2_server_perf.workflow_1"]","message":"mzadmin, Workflow perf_http2_client_server.wf_http2_server_perf.workflow_1 (1) started."}] Remote rsyslog Server Nov 6 03:17:27 server-host.local - The pico instance platform (platform) at host localhost has connected. Nov 6 03:17:27 server-host.local - System message: The system started Nov 6 03:17:37 server-host.local - The pico instance ec1 (ec) at host localhost has connected. Nov 6 03:17:48 server-host.local - The pico instance ec2 (ec) at host localhost has connected. Nov 6 03:19:39 server-host.local - The pico instance desktop-0 (desktop) at host 192.168.100.3 has connected. Nov 6 03:19:39 server-host.local - mzadmin, Desktop user logged in Nov 6 03:29:12 server-host.local - mzadmin, Debug has been enabled on workflow perf_http2_client_server.wf_http2_server_perf.workflow_1. Nov 6 03:29:12 server-host.local - System message: Workflow perf_http2_client_server.wf_http2_server_perf.workflow_1 is being manually started by user: mzadmin Nov 6 03:29:12 server-host.local - mzadmin, Workflow perf_http2_client_server.wf_http2_server_perf.workflow_1 (1) started

---

# Document 298: Streaming Telemetry Events - MediationZone Documentation 9.3 - InfoZone

**Source:** ratanon/mz93-documentation
**URL:** https://infozone.atlassian.net/wiki/spaces/MD93/pages/204643323/Streaming+Telemetry+Events
**Categories:** chunks_index.json

Agent Message Events There are no message events for this agent. Debug Events There are no debug events for this agent.

---

# Document 299: ECS Collection Agent Configuration - MediationZone Documentation 9.3 - InfoZone

**Source:** ratanon/mz93-documentation
**URL:** https://infozone.atlassian.net/wiki/spaces/MD93/pages/204999973/ECS+Collection+Agent+Configuration
**Categories:** chunks_index.json

To open the ECS collection agent configuration, click Build  New Configuration . Select Workflow from the Configurations dialog. When prompted to Select workflow type , select Batch . Click Add agent and select Ecs from the Agent Selection dialog. Double-click the agent icon or right-click the icon and select Edit agent , to display the Agent Configuration dialog. You either collect data from a Reprocessing Group that has been defined in the ECS Inspector or from a Saved Filter defined in the ECS Inspector. The settings in the configuration dialog depends on which option you choose. Note! The default directory, used to store UDRs and batches routed to the ECS, is $MZ_HOME/ecs . Open ECS collection configuration dialog Setting Description Setting Description Reprocessing Group Select this checkbox to collect data from a predefined Reprocessing Group . The groups in the Reprocessing Group list are suffixed with their type - batch or UDR. Reprocessing groups are defined in the ECS Inspector. Collected UDRs or batches are automatically marked as Reprocessed . Reprocessed data can be collected again, if the state is manually changed back to New in the ECS Inspector. Saved Filter (Read Only) Select this checkbox to collect data defined by a filter saved in the Search ECS dialog in the ECS Inspector. This option can only be used for UDRs. In order for UDRs to be collectible, they must match the search criteria in the selected filter. Collection Size This field is enabled when a UDR Reprocessing Group is selected. The value defines how many UDRs to collect before the ECS collection agent finishes the current batch and starts a new one. The valid range is 1,000 to 100,000 UDRs. A higher value requires more memory and can have an impact on performance. SQL Bulk Size To improve performance, data records are retrieved in bulk. The SQL Bulk Size value specifies how many records are included in each bulk. The valid range is 1 to 1000, with a default value of 20. Routed Types A group of UDRs can consist of several format types. Select Add to display the UDR Internal Format Browser. Select the type or types to collect. Any UDRs in the Reprocessing Group that do not match the selected types are ignored.

---

# Document 300: ADLS2 File Forwarding Agent Events - MediationZone Documentation 9.3 - InfoZone

**Source:** ratanon/mz93-documentation
**URL:** https://infozone.atlassian.net/wiki/spaces/MD93/pages/204606103/ADLS2+File+Forwarding+Agent+Events
**Categories:** chunks_index.json

Agent Message Events An information message from the agent, stated according to configurations done in an Event Notification configuration. For further information about the agent message Ready with file: name Reported along with the name of the target file when it has been successfully stored in the target directory. If an After Treatment Command is specified, the message also indicate that it has been executed. Debug Events There are no debug events for this agent.

---

# Document 301: Configuration of Data Repository for PCC - MediationZone Documentation 9.3 - InfoZone

**Source:** ratanon/mz93-documentation
**URL:** https://infozone.atlassian.net/wiki/spaces/MD93/pages/204744745/Configuration+of+Data+Repository+for+PCC
**Categories:** chunks_index.json

This chapter describes how you can change the configuration of the Data Repository after the initial installation of PCC has been completed. This chapter includes the following sections: Couchbase Configuration Redis Configuration MySQL Cluster Configuration

---

# Document 302: Radius Server Agent Preparations - MediationZone Documentation 9.3 - InfoZone

**Source:** ratanon/mz93-documentation
**URL:** https://infozone.atlassian.net/wiki/spaces/MD93/pages/205034315/Radius+Server+Agent+Preparations
**Categories:** chunks_index.json

If you want to ensure that a specific IP address is used for the Radius Server agent, you must set the property mz.radius.server.host in the execution container: $ mzsh topo set topo://container:<container name>/pico:<ec name>/val:config.properties.mz.radius.server.host <host address or name> For this change to take effect, you must restart the EC after setting this property. If this property is not set, the agent will listen on the host set in the property pico.rcp.server.host in the container.conf . If the property pico.rcp.server.host is not set in the container.conf , the agent listen on all interfaces.

---

# Document 303: RCP Encryption - MediationZone Documentation 9.3 - InfoZone

**Source:** ratanon/mz93-documentation
**URL:** https://infozone.atlassian.net/wiki/spaces/MD93/pages/205783296/RCP+Encryption
**Categories:** chunks_index.json

The RCP (MediationZone internal protocol) communication can be protected by using TLS (Transport Layer Security). To enable TLS, various configurations need to be made in the Platform and pico-instance settings. Furthermore, TLS can be used with or without authentication. The TLS support uses a keystore file, generated by using the Java standard tool keytool . For further information about keytool , see the JDK product documentation. Crypto algorithms are in place in the system to ensure secure data communication. The default crypto algorithms used are AES. If you require to modify the default crypto algorithms, see Platform Properties (to be removed) or Desktop Properties . This chapter includes the following sections: TLS Configuration Properties TLS Standard Setup Enabling Client Authentication

---

# Document 304: SFTP Forwarding Agent Events - MediationZone Documentation 9.3 - InfoZone

**Source:** ratanon/mz93-documentation
**URL:** https://infozone.atlassian.net/wiki/spaces/MD93/pages/204643096/SFTP+Forwarding+Agent+Events
**Categories:** chunks_index.json

Agent Message Events An information message from the agent, stated according to the configuration done in the Event Notification Editor . For further information about the agent message event type, see Agent Event . Ready with file: filename Reported, along with the name of the target file, when the file is successfully written to the target directory. Debug Events Debug messages are dispatched when debug is used. During execution, the messages are shown in the Workflow Monitor and can also be stated according to the configuration done in the Event Notification Editor . For further information about the debug event type, see Debug Event . Loading

---

# Document 305: External - Sequential Format - MediationZone Documentation 9.3 - InfoZone

**Source:** ratanon/mz93-documentation
**URL:** https://infozone.atlassian.net/wiki/spaces/MD93/pages/204612811
**Categories:** chunks_index.json

A sequential external format specification consists of two parts; the record declaration and the field declaration. The record declaration can contain information about UDR size and how the record type is identified. The field declarations may be grouped into larger structures such as bit_block and set . The syntax of the external format declarations is declared as follows: external <format_name> [: <record declaration>] { <content declarations> }; The comma-separated elements of the record declaration list may be (in any order): terminated_by( <terminator> ) dynamic_size( <expression> ) static_size( <constant expression> ) identified_by( <conditional expression> ) The content declarations can be: field declarations bit_block declarations set declarations switched_set declarations This chapter includes the following sections: Record Declaration Field Declarations Expressions

---

# Document 306: Workflow Bridge Batch Forwarding Agent - MediationZone Documentation 9.3 - InfoZone

**Source:** ratanon/mz93-documentation
**URL:** https://infozone.atlassian.net/wiki/spaces/MD93/pages/204741355/Workflow+Bridge+Batch+Forwarding+Agent
**Categories:** chunks_index.json

The Workflow Bridge forwarding agent is responsible for sending data to a Workflow Bridge collection agent. The section contains the following subsections: Workflow Bridge Batch Forwarding Agent Configuration Workflow Bridge Batch Forwarding Agent Events Workflow Bridge Batch Forwarding Agent Transaction Behavior, Input/Output Data and MIM

---

# Document 307: Encoders - MediationZone Documentation 9.3 - InfoZone

**Source:** ratanon/mz93-documentation
**URL:** https://infozone.atlassian.net/wiki/spaces/MD93/pages/204678339/Encoders
**Categories:** chunks_index.json

An encoder specifies how data is to be encoded. The syntax for the encoders is as follows: encoder <encoder_name> : <encoder options>; The encoder options are: Option Description out_map(<map name>) Specifies what out-maps to use. At least one is required. block_size(<size>) Specifies that this is a blocked format with a certain block size. terminated_by(<terminator>) Specifies the block filler used. This option has no effect if the block_size has not been specified. When encoding a record, the encoder tries each out-map in the order specified. If the out-map can encode the record, then this out-map is used, otherwise, the next out-map is tried. An out-map can encode the data if: The record type matches the internal type specified in the out-map. All format-specific requirements are met. At the moment this evaluation is performed only for sequential data with an identified_by condition. Only data where the mapped fields meet the identification rule is accepted. This is to support mapping to different external record types from the same internal type. Note! There is no such thing as a constructed encoder. If the records are required to be forwarded in a specific order, an APL agent handling the output logic must precede the Encoder. Loading

---

# Document 308: Reporting - MediationZone Documentation 9.3 - InfoZone

**Source:** ratanon/mz93-documentation
**URL:** https://infozone.atlassian.net/wiki/spaces/MD93/pages/205849270/Reporting
**Categories:** chunks_index.json

The next coming sections include examples of customized reports that can be generated from statistical Audit data captured by MediationZone. The example reports could easily be made more graphical by using a reporting tool such as Crystal Reports.

---

# Document 309: SQL Processing Agent in Real-Time Workflows - MediationZone Documentation 9.3 - InfoZone

**Source:** ratanon/mz93-documentation
**URL:** https://infozone.atlassian.net/wiki/spaces/MD93/pages/205002178/SQL+Processing+Agent+in+Real-Time+Workflows
**Categories:** chunks_index.json

The SQL processing agent inserts UDR data into a database table according to your definitions of mapping between UDR fields and database table columns. The agent also enables you to populate database columns with MIM values either by using a plain SQL statement or by invoking a stored procedure that inserts the data. Note! Supported database commands depend on the JDBC driver of the database. The section contains the following subsections: SQL Processing Agent Configuration - Real-Time SQL Forwarding Agent Transaction Behavior, Input/Output Data and MIM - Real-Time SQL Processing Agent Events - Real-Time Example of SQL Processing Agent in Real-Time Workflow Handling Erroneous UDRs - Real-Time

---

# Document 310: Search & Repair - MediationZone Documentation 9.3 - InfoZone

**Source:** ratanon/mz93-documentation
**URL:** https://infozone.atlassian.net/wiki/spaces/MD93/pages/205032402/Search+Repair
**Categories:** chunks_index.json



---
**End of Part 14** - Continue to next part for more content.
