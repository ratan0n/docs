# RATANON/MZ93-DOCUMENTATION - Part 4/112

---
**Dataset:** ratanon/mz93-documentation
**Part:** 4 of 112
**GitHub:** https://github.com/ratan0n/docs/tree/main/mz93-documentation
**Size:** ~63.7 KB
---

The workflow configuration is a central part of the MediationZone Desktop. This is where all workflows are designed and configured by adding agents and connecting them to each other to form a data flow. The workflow configuration operates in three modes: Design mode  where workflows are created and configured Monitor mode  where workflows are started or stopped and the status of its individual agents is monitored Profiling mode  same as monitor mode but with graphical information on where most of the time is spent in the workflow A workflow that is fully configured will have access to all modes. This is determined when a workflow is opened and saved. If the workflow is not fully configured or deleted, the Monitor and Profiling modes are disabled. Workflow Group Configuration The Workflow Group configuration enables management of workflows. A workflow group can consist of one or several workflows, each with a diverse setup of scheduling, load balancing, and event notifications. Workflow groups enable you to configure these as a single entity. Groups are either of type batch or real-time, which means that batch and real-time workflows cannot be mixed in the same group. The example below shows a workflow group consisting of two batch workflows with a dependency (the first one must finish before the second can start). Open A workflow group configuration with three batch workflows Grouping of workflows can be useful in the following scenarios: There are dependencies between workflows within one line of business (e.g. collection, processing and forwarding) which can be managed through prerequisites, and the workflows need to be executed in a certain order. To limit the resource usage when executing groups with multiple workflows in parallel, you can control the maximum number of simultaneously running workflows. If there is a need to complete all collection before beginning the processing step, this can be achieved by creating a collection group and a processing group that belong to a super group. To simplify the monitoring as the groups show their status in the Execution Manager. Runtime Modification of the Workflow Configuration MediationZone includes two mechanisms by which an operator can modify a workflow that is already running. While a workflow is executing, it is possible to change the configuration of certain agents in their respective Configuration tabs which is available in the Monitor mode of the Workflow Designer. These changes will be automatically sent to the running workflow and provisioned into the agent that is being reconfigured. In this case, the changes are applied without affecting the execution of the workflow. The example below shows how this is performed for the TCP/IP Agent of an active Workflow. In this scenario, the IP address used for listening on incoming requests is changed. Open Example of runtime update of a TCP/IP agent configuration Runtime Modification of Workflow State MediationZone includes a mechanism through which it is possible  while the workflow is running  to send a signal to an agent to instruct it to perform some action without affecting the active workflow. The example below shows how this capability is used to instruct an Aggregation agent to execute the instructions within the command block for all sessions that have a timeout condition configured. This can be used, for example, to implement the capability to force a hard-flush of sessions in a Charging Gateway deployment. Executing command block from monitor mode in the graphical user interface: Open Example of runtime modification of a workflow state through the Aggregation agent A command block can also be executed from the command line interface, by using the wfcommand . This enables the workflow logic to be executed based on input from the Command Line Interface. Configuration Import and Export All, or part, of the configuration related to a MediationZone installation can be managed using the System Export/Import feature. Exporting configuration objects with this mechanism will create a compressed XML file that contains selected configuration. Exported information can also be protected through a one-way encrypted password. Using the export and import feature, it is possible to develop and test all functionality on one system, then export it and later import it into another environment. This feature can be combined with the external references feature that allows definition of all configuration parameters in a text file which gives the possibility to use one configuration export file across all environments which all have their individual parameter file. The following example shows the system import/export sub-system, creating a full configuration export: Open Example of full configuration export In addition to configuration data, the export/import function includes the capability to export runtime data from, for example, ECS and Archive systems. Parameters are available to the system import command in order to specify system behavior during the import. It is now possible to suppress all workflow scheduling until the import has finished in order, as well as a synchronized restart of all workflows. Profiles in Workflow Table The Workflow Table can be configured with: Manually entered values, e.g. directories, regular expressions, hosts, ports External References, pointing to values in property files Configuration profiles selected through the GUI, such as Database, Dup UDR, Aggregation and Inter Workflow profiles, as illustrated below: Open Workflow table including selected configuration profiles Import and Export of Workflow Table When managing multiple environments (e.g. test, pre-production and production) it can be beneficial to export the different workflow tables to CSV-format. This allows one configuration export to be valid across several environments in combination with importing the appropriate CSV-file containing the specific configuration. Also, when managing many rows in the table, it can be a good idea to import/export the table to a CSV-format (for easy editing in Excel). External References External References enable loading MediationZone with configuration values that originate from a properties file that is external to the workflow configuration. This allows MediationZone system administrators to have specific files on test and production servers, and when an export is made from the test deployment, no changes are necessary when deploying the configuration to the production installation. The example below shows a properties file containing mapping of values and variables used in MediationZone profiles, APL code and the workflow table. Open Properties file containing mapping of values and variables used in MediationZone The image below depicts the External References Profile where properties files are selected and the variable names from the file are mapped to internal variable names. Open An External References profile example The local key variables can then be mapped in the workflow instance table by activating External References in the relevant cells. Open Workflow table showing External References files usage

---

# Document 70: Legacy Kafka Profile - MediationZone Documentation 9.3 - InfoZone

**Source:** ratanon/mz93-documentation
**URL:** https://infozone.atlassian.net/wiki/spaces/MD93/pages/301138556
**Categories:** chunks_index.json

The Kafka profile enables you to configure which topic and which embedded service key to use, and it is loaded when you start a workflow that depends on it. Changes to the profile become effective when you restart the workflow. The Kafka profile configuration contains two tabs: Connectivity and Advanced . Connectivity tab The Connectivity tab is displayed by default when creating or opening a Kafka profile, and it contains the following settings: Setting Description Setting Description Topic Enter the Kafka topic that you want to use for your configuration. This field supports parameterization using ${} syntax, see Appendix 1 - Profiles for more information on how parameterization works. Use parameterized broker list Enable this checkbox if you want to set Brokers as a parameter instead. When enabled you need to set the parameter name using ${} syntax, see Appendix 1 - Profiles for more information on how parameterization works. Brokers A Broker is a node in a Kafka cluster. If you are using external Kafka, you must add Kafka Brokers. Use the Add button to enter the addresses of the Kafka Brokers you want to connect to. Host If you are using external Kafka, enter the hostname for Zookeeper. Port If you are using external Kafka, enter the port for Zookeeper. Group id Set this id to an identity of your choice, to enable load sharing between several Kafka collectors. Use this in combination with enable.auto.commit=true , in the Consumer and Advanced tab. This field supports parameterization using ${} syntax, see Appendix 1 - Profiles for more information on how parameterization works. Security Profile Select a Security Profile profile if you have defined it for your Kafka server. Advanced tab In the Advanced tab you can configure properties for optimizing the performance of the Kafka Producer and Consumer. The Advanced tab contains two tabs: Producer and Consumer . Producer tab In the Producer tab, you can configure the properties of the Kafka forwarding agent. The property producer.abortunknown=true sets the agent to abort if the broker replies with Unknown topic or partition . For further information on the other properties, see the text in the Advanced producer properties field , or refer to Apache Kafka . When running in Acknowledged execution mode, the property producer.full.response determines if the data sent to the Kafka log is also included in the response UDR. The value is set to true by default. Setting the value to false reduces the memory footprint. For information on how to configure the properties for SSL and Kerberos, please refer to Configuring Apache Kafka Security | 4.1.x | Cloudera Documentation . Caution! If you make any changes to the security configuration of the Kafka Producer, any topics used must be recreated before they can be used. This field supports parameterization using ${} syntax. For more information on parameterization see Appendix 1 - Profiles . Consumer tab In the Consumer tab, you can configure the properties of the Kafka collection agent. For further information about the properties, see the text in the Advanced Consumer Properties field, or refer to Apache Kafka . This field supports parameterization using ${} syntax. For more information on parameterization see Appendix 1 - Profiles . Note! The sasl.jaas.config client property has been added to Advance Producer Properties and Advance Consumer Properties in the Kafka profile. This new property is used to configure SASL authentication directly in the client's properties instead of using a JAAS file. This simplification lets you run multiple clients in the same JVM by using different sets of credentials, which is not possible with a JAAS file. You can still use the existing java.security.auth.login.config system property which points to a JAAS file. However, this option allows only one set of user credentials for all client connections from a JVM. This means that MediationZone users wont be able to run multiple Kafka workflows against different Kafka brokers on the same EC. When both the JAAS configuration system property ( java.security.auth.login.config) and client property ( sasl.jaas.config) are specified, the client property will be used.

---

# Document 71: HTTP Batch Events - MediationZone Documentation 9.3 - InfoZone

**Source:** ratanon/mz93-documentation
**URL:** https://infozone.atlassian.net/wiki/spaces/MD93/pages/205652947/HTTP+Batch+Events
**Categories:** chunks_index.json

Agent Message Events An information message from the agent, stated according to the configuration done in the Event Notification Editor. Message Event Description Ready with file Reported, along with the name of the URL, when the file is collected and inserted into the workflow. Failed to collect file Reported, along with the name of the URL, when the file failed to be collected. URL cancelled Reported, along with the name of the current URL, when a cancelBatch message is received. This assumes the workflow is not aborted; refer to HTTP Batch Agent Transaction Behavior for further information. For further information about the agent message event type, see Agent Event . Debug Events There are no debug events for this agent.

---

# Document 72: Event Notifications - MediationZone Documentation 9.3 - InfoZone

**Source:** ratanon/mz93-documentation
**URL:** https://infozone.atlassian.net/wiki/spaces/MD93/pages/204736858/Event+Notifications
**Categories:** chunks_index.json

An Event Notification configuration offers the possibility to route information from events generated in the system, to various targets. These targets include: Azure Application Insight Database Log File Send Mail Send SNMP Trap Send SNMP Trap, Alarm SNS Topic System Log There are several different event types that all contain specific data about the particular event. Besides being logged, events may be split up and selected parts may be embedded in user defined strings. For instance, consider an event originating from a user, updating an existing Notifier: userName: mzadmin3 , userAction: Notifier AnumberEvents updated . This is the default event message string for User Events. However, it is also possible to select parts of the information, or other information residing inside the event. Each type of event contains a predefined set of fields. For instance, the event message previously exemplified, contains the userName and userAction fields which may be used to customize event messages to suit the target to which they will be logged: Open Events can be customized to suit any target Note! The Category field in the above picture is left empty intentionally, since it does not have a value for this specific event. A category is user defined and is entered in the Event Categories dialog. It is a string which will route messages sent with the dispatchMessage APL function. The event types form a hierarchy, where each event type adds its own fields and inherits all fields from its ancestors. The event hierarchy is structured as follows: Base Alar Code Manager Group System Security User Workflow Agent Agent Failure Agent Message User Agent Message Agent State ECS Insert Debug Dynamic Update Workflow State External Reference <User Defined> Each event type and its fields are described in Event Types . This chapter includes the following sections: Event Notifications Configuration Event Types Event Category

---

# Document 73: SCP Collection Agent Configuration - MediationZone Documentation 9.3 - InfoZone

**Source:** ratanon/mz93-documentation
**URL:** https://infozone.atlassian.net/wiki/spaces/MD93/pages/205034593
**Categories:** chunks_index.json

You open the SCP collection agent configuration dialog from a workflow configuration. To open the Amazon S3 collection agent configuration, click Build  New Configuration . Select Workflow from the Configurations dialog. When prompted to Select workflow type , select Batch . Click Add agent and select SCP from the Collection tab of the Agent Selection dialog. Part of the configuration may be done in the Filename Sequence or Sort Order tab described in Workflow Template . The Configuration view consists of the following tabs: Connection Source Advanced Security Connection Tab The Connection tab contains configuration settings related to the remote host and authentication. Open The SCP collection agent configuration - Connection tab Setting Description Setting Description Connection Information Host Primary host name or IP-address of the remote host to be connected. If a connection cannot be established to this host, the Additional Hosts, specified in the Advanced tab, are tried. File System Type Type of file system on the remote host. This information is used to construct the remote filenames. Unix - remote host using Unix file system. Default setting. Windows NT - remote host using Windows NT file system. Authentication Mechanism Authenticate With Select the authentication mechanism to use. Password and Private Key modes are supported. Username Enter the username for an account on the remote host, enabling the SCP session to log in. Password Enter the associated password. This option only applies when password authentication is enabled. Private Key The Select... button will display a window where the private key may be inserted. If the private key is protected by a passphrase, the passphrase must be provided as well. This option only applies when private key authentication is enabled. For further information, see Authentication in SCP Agents Attributes and Authentication . Collection Retries Enable Select this check box to enable repetitive attempts to connect and start a file transfer. When this option is selected, the agent will attempt to connect to the host as many times as is stated in the Max Retries field described below. If the connection fails, a new attempt will be made after the number of seconds entered in the Retry Interval (s) field described below. Retry Interval (s) Enter the time interval in seconds, between retries. If a connection problem occurs, the actual time interval before the first attempt to reconnect will be the time set in the Timeout field in the Advanced tab plus the time set in the Retry Interval (s) field. For the remaining attempts, the actual time interval will be the number of seconds entered in this field. Max Retries Enter the maximum number of retries to connect. In case more than one connection attempt has been made, the number of used retries will be reset as soon as a file transfer is completed successfully. Note! This number does not include the original connection attempt. Source Tab The Source tab contains configurations related to the remote host, source directories, and source files. The configuration available can be modified through the choice of a Collection Strategy. The following text describes the configuration options available when no custom strategy has been chosen. Open The SCP collection agent configuration - Source tab Setting Description Setting Description Collection Strategy If there is more than one collection strategy available in the system a Collection Strategy drop-down list will also be visible. For further information about the collection strategy, see Appendix 4 - Collection Strategies . File Information Directory Enter the absolute pathname of the source directory on the remote host, where the source files reside. The pathname might also be given relative to the home directory of the Username account. Filename Enter the name of the source files on the remote host. Regular expressions according to Java syntax apply. For further information, see http://docs.oracle.com/javase/8/docs/api/java/util/regex/Pattern.html . Example To match all filenames beginning with TTFILES , type: TTFILES.* . Compression Select the compression type of the source files. Determines whether the agent will decompress the files before passing them on in the workflow or not. No Compression - the agent will not decompress the files. Gzip - the agent decompresses the files using gzip. Before Collection Move to Temporary Directory If enabled, the source files will be moved to the automatically created subdirectory DR_TMP_DIR in the source directory, prior to collection. This option supports safe collection of a source file reusing the same name. Append Suffix to Filename Enter the suffix that you want to be added to the file name prior to collecting it. Warning! Before you execute your workflow, make sure that none of the file names in the collection directory include this suffix. Inactive Source Warning (h) If enabled, when the configured number of hours have passed without any file being available for collection, a warning message (event) will appear in the System Log and Event Area: The source has been idle for more than <n> hours, the last inserted file is <file>. After Collection Move to If enabled, the source files will be moved from the source directory (or from the directory DR_TMP_DIR , if using Move to Temporary Directory ) after collection, to the directory specified in the Destination field. If Prefix or Suffix are set, the file will be renamed as well. Note! If a file with the same filename already exist in the target directory, this file will be overwritten and the workflow will not abort. Destination Enter the absolute pathname of the directory on the remote host into which the source files will be moved after the collection. This field is only available if Move to is enabled. Note! The Directory has to be located in the same file system as the collected files at the remote host. Also, absolute pathnames must be defined. Relative pathnames cannot be used. Prefix and Suffix Enter the Prefix and/or suffix that will be appended to the beginning and/or the end, respectively, of the source files after the collection. This field is only available if Move to or Rename is enabled. Note! If Rename is enabled, the source files will be renamed in the current directory (source or DR_TMP_DIR ). Be sure not to assign a Prefix or Suffix, giving files new names still matching the Filename Regular Expression. That would cause the files to be collected over and over again. Search and Replace Select this option if you want to apply the Search and Replace function. Select either the Move to or Rename setting.  Search - Enter the part of the filename that you want to replace.  Replace - Enter the replacement text. Search and Replace operate on your entries in a way that is similar to the Unix sed utility. The identified filenames are modified and forwarded to the following agent in the workflow. This functionality enables you to perform advanced filename modifications, as well:  Use regular expression in the Search entry to specify the part of the filename that you want to extract.  Enter Replace with characters and metacharacters that define the pattern and content of the replacement text. Search and Replace Examples To rename the file file1.new to file1.old , use: Search : .new Replace : .old To rename the file JAN2011_file to file_DONE , use: Search : ([A-Z]*[0-9]*)_([a-z]*) Replace : $2_DONE Note that the search value divides the file name into two parts by using brackets. The replace value applies the second part by using the place holder $2. Keep (days) Enter the number of days to keep moved or renamed source files on the remote host after the collection. In order to delete the source files, the workflow has to be executed (scheduled or manually) again, after the configured number of days. Note, a date tag is added to the filename, determining when the file may be removed. This field is only available if Move to or Rename is selected. Rename If enabled, the source files will be renamed after the collection, remaining (or moved back from the directory DR_TMP_DIR , if using Move to Temporary Directory ) in the source directory from which they were collected. Remove If enabled, the source files will be removed from the source directory (or from the directory DR_TMP_DIR , if using Move to Temporary Directory ), after the collection. Ignore If enabled, the source files will remain in the source directory after the collection. This option is not available if Move to Temporary Directory is enabled. UDR Type Route FileReferenceUDR Select this check box if you want to forward the data to an SQL Loader agent. See the description of the SQL Loader agent in SQL Loader Agent for further information. Advanced Tab The Advanced tab contains configurations related to a more specific use of the SCP service. Open The SCP collection agent configuration - Advanced tab Setting Description Setting Description Advanced Settings Port Enter the port number the SCP service will use on the remote host. Timeout (s) Enter the maximum time, in seconds, to wait for a response from the server. 0 (zero) means to wait forever. Accept New Host Keys If selected, the agent overwrites the existing host key when the host is represented with a new key. The default behavior is to abort when the key mismatches. Note! Selecting this option causes a security risk since the agent will accept new keys regardless if they possibly belong to another machine. Enable Key Re-Exchange This option enables or disables automatic re-exchange of session keys during ongoing connections. This can be useful if you have long-lived sessions since you may experience connection problems for some servers if one of the sides initiates a key re-exchange during the session. Additional Hosts Additional Hosts This option allows additional host names or IP addresses to be used during the connection establishment. These hosts are tried, in sequence from top to bottom, if the agents fail to connect to the remote host set in their Connection tabs. Use the Add , Edit , Remove , Up , and Down buttons to configure the host list. Security Tab The Security tab contains configurations related to the Advanced Security Options for SCP. The Configuration available can be modified by enabling the Advanced Security Option check box. If the Advanced Security Option is not enabled, the Cipher Mode will default to aes128-ctr and the HMac Type will default to hmac-sha2-256 . If the Advanced Security Option is enabled but the combo box fields are left empty, the Cipher Mode will default to aes128-ctr and the HMac Type will default to hmac-sha2-256 . Open The SCP collection agent configuration - Security tab Note! Due to an upgrade of the Maverick library for MediationZone version 8.1.5.0, the default handling of the advanced security has changed. Users should take note of the behavior change for the Advanced Security Option for the SCP agents. The Advanced Security Option will be disabled by default. Users will have to enable it on their own accord from the Security Tab in the SCP agents configuration. With Advanced Security Option disabled, Maverick will manage the connection between the SCP agent and the server. Maverick will attempt to connect with the STRONG security level. Failing to do so, it will auto downgrade the security level to WEAK and attempt to connect, this behaviour will allow our agents to work well with backwards compatibility for servers with older instances of the Maverick library. Furthermore, having a STRONG security level will result in performance degradation. However, when a user manually enables the Advanced Security Option from the security tab, Maverick will instead assign the WEAK security level, which will not be as strict or resource intensive as the STRONG security level. For more information about security levels, you can refer to this page: https://www.jadaptive.com/managed-security-in-our-java-ssh-apis/ Setting Description Setting Description Advanced Security Settings Enable Advanced Security Option If enabled, this will enable the Cipher Mode and HMac Type options below, allowing for advanced security configuration. Cipher Mode Select the algorithms for the Block Cipher Modes. This allows the agent to determine which algorithm for the block cipher to be used when communicating with the servers. 3des-cbc 3des-ctr blowfish-cbc aes128-cbc aes192-cbc aes256-cbc aes128-ctr aes192-ctr aes256-ctr arcfour arcfour128 arcfour256 HMac Type Select the encryption methoc for Key Exchange. This allows the agent to determine the method of encryption to be used when the keys are exchanged between the servers and the SCP agent. hmac-sha1 hmac-sha1-96 hmac-sha1-etm@openssh.com hmac-md5 hmac-md5-96 hmac-md5-etm@openssh.com hmac-sha2-256 hmac-sha2-256-96 hmac-sha2-256-etm@openssh.com hmac-sha2-512 hmac-sha2-512-96 hmac-sha2-512-etm@openssh.com hmac-ripemd160 hmac-ripemd160-etm@openssh.com

---

# Document 74: Callable Statements - MediationZone Documentation 9.3 - InfoZone

**Source:** ratanon/mz93-documentation
**URL:** https://infozone.atlassian.net/wiki/spaces/MD93/pages/204612306/Callable+Statements
**Categories:** chunks_index.json

Callable Statements enable usage of Stored Procedures with output parameters. The Callable Statement functions are used execute stored procedures and to manage the results. The DBErrorUDR is used to handle SQL errors. Note Please refer to the Notes section on the Database Functions page for details on allowed database data type. The following functions for Database Callable Statement described here are: prepareCall To prepare a call with an out parameter, the Stored Procedure must be defined with the prepareCall function. any CallableStatement.prepareCall ( string dbProfile , string sqlProc(?,?) , boolean captureSQLError (optional) , boolean isFunction (optional) , boolean inclResultParam (optional) ) Parameter Description dbProfile Name of the database, including the folder name sqlProc(?,?) Name of the stored procedure, including a question mark for each parameters it requires Example - Using sql_proc Definition of a Stored Procedure, declared in the database: create or replace procedure sql_proc(i int, OUT o char) is begin . . . o:='value for o'; end; / Note! The number of question marks must match the number of defined parameters in the Stored Procedure. captureSQLError Optional parameter that controls error handling. If the parameter's value is set to true, any SQL error gets captured, without disrupting the execution. For more information about how to fetch the SQL error code and message, see the section below, getError. This parameter is set to false by default. isFunction Optional parameter that indicates that the call will be made for a stored function. This parameter is set to false by default. inclResultParam Optional parameter that you can set to true to apply a result parameter of ?= on the JDBC API stored procedure SQL escape syntax. If the isFunction parameter is set to true, the inclResultParam will be set to true by default. Returns Callable Statement Identifier. This object is threadsafe and is used when executing calls towards the stored procedure. execute The execute function maps to the corresponding JDBC API and could differ slightly depending on the JDBC driver. The function is used for questions and lookups. If the database should be updated, use the function executeUpdate instead. execute can handle several OUT parameters including a table format. Note! The table format OUT parameter is applicable only when using a PostgreSQL database. To execute a call with the parameters expected by the stored procedure, the parameters must be specified in correct order. any CallableStatement.execute (any csi, any param1, ..., any paramN) Parameter Description csi The Callable Statement Identifier that is returned from the prepareCall function paramN The values expected by the stored procedure declared in the prepareCall function. Parameters registered as out parameters in the stored procedure must be omitted. The parameters must have the same type as defined in the stored procedure. Returns The returned value is the Result Identifier of the execution. A new object is returned for every call executed. executeQuery The executeQuery function maps to the corresponding JDBC API and could differ slightly depending on the JDBC driver. The function is used for questions and lookups. If the database should be updated, use the function executeUpdate instead. executeQuery can handle several OUT parameters except a table format. To execute a call with the parameters expected by the stored procedure, the parameters must be specified in correct order. any CallableStatement.executeQuery (any csi, any param1, ..., any paramN) Parameter Description csi The Callable Statement Identifier that is returned from the prepareCall function paramN The values expected by the stored procedure declared in the prepareCall function. Parameters registered as out parameters in the stored procedure must be omitted. The parameters must have the same type as defined in the stored procedure. Returns The returned value is the Result Identifier of the execution. A new object is returned for every call executed. executeUpdate The executeUpdate function maps to the corresponding JDBC API and could differ slightly depending on the JDBC driver. The function is used for updating the database. To execute a call with the parameters expected by the stored procedure, the parameters must be specified in correct order. any CallableStatement.executeUpdate (any csi, any param1, ..., any paramN) Parameter Description csi The Callable Statement Identifier that is returned from the prepareCall function paramN The values expected by the stored procedure declared in the prepareCall function. Parameters registered as out parameters in the stored procedure must be omitted. The parameters must have the same type as defined in the stored procedure. Returns The returned value is the Result Identifier of the execution. A new object is returned for every call executed. get The get function is used to retrieve the result from the executed call. any CallableStatement.get (any resultIdentifier, int spIndex) Parameter Description resultIdentifier The Result Identifier that is returned from the executeUpdate function spIndex Index of the requested parameter from the stored procedure (type int ). The first parameter has index 1. Returns The value of the out parameter Note! The return value must be type casted. getUpdateCount This function returns the number of rows that were affected by the executeUpdate function. int CallableStatement.getUpdateCount(any resultIdentifier); Parameter Description resultIdentifier The Result Identifier that is returned from the executeUpdate function Returns For Oracle databases, it returns this statement: The number of rows in the database that were affected by the call. If an update exists, -1 will be returned . For MySQL and PostgreSQL databases, it returns this statement: The number of rows in the database that were affected by the update . getError This function will capture potential SQL errors from the executeUpdate function and return a UDR that contains both the error code and the error message. DatabaseFunctions.DBErrorUDR = CallableStatement.getError(any resultIdentifier); Parameter Description resultIdentifier The Result Identifier that is returned from the executeUpdate function. Returns Returns an error UDR. For more information about the error UDR, see the section below, DBErrorUDR. If no error occurred, null will be returned. Example - Handle error raised by Stored Procedure Stored Procedure definition: create or replace procedure upd_item(id int, amount int) is begin if amount > 110000 THEN RAISE_APPLICATION_ERROR(-20001, 'Amount is to high!'); end if; ... end; / APL Code: any s; DatabaseFunctions.DBErrorUDR error; initialize { s = CallableStatement.prepareCall("p.db","UPD_ITEM(?,?)",true); } consume { ... any result = CallableStatement.executeUpdate(s, id, amount); error = CallableStatement.getError(result); if (error != null) { //handle error if (error.ErrorCode == -20001) { udrRoute(input, "adjust_amount"); } else { abort(error.ErrorCode + error.ErrorMessage); } } else { //no error -let's proceed int cnt = CallableStatement.getUpdateCount(result); ... } } DBErrorUDR If the executeUpdate function generates an SQL error, the getError function will generate a DBErrorUDR . The following fields are included in the DBErrorUDR : Field Description ErrorCode (int) The SQL error code. ErrorMessage (string) The SQL error message.

---

# Document 75: Security and Privacy - MediationZone Documentation 9.3 - InfoZone

**Source:** ratanon/mz93-documentation
**URL:** https://infozone.atlassian.net/wiki/spaces/MD93/pages/205815852/Security+and+Privacy
**Categories:** chunks_index.json

Search this document: This document describes the security aspects on the environment for MediationZone Platform. Chapters The following chapters are included: System Overview - Security Network Operating System Oracle Database Users Configuration Security External Systems Data Protection and Privacy Guide Application Security Testing

---

# Document 76: Important Information - MediationZone Documentation 9.3 - InfoZone

**Source:** ratanon/mz93-documentation
**URL:** https://infozone.atlassian.net/wiki/spaces/MD93/pages/204647504/Important+Information
**Categories:** chunks_index.json

Open The following provides important information related to MediationZone 9.3: 1 MD5 Message Algorithm for MZ CTS+ Integration 2 Support for Insecure Ciphers Removed 3 Deprecated Agents or Features 4 Replaced and Removed Functionality 5 Some Functionality only Available in Legacy Desktop Client 6 Auto Edit Mode in UDR File Editor 7 REST is not Supported for Conditional Trace 8 Context-Sensitive Help and Offline Documentation in Browser Not Available 9 Performance Degradation When Using Unsupported Oracle versions and Oracle JDBC drivers 10 Importing Old IPDR SP Agent Workflow Configurations Returned Validation Errors 11 Unavailable mzsh Commands 12 13 Proxy Support 14 SAP CC agents only support SAP CC version 2023 15 Unable to select profile at instance table because profile type is null MD5 Message Algorithm for MZ CTS+ Integration Mediation Zone's integration with CTS+ now supports the MD5 message algorithm. MD5 is used for compatibility and integrity checks during the transport process, ensuring that transported configurations or files remain unaltered. However, it's important to note that MD5 is utilized because it is the only algorithm that works for this integration, even though it is not the most secure option available today. Support for Insecure Ciphers Removed Support for using the old RC4 or ARCFOUR ciphers in the SFTP agents have been removed since these ciphers are considered insecure. Deprecated Agents or Features When the term deprecated is used for an agent or a feature, this means: The agent or feature is still available for use in the current version. You are not encouraged to use the agent or feature long-term. You need to switch to an alternative soon as the agent and feature will be replaced, or sunset in upcoming versions. Info ! Profiles and agents to be deprecated: REST Server profile REST Client agent REST Server agent HTTPD agent Desktop Launcher Legacy Kafka agents Real-Time Disk collection agent Real-Time Diskforwarding agent Legacy Ultra Avro disableCommit parameter for Database Table Function, Database Bulk Functions and Prepared Statements. Replaced and Removed Functionality Functionality that has been replaced with a functional equivalent or sunset from the product is described in the MediationZone 9 Product Catalog here: 12. APPENDIX - Changes from 8.3 Product Catalog Some Functionality only Available in Legacy Desktop Client Certain features have not yet made it into the new Desktop and are only available in the Legacy Desktop client. These are described in Legacy Desktop . Auto Edit Mode in UDR File Editor While editing UDRs in bulk, there is a mode available called Auto Edit . Using this mode you can edit multiple UDRs using matchers and assignments. See Editing a Bulk of UDRs . This mode is available in Legacy Desktop only. REST is not Supported for Conditional Trace In this new version of Conditional Trace, REST is not supported, configurations can be done in Desktop only. Context-Sensitive Help and Offline Documentation in Browser Not Available For this release, documentation is available in InfoZone and PDF format only. Performance Degradation When Using Unsupported Oracle versions and Oracle JDBC drivers As a result of our performance testing for MediationZone 9.3 and using Oracle database, there is noticeable performance degradation when connecting to Oracle versions older than Oracle 19 and using Oracle JDBC drivers older than OJDBC 10. We recommend that you use the latest supported Oracle versions and Oracle JDBC drivers when using MediationZone 9.3. Importing Old IPDR SP Agent Workflow Configurations Returned Validation Errors If you have an old IPDR Workflow configuration from version 8. x, it is possible that validation errors about invalid IPDR SP agents may occur. Example error during import: The following agents returned validation errors. IPDR_SP_1 is invalid. Default is not a valid property To resolve this, you will need to open the workflow and save the workflow configuration. Alternatively, you can manually add # to each Default value is  in the IPDR SP agents Advanced Properties tab. Unavailable mzsh Commands In MediationZone 9.3 the following mzsh commands from 8.x are not available: Command Comment Command Comment db-scripts jcreate keytool kpimodel Not needed anymore since the structure of the model can now be viewed in the user interface. apl-loglevel pexport reloadkeystore spaceactivation spacecopy spacecreate spacelist spaceremove Not valid any more since Configuration Spaces is no longer available. spark udrview echo Proxy Support Proxy support has been added for: HTTP2 APL functions GCP Storage agents See HTTP/2 Functions and GCP Agents for more information. Hint ! Previously, Proxy has also been available for the following: HTTP APL functions HTTP Batch agent GCP agents HTTP/2 Client agent Salesforce Streaming agent Web Service agents Amazon S3 HTTP/2 Server agent REST Client_Deprecated Agent SAP CC agents only support SAP CC version 2023 SAP CC server version 2023 requires client applications to run on Java 17 . Since MediationZone 9.x is based on Java 17 , SAP CC agents only support SAP CC server version 2023. When upgrading from MediationZone 8.3.x to MediationZone 9.x, it is essential to ensure simultaneous upgrade to both Java 17 and SAP CC version 2023 as well. For SAP CC server version 2022 or earlier, please use Java 8-based clients, such as on MediationZone 8.3.x. Unable to select profile at instance table because profile type is null In the Workflow Editor, the Configuration input fields of the impacted agents are exposed in the Workflow Table via Workflow Properties by setting the field type to either Default or Per Workflow. Attempting to set the Configuration input field at the Workflow Table by opening the Configuration Selection Dialog will result in either of the following: An empty table in the dialog with no Configuration to select A java.lang.NullPointerException error The impacted agents and versions are: Agent Workflow Type Impacted Versions Agent Workflow Type Impacted Versions SQS (Amazon Simple Queue Service) collection agent Realtime 9.3.1.0 and older SQS (Amazon Simple Queue Service) processing agent Realtime 9.3.1.0 and older APN (Apple Push Notification) Processing Agent Realtime 9.3.1.0 and older KPI cluster in processing agent Realtime 9.1.0.3 and older 9.2.2.0 and older 9.3.1.0 and older KPI cluster out processing agent Realtime 9.1.0.3 and older 9.2.2.0 and older 9.3.1.0 and older Parquet Decoder Processing Agent Batch 9.0.3.0 and older 9.1.0.3 and older 9.2.2.0 and older 9.3.1.0 and older Parquet Encoder Processing Agent Batch 9.0.3.0 and older 9.1.0.3 and older 9.2.2.0 and older 9.3.1.0 and older SAP CC Batch Agent Batch 9.0.3.0 and older 9.1.0.3 and older 9.2.2.0 and older 9.3.1.0 and older SQL Collection Agent Batch 9.0.3.0 and older 9.1.0.3 and older 9.2.2.0 and older 9.3.1.0 and older JMS collection agent Realtime 9.0.3.0 and older 9.1.0.3 and older 9.2.2.0 and older 9.3.1.0 and older JMS request processing agent Realtime 9.0.3.0 and older 9.1.0.3 and older 9.2.2.0 and older 9.3.1.0 and older SQL processing agent Realtime 9.0.3.0 and older 9.1.0.3 and older 9.2.2.0 and older 9.3.1.0 and older KPI processing agent Realtime 9.0.3.0 and older 9.1.0.3 and older 9.2.2.0 and older 9.3.1.0 and older REST Server collection agent (deprecated) Realtime 9.0.3.0 and older 9.1.0.3 and older 9.2.2.0 and older 9.3.1.0 and older Python Connector collection agent Realtime 9.0.3.0 and older 9.1.0.3 and older 9.2.2.0 and older 9.3.1.0 and older SQL agent Task 9.0.3.0 and older 9.1.0.3 and older 9.2.2.0 and older 9.3.1.0 and older

---

# Document 77: PulseUDR - MediationZone Documentation 9.3 - InfoZone

**Source:** ratanon/mz93-documentation
**URL:** https://infozone.atlassian.net/wiki/spaces/MD93/pages/205001376/PulseUDR
**Categories:** chunks_index.json

PulseUDR is the UDR that is routed out from Pulse agent on each pulse. Field Description Field Description data (bytearray) The data specified in the agent can be random or fixed. Sequence (long) The sequence number, and how it is generated is specified in agent.

---

# Document 78: SCIM - MediationZone Documentation 9.3 - InfoZone

**Source:** ratanon/mz93-documentation
**URL:** https://infozone.atlassian.net/wiki/spaces/MD93/pages/205816113/SCIM
**Categories:** chunks_index.json

It is possible to use SCIM via the REST HTTP interface to POST, GET, DELETE, PUT and PATCH user and group configurations. This section will cover the schemas used to create, update and remove users and groups, as well as the limitations when using SCIM for MediationZone . For more information regarding the specifications for SCIM, please see RFC: https://tools.ietf.org/html/rfc7643 For information regarding the API endpoints, please see RFC: https://tools.ietf.org/html/rfc7644#section-3.2 Note! When importing the user configurations into MediationZone or when upgrading MediationZone, the users will be disabled after the import operation or the upgrade. To enable the users, you can use PATCH or PUT, a user with attribute active : true. You can also enable the user by ticking the checkbox for the users you want to enable from the User tab in the Access Controller on the MediationZone desktop. When creating a new user from SCIM, the user will be enabled by default. These are the limitations for using SCIM instead of the MediationZone desktop. Only users with write access for application Access Controller should be able to Add, update and delete users or groups. A user can only be created once using the HTTP method POST The password attribute is not mandatory when you create a user with POST, however the user will not be able to login to MediationZone without a password. All user details can be modified except the username. The users assigned group can only be updated using the HTTP method PUT When using PUT to assign a user's group, no default group will be selected. You can only POST an access group with same name one time, the group name can not be changed. It is not possible to set or change the applications connected to the access group using the HTTP methods available via SCIM, this is only possible using the desktop. Custom Schema MediationZone has an additional schema for the "User" resource. The Schema URI for it is: urn:sap:cloud:scim:schemas:extension:custom:2.0:mzuser The following attributes are defined: successor : The successor user takes over all configs when the current user is removed. value: The identifier of the successor user. display: A human-readable name, primarily used for display purposes. It is read-only. validityPeriod : The validity period of a user. Format is: yyyy-mm-ddThh:mm:ss from : The "DateTime" the user should be valid from. to: The "DateTime" the user should be valid to. User related APIs This section will cover all the REST HTTP APIs that are used for user related operations. Retrieving Users You can use this to retrieve all users: URL: http://<host>:9000/scim/api/v1/Users Method: GET Header: Accept: application/scim+json Content-Type: application/scim+json You can use this to retrieve a specific user: URL: http://<host>:9000/scim/api/v1/Users/14c257bd-e486-4ec6-b73e-47bb1e9b491b Method: GET Header: Accept: application/scim+json Content-Type: application/scim+json Creating Users You can use this to create a user: Info! The schemas and userName fields as shown below are mandatory. They must be filled in. The rest of the fields are optional URL: http://<host>:9000/scim/api/v1/Users Method: POST Header: Accept: application/scim+json Content-Type: application/scim+json Request Body: { "schemas":["urn:ietf:params:scim:schemas:core:2.0:User", "urn:sap:cloud:scim:schemas:extension:custom:2.0:mzuser"], "userName":"bjensen", "displayName": "mz80u3", "password": "mz80u3", "active": "true", "emails": [ { "value": "b@b.com", "display": "bbb", "primary": true } ], "externalId":"bjensen", "name": { "formatted":"Ms. Barbara J Jensen III", "familyName":"Jensen", "givenName":"Barbara" }, "groups": [ { "value": "ed309a27-3f34-45d3-ade5-b2f8f798deb5" }, { "value": "86138dad-9742-44a2-a9cb-70347fb884a8" } ], "urn:sap:cloud:scim:schemas:extension:custom:2.0:mzuser": { "successor": { "value": "71a36bb7-816f-460d-b580-3bd9352b0953" }, "validityPeriod": { "from": "2021-03-19T23:00:00Z", "to": "2021-03-23T22:59:59Z" } } } Updating Users You can use this to update all the values for a user: Info! The schemas and userName fields as shown below are mandatory. They must be filled in. The rest of the fields are optional URL: http://<host>:9000/scim/api/v1/Users/c9706a50-6fd3-44cf-8f8d-7ea00fb05f1c Method: PUT Header: Accept: application/scim+json Content-Type: application/scim+json Request Body: { "schemas": ["urn:ietf:params:scim:schemas:core:2.0:User", "urn:sap:cloud:scim:schemas:extension:custom:2.0:mzuser"], "userName": "bjensen", "displayName": "mz80u3", "emails": [ { "value": "b@b.com", "display": "mz80u3", "primary": true } ], "groups": [ { "value": "119fe1b7-4b8b-4970-8ea6-b62bdaa11f05" }, { "value": "53aabe0b-715d-4d96-a220-56c6efc11ae9" } ], "urn:sap:cloud:scim:schemas:extension:custom:2.0:mzuser": { "successor": { "value": "71a36bb7-816f-460d-b580-3bd9352b0953" }, "validityPeriod": { "from": "2021-03-20T23:00:00Z", "to": "2021-03-25T22:59:59Z" } } } You can use this to update specific values for a user: Info! The schemas, Operations, op and value fields as shown below are mandatory. They must be filled in. The rest of the fields are optional URL: http://<host>:9000/scim/api/v1/Users/c9706a50-6fd3-44cf-8f8d-7ea00fb05f1c Method: PATCH Header: Accept: application/scim+json Content-Type: application/scim+json Request Body: { "schemas":["urn:ietf:params:scim:api:messages:2.0:PatchOp", "urn:sap:cloud:scim:schemas:extension:custom:2.0:mzuser"], "Operations":[ { "op":"add", "value": { "emails":[ { "value":"babs@jensen.org", "type":"home" } ] } }, { "op": "add", "path": "urn:sap:cloud:scim:schemas:extension:custom:2.0:mzuser:validityPeriod", "value": { "from": "2021-03-19T23:00:00Z", "to": "2021-03-23T22:59:59Z" } } ] } Removing Users You can use this to remove a user: URL: http://<host>:9000/scim/api/v1/Users/c9706a50-6fd3-44cf-8f8d-7ea00fb05f1c Method: DELETE Header: Accept: application/scim+json Content-Type: application/scim+json Group related APIs This section will cover all the REST HTTP APIs that are used for group related operations. Retrieving Groups You can use this to retrieve all groups: URL: http://<host>:9000/scim/api/v1/Groups Method: GET Accept: */* Content-Type: */* You can use this to retrieve a specific group: URL: http://<host>:9000/scim/api/v1/Groups/119fe1b7-4b8b-4970-8ea6-b62bdaa11f05 Method: GET Accept: */* Content-Type: */* Creating groups You can use this to create a group: Info! The schemas and userName fields as shown below are mandatory. They must be filled in. The rest of the fields are optional URL: http://<host>:9000/scim/api/v1/Groups Method: POST Accept: */* Content-Type: */* Request body: { "schemas":["urn:ietf:params:scim:schemas:core:2.0:Group"], "displayName":"group2", "members":[ { "value":"a12822ad-a5c0-4f83-9a4e-96733a0d2e1b" }, { "value":"8792b456-860a-499d-aa38-5caf4fe487c3" } ] } Updating Groups You can use this to update a group: Info! The schemas and userName fields as shown below are mandatory. They must be filled in. The rest of the fields are optional URL: http://<host>:9000/scim/api/v1/Groups/a85d8e8c-0b6d-4653-b7c6-33c1fd6c1921 Method: PUT Accept: */* Content-Type: */* Request body: { "schemas":["urn:ietf:params:scim:schemas:core:2.0:Group"], "displayName":"group2", "members":[ { "value":"a12822ad-a5c0-4f83-9a4e-96733a0d2e1b" }, { "value":"8792b456-860a-499d-aa38-5caf4fe487c3" } ] } Deleting Groups You can use this to delete a group: URL: http://<host>:9000/scim/api/v1/Groups/a85d8e8c-0b6d-4653-b7c6-33c1fd6c1921 Method: DELETE Accept: */* Content-Type: */*

---

# Document 79: wfgrouplist - MediationZone Documentation 9.3 - InfoZone

**Source:** ratanon/mz93-documentation
**URL:** https://infozone.atlassian.net/wiki/spaces/MD93/pages/205657178/wfgrouplist
**Categories:** chunks_index.json

usage: wfgrouplist <pattern match expression for workflow group names> ... [ -valid ] [ -invalid ] [ -active ] [ -inactive ] [ -scheduled ] [ -unscheduled ] [ -mode < D | E >] [ -short ] [ -members ] Lists the groups that are configured in the system. If no option is used, the list consists of four columns: Workflow Group Names, State, Mode, and Scheduled (true/false). With this command, you compare a single pattern match expression, or several, with the full workflow group name, <folder>.<groupconfigurationname>.<workflowgroupname> , of all the workflows. The command accepts wild cards, such as '*' and '?'. For further information see Textual Pattern Matches . The command accepts the following options: Option Description Option Description [-valid] Lists all valid groups. [-invalid] Lists all invalid groups. [-active] Lists all active groups. [-inactive] Lists all inactive groups. [-scheduled] Lists all the scheduled workflow groups. [-unscheduled] Lists all the workflow groups that are not scheduled. [-mode <D|E>] Lists only workflow groups marked with a specified mode: D - Disabled E - Enabled [-short] If set only the Workflow Group Names will be listed. [-members] Lists the members of the workflow groups and some details of the members, for example, Mode. Return Codes Listed below are the different return codes for the wfgrouplist command: Code Description Code Description 0 Will be returned if the command was successful. 13 Will be returned if the arguments are not recognized.

---

# Document 80: Internal Formats - MediationZone Documentation 9.3 - InfoZone

**Source:** ratanon/mz93-documentation
**URL:** https://infozone.atlassian.net/wiki/spaces/MD93/pages/204612847
**Categories:** chunks_index.json

MediationZone uses internal formats to represent data entities that it can process. All processing agents (for instance, Analysis and Aggregation) work with these internal formats. A syntax for the internal format is declared as follows: internal <name> [: (<class specifications> | <format inheritance>) ] { <field_type> <field_name> [:optional] ; ... }; The field types may be any of the following: Field Type Description Field Type Description any Any type. bigint Big integer. bigdec Big decimal. boolean Boolean. bytearray Byte array. byte Integer type (8-bit signed). char Integer type (16-bit unsigned). short Integer type (16-bit signed). int Integer type (32-bit signed). long Integer type (64-bit signed). float Float type (32-bit). double Float type (64-bit). date Date type, with capability to hold date parts, time parts, or both. bitset A set of bits. ipaddress An IP address. drudr An instance of any other internal (all internal are drudr instances). string String. The field_type can also be any other internal or list type that is defined in either the same ultra file or in another. See the example below. Example - Internal formats Case 1: internal I1 { I2 f1; }; internal I2 { list<int> f1; }; Case 2: In file A internal I1 { <foldername>.<filename>.I2 f1; //When referring an internal from another file that is in the same folder, the folder name can be omitted. }; In file B internal I2 { list<int> f1; }; List types are declared as follows: list< ElementType > Where ElementType can be any of the previous, including an internal format identifier, or another list type. Example - List type internal I1 { list<list<I2> > f1; }; It is also possible to specify a field as optional: Example - Specifying a field as optional internal I1 { drudr f1: optional; }; Similarly, you declare a map field type this way: map< ElementType, ElementType > Example - Declaring a map field internal I1 { map<string, int> f1; }; Internal formats can also be automatically generated from in_map definitions. For further information, see target_internal specification in In-maps . Class Specifications All internal formats are compiled into Java classes. It is possible to specify additional interfaces for the class to implement: Example - Class specifications internal I1 : implements("Interface1"), implements("Interface2") { ... }; However, this requires that Interface1 and Interface2 only declare methods that are later generated by Ultra when it creates the Java class. For further information about methods and types for UDR type methods, see the Development Toolkit user's guide . Format Inheritance You can use alternative base UDR definitions for the generated Ultra classes by using the extends_class or extends option, but all UDR types cannot be used as an extension base. Except for UDR types defined in Ultra, only some specific agent UDRs are extendible, and session UDR types can not be used. extends_class is used by some agents (for instance, the HTTP agent) for better processing support. Example - extends_class internal I1 : extends_class( com.mysite.myDTKUltraFormat ) { ... }; The extends option lets a format inherit fields defined in an ancestor. Example - extends internal A { int a; ... }; internal B : extends ( A ) { int b; ... }; Multiple inheritances is not supported, meaning you can only use the extends or extends_class option once in the definition of an internal format. Event Types It is possible to declare user-defined event types in Ultra by using the event keyword instead of internal . Such an event is a special type of internal format with added event processing support.

---

# Document 81: SAP CC Batch Agents - MediationZone Documentation 9.3 - InfoZone

**Source:** ratanon/mz93-documentation
**URL:** https://infozone.atlassian.net/wiki/spaces/MD93/pages/204642712/SAP+CC+Batch+Agents
**Categories:** chunks_index.json

This section describes the SAP CC Batch agents. These agents are available in batch and real-time workflow config uratio ns. SAP Convergent Charging provides a rating and charging solution for high-volume processing in service industries. It delivers pricing design capabilities, high-performance rating, and convergent balance management. The SAP CC Batch agent provides an easy way to integrate MediationZone with SAP Convergent Charging using Offline Charging. The SAP CC Batch agent is a batch and real-time agent that can be used to: Send charging requests to the SAP Convergent Charging server back end Send batch acquisition operation requests for chargeable items Send event-based advice of charge (i e blankCharge) to the SAP Convergent Charging server The SAP CC Batch agent sends chargeable items in a disconnected or offline mode to the SAP Convergent Charging Server system. This feature is termed by SAP as Offline Charging. More information regarding offline charging can be found in the SAP Convergent Charging application help PDF . The SAP CC Batch agent communicates with the workflow using a dedicated set of UDRs. The SAP CC Batch agent accepts a charge request, a blank charge request, an acquiring request, or a CCBatchCycleUDR that refers to one of these three request types as input. A CCBatchCycleUDR that refers to the result of the processed request, i e the result of a charge or blank charge operation or the result of an acquire operation, will be returned as output. For further information on the SAP CC Batch UDR types, see SAP CC Batch UDRs . SAP CC Batch agent uses the Asynchronous Batch Service Client to send the chargeable items to the Offline Charging system. For further information about the AsyncBatchServiceClient API see the SAP AsyncBatchServiceClient documentation . Note! The SAP CC APIs that the SAP CC Batch agents depend on do not support setting the itemImmediatelyLoaded flag for ChargingOutputContext . As a result, the SAP CC Batch agents cannot support scenarios such as CIT creation via charging requests. The section contains the following subsections: SAP CC Batch Agent in Batch Workflows SAP CC Batch Agent in Real-Time Workflows

---

# Document 82: Provisioning Products for Buckets in Desktop - MediationZone Documentation 9.3 - InfoZone

**Source:** ratanon/mz93-documentation
**URL:** https://infozone.atlassian.net/wiki/spaces/MD93/pages/204743159/Provisioning+Products+for+Buckets+in+Desktop
**Categories:** chunks_index.json

Rules can be provisioned in the PCC Usage Management screen in Desktop. To open the PCC Usage Management screen, click on the Manage screen option in Desktop and then click on the PCC Usage Management button. Open The PCC Usage Management screen In the PCC Usage Management screen you can view, add, edit and remove populated definitions for: Product Mappings Subscriber Profile Product Period Capacity Notification Enforcement See Product Data Model for information about the different definitions and their respective fields. Hint! Whenever configurations are viewed, added, edited, copied, or deleted, this is being logged for the EC log with log level INFO. The system is by default configured to only register log entries with log level WARNING and higher, so if you want the log entries from the PCC Web UI to be registered, change the log level to INFO instead. See System Properties for further information. Creating Product Definitions The different definitions need to be configured in the following order: Periods Capacity Enforcement Notification Product Subscriber Profile Product Mappings The reason for the order stated above is that some definitions are selectable in other definitions as follows: In the Product you can select among the Capacities , Period , Enforcement , and Notification definitions. In the Subscriber Profile you can select among the Product definitions. In the Product Mapping you select among the Products definitions. See Product Data Model and Periods Data Model Rules , for more information about these dependencies. To create the different definitions: In the PCC Usage Management screen, click on the definition type you want to create definitions for. A new screen will be displayed where you can see the definitions that have already been created for the selected type. Click on the New button, fill in the mandatory information and click Save . The definition will be saved and listed in the view, and will now be selectable when creating other definition types that depends on it. Open The Create Product dialog Open The Product Mapping screen showing the Product Mapping definitions The Subscriber Profiles screen showing the Subscriber Profile definitions Editing a Product Definition To edit the different definitions: In the PCC Usage Management screen, click on the definition type you want to definitions for. A new screen will be displayed where you can see the existing definitions. Select the check box for the definition you want to edit and click on Details in the Actions column. A dialog opens up displaying the configuration for the definition. Make your changes and click on the Save button. The definition will be saved and listed in the view, and will now be selectable when creating other definition types that depends on it. Copying Product Definitions To copy definitions: In the PCC Usage Management screen, click on the definition type you want to copy definitions for. A new screen will be displayed where you can see the existing definitions. Select the check box(es) for the definition(s) you want to copy and click on the Copy button. The selected definition(s) will be copied with new ID(s) and you can then edit the definition(s) as described above. Deleting Product Definitions To delete definitions: In the PCC Usage Management screen, click on the definition type you want to delete definitions for. A new screen will be displayed where you can see the existing definitions. Select the check box(es) for the definition(s) you want to copy and click on the Delete button. You will get a question if you are sure you want to delete the definition(s). Click OK if you are sure. The selected definition(s) will be deleted.

---

# Document 83: Contractual Documents - MediationZone Documentation 9.3 - InfoZone

**Source:** ratanon/mz93-documentation
**URL:** https://infozone.atlassian.net/wiki/spaces/MD93/pages/204613907/Contractual+Documents
**Categories:** chunks_index.json

Support Service Descriptions Support Service Descriptions - Service Level Agreement Release and Support Lifecycle MediationZone Security and Privacy Software Description Right to Use Documentation

---

# Document 84: Aggregation Agent Configuration - Batch - MediationZone Documentation 9.3 - InfoZone

**Source:** ratanon/mz93-documentation
**URL:** https://infozone.atlassian.net/wiki/spaces/MD93/pages/205031636
**Categories:** chunks_index.json



---
**End of Part 4** - Continue to next part for more content.
