# RATANON/MZ93-DOCUMENTATION - Part 65/112

---
**Dataset:** ratanon/mz93-documentation
**Part:** 65 of 112
**GitHub:** https://github.com/ratan0n/docs/tree/main/mz93-documentation
**Size:** ~67.6 KB
---

This section describes different ways of managing MediationZone related packages by using the Command Line tool and by using the Java Command Line tool. Removing Packages The following mzsh command can be used for deleting a specific package. The command assumes that you have started mzsh interactively. MZ>> premove <package name> The command should only be used by system administrators with authority to maintain the MediationZone software. Example - Removing a package If you want to remove the XFER_X25 package, enter: MZ>> premove XFER_X25 The following line will be displayed while the package is being removed: Removing XFER_X25, 8.0.0.0...done. After a package has been removed, the Platform and Execution Contexts may have to be stopped and restarted. If a removed package contained a bootstrap class, a cache error message will be displayed. The corresponding bootstrap class must be removed from the STR before the pico instance can be restarted. Package Management Tool All .mzp files provide a built in management tool. It is executed in a Unix shell by running the following command: java -jar <.mzp> <management argument> Management Arguments The added <management argument> controls the execution of the packages. Currently there are seven different arguments; Create, Extract, Help, Install, Patch , Provides and Query. Create Creates the database definitions needed for a package. If no database definitions are needed, the response will be: Nothing to create for this <PACKAGE>. The following is an example of a create command syntax. $ java -Dmz.home=$MZ_HOME -jar archiving_8.0.0.0.mzp create Unpacking database/oracle/packages/archiving/oracle_tables.sql...done Unpacking database/oracle/packages/archiving/oracle_grants.sql...done Unpacking database/oracle/packages/archiving/oracle_synonyms.sql...done Note! If the file install.xml file is not available in the current directory, the environment variable MZ_HOME must be set. Extract Adds any package parameters to install.xml in the current directory. If this file does not exist, it will be created. Help Displays help for the given argument or a help session about all arguments. $ help Install Performs an installation of the selected package. This command is only used when making a new installation. Note! Some packages, e g core, require that install.xml file is available in the current directory when you use the install command. The following is an example of an install command syntax. Example - Installing a package $ java -Dinstall.types=platform -Dmz.home=$MZ_HOME -jar  archiving_8.0.0.0.mzp install ... Inserting Archiving, 8.0.0.0...done. Patch The patch argument is used to perform a patch installation of packages, generally used for upgrading the system, and if necessary, perform patch only specific operations on the system. Note! The command should be executed in the directory where the new package is present. The following is an example of a command using the patch argument. $ java -jar <package name>.mzp patch  mzadmin/<password> In order for the changes to take effect after the command has been executed, some components including the upgraded item may have to be restarted. This could include the Desktop user interface, the Platform, the Execution Contexts and the workflows. Provides Describes the components that the stated package will install. Query This argument will make a query about the existence of a specific package in the installed system. If the queried package is already installed or if the last version is not present, a message stating this will be displayed. Example - Querying a package $ java -jar java -jar ftp_forwarding_8.0.0.0-SNAPSHOT.mzp query FTP Forwarding, 8.0.0.0 (8.0.0.0) The package ftp_forwarding_8.0.0.0-SNAPSHOT.mzp is identical to the committed one. Note! If the install.xml file is not available in the current directory, the environment variable MZ_HOME must be set. Adding or Updating Packages During upgrade or addition of new packages, the mz.license file must be available in the directory specified by the platform property mz.license.file . If this property is not set, the license file must be stored in the $MZ_HOME/etc directory. If new packages are added, the new license file must be copied to the "license" directory before the installation. The addition/upgrade process consists of three steps: Create all database definitions needed for a package using the create argument. Log in as database administrator and execute the corresponding sql files. Install the package using the install argument.

---

# Document 1529: SCP Collection Agent Configuration - MediationZone Documentation 9.3 - InfoZone

**Source:** ratanon/mz93-documentation
**URL:** https://infozone.atlassian.net/wiki/spaces/MD93/pages/205034593/SCP+Collection+Agent+Configuration
**Categories:** chunks_index.json

You open the SCP collection agent configuration dialog from a workflow configuration. To open the Amazon S3 collection agent configuration, click Build  New Configuration . Select Workflow from the Configurations dialog. When prompted to Select workflow type , select Batch . Click Add agent and select SCP from the Collection tab of the Agent Selection dialog. Part of the configuration may be done in the Filename Sequence or Sort Order tab described in Workflow Template . The Configuration view consists of the following tabs: Connection Source Advanced Security Connection Tab The Connection tab contains configuration settings related to the remote host and authentication. Open The SCP collection agent configuration - Connection tab Setting Description Setting Description Connection Information Host Primary host name or IP-address of the remote host to be connected. If a connection cannot be established to this host, the Additional Hosts, specified in the Advanced tab, are tried. File System Type Type of file system on the remote host. This information is used to construct the remote filenames. Unix - remote host using Unix file system. Default setting. Windows NT - remote host using Windows NT file system. Authentication Mechanism Authenticate With Select the authentication mechanism to use. Password and Private Key modes are supported. Username Enter the username for an account on the remote host, enabling the SCP session to log in. Password Enter the associated password. This option only applies when password authentication is enabled. Private Key The Select... button will display a window where the private key may be inserted. If the private key is protected by a passphrase, the passphrase must be provided as well. This option only applies when private key authentication is enabled. For further information, see Authentication in SCP Agents Attributes and Authentication . Collection Retries Enable Select this check box to enable repetitive attempts to connect and start a file transfer. When this option is selected, the agent will attempt to connect to the host as many times as is stated in the Max Retries field described below. If the connection fails, a new attempt will be made after the number of seconds entered in the Retry Interval (s) field described below. Retry Interval (s) Enter the time interval in seconds, between retries. If a connection problem occurs, the actual time interval before the first attempt to reconnect will be the time set in the Timeout field in the Advanced tab plus the time set in the Retry Interval (s) field. For the remaining attempts, the actual time interval will be the number of seconds entered in this field. Max Retries Enter the maximum number of retries to connect. In case more than one connection attempt has been made, the number of used retries will be reset as soon as a file transfer is completed successfully. Note! This number does not include the original connection attempt. Source Tab The Source tab contains configurations related to the remote host, source directories, and source files. The configuration available can be modified through the choice of a Collection Strategy. The following text describes the configuration options available when no custom strategy has been chosen. Open The SCP collection agent configuration - Source tab Setting Description Setting Description Collection Strategy If there is more than one collection strategy available in the system a Collection Strategy drop-down list will also be visible. For further information about the collection strategy, see Appendix 4 - Collection Strategies . File Information Directory Enter the absolute pathname of the source directory on the remote host, where the source files reside. The pathname might also be given relative to the home directory of the Username account. Filename Enter the name of the source files on the remote host. Regular expressions according to Java syntax apply. For further information, see http://docs.oracle.com/javase/8/docs/api/java/util/regex/Pattern.html . Example To match all filenames beginning with TTFILES , type: TTFILES.* . Compression Select the compression type of the source files. Determines whether the agent will decompress the files before passing them on in the workflow or not. No Compression - the agent will not decompress the files. Gzip - the agent decompresses the files using gzip. Before Collection Move to Temporary Directory If enabled, the source files will be moved to the automatically created subdirectory DR_TMP_DIR in the source directory, prior to collection. This option supports safe collection of a source file reusing the same name. Append Suffix to Filename Enter the suffix that you want to be added to the file name prior to collecting it. Warning! Before you execute your workflow, make sure that none of the file names in the collection directory include this suffix. Inactive Source Warning (h) If enabled, when the configured number of hours have passed without any file being available for collection, a warning message (event) will appear in the System Log and Event Area: The source has been idle for more than <n> hours, the last inserted file is <file>. After Collection Move to If enabled, the source files will be moved from the source directory (or from the directory DR_TMP_DIR , if using Move to Temporary Directory ) after collection, to the directory specified in the Destination field. If Prefix or Suffix are set, the file will be renamed as well. Note! If a file with the same filename already exist in the target directory, this file will be overwritten and the workflow will not abort. Destination Enter the absolute pathname of the directory on the remote host into which the source files will be moved after the collection. This field is only available if Move to is enabled. Note! The Directory has to be located in the same file system as the collected files at the remote host. Also, absolute pathnames must be defined. Relative pathnames cannot be used. Prefix and Suffix Enter the Prefix and/or suffix that will be appended to the beginning and/or the end, respectively, of the source files after the collection. This field is only available if Move to or Rename is enabled. Note! If Rename is enabled, the source files will be renamed in the current directory (source or DR_TMP_DIR ). Be sure not to assign a Prefix or Suffix, giving files new names still matching the Filename Regular Expression. That would cause the files to be collected over and over again. Search and Replace Select this option if you want to apply the Search and Replace function. Select either the Move to or Rename setting.  Search - Enter the part of the filename that you want to replace.  Replace - Enter the replacement text. Search and Replace operate on your entries in a way that is similar to the Unix sed utility. The identified filenames are modified and forwarded to the following agent in the workflow. This functionality enables you to perform advanced filename modifications, as well:  Use regular expression in the Search entry to specify the part of the filename that you want to extract.  Enter Replace with characters and metacharacters that define the pattern and content of the replacement text. Search and Replace Examples To rename the file file1.new to file1.old , use: Search : .new Replace : .old To rename the file JAN2011_file to file_DONE , use: Search : ([A-Z]*[0-9]*)_([a-z]*) Replace : $2_DONE Note that the search value divides the file name into two parts by using brackets. The replace value applies the second part by using the place holder $2. Keep (days) Enter the number of days to keep moved or renamed source files on the remote host after the collection. In order to delete the source files, the workflow has to be executed (scheduled or manually) again, after the configured number of days. Note, a date tag is added to the filename, determining when the file may be removed. This field is only available if Move to or Rename is selected. Rename If enabled, the source files will be renamed after the collection, remaining (or moved back from the directory DR_TMP_DIR , if using Move to Temporary Directory ) in the source directory from which they were collected. Remove If enabled, the source files will be removed from the source directory (or from the directory DR_TMP_DIR , if using Move to Temporary Directory ), after the collection. Ignore If enabled, the source files will remain in the source directory after the collection. This option is not available if Move to Temporary Directory is enabled. UDR Type Route FileReferenceUDR Select this check box if you want to forward the data to an SQL Loader agent. See the description of the SQL Loader agent in SQL Loader Agent for further information. Advanced Tab The Advanced tab contains configurations related to a more specific use of the SCP service. Open The SCP collection agent configuration - Advanced tab Setting Description Setting Description Advanced Settings Port Enter the port number the SCP service will use on the remote host. Timeout (s) Enter the maximum time, in seconds, to wait for a response from the server. 0 (zero) means to wait forever. Accept New Host Keys If selected, the agent overwrites the existing host key when the host is represented with a new key. The default behavior is to abort when the key mismatches. Note! Selecting this option causes a security risk since the agent will accept new keys regardless if they possibly belong to another machine. Enable Key Re-Exchange This option enables or disables automatic re-exchange of session keys during ongoing connections. This can be useful if you have long-lived sessions since you may experience connection problems for some servers if one of the sides initiates a key re-exchange during the session. Additional Hosts Additional Hosts This option allows additional host names or IP addresses to be used during the connection establishment. These hosts are tried, in sequence from top to bottom, if the agents fail to connect to the remote host set in their Connection tabs. Use the Add , Edit , Remove , Up , and Down buttons to configure the host list. Security Tab The Security tab contains configurations related to the Advanced Security Options for SCP. The Configuration available can be modified by enabling the Advanced Security Option check box. If the Advanced Security Option is not enabled, the Cipher Mode will default to aes128-ctr and the HMac Type will default to hmac-sha2-256 . If the Advanced Security Option is enabled but the combo box fields are left empty, the Cipher Mode will default to aes128-ctr and the HMac Type will default to hmac-sha2-256 . Open The SCP collection agent configuration - Security tab Note! Due to an upgrade of the Maverick library for MediationZone version 8.1.5.0, the default handling of the advanced security has changed. Users should take note of the behavior change for the Advanced Security Option for the SCP agents. The Advanced Security Option will be disabled by default. Users will have to enable it on their own accord from the Security Tab in the SCP agents configuration. With Advanced Security Option disabled, Maverick will manage the connection between the SCP agent and the server. Maverick will attempt to connect with the STRONG security level. Failing to do so, it will auto downgrade the security level to WEAK and attempt to connect, this behaviour will allow our agents to work well with backwards compatibility for servers with older instances of the Maverick library. Furthermore, having a STRONG security level will result in performance degradation. However, when a user manually enables the Advanced Security Option from the security tab, Maverick will instead assign the WEAK security level, which will not be as strict or resource intensive as the STRONG security level. For more information about security levels, you can refer to this page: https://www.jadaptive.com/managed-security-in-our-java-ssh-apis/ Setting Description Setting Description Advanced Security Settings Enable Advanced Security Option If enabled, this will enable the Cipher Mode and HMac Type options below, allowing for advanced security configuration. Cipher Mode Select the algorithms for the Block Cipher Modes. This allows the agent to determine which algorithm for the block cipher to be used when communicating with the servers. 3des-cbc 3des-ctr blowfish-cbc aes128-cbc aes192-cbc aes256-cbc aes128-ctr aes192-ctr aes256-ctr arcfour arcfour128 arcfour256 HMac Type Select the encryption methoc for Key Exchange. This allows the agent to determine the method of encryption to be used when the keys are exchanged between the servers and the SCP agent. hmac-sha1 hmac-sha1-96 hmac-sha1-etm@openssh.com hmac-md5 hmac-md5-96 hmac-md5-etm@openssh.com hmac-sha2-256 hmac-sha2-256-96 hmac-sha2-256-etm@openssh.com hmac-sha2-512 hmac-sha2-512-96 hmac-sha2-512-etm@openssh.com hmac-ripemd160 hmac-ripemd160-etm@openssh.com

---

# Document 1530: mzcli - wfgroupremovewfgroup - MediationZone Documentation 9.3 - InfoZone

**Source:** ratanon/mz93-documentation
**URL:** https://infozone.atlassian.net/wiki/spaces/MD93/pages/547980140/mzcli+-+wfgroupremovewfgroup
**Categories:** chunks_index.json

Usage usage: wfgroupremovewfgroup <workflow group name> <regexp for workflow group name(s)> This command removes one or more workflow groups from a workflow group. Note! With wfgroupremovewfgroup you cannot remove all the workflow groups from a workflow group, as this will result in an invalid workflow group configuration. In that case, the command aborts and an error message informs you about the abort cause. Since the workflow group should not be emptied, the command enables you to remove all the workflow groups from the parent workflow group only if the workflow group also contains a workflow. This means that after removing all the workflow groups, the parent workflow group is not empty. See the figure below, The wfgroupremovewfgroup command. Open The wfgroupremovewfgroup Return Codes Listed below are the different return codes for the wfgroupremovewfgroup command: Code Description Code Description 0 Will be returned if the command was successful. 1 Will be returned if the number of arguments is incorrect. 2 Will be returned if the group is not found. 3 Will be returned if the workflow(s) you want to remove cannot be found. 4 Will be returned if there is no connection to Mgmt_Utils. 5 Will be returned if the group is locked. 6 Will be returned if the updating of group data failed. 7 Will be returned if the configuration lock could not be released. 8 Will be returned if the group is empty (all members have been removed).

---

# Document 1531: Log Filter - MediationZone Documentation 9.3 - InfoZone

**Source:** ratanon/mz93-documentation
**URL:** https://infozone.atlassian.net/wiki/spaces/MD93/pages/314998785
**Categories:** chunks_index.json

In the Log Filter tool, you can edit log settings for the picos and update the logging dynamically. To view the Log Filter, go to Manage  Tools & Monitoring and then select Log Filter . Open Log Filter In Log Filter you have the following settings: Setting Description Setting Description Picos Select the pico(s) you want to update log settings for. If you select several picos, only one pico name will be displayed but you will see their names when hovering the number to the left of the pico. Refresh Click on this button to refresh the list of available picos. Some may have been added or removed since you opened the Log Filter. Reset Select this check box to remove all updated settings and revert to the default settings which are as follows: Stacktrace: ON Level: Set to the value of system property: pico.log.level Package: Any package/class. File: No additional file Stacktrace Select this check box to configure whether the stacktrace should be included in the log or not. Available options in the drop-down are ON and OFF . Level Select the lowest level of severity you want to log in this drop-down; ERROR , WARN , INFO , CONFIG , DEBUG , TRACE , FINEST . You can also select ALL to log all events regardless of severity, and OFF to stop all logging for the selected picos . Caution! If you set a detailed log level, such as DEBUG, TRACE, or FINEST, logging will be done for all classes in the selected pico(s), including APL logging, which may have a negative impact on performance. To avoid excessive logging when using these log levels, you can select the Package check box, described below, and enter a package, for example, aplLogger to only do logging for APL. Package Select this check box to only log events for a specific *.mzp package or class. Specify the package name or class in the field to the right. This setting can be useful if you have built your own DTK packages, or if you need help from support. Note! When you use the Package option and state aplLogger, you can also specify a specific workflow by appending it like this: aplLogger.<workflow name>. File Select this check box to send logging an additional file with the filename specified in the field to the right. If you only select this check box and nothing else, the same logging will be done in both the regular log files and the additional file, but if you make any other log settings and select this check box, the other setting will only be applied for the logging in the additional file and not for the regular logging. Update Click on this button to apply your changes to the log settings for the selected pico(s). Clear Click on this button to clear all settings you have made.

---

# Document 1532: Google Secret Manager Profile - MediationZone Documentation 9.3 - InfoZone

**Source:** ratanon/mz93-documentation
**URL:** https://infozone.atlassian.net/wiki/spaces/MD93/pages/227311617
**Categories:** chunks_index.json

You can use the Google Secret Manager profile to setup up the access credentials and properties for connecting to a Google Secret Manager environment. Currently, the profile can be used in the following Profiles: Secrets Profile Security Profile Buttons The contents of the buttons bar may change depending on which configuration type has been opened in the currently displayed tab. The Google Secret Manager profile uses the standard buttons that are visible for all configurations, and these are described in Common Configuration Buttons . The Edit menu is specific for the Google Secret Manager Profile configurations. Button Description Button Description External References Click on this button to enable External References in the Google Secret Manager profile configuration. This can be used to configure the following fields: Project Id Private Key Id Private Key Client Email Client Id Other Information For further information, see Using External Reference in Agent Profile Fields and External Reference Profile . Note! If there is a proxy in your network environment, it will work with a proxy that does not require authentication. Currently, it does not work with a proxy that requires authentication. Refer to HTTP Proxy Support for more details. Configuration Open Google Secret Manager Profile Setting Description Setting Description Environment-Provided Service Account When MediationZone is deployed in a GCP environment, such as in Compute Engine, enable this option to retrieve the Service Account credentials provided by the environment. Project Id The GCP Project Id that hosts the GCP service that MediationZone should access. Private Key Id The Private Key Id to be used for the service account. Private Key The full content of the private key. Client Email The email address given to the service account. Client Id The Id for the service account client. Other Information The Auth URI, Token URI and info about the certs are to be added into this field.

---

# Document 1533: Data Repository - MediationZone Documentation 9.3 - InfoZone

**Source:** ratanon/mz93-documentation
**URL:** https://infozone.atlassian.net/wiki/spaces/MD93/pages/204647344/Data+Repository
**Categories:** chunks_index.json

This section will describe how to perform basic administration for the data repository. Couchbase In Couchbase clusters, the data is stored in data buckets. During the PCC installation, you can create data buckets in the cluster by using Couchbase profiles. See the PCC Installation Instructions for further information regarding this procedure. Once you have made your installation, you can select to add, edit, and delete buckets either in the Couchbase Web Console or by using Couchbase profiles. For information about how to create, edit, and remove buckets in Couchbase, see the official Couchbase documentation: https://docs.couchbase.com/home/index.html . Redis For information about the basic administration of a Redis database, see the official Redis documentation: https://redis.io/docs/ . MySQL Cluster For information about the basic administration of a MySQL Cluster database, see the official Oracle documentation: https://docs.oracle.com/cd/E37745_01/html/E38170/toc.html . Loading

---

# Document 1534: EC Groups - MediationZone Documentation 9.3 - InfoZone

**Source:** ratanon/mz93-documentation
**URL:** https://infozone.atlassian.net/wiki/spaces/MD93/pages/204671006
**Categories:** chunks_index.json

The EC Groups tool allows you to view/add EC Groups. The EC groups can be added here or by using the mzsh command pico for example. See the Execution Tab for more information on how to add ECs to an EC Group. In the following sections, we will explain the EC Groups tool and the configuration files. EC Groups Tool The EC Groups tool shows the list of EC groups. From the list, you are able to add, delete or edit groups. You can sort the group names alphabetically. To refresh the list, click the Refresh button at the top of the list. Open EC Groups Add a New Group Click the Add button to add a new EC Group. A window pops up where you can fill in the name of the EC Group. Click OK and the group becomes visible in the list. See the mzsh command pico for an example on how to add an EC group. Editing an Existing Group To edit an existing EC group, select the checkbox of the EC Group and click the Edit button. A new window is displayed using which you can edit the group name. Click OK to close the window and submit the changes. The list is updated with your changes. Open EC Groups - Edit Removing a Group To delete one or many groups, select the group to remove and click the Delete button. EC groups from Topo or Pico Management If you have defined EC Groups using topo commands or in the Pico Management tool, the list will automatically display these EC groups, when they are started.

---

# Document 1535: JWT Validation Result UDR - MediationZone Documentation 9.3 - InfoZone

**Source:** ratanon/mz93-documentation
**URL:** https://infozone.atlassian.net/wiki/spaces/MD93/pages/304515657
**Categories:** chunks_index.json

The OAuth validateAndDecodeJwt APL plugin produce one type of UDR: JwtValidationResult. JwtValidationResult This UDR is used for describing a specific attachment. Field Description Field Description errorMessage (string) The error message returned when validation fails. It will be null if validation succeeds. claims (map<string, any>) The decoded payload data. OriginalData (bytearray) The original data in bytearray format.

---

# Document 1536: Launcher Service Interface - MediationZone Documentation 9.3 - InfoZone

**Source:** ratanon/mz93-documentation
**URL:** https://infozone.atlassian.net/wiki/spaces/MD93/pages/204647305
**Categories:** chunks_index.json

When you run the Desktop Launcher, you may add one or more launcher services that provide connection settings for MediationZone deployments. You may use launcher services as an alternative to manually entering the settings for each instance. A launcher service is an external web service that returns a list of existing Platform processes to the desktop launcher. The launcher will only know the URL to the service and uses this information to retrieve the list of instances via HTTP GET. Launcher services are useful in a dynamic environment, e g cloud deployments, where platforms are expected to change IP addresses and ports often. But it can also be useful in a static environments since it reduces the need for manual configuration. Response Format In order for the Desktop Launcher to correct parse the response from launcher service, it must adhere to the following format. mz.<unique identifier>.<attribute>=<value> The unique identifier is used for grouping attributes of a MediationZone instance. You may use e g a UUID for this purpose. The following attributes are available: Attribute Description Attribute Description url The URL Platform Container host, e g https://example.com . This attribute is mandatory. name An arbitrary name of the instance that will be displayed in the Desktop Launcher. This is attribute is mandatory. overrides.pico.rcp.platform.port When the Desktop connects to the Platform it retrieves the value of the property pico.rcp.platform port from the STR. If the Desktop will run on a different network than the Platform, you may need to include this attribute in order to override the retrieved value with an external port number. This attribute is optional. Example - GET request with curl and response from launcher service $ curl examplehost.com mz.139808b7-b9ad-4434-9dbd-5233188c6b2c.url=http://10.10.46.1:9000 mz.139808b7-b9ad-4434-9dbd-5233188c6b2c.name=test-environment mz.a01884d2-cd76-4080-857c-db1d42d8ecdc.url=https://example.com:32768 mz.a01884d2-cd76-4080-857c-db1d42d8ecdc.name=prod-environment mz.a01884d2-cd76-4080-857c-db1d42d8ecdc.overrides.pico.rcp.platform.port=32770 Example Implementation Below is an example of a launcher service implementation written in Python. The script will return the contents of the file that is specified in the first argument. #!/usr/bin/env python import sys from BaseHTTPServer import BaseHTTPRequestHandler, HTTPServer class LauncherService(BaseHTTPRequestHandler): def do_GET(self): try: f = open(sys.argv[1], 'r') self.send_response(200) self.send_header('Content-type', 'text/plain') self.end_headers() self.wfile.write(f.read()) f.close() return except IOError: self.send_error(404, 'file not found') def run(): server_address = ('0.0.0.0', 80) httpd = HTTPServer(server_address, LauncherService) print('http server is running...') httpd.serve_forever() if __name__ == '__main__': run() To run the script: Install python 2x. Save the code above in a file named launcher_service.py . Create a file that contains the instance information. For further information, see Response Format above. Set executable permissions on the file: $ chmod +x launcher_service.py Run the script: $ ./launcher_service.py <file> You may now add the service in the Desktop Launcher.

---

# Document 1537: Appendix 2 - Batch and Real-Time Workflow Agents - MediationZone Documentation 9.3 - InfoZone

**Source:** ratanon/mz93-documentation
**URL:** https://infozone.atlassian.net/wiki/spaces/MD93/pages/204606046/Appendix+2+-+Batch+and+Real-Time+Workflow+Agents
**Categories:** chunks_index.json

This appendix contains descriptions for all the agents that are available in MediationZone: ADLS2 File Agents Aggregation Agent Amazon S3 Agents AMQP Agent Analysis Agent APN Agent Archiving Agents Azure Event Hub Agents Categorized Grouping Agent Compression Agents Database Agents Data Masking Agent Data Veracity Decoder Agent Diameter Agents Disk Agents Duplicate Batch Agent Duplicate UDR Agent Email Agent Encoder Agent Encryption Agent Error Correction System Excel Agents Firebase Agent FTAM EWSD Agent FTAM IOG Agent FTP Agents FTP DX200 Agent FTP EWSD Agent FTP NMSC Agent FTPS Agents GCP Agents GTP' Agent GTP' LGU Agents HDFS Agents HTTP Batch Agent HTTPD_Deprecated Agent HTTP/2 Agents IBM MQ Agent Inter Workflow Agents IPDR SP Agent JMS Agents Kafka Agents LDAP Agent Merge Files Agent MQTT Agent MSMQ Agents Netflow Agent Netia FTP Agent Parquet Agents Prometheus Agent Pulse Agent Python Agents Radius Agents REST_Deprecated Agents Salesforce Streaming API Agent SAP CC Agents SAP JCo Uploader Agent SAP RFC Processor Agent SCP Agents SFTP Agents SMPP Agents SNMP Agents SQL Agents SQL Loader Agent SQS Agents Streaming Telemetry Agent Syslog Collection Agent TCP/IP Agents UDP Agent UI Builder Agent Web Service Agents Websocket Agents Workflow Bridge Agents Batch-Based Real-Time Agents

---

# Document 1538: Service Model Definition - MediationZone Documentation 9.3 - InfoZone

**Source:** ratanon/mz93-documentation
**URL:** https://infozone.atlassian.net/wiki/spaces/MD93/pages/205655925
**Categories:** chunks_index.json

A service model contains definitions of objects that represent dimensions, metrics, KPIs, and alarm thresholds. The service model also describes these objects, e g the metrics and dimensions that are required to calculate a KPI. Open Service model objects and dependencies The metric and dimension objects are mapped to specific fields in the KDR input. The figures in the example below illustrate how the input data is mapped to a KDR and finally to dimensions and a metric. Example - Mapping objects to KDR input The UDR types below have a startTime field that can be used for triggering start and closing of period, i e timestamp field of the KDR is populated with this value. If this type of field does not exist, you can generate a timestamp from APL. The UDRs RecA and RecB have a different set of fields but it is possible to define dimensions and metrics for the set fields that are available in each type. For instance, a metric can be defined so that it is calculated based on valueX for type 1 and valueY for type 2. You may use any string value as a type identifier. In this example the recordType field is used to identify the type. Open Ultra configuration The KDRs are populated with the values from the collected UDRs. The keys in the value field of the KDR (hereafter also referred to as "fields") can be selected arbitrarily but have to be unique within the KDR. These fields will be referenced in the metric and dimension definitions of the service model. At this point it would have been possible to treat both UDR types, RecA and RecB , as a single type. In this case you would assign the same field names to both records. For instance, myvalue instead of valueX or valueY . The fields that will be used for metric calculations must be numerical types, e g int, long, float, double etc. Open APL configuration The service model has two dimensions, Region and Site . There are two references for each of the dimensions, one for the respective types. For type 1, the model references the field region to retrieve the instantiated name of Region . For type 2, it references the field named district . It is assumed here that these will serve an identical purpose even though the original UDRs have distinct formats. The service model has a simple structure under the tree object that indicates that Region is the parent dimension to Site . This tree has a single root node, tree1 , but you may add multiple root nodes. For instance, if a site may span multiple regions, you may want to add a second tree where the hierarchal order is reversed. The service model has one metric that calculates an average value. Similar to the dimension, there are references for each type in the expression (expr). The expression only contains one field name, which will return its actual value as a floating-point number (double). You may perform more complex calculations using functions, operators, and a combination of fields. For further information, see metric . Finally the the dimensions, metric, and the tree are combined to define two KPIs. When you apply this model in KPI Management, the output in each period will be the Average metric for the two dimensions, Region and Site . The length of the periods is specified by windowSize , which will have the same unit as the input value. For instance, if the value in the timestamp field of the KDR has the unit seconds, the period length will be 60 seconds. Open Service model Object Types Overview These are the main object types in the service model: Object Type Description Object Type Description dimension The dimension objects represent values that are extracted from KDR UDRs and are used for grouping in KPI calculations. For instance, if the input data contains a field that represents a geographic region, it can be mapped to an object instance named "Region". Example - JSON Representation "dimension": { "Region": { "kdr_record_type_a": "region_name" } } For further information about the dimension object type, see dimension . tree The tree objects contain nodes that describe the hierarchical structure of the dimensions. The name of a tree object constitutes the root node of a tree. The root node may have one or more child nodes, e g "Region". A child node in turn may have its own child nodes, e g "City" or "Site", and so on. Example - JSON Representation "tree": { "tree1": { "Region": { "Site": {} } } } For further information about the tree object type, see tree . metric The metric objects represent values that are extracted from KDR UDRs and aggregated according to the tree structure in the model. Expressions are applied on the various fields in the UDRs to calculate a value, e g a sum, average, or min/max value. Example - JSON Representation "metric": { "AvgDuration": { "fun": "avg", "expr": { "kdr_record_type_a": "field2-field1", "kdr_record_type_b": "field3" } } } For further information about the metric object type, see metric . threshold The threshold objects contain a set of level objects that define limits for the KPIs. When a limit is exceeded within a defined period, a threshold object and a level object are referenced in the KPIOutput UDRs. You can define the limit values for a threshold object in ascending or descending order. Example - JSON Representation "threshold": { "Region.AD": { "orderDescending": true, "levels": { "1": { "alarmDescription": "", "value": 200 }, "2": { "alarmDescription": "", "value": 100 } } } } For further information about the threshold object type, see threshold . kpi The kpi objects describe how metrics are linked to dimensions and threshold levels. You may configure kpi objects to perform additional calculations based on metrics, e g ratios or sums of ratios. Example - JSON Representation "kpi": { "Region.AD": { "node": [ "tree1", "Region" ], "windowSize": 60, "threshold": "Region.AD", "expr": "AvgDuration" } } For further information about the kpi object type, see kpi .

---

# Document 1539: File System Type -Amazon S3 - MediationZone Documentation 9.3 - InfoZone

**Source:** ratanon/mz93-documentation
**URL:** https://infozone.atlassian.net/wiki/spaces/MD93/pages/315195442/File+System+Type+-Amazon+S3
**Categories:** chunks_index.json

When selecting Amazon S3 as a file system, you will see two tabs  General and Advanced . Open Amazon S3 File System Type Configuration General tab The following settings are available in the General tab in the File System profile: Setting Description Setting Description File System Type Select which file system type this profile should be applied for. Currently, only Amazon S3 is available. Credentials Settings Credentials from Environment Select this check box in order to pick up the credentials from the environment instead of entering them in this profile. If this check box is selected, the Access Key and Secret Key fields will be disabled. Access Key Enter the access key for the user who owns the Amazon S3 account in this field. Secret Key Enter the secret key for the stated access key in this field. Location Settings Region from Environment Select this check box in order to pick up the region from the environment instead of entering the region in this profile. If this check box is selected, the Region field will be disabled. Region Enter the name of the Amazon S3 region in this field. Bucket Enter the name of the Amazon S3 bucket in this field. Use Amazon Profile Select this check box if you already have an Amazon Profile set up, this will disable the fields above and allow you to utilize the credentials that you have defined in your chosen Amazon Profile. Advanced tab The Advanced tab allows for advanced properties to be configured in the profile. Open File System profile - Amazon S3 - Advanced tab

---

# Document 1540: Amazon S3 Forwarding Agent Configuration - MediationZone Documentation 9.3 - InfoZone

**Source:** ratanon/mz93-documentation
**URL:** https://infozone.atlassian.net/wiki/spaces/MD93/pages/204639956
**Categories:** chunks_index.json

To open the Amazon S3 collection agent configuration dialog from a workflow configuration, you can do the following: right-click the agent icon and select Configuration... select the agent icon and click the Edit button Note! If you are using the Amazon S3 collection agent in a Batch workflow, part of the configuration may be done in the Filename Template tab in Workflow Template . For Real-Time workflow, additional configurations in File Closing Criteria tab are available in Batch-Based Real-Time Agents - Agent Configuration . Open Amazon S3 forwarding agent configuration dialog - Amazon S3 tab Setting Description Setting Description Profile Select the File System profile you want the agent to use, see File System Profile for further information about this profile. Input Type The agent can act on two input types. Depending on which one the agent is configured to work with, the behavior will differ. The default input type is bytearray, that is the agent expects bytearrays. If nothing else is stated the documentation refer to input of bytearray. If the input type is MultForwardingUDR , the behavior is different. For further information about the agent's behavior in MultiForwardingUDR input, see Amazon S3 Forwarding MultiForwardingUDR Input . File Information Directory Enter the absolute pathname of the target directory on the location stated in the referenced File System profile, where the forwarded files will be stored. The files will be temporarily stored in the automatically created subdirectory DR_TMP_DIR , in the target directory. When an End Batch message is received, the files are moved from the subdirectory to the target directory. Create Directory Select this setting to create the directory, or the directory structure, of the path that you specify in the Directory field. Note! The directories are created when the workflow is executed. Compression Select the compression type of the target files: No Compression - agent does not compress the files. This is the default setting. Gzip - agent compresses the files using gzip. This determines if the agent will compress the files or not. Note! No extra extension will be appended to the target filenames, even if compression is selected. The configuration of the filenames is managed in the Filename Template tab only. After Treatment Command If a UNIX command is supplied, it will be executed on each successfully closed temporary file, using the parameter values declared in the Arguments field. Note! At this point the temporary file is created and closed, however the final filename has not yet been created. The entered command has to exist in the execution environment, either including an absolute path, or to be found in the PATH for the execution environment. Arguments This field is optional. Each entered parameter value has to be separated from the preceding value with a space. The temporary filename is inserted as the second last parameter, and the final filename is inserted as the last parameter, automatically. This means that if, for instance, no parameter is given in the field, the arguments will be as follows: $1=<temporary_filename> $2=<final_filename> If three parameters are given in the field Arguments, the arguments are set as: $1=<parameter_value_#1> $2=<parameter_value_#2> $3=<parameter_value_#3> $4=<temporary_filename> $5=<final_filename> Produce Empty Files If enabled, files will be produced although containing no data.

---

# Document 1541: Data Processing Reports - MediationZone Documentation 9.3 - InfoZone

**Source:** ratanon/mz93-documentation
**URL:** https://infozone.atlassian.net/wiki/spaces/MD93/pages/205849298/Data+Processing+Reports
**Categories:** chunks_index.json

Below is an example of a customized Data processing report either executed as scheduled or on demand. Audit can be selected on a high level or for each individual file. The balance column gives a view of the current state that is the total number of UDRs into the system minus number of dropped, error system, split and out. Open Example of customized data processing report

---

# Document 1542: MSMQ Collection Agent - MediationZone Documentation 9.3 - InfoZone

**Source:** ratanon/mz93-documentation
**URL:** https://infozone.atlassian.net/wiki/spaces/MD93/pages/205001050/MSMQ+Collection+Agent
**Categories:** chunks_index.json

The MSMQ collection agent is used to connect to an MSMQ queue and receive messages. For example: Open MSMQ Collection Workflow Consider this simple workflow where an MSMQ collection agent is connected to an Analysis agent. Configure the Analysis agent as specified below: Example: Collecting and Processing an MSMQ Message consume { if ( instanceOf (input, MSMQ)) { MSMQ msg = (MSMQ) input; //Process the MSMQ Message } } The section contains the following subsections: MSMQ Collection Agent Configuration

---

# Document 1543: Syslog Collection Agent Example - MediationZone Documentation 9.3 - InfoZone

**Source:** ratanon/mz93-documentation
**URL:** https://infozone.atlassian.net/wiki/spaces/MD93/pages/205002276/Syslog+Collection+Agent+Example
**Categories:** chunks_index.json

The example below demonstrates how to extract the contents of a SyslogMessageUDR . Open Syslog workflow Set the output route from Syslog_1 to synchronous in order to facilitate debugging. This causes the messages to be processed in sequential order. For other purposes the route should be set to asynchronous (default). Example - Analysis_1 APL Code consume { debug("*** BEGIN ***"); debug("AppName: " + input.AppName); debug("Facility: " + input.Facility); debug("HostName: " + input.HostName); debug("Message: " + input.Msg); debug("MsgId: " + input.MsgId); debug("ProcId: " + input.ProcId); debug("Severity: " + input.Severity); debug("Timestamp: " + input.Timestamp); debug("Version: " + input.Version); if(null != input.StructuredData) { debugStructuredData(input.StructuredData); } debug("*** END ***"); } void debugStructuredData(map<string,map<string,string>> sdData) { debug("StructuredData:"); //Get the SD-ELEMENT keys from Structured Data list<string> sdKeys = mapKeys(sdData); //Get the number of SD elements int sdSize = listSize(sdKeys); //Iterate through the SD-ELEMENTs for(int i=0;i<sdSize;i++) { debug("SD-ELEMENT #" + (i+1)); //Get the next SD-ELEMENT map<string,string> element = mapGet(sdData, (string) listGet(sdKeys,0)); //Get the SD-PARAM keys in the SD-ELEMENT list<string> paramKeys = mapKeys(element); //Get the number of SD-PARAMs int paramSize = listSize(paramKeys); //Iterate through the SD-PARAMs for(int j=0;j<paramSize;j++) { string curKey = listGet(paramKeys,j); string curVal = mapGet(element, curKey); debug("SD-PARAM #" + (j+1) + ":" + curKey + ":" + curVal); } } }

---

# Document 1544: mzcli - premove - MediationZone Documentation 9.3 - InfoZone

**Source:** ratanon/mz93-documentation
**URL:** https://infozone.atlassian.net/wiki/spaces/MD93/pages/547979644/mzcli+-+premove
**Categories:** chunks_index.json

Usage premove <package-name> Removes the selected package from the system. The command should only be used by system administrators with authority to maintain the software. Return Codes Listed below are the different return codes for the premove command: Code Description Code Description 0 Will be returned if the command was successful. 1 Will be returned if there is no package with the specified name.

---

# Document 1545: Batch Answer - MediationZone Documentation 9.3 - InfoZone

**Source:** ratanon/mz93-documentation
**URL:** https://infozone.atlassian.net/wiki/spaces/MD93/pages/204642810/Batch+Answer
**Categories:** chunks_index.json

The answer field for CCBatchcycleUDR may contain a UDR that is described here or a UDR in Charging Answer UDRs . AcquisitionExceptionUDR This UDR represents the exception thrown when a direct batch acquisition operation of a collection of chargeable items fails in the connected SAP CC Server system. Field Description Field Description message (string) A string description of the error message reason (string) A string description of the reason for the exception REASON_ACCESS_NOT_FOUND (string) This exception is thrown when the service identifier (SID), user service identifier (USID), and consumption date specified in the operation request, do not correspond to existing access data in the customer master data of the service provider. REASON_ACQUISITION_NOT_ALLOWED (string) This exception is thrown when the acquisition operation request is not allowed. REASON_EXPORT_FAILURE (string) This exception is thrown when the chargeable item cannot be exported. REASON_INVALID_ACCESS (string) This exception is thrown when one of the access information subelements specified in the operation request (service identifier (SID), user service identifier (USID), or consumption date) is empty. REASON_INVALID_CHARGEABLE_ITEM (string) This exception is thrown when the chargeable item to acquire is not specified in the operation request or its name is empty. REASON_SERVER_FAILURE (string) This exception is thrown when an unexpected error occurs during the acquisition of the chargeable item. REASON_TARGET_NOT_FOUND (string) This exception is thrown when the provider contract (or subscription) targeted by the access cannot be found in the customer master data of the service provider. REASON_COMMUNICATION_FAILURE (string) This exception is thrown when a communication failure occurs during the acquisition of the chargeable item. AcquisitionResultsUDR This UDR represents the operation results replied by the connected SAP Convergent Charging server in response to a batch acquisition operation request of a chargeable item or a collection of chargeable items. For the field definitions, see the section below, AcquisitionResultUDR. AcquisitionResultUDR This UDR represents the operation result replied by the connected SAP Convergent Charging server in response to a batch acquisition operation request of a chargeable item or a collection of chargeable items. Field Description Field Description exception (AcquisitionExceptionUDR (sapcc.batch)) This field indicates the exception that describes the error encountered during the acquisition of the chargeable item. For more details on the possible values, see the section above, AcquisitionExceptionUDR. isSuccessful (boolean) This field indicates whether the corresponding chargeable item was acquired successfully. operandReference (string) This field is populated with the code or the reference (if no code exists) that identifies the operand of the operation request. If the operation is not auditable, the operand reference is null.

---

# Document 1546: The Diameter Transport Protocols - MediationZone Documentation 9.3 - InfoZone

**Source:** ratanon/mz93-documentation
**URL:** https://infozone.atlassian.net/wiki/spaces/MD93/pages/205684994/The+Diameter+Transport+Protocols
**Categories:** chunks_index.json

The Diameter agents support Transmission Control Protocol (TCP) and Stream Control Transmission Protocol (SCTP) as transport protocols over IPv4 and IPv6. Even though there are similarities between these protocols, SCTP provides some capabilities that TCP is lacking, including multistreaming and multihoming. TCP transmits data in a single stream and guarantees that data will be delivered in sequence. If there is data loss, or a sequencing error, delivery must be delayed until lost data is retransmitted or an out-of-sequence message is received. SCTP's multistreaming allows data to be delivered in multiple, independent streams, so that if there is data loss in one stream, delivery will not be affected for the other streams. The multihoming feature adds more redundancy benefits of having multiple network interfaces. When a network interface of a TCP connection fails, the connection will time out as it cannot redirect data using an alternate network interface that is available on the host. Instead, failover to another interface must be handled in the application layer. Multihoming in SCTP allows multiple IP addresses in association. As a result, failover to an alternate interface can be handled in the transport layer. Typically, different IP addresses are bound to different networks thus providing additional resiliency in case of failure. The number of transmissions, timeouts and any other parameters that determine when the failover should occur must be set in the SCTP software specific to your operating system. Open TCP connection Open SCTP association On a system with SCTP installed you can bind multiple IP addresses to a hostname by editing the hosts file. The location of this file is operating system specific but it can be found under /etc on most Linux and Unix distributions. Example- Host-to-IP address mapping using the hosts file 127.0.0.1 localhost 192.168.1.111 server1 192.168.1.112 server1 When a Diameter Stack agent receives a connection request from a peer over SCTP, it is not certain that its hostname will be resolved to the IP address of a particular network interface. To ensure that a specific interface is used to setup the connection, you must specify the IP address of the interface in the Primary Host field in the Diameter Stack agent. This can be useful if the peer only uses a single static IP address to connect to the agent. Once the connection is established, failover to an alternate interface is possible. For further information about the Diameter Stack agent, see Diameter Stack Agent . Caution! To run Diameter over SCTP, the target JVM / EC must be running on a X86_64 or AMD Linux configured for SCTP and you must extend the EC configuration with add-opens as shown in the example below. Example - Configuring add-opens for Running Diameter over SCTP jvmargs { args=[] addOpens=[ "--add-opens", "java.base/java.lang.reflect=ALL-UNNAMED", "--add-opens", "jdk.sctp/sun.nio.ch.sctp=ALL-UNNAMED", "--add-opens", "java.base/java.io=ALL-UNNAMED", "--add-opens", "java.base/java.util=ALL-UNNAMED" ] }

---

# Document 1547: Desktop Reinstallation - MediationZone Documentation 9.3 - InfoZone

**Source:** ratanon/mz93-documentation
**URL:** https://infozone.atlassian.net/wiki/spaces/MD93/pages/205029797/Desktop+Reinstallation
**Categories:** chunks_index.json

Reinstall the Desktop according to the information in Desktop Launcher section.

---

# Document 1548: Response UDR - MediationZone Documentation 9.3 - InfoZone

**Source:** ratanon/mz93-documentation
**URL:** https://infozone.atlassian.net/wiki/spaces/MD93/pages/205002414/Response+UDR
**Categories:** chunks_index.json

The Response UDR contains the UI built with UI Builder Component UDRs. The following fields are included in the Response UDR : Field Description Field Description body (bytearray) This field can contain the HTTP message body. If the page is built up manually or a File should be downloaded. In normal cases this field is not used. cookies (list<CookieUDR> This field can contain a list of Cookie UDRs. headerFields (map<string,list<string>>) This field may contain an HTTP header. The header is stored as key-value pairs. httpResponseCode (int) This field can contain the response code to the client. If not set response code 200 will be sent to client. mainGrid (GridUDR) This field can contain the Grid UDR to build up the UI. This field or body field must be set. menuItems (map<string,string>) This field may contain menu items. The menu items are stored as key-value pairs. Where key is the text showed in the menu and value is a URL to the new page. naviContent (list<ComponentUDR>) This field may contain a list of any Component UDR to be present in the top navibar on the UI. scripts (list<ScriptUDR>) This field may contain a list of Script UDR to be added to the page.

---

# Document 1549: Event Fields - MediationZone Documentation 9.3 - InfoZone

**Source:** ratanon/mz93-documentation
**URL:** https://infozone.atlassian.net/wiki/spaces/MD93/pages/204997812/Event+Fields
**Categories:** chunks_index.json

An event is an object containing information related to an event. For example, there are Workflow State events that are emitted each time the state of a workflow is changed. The Event Notification configuration subscribes to these events and routes them to notifiers, for example, log files or a database. An Event Type is comprised of a set of fields containing the original event message, a set of standard workflow related information, and event specific fields that are the parameters the original event message. An Event Message contains information ordered in fields All event types in the system inherit fields from the Base event type. Workflow related events inherit fields related to the Workflow event as well, such as agentName . In addition to these, User Defined Events will receive any fields as defined by the user. There are two types (hierarchies) of events: User Defined events. Events inherited from a Base event (all other events), with additional information added. The user-defined event must be configured in an Ultra Format configuration. Other than the fields entered by the user, the system will automatically add basic fields. User Defined Events may only be dispatched from an agent using APL, i e Analysis or Aggregation. User defined events are sent from Analysis or Aggregation agents Fields added by the user must be populated manually by using APL commands, while the basic fields are populated automatically. From the basic fields, only category and severity may be assigned values. The other basic fields are read only, hence it is not possible to assign values to them.

---

# Document 1550: Inter Workflow Collection Agent in a Batch Workflow - MediationZone Documentation 9.3 - InfoZone

**Source:** ratanon/mz93-documentation
**URL:** https://infozone.atlassian.net/wiki/spaces/MD93/pages/204673620/Inter+Workflow+Collection+Agent+in+a+Batch+Workflow
**Categories:** chunks_index.json

To open the Inter Workflow collection agent configuration, click Build  New Configuration . Select Workflow from the Configurations dialog. When prompted to select a workflow type, click Batch . Click Add agent and select Inter Workflow from the Agent Selection dialog. Double-click the agent icon or right-click the icon and select Edit agent to display the Agent Configuration dialog. Open Inter Workflow collection agent configuration Setting Description Setting Description Profile The name and most recent version of the Inter Workflow profile. All workflows in the same workflow configuration can use separate Inter Workflow profiles, if that is preferred. In order to do that the profile must be set to Default in the Workflow Table tab found in the Workflow Properties dialog. After that each workflow in the table can be appointed different profiles. Deactivate on Idle If enabled, the agent will deactivate the workflow if it has no more batches to collect. Note! Make sure a proper scheduling criteria is defined for a workflow with this feature turned on, since the agent will cause the workflow to deactivate immediately if no data is available. Note! When you use the Inter Workflow collection agent with a Local Archiving agent, if you want outdated files to be cleaned up, you must select this check box. No Merge If enabled, each incoming batch will generate one outgoing batch. Merge Batches Based on Criteria If enabled, decides if the incoming batches will be merged into larger entities, as soon as any of the merge criteria defined in the Merge Definition, are met. Note! It is not possible to import MIM values for all batches in a merge; header MIMs for the first batch will be selectable, as well as trailer and batch MIMs for the last batch. Merge All Available Batches If enabled, all incoming batches will be inserted into one outgoing batch. Age of Oldest Batch (sec) Indicates for how long (in seconds) the agent will wait after the first incoming batch. When this time has expired, an outgoing batch will be produced, regardless if the Number of Bytes/Batches criteria has been fulfilled or not. Number of Batches The number of incoming batches to merge. Number of Bytes The size of the batches produced by the collection agent. The incoming files are never split. For instance, if 300 is entered and the source files are 200 bytes each, the produced batches will be 400 bytes. Use Custom Stream Select this checkbox to enable Stream ID-based connections across multiple workflows using the same profile. When checked, collector and forwarding agents establish connections based on both the profile and a Stream ID, allowing workflows to link dynamically. In cases where a real-time workflow connects to a batch workflow, they scale as a unit, ensuring backend/frontend pairs stay linked via the Stream ID. Note! If this checkbox is cleared, the Inter Workflow profile is fixed at design time and cannot be changed dynamically, preventing chained workflows from scaling. Example - Configuring a Stream ID in Inter Workflow Forwarder and Collection Agents Scenario: You have multiple processing workflows that each need to send data to a specific collection workflow. Instead of creating separate Inter Workflow profiles for each pair, you can configure a stream ID to manage these connections within a single profile. For example, if three processing workflows (A, B, and C) need to send data to three corresponding collection workflows (X, Y, and Z), you can define stream IDs like "A-X", "B-Y", and "C-Z". This ensures each processing workflow sends data to the correct collection workflow while maintaining a simpler, more scalable configuration. Stream ID If you have checked the Use Custom Stream checkbox add a Stream ID.

---

# Document 1551: Python Module - MediationZone Documentation 9.3 - InfoZone

**Source:** ratanon/mz93-documentation
**URL:** https://infozone.atlassian.net/wiki/spaces/MD93/pages/204739939/Python+Module
**Categories:** chunks_index.json

With the Python Module configurations, you can write shared Python code that can be imported by multiple Python agents. This allows you to organize your Python code into different modules that can be reused. Open Python Module To access the Python Module, click the New Configuration button and then select Python Module from the menu. The entire Python Module configuration is a code area where you can write code that you want Python agents to be able to import. See the code section for the relevant agent for further information. The imported modules are referenced by the workflows, but as each agent has its own memory space, global variables will not be shared between agents or workflows. Python Code Editor Assistance To provide assistance when you are writing code in the Python code area, there are several features in place: Syntax Highlighting - Different parts of the code are color-coded according to type Right-click Menu - A menu that provides editor options. Code Completion - Helps you to write Python code in the Python Code Editor by providing context-sensitive proposals. For further information on these features, see Python Code Editor Assistance .

---

# Document 1552: GCP PubSub Publisher Agent Events - MediationZone Documentation 9.3 - InfoZone

**Source:** ratanon/mz93-documentation
**URL:** https://infozone.atlassian.net/wiki/spaces/MD93/pages/204607727/GCP+PubSub+Publisher+Agent+Events
**Categories:** chunks_index.json

Agent Message Events There are no agent message events for this agent. For information about the agent message event type, see Agent Event . Debug Events There are no debug events for this agent.

---

# Document 1553: Event Notifications Configuration - MediationZone Documentation 9.3 - InfoZone

**Source:** ratanon/mz93-documentation
**URL:** https://infozone.atlassian.net/wiki/spaces/MD93/pages/204638712
**Categories:** chunks_index.json

A notifier is a selected target, receiving event data when one or several selected event types are generated in the system. In addition, filters may be applied for each selected event type. Notifiers are configured in the Event Notification Editor . To create a new Event Notification configuration, click the New Configuration button in the upper left part of the Desktop window, and then select Event Notification from the menu. Open An Event Notification configuration The configuration contains the standard configuration buttons as described in Common Configuration Buttons and two additional button: Button Description Button Description Open To Enable External References in an agent profile field. Refer to the section Enabling External References in an Agent Profile Field in External Reference Profile for further information. Note! If you update the properties file used by the External References file, and resave the External References profile, you will also have to resave the Event Notification configuration for the changes to take effect. Open To define an Event Category, to send any kind of information to a Column. Refer to Event Category for further information. The Event Notification configuration contains two different tabs: Notifier Setup - A Notifier is the target where event messages, configured in the Event Setup, are sent. For instance, to a database table, a log file or to the System Log. The overall appearance of the message string is also defined in this tab. Event Setup - In the Event Setup tab, events to catch are defined. If necessary, the message string defined in the Notifier Setup is also modified. This section contains the following subsections: Notifier Setup Tab Event Setup Tab Event Fields

---

# Document 1554: Database Functions - MediationZone Documentation 9.3 - InfoZone

**Source:** ratanon/mz93-documentation
**URL:** https://infozone.atlassian.net/wiki/spaces/MD93/pages/205656792/Database+Functions
**Categories:** chunks_index.json

The following sets of functions are used for managing data in databases accessed via Database profiles: Database Table functions - Look up and insert data into tables Callable Statement functions - Execute stored procedures Prepared Statement functions - Efficiently execute statements multiple times and has support for failover Database Bulk functions - Bundle multiple queries into one SQL statement Note! All database-related APL functions use a db connection pool, and they pick a connection from the pool for each invocation. Connection properties, such as the transaction state, are handled internally by each function and are never visible in APL. These database functions are currently designed to work with the following database data types; character , string , integer and date data types such as VARCHAR, INTEGER, NUMBER, DATE, TIMESTAMP and BOOLEAN. Other database data types are restricted for APL database functions. The list below contains examples of such types, usually very large data types or custom objects, structures and similar types. Large object data types such as BLOB/CLOB User-defined structures/objects User-defined collections/arrays Spatial/Geometry JSON, XML The BLOB data is parsed and stored as a hex string and CLOB data as a string. To insert BLOB data using APL, you must use string/bytearray. Warning! PostgreSQL does not support BLOB/CLOB. The BLOB equivalent for PostgreSQL will be BYTEA and CLOB equivalent will be TEXT. This chapter includes the following sections: Callable Statements Database Bulk Functions Database Table Functions Prepared Statements

---

# Document 1555: Inspectable - MediationZone Documentation 9.3 - InfoZone

**Source:** ratanon/mz93-documentation
**URL:** https://infozone.atlassian.net/wiki/spaces/MD93/pages/205655685/Inspectable
**Categories:** chunks_index.json



---
**End of Part 65** - Continue to next part for more content.
