# RATANON/MZ93-DOCUMENTATION - Part 32/112

---
**Dataset:** ratanon/mz93-documentation
**Part:** 32 of 112
**GitHub:** https://github.com/ratan0n/docs/tree/main/mz93-documentation
**Size:** ~66.7 KB
---

User authentication is by default performed in MediationZone. As an alternative, you can connect to an external LDAP directory for delegated authentication. This facilitates automation of administrative tasks such as creation of users and assigning access groups. When you create a new user in the Access Controller Users tab, the system will verify against the LDAP Server to make sure that the new user name does not already exist in the LDAP Server. If the LDAP Server is down, you will not be able to create or edit any LDAP users in Users tab. Users that are already included in the Access Controller's Users Tab can still login to the system even when the LDAP Server is down. Note! User created using the Users Tab in Access Controller will not be impacted nor will they have an impact on external authentication servers. LDAP Authentication Preparations Directory Structure The LDAP directory that is used for authentication must conform to the following requirements: The cn attribute of group entries must match an access group defined in the system. For each user in a group entry, the memberUid attribute must be set. All group entries must belong to the object class posixGroup . All user entries must belong to the objectclass posixAccount . The username must be unique. It cannot duplicate a username that already exists in the system. Note! If a user requires administration rights, they must be added to the Administrator access group, which is a default access group. You must create a group named Administrator in the LDAP directory. Secure Access The following steps are required before configuration of authentication with LDAPS or LDAP over TLS: Obtain the server certificate for the authentication server from your LDAP administrator. Start a command shell and copy the server certificate to the platform host. Change directory to $JAVA_HOME/lib/security on the platform host. Install the server certificate using the Java keytool command: keytool -import -file <certificate> -keystore cacerts Active Directory Important Information Directory Structure The LDAP directory that is used for authentication must conform to the following requirements: All user entries must belong to the objectclass user . User's groups have to be provided via memberOf attribute. User's login has to be provided via samaccountname attribute. The username must be unique. It cannot duplicate a username that already exists in the System. LDAP Configuration Select LDAP in Authentication Method dropdown list in the Access Controller Advanced tab. Open Access Controller - Advanced tab with LDAP Authentication example Setting Description Setting Description Authentication Method Select the authentication method to be used. The following settings are available: Default LDAP The default setting is authentication performed by MediationZone. The selected authentication method becomes effective when the configuration is saved. Note! Authentication for the user mzadmin is always performed by MediationZone regardless of the selected authentication method. URL Enter the URL for the external authentication server. The default ports, 389 for LDAP and 686 for LDAPS, are used unless other ports are specified in the URL. Example of LDAP URL ldap://ldap.example.com:389 Example of LDAPS URL ldaps://ldap.example.com:636 Test Connection Click this button to test the connection to the authentication server. LDAP attributes and other settings than the URL are not used when testing the connection. User Base DN Enter the LDAP attributes for user lookups in the external authentication server. The substring %s in this value will be replaced with the username entered at login to produce an identifier that is passed to the LDAP server. Example of User Base DN uid=%s,ou=users,dc=digitalroute,dc=com Group Base DN Enter the LDAP attributes for group lookups in the external authentication server. Example of Group Base DN ou=groups,dc=digitalroute,dc=com Note! The name of the groups created in LDAP Server must be identical to the names configured in Access Controller Access Groups tab . Use TLS Select this check box to enable Transport Layer Security. Note! The following must be considered when using TLS: LDAPS and TLS is not a valid combination. The URL must contain a fully qualified DNS name or the authentication will fail. The default LDAP port, 389, should be used. Use Active Directory Naming Select this check box if you want to use Active directory specific naming. Enable Group Search Bind Credentials Select this check box if you want to enable group search. You must also populate the Bind DN and Password fields. If you want to run an anonymous lookup, leave this check box empty. Bind DN If you want to use a specific Bind DN to search for the group, enter the Bind DN. Password If you want to use a specific Bind DN to search for the group, enter the password to connect LDAP Server.

---

# Document 690: Charging Function (CHF) - MediationZone Documentation 9.3 - InfoZone

**Source:** ratanon/mz93-documentation
**URL:** https://infozone.atlassian.net/wiki/spaces/MD93/pages/205882018/Charging+Function+CHF
**Categories:** chunks_index.json

Version History Date Version Editor Comments 2022-03-15 1.0 Patrik Bruce First version Definition Charging Function (CHF) is defined using the Charging architecture and principles outlined by 3GPP TS32.240 (Ref 1) as the baseline. It is constructed as a set of capabilities to facilitate charging for telecom network connectivity services delivered by the CSP using 5G stand-alone networks (5GC), characterized by, and limited to: Interoperability with the 5G Service Based Architecture The ability to define and terminate the Nchf interface, via reference points N28 (SMF <-> CHF) and N40 (PCF <-> CHF) The ability to register as a CHF with the Network Repository Function (NRF) via the Nnrf API Interoperability with Charging Domain components Integration and call-flow orchestration between the CHF, Account Balance Management Function (ABMF), and Rating Function (RF) via a supported interface Interoperability with the Charging Gateway Function (CGF) via a supported interface, in order to facilitate CDR generation and data flow to downstream Billing Domain (BD) systems Commercial Models and purposes Direct B2C connectivity Direct B2B connectivity Telecom network inbound roaming Telecom network outbound roaming This Right to Use (RTU) grants the licensee the right to use DigitalRoutes MediationZone software in accordance with this definition.

---

# Document 691: Duplicate UDR Using Indexing Field Instead of System Time - MediationZone Documentation 9.3 - InfoZone

**Source:** ratanon/mz93-documentation
**URL:** https://infozone.atlassian.net/wiki/spaces/MD93/pages/205032753
**Categories:** chunks_index.json

The "cache time window" (see the figure below) decides whether a UDR shall be removed from the cache or not. The maximum number of days to store a UDR in the cache is retrieved from the setting Max Cache Age (days) each time a new batch file is processed (and the age of the UDRs is calculated). The "cache time window" will be moved forward and old UDRs will be removed. Calculation of the UDR age can be done in two ways: Using the latest indexing field (timestamp) of a UDR that is included in the previously processed batch files. Using system time. The following figure illustrates the difference: Open UDR removed from the cache based on indexing field or system time If the system has been idle for an extended period of time, there will be a "delay" in time. So when a new batch file is processed, and if the system time is used for UDR age calculation, the "cache time window" will be moved forward with the delay included, and this might result in all UDRs being removed from the cache, as shown in the figure above. The consequence of this is that the improperly removed UDRs will be considered non-duplicates and, hence, might be handled even though they still are duplicates. If the indexing field is used instead, a more proper calculation will be done, since the "system delay time" will be excluded. In this case, only UDR 1 and UDR 2 will be removed.

---

# Document 692: Data Veracity Profile - MediationZone Documentation 9.3 - InfoZone

**Source:** ratanon/mz93-documentation
**URL:** https://infozone.atlassian.net/wiki/spaces/MD93/pages/204738346
**Categories:** chunks_index.json

The Data Veracity Profile is used to select the particular database that Data Veracity will be connected. The profile can also generate the SQL scripts to be used for creating the database tables where the erroneous UDRs will be stored in. The Data Veracity profile is loaded when you start a workflow that depends on it. Changes to the profile become effective when you restart the workflow. Configuration To create a new Data Veracity profile, click the New Configuration button from the Configuration dialog available from Build View , and then select Data Veracity Profile from the menu. The contents of the menus in the menu bar may change depending on which configuration type has been opened in the currently active tab. The Data Veracity profile uses the standard menu items and buttons that are visible for all configurations, and these are described in Common Configuration Buttons . UDR Tab Open Data Veracity profile - UDR Tab The following settings are available in the UDR Tab of the Data Veracity profile: Setting Description Setting Description Database Profile This is the database the agent will connect and send data to. Click the Browse... button to get a list of all the database profiles that are available. For further information see Database Profile . Data Veracity is supported for use with the following databases: PostgreSQL 13 PostgreSQL 14 PostgreSQL 15 Oracle Database 19c SAP HANA 2.0 SP 7 UDR Type Mapping UDR Type Mapping UDRs to be used by the Data Veracity Profile are listed here MIM Mapping Use MIM Select this check box to allow the use MIMs listed under the Named MIMs table. Named MIMs This list will display the user-defined MIMs that can be made available for use by the Data Veracity Forwarding Agent. Generate SQL This text box will generate the SQL statements for the selected UDRs' table schema and indexes for the TXN_ID, ERROR_CODE, INSERT_TIME and STATE field. The schema will be generated based on the number of UDRs in the UDR Type Mapping table. Click the SQL button to generate the SQL statements. Warning! Users will have to copy the SQL script generated in the text box to create the Data Veracity tables on their own in the database listed in the Database profile. The Data Veracity profile will not automatically create the tables for you. PostgreSQL Schema Name There will not be a schema name included with the SQL command generated for PostgreSQL. Info! The user should create adequate indexes along with the indexes already provided by the script, in order to achieve the best performance for Data Veracity. Note! The name of the column constraints will be based on the Internal UDR name. An example would be, if an Internal UDR is named customerTI, the name of the column constraints will be prefixed with customerTI. When there are multiple Internal UDRs with identical names but present in different folders in your configuration, the names of the column constraints will be the same as well. This will cause a conflict error to occur when creating the table in your Database. It is highly recommended to have proper naming conventions for Internal UDRs, to prevent any conflicts. Batch Tab Open Data Veracity profile - Batch Tab The following settings are available in the Batch Tab of the Data Veracity profile: Setting Description Setting Description Database Profile This is the database the agent will connect and send data to. Click the Browse... button to get a list of all the database profiles that are available. For further information see Database Profile . Data Veracity is supported for use with the following databases: PostgreSQL 13 PostgreSQL 14 PostgreSQL 15 Oracle Database 19c SAP HANA 2.0 SP 7 Enabled This checkbox enables the batch mode configuration. Table Name Enter the table name that is to be used with this profile. MIM Mapping Use MIM Select this check box to allow the use MIMs listed under the Named MIMs table. Named MIMs This list will display the user-defined MIMs that can be made available for use by the Data Veracity Forwarding Agent. Generate SQL This text box will generate the SQL statements for the selected UDRs' table schema and indexes for the TXN_ID, ERROR_CODE, INSERT_TIME and STATE fields. The schema will be generated based on the number of UDRs in the UDR Type Mapping table. Click the SQL button to generate the SQL statements. Warning! Users will have to copy the SQL script generated in the text box to create the Data Veracity tables on their own in the database listed in the Database profile. The Data Veracity profile will not automatically create the tables for you. PostgreSQL Schema Name There will not be a schema name included with the SQL command generated for PostgreSQL. Info! The user should create adequate indexes along with the indexes already provided by the script, in order to achieve the best performance for Data Veracity. Note! The name of the column constraints will be based on the Internal UDR name. An example would be, if an Internal UDR is named customerTI, the name of the column constraints will be prefixed with customerTI. When there are multiple Internal UDRs with identical names but present in different folders in your configuration, the names of the column constraints will be the same as well. This will cause a conflict error to occur when creating the table in your Database. It is highly recommended to have proper naming conventions for Internal UDRs, to prevent any conflicts. Generate SQL Dialog Box When a user clicks on the Generate SQL button in either tab, the associated dialog box will open. Here the generated SQL statement can be viewed. Open Results of a Tables SQL Script

---

# Document 693: Billing Mediation - MediationZone Documentation 9.3 - InfoZone

**Source:** ratanon/mz93-documentation
**URL:** https://infozone.atlassian.net/wiki/spaces/MD93/pages/204613928/Billing+Mediation
**Categories:** chunks_index.json

Version History Date Version Editor Comments 2022-02-24 1.0 Patrik Bruce First version Definition Billing Mediation provides the Billing Domain (BD) components with the ability to ingest network CDR data for monetization, reporting, fraud detection, and settlement purposes. It is defined using the Charging architecture and principles outlined by 3GPP TS32.240 (Ref 1) as the baseline. It is constructed as a set of capabilities to facilitate charging for telecom network connectivity services delivered by the CSP using 3G/4G/5G networks (GPRS/EPC/5GC), characterized by, and limited to: Originating Data Sources CDRs received as files over the Bx interface CDRs received as files directly from network elements and other systems in vendor proprietary formats Network charging information received via real-time interfaces, over non-3GPP defined interfaces Output Data Targets Billing Domain functions of Rating, and Billing Interconnect billing platforms Roaming settlement platforms Revenue Assurance systems Fraud Management systems Analytics and reporting platforms Data warehouse and data lake systems MVNO platforms Commercial Models and purposes Direct B2C connectivity Direct B2B connectivity Telecom network in-bound roaming Telecom network out-bound roaming This Right to Use (RTU) grants the licensee the right to use software in accordance with this definition.

---

# Document 694: Inter Workflow Forwarding Agent in a Real-Time Workflow - MediationZone Documentation 9.3 - InfoZone

**Source:** ratanon/mz93-documentation
**URL:** https://infozone.atlassian.net/wiki/spaces/MD93/pages/204608121/Inter+Workflow+Forwarding+Agent+in+a+Real-Time+Workflow
**Categories:** chunks_index.json

To open the Inter Workflow forwarding agent configuration, click Build  New Configuration . Select Workflow from the Configurations dialog. When prompted to Select workflow type , click Realtime . Click Add agent  Processing tab and select Inter Workflow from the Agent Selection dialog. Double-click the agent icon or right-click the icon and select Edit agent , to display the Agent Con figura tion dialog. Open Inter Workflow forwarding agent configuration - real-time workflow Setting Description Setting Description Profile The name and most recent version of the profile as defined in the Inter Workflow profile configuration. All workflows in the same workflow configuration can use separate Inter Workflow profiles, if that is preferred. In order to do that, the profile must be set to Default in the Workflow Table tab found in the Workflow Properties dialog. After that each workflow in the table can be appointed different profiles. Named MIM The user defined MIM names according to the definitions in the selected profile. MIM Resource Selected, existing MIM values of the workflow that the Named MIMs are mapped to. This way, MIM values from this workflow are passed on to the collection workflow. Volume (bytes) When the file size has reached the number of bytes entered in this field, the file will be closed as soon as the current bytearray has been included, and stored in the storage directory. This means that the file size may actually be larger than the set value since the system will not cut off any bytearrays. If nothing is entered, this file closing criteria will not be used. Volume (UDRs) When the file contains the number of UDRs entered in this field, the file will be closed and stored in the storage directory. If nothing is entered, this file closing criteria will not be used. Timer (sec) When the file has been open for the number of seconds entered in this field, the file will be closed and stored in the storage directory. If nothing is entered, this file closing criteria will not be used. Enable Worker Thread Select this check box to enable worker thread functionality, allowing you to configure a queue size in order to improve performance and reduce the risk for blocking during heavy I/O. Caution! If Enable Worker Thread is deselected and the agent cannot access the storage, the workflow will not abort. This may cause loss of the incoming data. Queue Size Enter the queue size you wish to have for the Worker Thread in this field. Include outstanding Select this checkbox to include outstanding requests in the Queue Size . Use Custom Stream Select this checkbox to enable Stream ID-based connections across multiple workflows using the same profile. When checked, collector and forwarding agents establish connections based on both the profile and a Stream ID, allowing workflows to link dynamically. In cases where a real-time workflow connects to a batch workflow, they scale as a unit, ensuring backend/frontend pairs stay linked via the Stream ID. Note! If this checkbox is cleared, the Inter Workflow profile is fixed at design time and cannot be changed dynamically, preventing chained workflows from scaling. Example - Configuring a Stream ID in Inter Workflow Forwarder and Collection Agents Scenario: You have multiple processing workflows that each need to send data to a specific collection workflow. Instead of creating separate Inter Workflow profiles for each pair, you can configure a stream ID to manage these connections within a single profile. For example, if three processing workflows (A, B, and C) need to send data to three corresponding collection workflows (X, Y, and Z), you can define stream IDs like "A-X", "B-Y", and "C-Z". This ensures each processing workflow sends data to the correct collection workflow while maintaining a simpler, more scalable configuration. Stream ID If you have checked the Use Custom Stream checkbox add a Stream ID. Send response UDR Select to send a UDR with the data and context information as an InterWorkflow.RequestCycleUDR, instead of a bytearray, to the agent. After forwarding, the agent writes the data (or fails to write), and the Inter Workflow forwarding agent responds with confirmation (true or false) of depending on if the write was successful or not. Note! Since there are no natural batch boundaries within a real-time workflow, volume and/or timer criteria must be set to close the file and open a new one. If several criteria for closing the file have been selected, all will apply, using a logical OR. If the workflow is deactivated before any of the file closing criteria has been fulfilled, the UDRs currently stored in memory will be flushed, that is flushed to the current batch without being processed. Hence, the size of the last file cannot be predicted. In case of a crash, the content of the last batch cannot be predicted. The error handling is taken care of by the Inter Workflow collection agent. If the file is corrupt, it will be thrown away and a message is logged in the System Log. The collector will automatically continue with the batch next in order.

---

# Document 695: Signature Functions - MediationZone Documentation 9.3 - InfoZone

**Source:** ratanon/mz93-documentation
**URL:** https://infozone.atlassian.net/wiki/spaces/MD93/pages/205656942/Signature+Functions
**Categories:** chunks_index.json

Use the Signature functions to generate digital signatures for data. The following functions for Signature described here are: 1 signPrepare 2 signData 3 signHmac 4 signHmacSHA256 5 signHmacSHA512 signPrepare This function is called to get a key from a Java keystore file. any signPrepare ( string file, string keystoreType, string password) Parameter Description Parameter Description file The file that contains the keystore dat keystoreType The keystore type e g . JKS, PKCS8, PKCS12 or CA_CERTIFICATES_PATH password The keystore password Returns A private key object signData This function calculates the hash value of a bytearray, using the specified algorithm, and signs the result. bytearray signData ( any key, bytearray data, string algorithm) Parameter Description Parameter Description key A private key object data The data to be signed algorithm The signature algorithm e g SHA1withDSA, SHA1withRSA or SHA256withRSA. Returns A bytearray containing the digital signature signHmac This function calculates the hash value of a key retrieved with the signPrepare function or a bytearray constituting a key, using the specified algorithm, and signs the result. bytearray signData ( any key, bytearray data, string algorithm) Parameter Description Parameter Description key A private key object data The data to be signed algorithm The signature algorithm e g Hmac-SHA256 or Hmac-SHA512. Returns A bytearray containing the digital signature signHmacSHA256 This function calculates the hash value of a key retrieved with the signPrepare function or a bytearray constituting a key, using Hmac-SHA256, and signs the result. bytearray signData ( any key, bytearray data) Parameter Description Parameter Description key A private key object data The data to be signed Returns A bytearray containing the digital signature signHmacSHA512 This function calculates the hash value of a key retrieved with the signPrepare function or a bytearray constituting a key, using Hmac-SHA512, and signs the result. bytearray signData ( any key, bytearray data) Parameter Description Parameter Description key A private key object data The data to be signed Returns A bytearray containing the digital signature

---

# Document 696: HTTP Configuration Properties - MediationZone Documentation 9.3 - InfoZone

**Source:** ratanon/mz93-documentation
**URL:** https://infozone.atlassian.net/wiki/spaces/MD93/pages/204613202/HTTP+Configuration+Properties
**Categories:** chunks_index.json

TLS is configured with properties that are typically set on the container level. Note! Quotes and double quotes surrounding the target path and property names are required to prevent overwriting of properties. For further information, see Working with STR . The available properties are: mz.httpd.security Set the value of this to property to true (default value is false ) to enable encryption. $ mzsh topo set 'topo://container:<container>/val:common."mz.httpd.security"' true mz.httpd.security.keystore Use this property to set the keystore path, which must be absolute. $ mzsh topo set 'topo://container:<container>/val:common."mz.httpd.security.keystore"' <keystore path> mz.httpd.security.keystore.password Use this property to set the password for the keystore, as selected in keytool . $ mzsh topo set 'topo://container:<container>/val:common."mz.httpd.security.keystore.password"'  `mzsh encryptpassword <password>` mz.httpd.security.key.password Use this property to set the password for the key, as chosen in keytool . By default, this is the same as the keystore password. (This is the default for keytool ). $ mzsh topo set topo://container:<container>/val:common.mz.httpd.security.key.password  `mzsh encryptpassword <password>` Note! After having configured the properties, this section: # Http url to platform, e.g http://localhost:9000 if [ -z "${MZ_PLATFORM+x}" ]; then MZ_PLATFORM="http://localhost:9000" export MZ_PLATFORM in the $MZ_HOME/bin/mzsh file needs to be updated to state https instead of http for both the Platform and the ECs. Restart Required After the configuration is done all affected processes need to be restarted. Use the following command: mzsh restart platform ui

---

# Document 697: Execution Zone - MediationZone Documentation 9.3 - InfoZone

**Source:** ratanon/mz93-documentation
**URL:** https://infozone.atlassian.net/wiki/spaces/MD93/pages/204613008/Execution+Zone
**Categories:** chunks_index.json

The Execution Zone consists of one or several Execution Containers. There are two types of pico instances that may run in these containers: Execution Context (EC) Execution contexts need to be added to pico groups with the same name for proper configuration! For more information, see topo . Service Context Execution Context An EC will stop execution if the connection with the Platform is lost, but for realtime workflows you can configure the workflow to run as a standalone, which will allow it to continue running even if the EC looses connection with the Platform. See Workflow Properties for more information. All the Execution Contexts will register themselves as available in the system at startup. Since batch and real-time processing has different characteristics and requirements, workflows of different types should be executed on separate ECs. If an EC loses contact with the Platform, workflows that have not been configured to run as standalone workflows will abort as soon as information supplied by the Platform is missing, e g when a transaction is finished. A realtime workflow configured to run as a standalone workflow can continue to run as long as it does not require any information from the Platform. The EC property ec.backlog.dir determines whether you want events and error messages, occurring when the contact is lost, to be logged in a backlog or not. If the property is not set, events and messages will not be logged. The value of the property states where the backlog resides. The default location is the MZ_HOME/tmp directory. For further information about this directory, see Software Environment . When the connection between the EC and the Platform is restored, the backlog will be transferred to the Platform. The System log entries will contain a timestamp from when they were transferred, that is the time when the connection was reestablished. In case the EC is shutdown during an unreachable state, the backlog will be removed and will never be transferred to the Platform. An unreachable EC will be deregistered, and after 45 minutes it will be removed from the Pico Viewer , if a manual deregistration has not been made before that time has passed. When an EC is deregistered, the workflow will be considered to be aborted on the Platform. In reality, however, it can still be running on the EC. In that case, the workflow needs to be stopped manually in the Execution Manager . For further information about the different types of workflows, see Workflow Types . Service Context An SC provides a place to host services that workflows running in ECs can share, independently from the Platform. SCs complement the ECs and are part of the Execution Zone. During installation of the Platform Container or an Execution Container, you can select a default template that includes installation of SCs. For further information, see Updating the Installation Properties for Platform . The introduction of SCs in MediationZone is part of a larger architectural initiative, which will span several releases. SC processes have the following objectives: To facilitate the use of embedded services, such as Kafka and Zookeeper through a centralized approach to configuration and lifecycle management To support running traditional Control Zone services outside the Platform to improve the availability and scalability of the system It is planned that services will gradually be moved out of the Platform process to decrease the load on the Platform and to allow the scaling out of relevant services. The SC psc1 is designated for Platform type of services is installed by default together with the Platform Container. Services executed in SCs continue to function without connection to the Platform, which is only required when you start an SC.

---

# Document 698: SQL Forwarding Agent Transaction Behavior, Input/Output Data and MIM - Batch - MediationZone Documentation 9.3 - InfoZone

**Source:** ratanon/mz93-documentation
**URL:** https://infozone.atlassian.net/wiki/spaces/MD93/pages/205002157/SQL+Forwarding+Agent+Transaction+Behavior+Input+Output+Data+and+MIM+-+Batch
**Categories:** chunks_index.json

Transaction Behavior Emits This agent does not emit anything. Retrieves The database transaction in the SQL forwarding agent is not consistent with the batch transaction behavior, that is the normal batch transaction safety is not guaranteed for this agent. If a workflow aborts, the database transaction may have been partly or completely done, however the input file will be reprocessed and consequently can cause duplication of data if an INSERT statement is used in the forwarding agent. Input/Output Data The input/output data is the type of data an agent expects and delivers. The agent consumes the selected UDR type. MIM For information about the MIM and a list of the general MIM parameters, see MIM . The agent does not publish nor access any MIM parameters.

---

# Document 699: Database Configuration - MediationZone Documentation 9.3 - InfoZone

**Source:** ratanon/mz93-documentation
**URL:** https://infozone.atlassian.net/wiki/spaces/MD93/pages/205657700/Database+Configuration
**Categories:** chunks_index.json

This section contains recommendations related to the configuration of database connections and usage. This section includes the following subsections: Time Zone Settings Database Related Properties Changing Platform Database Database Sizing

---

# Document 700: Generating New Config Class using DTK - MediationZone Documentation 9.3 - InfoZone

**Source:** ratanon/mz93-documentation
**URL:** https://infozone.atlassian.net/wiki/spaces/MD93/pages/204645082/Generating+New+Config+Class+using+DTK
**Categories:** chunks_index.json

A DTK plugin is created and committed by following these steps: For agent plugins, create a Configuration Contract, see Configuration Contract for further information about the contents of the configuration contract. For other types of plugins, skip this step. For agent plugins, generate a Java file from your configuration contract: > java -classpath $CLASSPATH com.digitalroute.tools.ContractGen  -d . -f MyAgentConfigContract.xml For other types of plugins, skip this step. Create the different Java files required for the type of plugin you want to create. See the chapters describing each plugin for further information. Compile all the Java files for your plugin into classes: > javac -classpath $CLASSPATH com/mycompany/myagent/*.java Note! It is strongly recommended that the Java code does not use the default package context. All classes in the system must have unique names. Create a user-defined *.jar file containing the classes, see the section below, Creating a User-Defined Jar File. Create a user-defined *.mzp package containing the *.jar file, see the section below, Creating a User-Defined Package. Commit your user-defined package, see the section below, Committing a User-Defined Package. Creating a User-Defined Jar For more information, refer to the same section in Creating a DTK Plugin . Creating a User-Defined Package For more information, refer to the same section in Creating a DTK Plugin . Committing a User Defined Package For On-Premise, Non-Containerized environment : New or updated code is inserted into the system using the mzsh Command Line Tool: > mzsh username/password pcommit my_agent.mzp Loading

---

# Document 701: SAP CTS+ Integration User's Guide - MediationZone Documentation 9.3 - InfoZone

**Source:** ratanon/mz93-documentation
**URL:** https://infozone.atlassian.net/wiki/spaces/MD93/pages/261914788
**Categories:** chunks_index.json

The SAP CTS+ (Change and Transport System Plus) integration in MediationZone enables streamlined management of MediationZone configurations across different environments. SAP CTS+ uses SAP TMS (Transport Management System) as the engine to move changes. This integration allows for greater control, flexibility, and efficiency when moving changes between development, test, and production systems. You can find more information on SAP CTS+ in the SAP Help Portal - SAP Online Help . Note! Configuration exports in MediationZone are referred to as Changes in the SAP CTS+ Integration Users Guide. Key Features of the SAP CTS+ Integration in MediationZone Simplified Configuration Management : Manage regular system exports and workflow packages seamlessly through the SAP CTS+ interface. Please note that Development Toolkit bundles are excluded from this integration. Flexible Import Options : You can easily import configurations to any system in your landscape using CTS+. The source systems for imports can be customizedeither allowing all systems or limited to specific ones, as defined by the cts.source.systems property. For more information, see https://infozone.atlassian.net/wiki/x/8BVCD . Decoupled Export Process : With loose coupling between export and transport, exports are triggered separately from the CTS+ transport process. Use the System Export tool in Desktop, or the mzsh command line tool, to create export files, which you then upload to CTS+ for transport and deployment. Open The SAP CTS+ integration in MediationZone Subsections This section contains the following subsections: SAP CTS+ Export SAP CTS+ Import

---

# Document 702: Mapping Assignments between Database Fields and UDR Fields - MediationZone Documentation 9.3 - InfoZone

**Source:** ratanon/mz93-documentation
**URL:** https://infozone.atlassian.net/wiki/spaces/MD93/pages/205032171/Mapping+Assignments+between+Database+Fields+and+UDR+Fields
**Categories:** chunks_index.json

Assignments The Database agents are designed to either collect data from a database column and assign it to a UDR field, or vice versa. In their configuration they share the Assignment tab, where these mappings are configured. Due to the resemblance this configuration is described here. Open Database collection agent configuration dialog - Assignment tab Item Description Item Description Refresh Updates the table with all the columns or parameters from the selected table or stored procedure (Database forwarding agent, only). Note! Potential changes in the database table will not be visible until Refresh for the database in the Source tab, has been selected. If rows already exist in the table, the refresh operation preserves the configuration for all rows with a corresponding column or parameter name. Thus, if a table has been extended with a new column, the old column configurations are left untouched and the new column appears when Refresh is selected. The value type on each new column that appears in the table is automatically set to UDR Field . Auto assignment: All rows with no value assigned and with a value type of UDR Field will be targeted for auto assignment in the end of the refresh process. If the selected UDR type contains a field whose name matches the column name, the field will be automatically assigned in the Value column. Matching is not case-sensitive and is done after stripping both the column and field names from any characters, except a-z and 0-9. Column Name Displays a list of all columns or stored procedure parameters (Database forwarding agent, only) for the selected table or stored procedure, except the Transaction ID column. Column Type Displays the data type for each column as declared in the database table. If the column does not accept NULL this is displayed as: (NOT NULL). Note! If using Oracle and assigning a value of type bigint , the column type VARCHAR should be used. Setting a full range of the bigint value type could otherwise lead to a wrong value being inserted, due to a limitation in the JDBC interface. Value Type Allows the user to select what type of value to be assigned to the column, or vice versa. For further information, see the section below, Value Types. Value The value to be assigned to the column, or vice versa. The technique of selecting a value depends on the selected Value Type . Note! It is important that the data type of the selected value corresponds to the data type of the column. Most incompatibilities will automatically be detected, however, there are situations where validation is not possible. Value Types The Database agents offer six different types of values that may be assigned to a column, or vice versa. Depending on the agent, not all value types are applicable and will therefore not be available in the list. Both Database Agents Both Database Agents Value Type Description UDR Field If selected, a UDR browser will be launched when the corresponding Value cell is selected. When a UDR field has been selected in the browser it will appear in the Value cell. Info! This field can also be found in the Function Editor on the Database Forwarding agent Note! To save the user from launching the UDR browser for every cell to be assigned, the browser window may be kept on display. When a UDR field is selected and Apply is selected or if a UDR field is double-clicked, the field will go into the Value cell of the selected row, provided that this row has a value type of UDR Field . The same rule applies when OK is selected in the browser, however the browser will be dismissed. It is possible to change target ( Value cell) by selecting the desired row in the Assignment tab in the configuration dialog, while still keeping the UDR browser window open. Whether data types of the selected UDR and the database column are compatible or not, is validated when the configuration dialog is confirmed. NULL If selected, no value may be entered. In Database collection agents, NULL must be selected for all columns whose values are not mapped into a UDR Field. In Database forwarding agents, NULL must be selected for columns populated with a NULL value or columns that, when inserted, will be populated by internal database triggers. Database Collection Agent Only Value Type Description To UDR It is supposed to be selected if a complete UDR has been stored in a binary column by a Database forwarding agent and that UDR will be recollected by the Database collection agent. The Database forwarding agent must have been populating the column from the special field Storable , available in all UDR types. If this value type is selected no other assignments are allowed. If other columns exist their value types must be set to NULL. An evaluation to ensure the column type is actually a RAW, LONG RAW or BLOB, is carried out. Database Forwarding Agent Only Value Type Description MIM Entry If selected, a MIM browser will be launched when the corresponding Value cell is clicked. When a MIM resource has been selected in the browser it will appear in the Value cell. The previous Note for the UDR Field applies to this browser as well. Whether data types of the selected UDR and the database column are compatible or not, is validated when the configuration dialog is confirmed. Info! This field can also be found in the Function Editor on the Database Forwarding agent and also on the Parameter Editor on the Database Collection agent. Constant If selected, a text entry field will be available in the Value cell where any constant to be assigned to the column may be entered. The agent automatically appends possible quotes needed in the SQL statement, based on the data type of the column. Info! This field can also be found in the Function Editor on the Database Forwarding agent and also on the Parameter Editor on the Database Collection agent. From UDR It is selected if a complete UDR is to be stored in a binary column to later be collected by a Database collection agent. The Database forwarding agent must populate the column from the special field Storable , available in all UDR types. This is only applicable for column types RAW, LONG RAW or BLOB. Function If selected, a text entry field will be available in the Value cell where any database related function to be called may be entered. If the function takes parameters, these must be marked as question marks. Selecting a cell containing question marks will display the Function Editor dialog where each question mark is represented by a row. Open Function Editor dialog The selection of parameter values follows the same procedures as for the assignment of column values however Constant , UDR Field and MIM Entry are the only available value types. Note! If constants are entered in the Function Editor they must be quoted correctly since the agent has no way of knowing what data types they must have.

---

# Document 703: Debug Event - MediationZone Documentation 9.3 - InfoZone

**Source:** ratanon/mz93-documentation
**URL:** https://infozone.atlassian.net/wiki/spaces/MD93/pages/204605260/Debug+Event
**Categories:** chunks_index.json

Dispatched when debug is used. The event is of Workflow type and therefore includes the following fields: agentMessage - Message issued by the agent. agentName - The name of the agent issuing the event. The following fields are inherited from the Base event, and described in more detail in Base Event : category contents eventName origin receiveTimeStamp severity timeStamp The following fields are inherited from the Workflow event, and described in more detail in Workflow Event : workflowKey workflowName workflowGroupName

---

# Document 704: APL - PCC Mapper Support - MediationZone Documentation 9.3 - InfoZone

**Source:** ratanon/mz93-documentation
**URL:** https://infozone.atlassian.net/wiki/spaces/MD93/pages/205656214/APL+-+PCC+Mapper+Support
**Categories:** chunks_index.json

The mapper support is used for accessing a table in the rules database containing references to the rules that are applicable for the specified service. The mapper support functions include: pccMapperCreate pccMapperGet pccMapperGetFlat pccMapperGetIndexes pccMapperGetFromIndex These functions can be used to create and use a PCC flexible mapper object. pccMapperCreate This function creates a mapper table. any pccMapperCreate ( string area, string typename [, string argumentsField, string targetField] Parameters Parameter Description Parameter Description area The name of the area which the mapper is operating against. typename The fully qualified UDR typename to be used for the mapper configuration information. argumentsField The field name of the field that contains the argument list to be used for matching. This field must be a list of strings. Either null or the string "*" can be used to signify a wildcard matching. This field is optional. targetField The field name of the field that contains the target value. This is the value that should be returned from the pcrfMapperGet function. This field is optional. Returns: A mapper table that can be used in pccMapperGet . Example rulesMapping = pccMapperCreate("PROD", "PCRF.Rules.Provisioning.RulesMapping"); will create a mapper table named rulesMapping that will use the PCRF.Rules.Provisioning.RulesMapping pccMapperGet This function matches a list of arguments using a PCC mapper table. list<any> pccMapperGet ( [any mapper,] any argument1, any argument2, ... ) Parameters Parameter Description Parameter Description mapper The mapper table to be used for matching the arguments. This field is optional. If no mapper is stated, the mapper last used by the workflow will be used for the lookup. argument...n Any number of arguments to match using the mapper object. The number of arguments must match the mapper configuration. Returns: The matched target, or null if the mapper did not match any data. Example list<any> rules = pccMapperGet(rulesMapping, "GOLD"); will return a list of rules matching argument "GOLD" using the rulesMapping mapper table. pccMapperGetFlat This function will provide a list of all matching products using a PCC mapper table. list<any> pccMapperGetFlat ( [any mapper,] any argument1, any argument2, ... ) Parameters Parameter Description Parameter Description mapper The mapper table to be used for matching the arguments. This field is optional. If no mapper is stated, the mapper last used by the workflow will be used for the lookup. argument...n Any number of arguments to match using the mapper object. The number of arguments must match the mapper configuration. Returns: A list of the matching products, or null if the mapper did not match any data. Example list<any> rules = pccMapperGetFlat(rulesMapping, "GOLD"); will return a list of rules matching argument "GOLD" using the rulesMapping mapper table. pccMapperGetIndex This function will provide a list of all matching products with an index for each matching. This index may then be used by the pccMapperGetFromIndex function below for retrieving the rules applicable for the actual object. list<any> pccMapperGetIndex ( [any mapper,] any argument1, any argument2, ... ) Parameters Paramater Description Paramater Description mapper The mapper object to be used for matching the arguments. This field is optional. If no mapper is stated, the mapper last used by the workflow will be used for the lookup. argument...n Any number of arguments to match using the mapper object. The number of arguments must match the mapper configuration. Returns: A list of the matching products with an index for each matching object, or null if the mapper did not match any data. Example list pccMapperGetIndex(rulesMapping,"GOLD"); will return a list of the products named "GOLD" using the mapper table rulesMapping , with an index for each matching object. pccMapperGetFromIndex This function will provide a list of rules applicable for the stated object. list<any> pccMapperGetFromIndex ( [any mapper,] int index ) Parameters Parameter Description Parameter Description mapper The mapper object to be used for matching the arguments. This field is optional. If no mapper is stated, the mapper last used by the workflow will be used for the lookup. index The index for the object that you want to retrieve rules for. Returns: A list of rules applicable for the object with the stated index.

---

# Document 705: Authorization Server Storage Database Schema - MediationZone Documentation 9.3 - InfoZone

**Source:** ratanon/mz93-documentation
**URL:** https://infozone.atlassian.net/wiki/spaces/MD93/pages/204648145
**Categories:** chunks_index.json

When the Authorization Server storage is set to Database, users are required to create two new tables manually in the Database where the Authorization Server will store the scope and details of the client registration. Users can refer to the following example of a table schema to generate the tables for Authorization Server. Example - Table Schema CREATE TABLE oauth_scope ( scope VARCHAR(64) NOT NULL PRIMARY KEY, description VARCHAR(128) ); CREATE TABLE oauth_client ( client_name VARCHAR(128) NOT NULL PRIMARY KEY, client_id VARCHAR(64) NOT NULL, client_secret VARCHAR(64) NOT NULL, client_scope VARCHAR(2048) NOT NULL );

---

# Document 706: User Documentation - MediationZone Documentation 9.3 - InfoZone

**Source:** ratanon/mz93-documentation
**URL:** https://infozone.atlassian.net/wiki/spaces/MD93
**Categories:** chunks_index.json

This release contains the following enhancements: New command line interface Automatic rollback will be triggered when upgrading fails. A rollback also can be manually triggered and a number of bug fixes for: Desktop Devkit MZSH Documentation Installation FTP SCP SFTP SAP RFC SAP CTS+ SQL System Log Workflow UI Events Realtime batch Execution Manager Configuration Browser Conditional Trace Azure Kafka Diameter Liquibase Audit Conditional Trace Pico Parquet JSON Decoder Ultra among others. See Bug Fixes for more details. Information about where the release can be accessed is available here: Release Information . Overall user documentation is available at: https://infozone.atlassian.net/wiki/spaces/MD93 . Enjoy!

---

# Document 707: Execution Container Properties - MediationZone Documentation 9.3 - InfoZone

**Source:** ratanon/mz93-documentation
**URL:** https://infozone.atlassian.net/wiki/spaces/MD93/pages/205029670/Execution+Container+Properties
**Categories:** chunks_index.json

Set the Execution Container related properties described below in the install.xml file. The properties are described in the order they appear in the install.xml file. Common Properties Property Description Property Description pico.rcp.platform.host Default value: "" Example value: 192.168.0.190 This property specifies the IP address or the hostname of the Platform to be used by other pico instances such as Execution Contexts, Service Contexts, or Command Line. If a failover occurs and you have entered a hostname as property value, the hostname is retrieved from the DNS enabling reconnection. If you have entered a static IP address as property value, reconnection issues may occur after a failover, if the IP address has changed. pico.rcp.platform.port Default value: 6790 This property specifies the port for connecting the Execution Contexts to the Platform. pico.rcp.server.host Default value: "" This property specifies the IP address or hostname of the pico instances. It is used to determine the interface that the pico instances must bind to and the IP address/hostname to be used by connecting processes. If a failover occurs and you have entered a hostname as property value, the hostname is retrieved from the DNS enabling reconnection. If you have entered a static IP address as property value, reconnection issues may occur after a failover, if the IP address has changed. When the value of this property is left blank, the pico instance binds to all IP addresses of the host. This means that the pico listens for inbound network traffic on all network interfaces, and may attempt to use any local IP address for outbound network traffic. Note! If the host has more than one IP address, this property has to be set with the correct IP address. Make sure to set the property if you use IPv6, or if a high availability environment is configured. For information about high availability, see High Availability . mz.webserver.port Default value: "9000" This property specifies the port for connecting to the Desktop. Config Properties Property Description Property Description mz.name Default value: DR This property specifies the name of the MediationZone deployment. Execution Context Properties - Not Used in Platform Only Installations Property Description Property Description mz.eclist Default value: ec1 This property specifies the EC(s) to be installed. Only applicable if install.types includes ec. To specify multiple ECs, the values should be delimited by comma: ec1,ec2,ec3 ec.backlog.dir Default value: ${mz.home}/tmp This property specifies the directory where ECs can store their backlogged events. If this parameter is removed, the EC's events are not logged. Only applicable if install.types includes ec. ec.webserver.enabled Default value: true This property specifies if the web server of the Execution Contexts should be active. Only applicable if install.types includes ec. ec.webserver.port Default value: 9090 This property specifies the EC web server port. Only applicable if install.types includes ec. Note! If you specify several ECs, you need to modify this value to use separate port numbers for each EC once the installation is completed. Do this by using the mzsh topo set command: mzsh topo set topo://container:<container>/pico:<name>/val:config.properties.ec.webserver.port <new_port_number>

---

# Document 708: Working with STR - MediationZone Documentation 9.3 - InfoZone

**Source:** ratanon/mz93-documentation
**URL:** https://infozone.atlassian.net/wiki/spaces/MD93/pages/204647090/Working+with+STR
**Categories:** chunks_index.json

A principle behind the configuration representation used in the STR, is to support both manual configuration, i e editing configuration files in a text editor, and scripted configuration using the mzsh topo command. Most changes to the files can be done in either way. The figure below illustrates how you can edit a particular system property, either using a command or a text editor. Open Updating a system property in STR Manual Configuration There are three methods of manually editing configurations in STR. Method 1 Open a configuration file under MZ_HOME/common/config/cell/default/master . Edit the file and save. Run the mzsh command topo activate . This is required in order for the changes to become effective. $ mzsh topo activate Method 2 Open a configuration by running the mzsh command topo open. The configuration opens in vi or the editor specified by the environment variable EDITOR. Example - Opening a Cell Configuration $ mzsh topo open cell:default Example - Opening a Container Configuration $ mzsh topo open main1 Example - Opening a Pico Configuration $ mzsh topo open ec1 If the pico name is not unique in the system, you will be prompted to specify the container. Example - Multiple Pico Configurations Sharing the Same Name $ mzsh topo open ec2 (/home/main1/common/config/cell/default/master/containers/main1/picos/ec2.conf,ec2,topo://container:main1/pico:ec2) (/home/main1/common/config/cell/default/master/containers/exec1/picos/ec2.conf,ec2,topo://container:exec1/pico:ec2) Multiple entries, select one: (1) topo://container:main1/pico:ec2 (2) topo://container:exec1/pico:ec2 [1] : Edit the configuration and save. The mzsh command topo activate will be called with the --verbose option and the saved changes are displayed in a scripted syntax. Method 3 As an alternative to the command line tool, you can manage pico configurations and start/stop pico instances from the System Administration GUI. For further information, see Managing Picos in Desktop . Activation and Validation When you use the mzsh commands topo set or topo open , changes are automatically validated before they are copied to the active registry. If the command and its arguments can be parsed but fails the validation, you can update the configuration or use a reset command to undo the changes. You can disable the validation by using the option --no-activation . Changes performed by the mzsh topo will then remain in the master registry until you submit a separate activate command. $ mzsh topo set --no-activation Hint! The options --dry-run and --verbose are useful to learn the mzsh topo syntax. When you have edited the configuration manually, use the following command, to view the corresponding edits in a scripted syntax: $ mzsh topo activate --dry-run --verbose Example - Output from activate with verbose Option $ mzsh topo activate -v --dry-run mzsh topo set topo://container:main1/pico:ec1/val:config.properties.ec.httpd.port 9096 # (was: 9092) Dry-run: Validation successful Dry-run: Stopping without performing activation Dry-run: Active registry not changed You can then restore the master registry with the command mzsh topo reset . Example - Restart the Picos to Apply the Changes Changes to the STR are not applied on running pico instances or services. If you, for example, have updated the properties of the Platform and an EC, both must be restarted after activation. Example, after an mzsh topo activate of ec5, mzsh shutdown and startup needs to be done to apply the changes. $ mzsh shutdown ec5 $ mzsh startup ec5 Note! The sorting and layout of the configuration files may change when it is updated both using manual editing and the commands. That means that the exact ordering of keys, and layout of the file could change. However: this will not affect how the system interprets the configuration at runtime. It is not supported to edit the configuration files using command line utilities (such as sed or awk), all scripted changes must be done via the mzsh topo command, to minimize the risk of invalid assumptions regarding the exact layout of the configuration files. For further information about the various sub-commands that are available in the mzsh topo command, see topo . For further information about how to manage pico- and service configurations, see Managing Picos with Topo and Managing Service Configurations .

---

# Document 709: Type Conversion Functions - MediationZone Documentation 9.3 - InfoZone

**Source:** ratanon/mz93-documentation
**URL:** https://infozone.atlassian.net/wiki/spaces/MD93/pages/204677850
**Categories:** chunks_index.json

This section describes functions that are used to perform conversions between different types. The following functions for Type Conversion described here are: baToBigInt Converts a bytearray to a big integer (two complement). void baToBigInt (bigint bigintVar, bytearray baValue) Parameter Description bigintVar Bigint variable to set baValue Bytearray value Returns Nothing baToHexString Converts a bytearray to a string containing the hexadecimal values. string baToHexString(bytearray baValue) Parameter Description baValue Bytearray value Returns A hexadecimal string baToStr Converts a bytearray to a string. string baToStr (bytearray array, string charEncoding) //Optional Parameter Description array The bytearray to convert charEncoding The character encoding to use. If no encoding is specified, ISO-8859-1 (Latin 1) is used. If you specify character encoding, it must match the character encoding included in the standard charsets found in https://docs.oracle.com/en/java/javase/17/docs/api/java.base/java/nio/charset/Charset.html or the extended charset of the target Java implementation. If you specify a character encoding that cannot be found, a compilation error occurs. Returns The result string dateToString Converts a date to a string and assigns the result to a string variable (or field). Returns true if the conversion succeeded. The only time the conversion can fail, is if the date is null or the format is invalid. boolean dateToString (string stringVar, date dateValue, string format) //optional Parameter Description stringVar String identifier to set. dateValue The date value. format If no format string is specified, the default system format is used as specified in the property mz.server.dateformat . For further information about this property, see Cell Properties in the System Administrator's Guide . The date formatting is based on standard Java syntax. For further information, see https://docs.oracle.com/en/java/javase/17/docs/api/java.base/java/text/SimpleDateFormat.html . Returns true or false . strToBA Converts a string to a bytearray and assigns the result to a bytearray variable (or field). void strToBA (bytearray array, string stringValue, string charEncoding) //Optional Parameter Description array The resulting bytearray stringValue The string value charEncoding The character encoding to use. If no encoding is specified, ISO-8859-1 (Latin 1) is used. If you specify character encoding, it must match the character encoding included in the standard charsets found in https://docs.oracle.com/en/java/javase/17/docs/api/java.base/java/nio/charset/Charset.html or the extended charset of the target Java implementation. If you specify a character encoding that cannot be found, a compilation error occurs. Returns Nothing strToBigInt Converts a string to a big integer. If the conversion was successful true is returned. If one of the keywords dec or hex are specified, the string is assumed to be decimal or hexadecimal respectively. Decimal is the default. boolean strToBigInt (bigint bigintVar, string stringValue, dec|hex) //Optional Parameter Description bigintVar Big integer variable to set stringValue String value Returns true or false strToDate Converts a string to a date and assigns the result to a date variable (or field). Returns true if the conversion succeeded. You can enable lenient interpretation of the date/time in the string to be converted by setting the Cell property mz.drdate.lenient to true in the cell.conf . With lenient interpretation, a date such as "January 32, 2016" will be treated as being equivalent to the 31nd day after January 1, 2016. With strict (non-lenient) interpretation, an invalid date will cause the function to leave the submitted date variable unchanged. The default value of mz.drdate.lenient is false . boolean strToDate (date dateVar, string stringValue, string format, //Optional string timeZone) //Optional Parameter Description dateVar Date identifier to set stringValue Date value format If no format string is specified, the default system format is used as specified in $MZ_HOME/ common/config/cell/default/master/cell.conf , the mz.server.dateformat property. The date formatting is based on standard Java syntax. For further information, see https://docs.oracle.com/en/java/javase/17/docs/api/java.base/java/text/SimpleDateFormat.html . Note! Even though the syntax conforms to SimpleDateFormat , it is not directly based on this class. You can enable date format handling based on the SimpleDateFormat class in the installed Java version by setting the Execution Context property mz.use.drdateformat to false. This enables use of additional patterns that are available in the installed Java version. $ mzsh topo set topo://container:<container>/pico:<pico name>/val:config.properties.mz.use.drdateformat false When mz.use.drdateformat is set to true (default), the function does not apply the timezone offset at conversion. The timezone can be specified but the date is not modified. Note! Unlike SimpleDateFormat the strToDate function does not accept the Locale parameter and uses the default JVM locale instead, which may result in parsing errors. If this is an issue, it can be solved by setting the locale to US_en in the JVM arguments of the relevant EC. $ mzsh topo set topo://container:<container>/pico:<pico name>/obj:config.jvmargs  'usercountry: ["-Duser.country=US"] userlanguage: ["-Duser.language=en"]' timeZone An optional string stating the time zone to set. It is recommended that you specify the time zone id using the long format, e g "America/St_Johns". It is possible to also use the abbreviated format, e g "PST". However, this can lead to ambiguous results and should be avoided. If an invalid time zone format is entered, no error is returned. Instead, the time zone is automatically set to "GMT". If the time zone is specified in the stringValue , it overrides the timeZone parameter. Returns true or false . strToDouble Converts a decimal string to a double and assigns the result to a double variable (or field). Returns true if the conversion succeeded. boolean strToDouble (double doubleVar, string stringValue) Parameter Description doubleVar Double identifier to set. stringValue String value. Returns true or false . strToFloat Converts a decimal string to a float and assigns the result to a float variable (or field). Returns true if the conversion succeeded. boolean strToFloat (float floatVar, string stringValue) Parameter Description floatVar Float identifier to set stringValue String value Returns true or false strToInt Converts a decimal or hexadecimal string to an integer and assigns the result to an integer variable (or field). Returns true if the conversion succeeded. If one of the keywords dec or hex are specified, the string is assumed to be decimal or hexadecimal respectively. Decimal is the default. boolean strToInt (int intVar, string stringValue, dec|hex) //Optional Parameter Description intVar Integer identifier to set. stringValue String value. Returns true or false . Example - Using strToInt Provided that the field CallTime is a string containing a hexadecimal string, it converts its content to an integer. int a; int b; strToInt( a, CallTime, hex ); strToInt( b, "12345" ); /* dec is default */ strToLong Converts a decimal or hexadecimal string to a long and assigns the result to an long variable (or field). Returns true if the conversion succeeded. If one of the keywords dec or hex are specified, the string is assumed to be decimal or hexadecimal respectively. Decimal is the default. boolean strToLong (long longVar, string stringValue, dec|hex) //Optional Parameter Description longVar Long identifier to set stringValue String value Returns true or false strToBigDec Converts a decimal or hexadecimal string to a BigDecimal and assigns the result to a BigDecimal variable (or field). Returns true if the conversion succeeded. boolean strToBigDec (bigdec bigdecVar, string stringValue) Parameter Description bigdecVar BigDecimal identifier to set stringValue String value Returns true or false udrToString Converts a UDR to a string. Each UDR will be preceded with the internal class name, and each of its field will be preceded with the field name. string udrToString(drudr myUDR) Parameter Description myUDR The UDR to convert Returns A string containing the UDR fields. The output will be in the following format: Field values for: <internal UDR reference> field1: <value> field2: <value>

---

# Document 710: Excel Decoder Agent Events - MediationZone Documentation 9.3 - InfoZone

**Source:** ratanon/mz93-documentation
**URL:** https://infozone.atlassian.net/wiki/spaces/MD93/pages/205652578/Excel+Decoder+Agent+Events
**Categories:** chunks_index.json

Agent Message Events There are no agent message events for this agent. Debug Events There are no debug events for this agent.

---

# Document 711: ADLS2 File Forwarding Agent - MediationZone Documentation 9.3 - InfoZone

**Source:** ratanon/mz93-documentation
**URL:** https://infozone.atlassian.net/wiki/spaces/MD93/pages/204671901/ADLS2+File+Forwarding+Agent
**Categories:** chunks_index.json

The ADLS2 file forwarding agent creates files on the Azure Data Lake Storage using the access credentials in an Azure profile, containing the received data. Files are created when a Begin Batch message is received and closed when an End Batch message is received. In addition, the Filename Template service offers the possibility to compress (gzip) the files, or to further process them, using commands. To ensure that downstream systems will not use the files until they are closed, they are stored in a temporary directory until the End Batch message is received. This behavior also applies to Cancel Batch messages. If a Cancel Batch is received, file creation is ca nce lled. ADLS2 File Forwarding Agent Configuration ADLS2 File Forwarding MultiForwardingUDR Input ADLS2 File Forwarding Agent Input/Output Data and MIM ADLS2 File Forwarding Agent Transaction Behavior ADLS2 File Forwarding Agent Events

---

# Document 712: SQL Forwarding Agent Configuration - Batch - MediationZone Documentation 9.3 - InfoZone

**Source:** ratanon/mz93-documentation
**URL:** https://infozone.atlassian.net/wiki/spaces/MD93/pages/204740755/SQL+Forwarding+Agent+Configuration+-+Batch
**Categories:** chunks_index.json



---
**End of Part 32** - Continue to next part for more content.
