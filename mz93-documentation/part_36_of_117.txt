# RATANON/MZ93-DOCUMENTATION - Part 36/112

---
**Dataset:** ratanon/mz93-documentation
**Part:** 36 of 112
**GitHub:** https://github.com/ratan0n/docs/tree/main/mz93-documentation
**Size:** ~69.9 KB
---

Configuration You open the Compressor processing agent configuration dialog from a workflow configuration. To open the Compressor processing agent configuration, click Build  New Configuration . Select Workflow from the Configurations dialog. When prompted to Select workflow type, select Batch . Click Add agent and select Compressor from the Processing tab of the Agent Selection dialog. Open The Compressor agent configuration dialog Setting Description Setting Description Compression Select Compression algorithm: No Compression: The agent will not compress the files. Gzip: The agent will compress the files by using gzip (Default). Compression Level Select the Compression level. The speed of compression is regulated using a level, where "1" indicates the fastest compression method (less compression) and "9" indicates the slowest compression method (best compression). The default compression level is "6". Produce Empty Archives Check this to make sure that an archive is produced and routed forward even if it has no content. Transaction Behavior This section includes information about the Compressor agent's transaction behavior. For information about the general transaction behavior, see Workflow Monitor . Emits The Compressor agent does not emit any commands. Retrieves The Compressor agent does not retrieve any commands. Input/Output Data Input/Output data is the type of data that an agent both recognizes and delivers. The Compressor agent consumes and delivers bytearray types. MIM For information about the MIM and a list of the general MIM parameters, see Administration and Management in Legacy Desktop . Publishes The Compressor agent does not publish any MIM resources. Accesses The Compressor agent does not access any MIM resources. Agent Message Events The Compressor agent does not generate any message events. Debug Events There are no debug events for the Compressor agent.

---

# Document 802: Excel Decoder Agent Transaction Behavior - MediationZone Documentation 9.3 - InfoZone

**Source:** ratanon/mz93-documentation
**URL:** https://infozone.atlassian.net/wiki/spaces/MD93/pages/204738814/Excel+Decoder+Agent+Transaction+Behavior
**Categories:** chunks_index.json

Transaction Behavior This section includes information about the Decompressor agent's transaction behavior. For information about the general transaction behavior, see 3.1.11 Workflow Monitor . Emits The Excel Decoder agent does not emit any commands. Retrieves The Excel Decoder agent does not retrieve any commands.

---

# Document 803: Installation and Configuration of Legacy Desktop - MediationZone Documentation 9.3 - InfoZone

**Source:** ratanon/mz93-documentation
**URL:** https://infozone.atlassian.net/wiki/spaces/MD93/pages/204741690
**Categories:** chunks_index.json

You can choose how you want to display the Legacy Desktop, and you can start the Legacy Desktop for multiple instances of the Platform via the Desktop Launcher application, or you can start it in your browser. Refer to the relevant section for how to install and configure the Legacy Desktop for each of these options. This chapter includes the following sections: Desktop Launcher

---

# Document 804: Users Tab - MediationZone Documentation 9.3 - InfoZone

**Source:** ratanon/mz93-documentation
**URL:** https://infozone.atlassian.net/wiki/spaces/MD93/pages/205030940/Users+Tab
**Categories:** chunks_index.json

The default user, mzadmin, will always have full permissions for any activity. It is recommended that the password for mzadmin is changed and kept in a safe place. Instead personal accounts should be created and used for handling the system in order to track changes. Create new user, edit user, delete user and change password for a user can be performed in Access Controller desktop online UI. Performing said action will require a user with Write permission on Access Controller. Users with the Execute permission can only view the Users. Users Table When users with Write permission for Access Controller are on the Access Controller dashboard, the logged in user will see a list of Users displayed in the Users Table. Users from the SSO login will be displayed here as well, you can refer to Single Sign On (OIDC) for more information about the SSO. Users from an LDAP server will not be displayed in the Access Controller Users list, refer to LDAP Authentication for more information. The possible values for the User Type column includes: Local - for users created locally. SSO - for users created via SSO authentication. LDAP - for users created via LDAP authentication. Open Access Controller dashboard button configuration for users with Write permission Open Access Controller dashboard button configuration for users with Execute permission Adding a New User To Add a User: Click on the New User button. Fill in the details according to the description below and click Save button. Info! Save button will remain greyed out until a field is filled in. Open Access Controller - Add new user screen Setting Description Enable Check to enable the user's predefined access rights. Leaving this unchecked will result in the user not being able to login. Username Enter the name of the user. Valid characters are: A-Z, a-z, 0-9, '-' and '_'. Note! A username must be unique. This also applies if you use an external authentication method, such as LDAP or SSO. Full Name Enter a descriptive name of the user. Email Enter the user's e-mail address. This address will be automatically applied to applications from which e-mails may be sent. Validity Period Check to enable the user's validity period for access to the system. Once the validity period for the user is over, the user will be disabled but not removed from the users list. This is so the user can be enabled again if needed. From From Date. User is allowed to login from this Date. To To Date. User is allowed to login until this Date. Successor A successor must be defined for when you want to remove the user that has ownership of configuration objects. The ownership of the configuration will be moved to whichever user is set as this user's successor. Allow access through SCIM Check to enable access through SCIM API. Refer to SCIM for more information. Password Enter a password for the user account. Note! The password is required when executing certain mzsh commands, so you should take into consideration the special characters used by bash and we do not recommend the use of these characters as part of your password. These characters are $, , /, |, *, &, space and any other special characters used by bash. For a better understanding of the characters not recommended to be included in your password, refer to https://mywiki.wooledge.org/BashGuide/SpecialCharacters . Verify Password Re-enter the password. Default Group Set as default group for the user. By default, this group will have read, write and execute permissions for new configurations created by the user. Member Groups The user is registered as a member of the specific group. An user is allowed to be a member for multiple access groups. Edit User To Edit a User: Click on the Edit button at the end of the row of the user you want to edit. Update the fields and click the Save button. Info! Consider the following when editing a user: Save button will be enabled when users started to fill in the fields. Non SSO users will be allowed to edit all fields except Username . SSO users will only be allowed to edit Successor and Allow access through SCIM option. Open Access Controller - Edit user screen - standard users Open Access Controller - Edit user screen - SSO users Delete User To delete a User: Click on the Delete button at the end of the row of the user you want to remove. On the confirmation dialog, click Delete to continue deletion. Info! Consider the following when removing a user: SSO users can be removed using the Access Controller. The Delete button is disabled for the default user mzadmin and mzk8soperator. Open Access Controller - Delete confirmation dialog When deleting a user with a successor, all the configuration ownership for the user would be updated to the successor automatically. When deleting a user without a successor, a dialog would pop up to confirm if you would like to transfer the ownership of the configuration to any other user with the proper access rights for the configuration. On confirmation, you would be able to choose the successor from a new dialog window. Clicking Set and delete would remove the user and update the ownership to the successor. Open Access Controller - Cannot delete user dialog Open Access Controller - Set Successor dialog Change Password To change password for a user: Click on the meatball menu button at the end of the row of the user you want to have the password changed, and then click on the Change Password button. Enter new password and confirm password. Click the Change Password button. Info! The Change Password button is disabled for users configured using SSO. Open Access Controller - Change Password screen View User The View button is displayed instead of the Edit button when the logged in user only has the Execute permission for Access Controller. All fields in the View user screen will be disabled. Open Access Controller - View user screen

---

# Document 805: SAP RFC Processor Agent - MediationZone Documentation 9.3 - InfoZone

**Source:** ratanon/mz93-documentation
**URL:** https://infozone.atlassian.net/wiki/spaces/MD93/pages/204642946/SAP+RFC+Processor+Agent
**Categories:** chunks_index.json

This section describes the SAP RFC profile and the SAP RFC Processor agent. The agent is a processing agent for real-time workflow configurations. SAP RFC (Remote Function Call) is the interface used for communication between SAP systems. Communication using the SAP RFC protocol is provided by the SAP Java Connector (JCo) library for Java-based applications. The SAP RFC Processor agent supports SAP JCo Release 3.1. Prerequisites The reader of this document should have basic understanding of the SAP JCo libraries. Before starting with the SAP RFC Processor agent, the following is required: SAP JCo library Info! To download the SAP JCo library, refer to SAP JCo Library Download . For more information on SAP JCo library system requirements, refer to SAP Note 2786882 . Setting up SAP JCo library's jar file Info! For more information on how to set up the jar file in Platform and Execution Container, refer to SAP RFC Agent Preparations . The section contains the following subsections: SAP RFC Agent Preparations SAP RFC Profile SAP RFC Processor Agent Configuration SAP RFC Agent Input/Output Data and MIM SAP RFC Processor Agent Events SAP RFC Processor Agent Example

---

# Document 806: SQL Loader Agent - MediationZone Documentation 9.3 - InfoZone

**Source:** ratanon/mz93-documentation
**URL:** https://infozone.atlassian.net/wiki/spaces/MD93/pages/204740809/SQL+Loader+Agent
**Categories:** chunks_index.json

This section describes the SQL Loader agent. This is a processing agent for batch workflow configurations. The SQL Loader agent is a batch processing agent designed to populate the database with data from existing files, either residing in a local directory or on the server filesystem of the database. The following agents can be used for data collection: Disk FTP SFTP The supported databases are: MySQL Netezza PostgreSQL SAP HANA Sybase IQ Vertica Prerequisites The reader of this information has to be familiar with: Structured Query Language (SQL) UDR structure and contents The section contains the following subsections: SQL Loader Agent Configuration SQL Loader Agent Events SQL Loader Agent Input/Output Data and MIM SQL Loader Agent Transaction Behavior SQL Loader Agent UDRs SQL Statements

---

# Document 807: SCP Forwarding Agent Input/Output Data and MIM - MediationZone Documentation 9.3 - InfoZone

**Source:** ratanon/mz93-documentation
**URL:** https://infozone.atlassian.net/wiki/spaces/MD93/pages/204609333/SCP+Forwarding+Agent+Input+Output+Data+and+MIM
**Categories:** chunks_index.json

Input/Output Data The agent consumes bytearray or MultiForwardingUDR types. MIM For information about the MIM and a list of the general MIM parameters, see Administration and Management in Legacy Desktop . Publishes MIM Parameter Description MultiForwardingUDR's FNTUDR This MIM parameter is only set when the agent expects input of MultiForwardingUDR type. The MIM value is a string representing the sub path from the output root directory on the target file system. The path is specified by the fntSpecification field of the last received MultiForwardingUDR . For further information about how to use input of MultiForwardingUDR type, see SCP Forwarding Agent MultiForwardingUDR Input . This parameter is of the string type and is defined as a batch MIM context type. File Transfer Timestamp This MIM parameter contains a timestamp, indicating when the target file is created in the temporary directory. File Transfer Timestamp is of the date type and is defined as a trailer MIM context type. Target Filename This MIM parameter contains the target filename, as defined in Filename Template . Target Filename is of the string type and is defined as a trailer MIM context type. Target File Size This MIM parameter provides the size of the file that has been written. The file is located on the server. Target File Size is of the long type and is defined as a trailer MIM context type. Target Hostname This MIM parameter contains the name of the target host, as defined in the Connection tab of the agent. Target Hostname is of the string type and is defined as a global MIM context type. Target Pathname This MIM parameter contains the path to the target file, as defined in the Target tab of the agent. Target Pathname is of the string type and is defined as a global MIM context type. Target Username This MIM parameter contains the login name of the user connecting to the remote host, as defined in the Connection tab of the agent. Target Username is of the string type and is defined as a global MIM context type. Connection Retries This MIM parameter contains the number of connection attempts made. Connection Retries is of the integer type and is defined as a batch MIM context type. Accesses Various resources from the Filename Template configuration to construct the target filename.

---

# Document 808: wfgroupmodify - MediationZone Documentation 9.3 - InfoZone

**Source:** ratanon/mz93-documentation
**URL:** https://infozone.atlassian.net/wiki/spaces/MD93/pages/204678095/wfgroupmodify
**Categories:** chunks_index.json

usage: wfgroupmodify -group NAME (-memberwf WF | -membergrp GRP) [-prereqwf WF...] [-prereqgrp GRP...] [-q] This command enables you to modify the prerequisites list for an entry in a workflow group. The workflow group name and workflow group member name are required parameters. Only one workflow group member at a time can be modified by the command. Parameters/Options Description Parameters/Options Description <group NAME> Enter the name of the workflow group which prerequisites you want to modify. (-memberwf WF | -membergrp GRP) Enter the name of the member that you want to modify, either a workflow or a workflow group. [-prereqwf WF...] Enter a list of workflows that the prerequisites list should include. Note! Leaving this parameter empty sets the workflow prerequisites list of the workflow group to be empty. [-prereqgrp GRP...] Enter a list of workflow groups that the prerequisites list should include. Note! Leaving this parameter empty sets the workflow-groups prerequisites list of the workflow group to be empty. [-q] Quiet mode. Use this parameter to eliminate the display of any report during execution. Return Codes Listed below are the different return codes for the wfgroupmodify command: Code Description Code Description 0 Will be returned if the command was successful. 1 Will be returned if the command was unsuccessful.

---

# Document 809: Reference Data Profile - MediationZone Documentation 9.3 - InfoZone

**Source:** ratanon/mz93-documentation
**URL:** https://infozone.atlassian.net/wiki/spaces/MD93/pages/204612029
**Categories:** chunks_index.json

In a Reference Data profile configuration, you can select the tables that should be available for query and editing via the Reference Data Management dashboard or RESTful interface. For information about these interfaces, refer to the Reference Data Management Dashboard or the RESTful Interface for Reference Data Management . This profile is loaded when you start the Platform. To create a new Reference Data profile configuration, click the New Configuration button from the Configuration dialog available from Build View , and then select Reference Data Profile from the menu . The contents of the menus in the menu bar may change depending on which configuration type has been opened in the currently active tab. The Reference Data profile uses the standard menu items and buttons that are visible for all configurations, and these are described in Common Configuration Buttons . To open an existing Reference Data profile configuration, click on the configuration in the Configuration Navigator, or right-click on the configuration and then select View Configuration . General The General tab is displayed by default. Open Reference Data profile - General tab Setting Description Setting Description Database This is the database the agent will connect and send data to. Click the Browse... button to get a list of all the database profiles that are available. For further information see Database Profile . If changes have been made in the selected database, click the Refresh button to retrieve updated db metadata that will be reflected in the table selector when adding entries into the Tables section of the configuration dialog. The Reference Data profile is supported for use with the following databases: Oracle PostgreSQL MariaDB SAP HANA Enable Enhanced Logging When you perform any of the following operations, entries are written to the System Log, and DB Ref event notifications are generated: Commit changes to the database Perform import operations Select Enable Enhanced Logging to include information about executed SQL statements in the event notifications. For more information about DB Ref events, see DB Ref Event . Tables Configurations of selected tables are listed here. Open Reference Data Profile - Add Table Dialog Setting Description Setting Description Table Select a table for the selected database with this table selector. Read Select this check box to enable read access to the selected tables. Users of the profile can query and export data. Write Select this check box to enable write access to the table data. If Read is also selected, users of the profile can insert, update, delete and import data. Last Update Select this check box to enable the Last Update feature. Last Update allows users to specify two columns in the table that will be used to automatically record the username and timestamp of when an entry was updated. Note! When creating tables to include the User column and Timestamp column, ensure that these columns are not UNIQUE and does not have any PRIMARY KEY constraints. The datatype for the User column should be set as VARCHAR and datatype of the Timestamp column should be set as TIMESTAMP. User Column This is to specify the name of the User column to be used for the Last Update feature. This column will be updated with the name of the last user to perform an operation on the record. This column can not be edited from Reference Data Management UI Timestamp Column This is to specify the name of the Timestamp column to be used for the Last Update feature. This column will be updated with the the timestamp when performing an operation on the record. This column can not be edited from Reference Data Management UI To Add a Table Note! Reference Data Management does not support tables that contain a column that has both GENERATED ALWAYS AS IDENTITY and PRIMARY KEY constraints. Having one or the other constraint in a column in your table will not affect Reference Data Management. Note! Modifications to a reference data entry are supported either on Oracle (based on ROWID pseudo column) or Postgres tables containing Primary Key constraint. Postgres tables without a Primary Key are not supported for data modifications. Note! Reference Data Management does not support the use of case sensitive identifiers. Click on the Add button. Select a table from the drop down list. Always select the Read access check box. If you want to enable editing of the table table, also select the Write access check box. If you want to enable Last Update, select the Last Update check box. Then fill up the User column and Timestamp column with the column names of your choice. Advanced In the Advanced tab, you can configure additional properties. You can use these parameters to tune the performance of database operations. Open Reference Data profile - Advanced tab prefetchSize - This setting defines the number of rows retrieved from the database in a single network round trip. Increasing the fetch size can improve query performance by reducing the number of trips between the application and the database, which is especially beneficial over high-latency connections. However, setting the fetch size too high may lead to increased memory consumption and potential out-of-memory errors. If prefetchSize is set to 0, no limit will be applied. The default value is 1000. maxRowsPerQuery - This setting sets the maximum number of rows returned for each query or table. It directly affects operations such as exporting results, for example, when using Manage  Reference Data Management  Export  Export Retrieved Rows (export query results). The default value is 50000.

---

# Document 810: Parquet Profile Configuration Schema - MediationZone Documentation 9.3 - InfoZone

**Source:** ratanon/mz93-documentation
**URL:** https://infozone.atlassian.net/wiki/spaces/MD93/pages/204608445/Parquet+Profile+Configuration+Schema
**Categories:** chunks_index.json

The Schema tab is the primary configuration in the Parquet Profile. This tab allows the author to specify a Parquet Schema. This schema will be used for different purposes by the Parquet Encoder and Paruet Decoder agents. Parquet Encoder Agent - The Parquet Encoder agent will generate a Parquet document that conforms to the specified schema. Not only will the data conform to the schema, but the schema itself is included in the Parquet document. Parquet Decoder Agent - When the Parquet Decoder processes a Parquet document, only the columns included in the specified schema will be included. For example: Consider a document with columns A, B, C, and D. Assume that the schema in the Parquet Profile only specifies columns A and D. The generated ParquetDecoderUDRs will include only fields A and D in the payload map. Note that the Parquet Profile (and hence the schema) are required for Parquet Encoder agents and optional for Parquet Decoders. Open The Parquet profile's Schema tab with an example of a defined Schema. You will have to write the Schema for your desired functions. Setting Description Setting Description Schema See below. Validate Press the Validate button to validate the Schema and make sure it has a correct format. Defining the Parquet Schema To be able to define a Schema, it is useful to have knowledge about primitives, nested groups, repetition levels, and logical types, as described below: Example Parquet Schema Apache Parquet supports a small set of primitives (integer, floating point, boolean, and byte array). These primitives can be extended using logical type annotations which are modifiers on primitives. For example, the UTF8 annotation is a modifier to byte arrays that denotes string data. Parquet also supports structured data through groups and repetitions (that is, optional, required, repeated). Example - Parquet Schema This structured text block shows an example Parquet schema for company employees: message employee { required group id { required group name { required binary surname (UTF8); required binary firstName (UTF8); optional binary preferredFirstName (UTF8); } required int32 employeeNumber; } optional group phones (LIST) { repeated group list { required group element { required binary type (ENUM); required binary phoneNumber (UTF8); } } } required binary email (UTF8); optional binary manager (UTF8); required binary jobTitle (UTF8); required group team { required binary country (UTF8); required binary businessUnit (UTF8); required binary function (UTF8); optional binary team (UTF8); optional binary department (UTF8); required binary legalEntity (UTF8); } optional int32 birthdate (DATE); }

---

# Document 811: Authorization Server User's Guide - MediationZone Documentation 9.3 - InfoZone

**Source:** ratanon/mz93-documentation
**URL:** https://infozone.atlassian.net/wiki/spaces/MD93/pages/205816932/Authorization+Server+User+s+Guide
**Categories:** chunks_index.json

Loading Prerequisites The reader of this information should be familiar with: Representational state transfer (REST) RFC 6749 - OAuth 2.0 Authorization Framework The Authorization Server is a service provider that generates OAuth2 based access token to be used for calling REST APIs hosted on the HTTP/2 Server agent that requires the OAuth2 authorization process. The Authorization Server utilizes platform to run and can be configured to store provisioned scopes and registered clients either in file-based storage or database storage. We currently only support Oracle and PostgreSQL database for the database storage. Preparing the Authorization Server requires a few steps, as described in Enabling Authorization Server Client Credentials Only The Authorization Server supports only the OAuth2 "client_credentials" grant type currently. Loading Loading

---

# Document 812: IBM MQ Examples - MediationZone Documentation 9.3 - InfoZone

**Source:** ratanon/mz93-documentation
**URL:** https://infozone.atlassian.net/wiki/spaces/MD93/pages/205653000/IBM+MQ+Examples
**Categories:** chunks_index.json

In an IBM MQ collection agent wor kflow th ere are four different UDRs created and sent. This requires one ore more agents containing APL code (Analysis or Aggregation) to be part of the workflow. Collect and Process IBM MQ Message If "dynamic initialization" has been configured, a configRequest, including an empty MQConnectionInfo UDR, is sent to an Analysis agent at startup. The Analysis agent populates the UDR with configuration info and returns it to the IBM MQ Collection agent. For each collected message, the IBM MQ collection agent sends an InputMessage including an MQMessage UDR to the Analysis agent. If "Auto Remove" has been configured, the message is removed from the queue and a remMessage is sent to the agent. Open Realtime workflow example - a message is collected from the IBM MQ collection agent Dynamic Initialization The following APL code example shows how to use dynamic initialization. consume { if (instanceOf(input, mq.MQConnectionInfo)) { mq.MQConnectionInfo info = (mq.MQConnectionInfo) input; info.Host = "mymqhost"; info.Port = 1415; info.ChannelName = "CHANNEL2"; info.QueueManager = "mgr2.queue.manager"; list<string> queues = listCreate(string); listAdd(queues,"Q1.QUEUE"); listAdd(queues,"Q2.QUEUE"); info.Queues = queues; udrRoute(info); } } Process the MQ Message The following APL code example shows how to process the IBM MQ message and remove it from the queue. consume { if (instanceOf(input, mq.MQMessage)) { mq.MQMessage msg = (mq.MQMessage) input; //Process the MQ Message handleResponse(msg); //Remove the message from the queue udrRoute(msg, "remMessage"); } } Send Messages to the IBM MQ Queue Manager In the following figure the workflow forwards a message to an IBM MQ queue manager. Open Workflow example - a message is sent to a queue manager The following APL code example shows how to send an IBM MQ message to a queue. mq.MQQueue queue; initialize { mq.MQQueueManagerInfo conUDR = udrCreate(mq.MQQueueManagerInfo); conUDR.ChannelName = "CHANNEL1"; conUDR.Host = "10.46.100.86"; conUDR.Port = 1414; conUDR.QueueManager = "mgr1.queue.manager"; queue = mqConnect(conUDR, "Q1.QUEUE"); } consume { mqStatus(queue); debug("Queue Depth: "+queue.CurrentDepth); debug("Queue Max Depth: "+queue.MaxDepth); mq.MQMessage msg = udrCreate(mq.MQMessage); msg.Message = input; mqPut(queue, msg); } deinitialize { mqClose(queue); }

---

# Document 813: Simplified Upgrade Procedure - MediationZone Documentation 9.3 - InfoZone

**Source:** ratanon/mz93-documentation
**URL:** https://infozone.atlassian.net/wiki/spaces/MD93/pages/205029762/Simplified+Upgrade+Procedure
**Categories:** chunks_index.json

This chapter describes the simplified upgrade procedure for MediationZone. The simplified upgrade procedure does not require any intermediary upgrade steps. You can upgrade directly from versions prior to 8.3. The simplified upgrade procedure can be used when downtime is not critical and you only wish to migrate configuration data. In all other cases, you should use the standard upgrade procedure. For information about the standard upgrade procedure, see Standard Upgrade Procedure . Note! This upgrade procedure is supported from MediationZone 8.0 and onwards. If your system has an older version, you need to upgrade to the supported version before you can use this Upgrade procedure. The upgrade procedure consists of the following steps: Getting Started Preparations for Simplified Upgrade Shut Down Platform and Execution System Installation Desktop Reinstallation Restore Configurations

---

# Document 814: Button UDR - MediationZone Documentation 9.3 - InfoZone

**Source:** ratanon/mz93-documentation
**URL:** https://infozone.atlassian.net/wiki/spaces/MD93/pages/204643566/Button+UDR
**Categories:** chunks_index.json

The Button UDR is used to create a button. There are different design variants to choose from: Open The following fields are included in the Button UDR : Field Description Field Description attributes (map<string,string>) This field may contain extra attributes to be added. buttonType (string) This field may contain the type of the button. Possible values are: BUTTON (button) SUBMIT (submit) RESET (reset) The default is BUTTON . buttonVariant (string) This field may contain the variant of the button. The text needs to follow Bootstrap . Some constants are added to help: PRIMARY , SECONDARY , SUCCESS , WARNING , DANGER The default is PRIMARY . components (list<ComponentUDR>) This field may contain a list of child components. cssClasses (list<string>) This field may contain a list of extra values added to class attribute. This is typically used to style the component. Please read more on Bootstrap . dialog (Dialog UDR) This field may contain a Dialog UDR if the button should open a dialog. If the Dialog UDR have the field addAutomatic it will also be added to the page. disabled (boolean) This field may contain a boolean if the component should be disabled or enabled. id (string) This field may contain the id of the component name (string) This field may contain the name of the component text (string) This field may contain the text on the button. It will be added as a child component.

---

# Document 815: Analysis Agent - MediationZone Documentation 9.3 - InfoZone

**Source:** ratanon/mz93-documentation
**URL:** https://infozone.atlassian.net/wiki/spaces/MD93/pages/204672084/Analysis+Agent
**Categories:** chunks_index.json

This section describes the Analysis agent. This is a processing agent for batch and real-time workflow configurations. The Analysis agent is used to process UDRs and, for example, to generate audit data and dispatch events in the system. These activities are established by editing the rich programming language - Analysis Programming Language (APL). The Analysis agent, depending on the configured APL code, can either be a pure processing agent with the ability to examine, alter, route and clone each UDR routed to the agent or it can be the final destination for a UDR in the workflow; a sort of forwarding agent. See the APL Reference Guide for descriptions of the Analysis Programming Language, APL, and the available functions. The Analysis agent can be part of both batch and real-time workflows. Differences in the configuration are described in the section Realtime Workflows in Analysis Agent Configuration . Prerequisites The reader of this information should be familiar with: UDR structure and content Basic programming For information about Terms and Abbreviations used in this section, see the Terminology document. Loading

---

# Document 816: Execution Tab - MediationZone Documentation 9.3 - InfoZone

**Source:** ratanon/mz93-documentation
**URL:** https://infozone.atlassian.net/wiki/spaces/MD93/pages/204736697/Execution+Tab
**Categories:** chunks_index.json

A workflow is loaded and started on an EC group according to configured distribution criteria, for example, based on machine load or by specifying the EC groups where the workflow should run. You can create EC groups using the EC Groups tool in the Manage view. Create EC using pico management or via topo commands. Refer to Pico Management or Managing Picos with Topo for more information. Add ECs into the EC group using the topo command: mzsh topo set topo://container:<container name>/pico:<ec name>/val:config.properties.pico.groups "<EC Group Name>" Note! To run a workflow on a specific EC, an EC group needs to be created. Multiple ECs can be included in an EC group to serve a workflow. There are multiple ways of adding EC groups to the system. Refer to EC Groups for additional information. If only one EC is to be included in the EC Group, you may do the following or do as for multiple ECs: Create the EC group with the same name as the EC from the UI Restart EC If multiple ECs are to be included in one EC Group, you must: Add the property pico.groups to all ECs that should be included by using this command: mzsh topo set topo://container:main1/pico:ec1/val:config.properties.pico.groups "myEcGroup" Restart the ECs. Execution Tab in Batch Workflow The Execution tab has settings that are related to where the workflow will be executed and how often it will execute. Open The Batch Workflow Execution tab Item Description Item Description Execution Settings Select Enable to enable setup of the execution parameters. Distribution A workflow executes on an EC group. You can specify these EC groups, or the system can select them automatically. Note! EC groups will only be used if you have selected them, the reason for this is to avoid the execution of undesired workflows. The following options exist: Sequential - Starts the workflow on the first EC group in the list, if you choose the sequential option and only configure one EC group then the workflow will not run if the EC group is not available. If this EC group is not available, it proceeds with the next in line. Workflow Count - Starts the workflow on the EC group running with the fewest number of workflows. Machine Load - Starts the workflow on the EC group with the lowest machine load. Round Robin - Starts the workflow on the available EC groups in turn, but not necessarily in a sequential order. If ecg1, ecg2 and ecg3 are defined, the workflow may first attempt to start on ecg2. The next time it may start on ecg3 and then finally on ecg1. This order is then repeated. If an EC group is not available, the workflow will be started on any of the other listed EC groups. Kafka Profile Required to enable the Kafka-based batch transaction handler for https://infozone.atlassian.net/wiki/x/GADzEQ . This setting must be selected to use Kafka agents in batch workflows. When selected, MediationZone uses the Kafka cluster identified by this profile for all Kafka agents in the workflow. It also uses a Kafka-based transaction handler to ensure batch transactions across all Kafka agents in the workflow. Debug Type Select Event to enable debug output, such as output from a debug call in the APL code, to appear in the Workflow Monitor . Select File to save debug results in $MZ_HOME/tmp/debug . The file name is made up of the names of the workflow template and of the workflow itself, for example: MZ_HOME/tmp/debug/Default.radius_wf.workflow_2 . Only debug events are written to the file. To save to file all the events that are shown when you select to monitor events in the Workflow Monitor, you must add an event notifier to the relevant Agent Message Event with file output. For further information, see Event Notifications . If you save debug results in a file, and you restart the workflow, this file gets overwritten by the debug information that is generated by the second execution. To avoid losing debug data of earlier executions, set Number of Files to Keep to a number that is higher than 0 (zero). Number of Files to Keep : Enter the number of debug output files that you want to save. When this limit is reached, the oldest file is overwritten. If you set this limit to 0 (zero), the log file is overwritten every time the workflow starts. Example - Debug output The workflow configuration Default.radius_wf includes a workflow that is called workflow_2. Number of Files to Keep is set to 10. The debug output folder contains the following files: Default.radius_wf.workflow_2 (current debug file) Default.radius_wf.workflow_2.1 (newest rotated file) Default.radius_wf.workflow_2.2 Default.radius_wf.workflow_2.3 Default.radius_wf.workflow_2.4 Default.radius_wf.workflow_2.5 Default.radius_wf.workflow_2.6 Default.radius_wf.workflow_2.7 Default.radius_wf.workflow_2.8 Default.radius_wf.workflow_2.9 Default.radius_wf.workflow_2.10 (oldest rotated file) According to this example there are totally 11 files that are being overwritten one-by-one and the rotation order is: Default.radius_wf.workflow_2 | V Default.radius_wf.workflow_2.1 | V Default.radius_wf.workflow_2.2 | V : : | V Default.radius_wf.workflow_2.n | V Deleted Example - Using the option Always Create a New Log File If you have a workflow named Default.radius_wf with an instance called workflow_2 and you create new debug output files every time the workflow executes, the debug output folder contains files like the following: Default.radius_wf.workflow_2.1279102896375 Default.radius_wf.workflow_2.1279102902908 Default.radius_wf.workflow_2.1279102907149 Caution! The system will not manage the debug output files when this option is used. It is up to the user to make sure that the disk does not fill up. Throughput Calculation MediationZone contains an algorithm to calculate the throughput of a running workflow. It locates the first agent in the workflow configuration that delivers UDRs, usually the decoder and counts the number of passed UDRs per second. If no UDRs are passing through the workflow, the first agent delivering raw data will be used. The statistics can be viewed in the System Statistics . If a MIM value other than the default is preferred for calculating the throughput, the User Defined check box is selected. From the browser button, a MIM Browser dialog is opened and available MIM values for the workflow configuration is shown and a new calculation point can be selected. Since the MIM value shall represent the amount of data entered into the workflow since the start (for batch workflows from the start of the current transaction), the MIM value must be of a dynamic numeric type, as it will change as the workflow is running. Execution Tab in Real-Time Workflow Open The Realtime Execution tab Item Description Item Description Execution Settings Select Enable to enable setup of the execution parameters. Distribution A workflow executes on an EC group. You can specify these EC groups, or the system can select them automatically. Note! If you select to configure the distribution using EC groups, the selected distribution type will also be applied on the ECs within the groups. The following options exist: Sequential - Starts the workflow on the first EC group in the list. If this EC group is not available, it proceeds with the next in line. Workflow Count - Starts the workflow on the EC group running the fewest number of workflows. If the Execution Contexts list contains at least one entry, only this/these EC groups will be considered. Machine Load - Starts the workflow on the EC group with the lowest machine load. If the Execution Contexts list contains at least one entry, only this/these EC groups will be considered. Which EC group to select is based on information from the System Statistics sub-system. Round Robin - Starts the workflow on the available EC groups in turn, but not necessarily in a sequential order. If ecg1, ecg2 and ecg3 are defined, the workflow may first attempt to start on ecg2. The next time it may start on ecg3 and then finally on ecg1. This order is then repeated. If an EC group is not available, the workflow will be started on any other available EC groups. Execution Context Type Select an execution context type that the workflow should execute on. The following options exist: Normal - This setting enables execution of the workflow on one or more ECs. If several ECs/EC groups are added to the Execution Contexts list, the selected Distribution is considered. If no EC/EC group is selected the system will consider all available ECs as possible targets. Standalone - This setting enables execution of a stand-alone workflow that is independent of the Platform. To add an EC group, click Add and select an EC Group in the drop-down list. Queue Size The number of unprocessed entries (backlog) that the workflow can store in a buffer before the collector is slowed down. The workflow and its back-end systems might slow its processing activity when the number of requests rises. To avoid congestion, while the records or decoding tasks are in the queue, the queue intake is delayed to limit the backlog from growing too fast. Default value is 1000. The value that you enter here is the size of each route's queue in the workflow. Queue Strategy Blocking queue This is the default method. Ordered Routing To be able to preserve the order of incoming UDRs, this option should be used in combination with Ordered Services in the Service tab. Open To maintain the order of the UDRs as the agent sees it from the source, you can use the function ordered routing. This ensures that you retain the routing order, even if the work is divided over several threads. When using this function you must define how to catch the order of the UDRs. This can be done with APL in the Services tab in Workflow Properties. Via the 'input' value, typically by instanceOf checks for each routed type, Use ordered.addInteger(si, i) etc with values from session defining fields. Hashing will select partition. Alternatively use ordered.setPartition(si, N) to explicitly chose a partition. void route(order.SessionIdentifier si, any input) {....} Queue Worker Strategy By selecting Queue Worker Strategy , you can determine how the workflow should handle queue selection, which may be useful if you have several different collectors. You have the following options: RoundRobin The RoundRobin strategy works in the same way as the InsertionOrder strategy, except that each workflow thread will be given its own starting position in the routing queue list. This means that as long as the number of workflow threads is equal to, or greater than, the number of routing queues, no queue will suffer from starvation. Faster routes will get more load than slower ones. This option provides pretty fair distribution. Use this strategy if the number of workflow threads is equal to, or greater than, the number of routing queues, and it is desirable to prioritize faster routes before slower ones. RoundRobin is the default strategy. DedicatedAndRoundRobin In the DedicatedAndRoundRobin strategy, each queue has one thread dedicated to it by default. The number of workflow threads (given in the Threads column) minus one, serve the queues in round robin fashion. The number of threads indicates the maximum number of threads that can collect from a queue at any one time. One workflow thread guarantees the order of the UDRs in the workflow. InsertionOrder With the InsertionOrder strategy, queues are selected in route insertion order. As long as there are queued UDRs available on the first queue, that queue will be polled. This means that routes with later insertion order may not receive as many UDRs as they have capacity for, and get no or little throughput. This type of condition may be detected by looking at the Queue Throughput for workflows in the System Statistics view. Only use this strategy, if this is not an issue. This is the preferred choice when you work synchronously with responses and process small amounts of UDRs at any given time (which is not the same as low throughput). Note! The insertion order depends primarily on how close the queues are to an "exit", i e an agent without any configured output. The queues that are closest to an exit will be inserted first. The queues that are furthest from an exit, will be inserted last. However, if the distance to an exit is equal for two or more queues, the insertion order is dictated by the sequence of the agents in the workflow configuration, i e the agent that was added first to the configuration has higher priority. Threads The number of workflow threads. The default value is 8. Throughput Calculation MediationZone contains an algorithm to calculate the throughput of a running workflow. It locates the first agent in the workflow configuration that delivers UDRs, usually the decoder and counts the number of passed UDRs per second. If no UDRs are passing through the workflow, the first agent delivering raw data will be used. The statistics can be viewed in the System Statistics . If a MIM value other than the default is preferred for calculating the throughput the User Defined check box is selected. From the browser button a MIM Browser dialog is opened and available MIM values for the workflow configuration is shown and a new calculation point can be selected. Since the MIM value shall represent the amount of data entered into the workflow since the start (for batch workflows from the start of the current transaction) the MIM value must be of a dynamic numeric type, as it will change as the workflow is running. Processed UDRs Count Interval (min) Select this option to specify the interval period in minutes for counting the number of processed UDRs. The default value is 1. The maximum value permitted is 1440 min (one day).

---

# Document 817: Batch-Based Real-Time Agents - UDR Types - MediationZone Documentation 9.3 - InfoZone

**Source:** ratanon/mz93-documentation
**URL:** https://infozone.atlassian.net/wiki/spaces/MD93/pages/204741505/Batch-Based+Real-Time+Agents+-+UDR+Types
**Categories:** chunks_index.json

This section describes the UDR types that are used with the agents. The UDR types used by the agents can be viewed in the UDR Internal Format Browser . To open the browser open an APL Editor, in the editing area. Right-click and select UDR Assistance... and the browser opens. BeginBatch The BeginBatch UDR type is used to indicate that collection of a file has begun. This UDR type does not contain any data from the collected file. Field Description Field Description batchCount (long) This field contains the sequential numbering of the file being collected. fileName (string) This field contains the name of the file being collected. CancelBatch The CancelBatch UDR type is used to indicate that collection of a file has been cancelled. This UDR type does not contain any data from the collected file. Field Description Field Description batchCount (long) This field contains the sequential numbering of the file being collected. fileName (string) This field contains the name of the file being collected. EndBatch The EndBatch UDR type is used to indicate that the collection agent has routed the last file record to the workflow. This UDR type does not contain any data from the collected file. Field Description Field Description batchCount (long) This field contains the sequential numbering of the file being collected. fileName (string) This field contains the name of the file being collected. UDR types consumed by the Collecting or Forwarding Agents ForceEndBatch The Force EndBatch UDR type is used to force an end to the batch. The UDR has no specific fields.

---

# Document 818: UDR File Editor - MediationZone Documentation 9.3 - InfoZone

**Source:** ratanon/mz93-documentation
**URL:** https://infozone.atlassian.net/wiki/spaces/MD93/pages/204646721
**Categories:** chunks_index.json

The UDR File Editor allows you to view and edit the content of UDR files. The UDR file may be of any format as long as it has an associated decoder. Since UDRs often contain a large number of fields, it is possible to create a UDR View to select specific fields to be displayed as columns in the UDR File Editor. See UDR Views for more information. Each UDR can also be opened in a separate dialog where all fields are available. Note! By default the UDR File Editor only supports input files up to size 3MB. If the file size exceeds this limit, the UDR File Editor only reads up to 3MB of the file and then stop, displaying only the read records. If you want to support decoding of files larger than 3 MB, you need to set the Desktop property mz.gui.udreditor.limit for the corresponding Desktop. See Desktop Properties . Setting the property to yes means the 3 MB limit applies. Setting the property to no bypasses the limitation mechanism, which may potentially cause out-of-memory errors in the Desktop. Several UDR File Editors can be used simultaneously, however, avoid editing the same UDR from several different editors, since there is no functionality to handle real-time co-authoring. To open the UDR File Editor , open the Manage screen and click the UDR File Editor button. Open UDR File Editor Setting Description Setting Description UDR View If you want to apply a configured UDR view, you can click the Browse... button to select and apply a defined UDR view. See UDR Views for more information. Orig Pos Shows the original position of the UDR. New indicates that the UDR did not exist prior to the last Save. Pos The current position of the UDR. The order applies upon saving. Type The UDR types Field Name All columns following the Type column list the field names of the UDR type according to the UDR view selection. If there is no field with the defined name, No such field is stated. UDR File Editor Buttons The Ultra File Editor contains the following buttons: Item Description Item Description Open Click this button to clear the UDR File Editor . Open Opens the Open UDR File dialog. Click Browse... to select the decoder you want to use for the data file, and then click Upload File... to browse the file system and select the file you want to view. Click OK to close the dialog and display the file in the UDR File Editor . Open Open Click to save your modified UDR file. Open Save the UDR File dialog Select the encoder you want to use by clicking the Browse button to the right of the Encoder field and selecting the decoder in the Select encoder dialog. Select the GZIP Compressed checkbox if you want to compress the file. Enter the name of the file in the File Name field and click Download to download your file. Open Click this button to open the Table Export dialog where you can export the data to be able to open it in any text editor. Open All UDRs are displayed as rows, where the fields are separated by any of the following: Comma Semicolon Tab Non-existing fields are marked [null] . The first line always holds the field names. Open Click this button to print either a selection of UDRs or all UDRs. Open Click to open a new dialog in which the selected UDRs can be edited simultaneously. For further information, see Editing a Bulk of UDRs . Open Click to open the UDR Views . Open Click this button to open the user documentation This chapter includes the following sections: Editing a UDR Editing a Bulk of UDRs

---

# Document 819: Diameter Application Profile - MediationZone Documentation 9.3 - InfoZone

**Source:** ratanon/mz93-documentation
**URL:** https://infozone.atlassian.net/wiki/spaces/MD93/pages/205685017/Diameter+Application+Profile
**Categories:** chunks_index.json

The D iamete r Application profile captures a set of AVP and command code definitions that are recognized by the Diameter Stack agent during runtime. The profile is loaded when you start a workflow that depends on it. Changes to the profile become effective when you restart the workflow. To open the configuration, click the New Configuration button and then select Diameter Application Profile from the menu. Open The Diameter Application profile Import Options Click on the Import button to open the Import Specifications dialog box. Open Import Specifications Dialog box To Import ABNF Specifications From the profile screen select Import and select Import ABNF Specifications . Select an ABNF file and click Upload to import the ABNF file to your application profile configuration. To Import XML Specifications From the profile screen select Import and select Import XML Specifications. Select an XML file and click Upload . The XML file is imported to your application profile configuration. Export Options Open Export Specifications Dialog box To Export ABNF Specifications From the profile select Export and the Export ABNF Specifications. Select an ABNF file and click Upload . The ABNF file (both AVPs and commands) is saved as an export file. To Export XML Specifications From the profile select Export and Export XML Specifications . Select an XML file and click Upload . The XML file (both AVPs and commands) is saved as an export file. Commands Tab The commands that you use in the Diameter Application profile are predefined command sets of specific solutions. The Commands tab in the Diameter Application profile enables you to create and edit command sets that are customized according to your needs. Open The Diameter Application profile dialog - Commands Tab Setting Description Setting Description Name The command name. For example Credit-Control-Request. Code The unique numeric command code. For example, 272. For further information, see Show Base Commands . Application ID The numeric representation of the Diameter Application that this command belongs to. For example, 4 - Diameter Credit-Control. Show Base Commands Select this check box to view predefined commands, their numeric code, and the Application ID. These are the commands specified in Diameter Base Protocol (RFC 6733). To Add a Diameter Command Specification The Add Diameter Command Specification a dialog box is displayed when clicking the Add button in the Commands tab. Open The Diameter Commands tab - Add Diameter Command Specification Setting Description Setting Description Command Name Enter a unique command name. When you save the configuration, a UDR type with the specified name will be generated. Command Code Enter a numeric command code. Each command that belongs to the same Diameter Application must have a unique code. Application ID The numeric representation of the Diameter Application that the command belongs to. Flags Select the Request check box to mark the command as a request message (r-bit is set in the Diameter message header); clear the Request check box to mark the command as an answer message. Select Proxiable to enable the command to support proxy, relay, or redirection (p-bit is set in the Diameter message header). For more information about the Proxiable flag, see the Diameter Base Protocol (RFC 6733). This flag is set by default when a new command is added. Select Error to mark that the message contains a protocol error (e-bit is set in the Diameter message header) so that the message will not conform to the ABNF described for this command. This flag is typically used for test purposes. If you want to send an error message answer from APL, it is recommended that you use the UDR Diameter.Base.Error_Answer_Message . Auto-Populate Click on this button to automatically fill out the AVP Layout table with data, based on your Flags selection. The Category of the AVP data is set to Required . Note! To manually modify the data in the table cells double-click a cell. Setting Flags to Request and Proxiable , auto-populates the AVP Layout table with the following AVPs: Origin-Realm Origin-Host Destination-Realm Setting Flags to Proxiable only, auto-populates the AVP Layout table with the following AVPs: Origin-Realm Origin-Host Result-Code Setting Flags to Error , prevents the AVP Layout table from being auto-populated. AVP Layout Table This table includes a list of all the AVPs in a specific command. From the table, you can add, edit, and remove AVPs. To manually modify the data in the table cells double-click a cell; either a drop-down list button appears and enables you to select a different content, or the cell becomes editable. Item Description Item Description Category There are three different AVP categories: A Fixed AVP must be included in its predefined space in the command. A Required AVP must be included but may appear anywhere in the message. An Optional AVP can appear anywhere in the message. AVP Enter or modify an AVP name. Min Enter the lowest number of AVPs that the command should contain. Max Enter the highest number of AVPs that the command should contain. UDR types are generated for the Diameter Application profile based on the command configuration. When Max is set to 2 or <unbounded> the data type of the UDR field for the AVP will be list<data type> . AVPs Tab AVPs carry the data payload in all Diameter messages. While the system recognizes all the AVPs that are defined in the Diameter Base Protocol, it also recognizes your customized AVPs. In the AVPs tab you can define your customized AVPs. Open The Diameter Application profile dialog - Diameter AVPs tab Setting Description Setting Description Auto-Populate Click this button to enter missing table entries in all the user-defined AVPs of a command in the table. Note! Does not apply to base AVPs. Clear Clear this button to clear the list of entries. Name The AVP name Code The numeric code that represents the AVP. This number is unique and fixed for every AVP. For further information, see the AVP specifications. For example RFCs. Type The AVP data format is specified in the Diameter Base Protocol (RFC 6733). UDR types are generated for the Diameter application profile based on the AVP configuration. The AVP data formats are mapped to the UDR data types as follows: Address - IP address DiameterIdentity - string Enumerated - int Grouped - list<type> Float32 - float Float64 - double IPFilterRule - IPFilterRuleUDR(Diameter) OctetString - bytearray Signed32 - int Signed64 - long Time - date Unsigned32 - int Unsigned64 - long UTF8String - string Vendor The numeric Vendor ID of the AVP. The vendor ID of all the IETF standard Diameter applications is 0 (zero). Show Base AVPs To display all predefined AVP types, check Show Base AVPs. These are the AVPs specified in Diameter Base Protocol (RFC 6733). To Add an AVP To open the Add Diameter AVP Specification configuration, click the Add button at the bottom of the AVP tab. Open The Add Diameter AVP Specification dialog Setting Description Setting Description AVP Name The name of the AVP. AVP Code The numeric id of the AVP. Vendor ID The number that represents the vendor. The default value is 0 (zero). AVP Type The data type of the AVP. Selecting Enumeration or Grouped reveals configuration options in the Enumeration/Group Properties table. Mandatory ('M') Bit The M-bit allows the sender to indicate to the receiver whether or not understanding the semantics of an AVP and its content is mandatory. If the M-bit is set by the sender and the receiver does not understand the AVP or the values carried within that AVP, then a failure is generated. For further information about the M-bit, see the Diameter Base Protocol (RFC 6733). The following applies to incoming and outgoing messages that contain the configured AVP: MUST : The M-bit is set to 1 in outgoing messages and must be set to 1 in incoming messages. MAY : The M-bit is set to 0 or 1 (configurable in the Advanced tab) in outgoing messages and may be set to 0 or 1 in incoming messages. SHOULD : The M-bit is set to 0 in outgoing messages and may be set to 0 or 1 in incoming messages. MUST NOT : The M-bit is set to 0 in outgoing messages and must be set to 0 in incoming messages. You can change the value of the M-bit from APL if Mandatory ('M') Bit is set to MAY or SHOULD . Protection ('P') Bit The P-bit bit is reserved for future usage of end-to-end security. Enumeration/Group Properties This table is accessible for editing only when AVP Type is configured as Enumerated or as Grouped. This table enables you to Add , Edit , or Remove AVPs or enumeration values. For further information about the tables columns and entries, see the section above, To Add a Diameter Command Specification. To Edit an AVP To open the Edit Diameter AVP Specification configuration, click the Edit button at the bottom of the AVP's tab. The Edit Diameter AVP dialog is identical to the Add Diameter AVP Specification dialog. The same description applies to editing an AVP specification. CER/CEA Tab The identifiers in this tab define the advertised applications for the capabilities handshake. They are used whenever the Diameter Stack agent initiates or responds to a new transport connection, to negotiate the compatible applications for the link. For further information about Authentication and Accounting Applications, see Diameter Base Protocol (RFC 6733). Open The Diameter Application Profile Editor - CER/CEA Tab Auto-Populate Click this button to add Application IDs, that are used in any of the commands, to the Application ID table. In the Vendor Specific Applications table, available Vendor IDs are extracted from the AVP's tab into the Vendor ID column. Note! Auto-Populate cannot populate Vendor ID and Application ID into a Vendor-Specific Applications table if a vendor-specific application command is configured in the command tab. This means that the command includes a Vendor-Specific-Application-Id AVP. Application IDs Table Item Description Item Description Application ID Numeric codes of the supported applications. Authentication Select and check to flag an application with Authentication. Accounting Select and check to flag an application with Accounting. Vendor-Specific Applications Table Item Description Item Description Vendor ID Enter the numeric code of the vendor Auth App ID Enter the vendor-specific authentication application ID. Acct App ID Enter the vendor-specific accounting application ID. Advanced Tab The Advanced tab contains additional settings. Open The Diameter Application profile - Advanced tab Setting Description Setting Description Default Outgoing 'M' Bit Set to 1 When Flag Rule MAY Is Selected When this check box is selected and Mandatory ('M') Bit is set to MAY in the AVPs tab, the M-bit will be set to 1 in outgoing messages.

---

# Document 820: External Version Control System - MediationZone Documentation 9.3 - InfoZone

**Source:** ratanon/mz93-documentation
**URL:** https://infozone.atlassian.net/wiki/spaces/MD93/pages/205849406/External+Version+Control+System
**Categories:** chunks_index.json

It is possible to use an external Version Control System for storing Configuration artifacts. MediationZone provides a way to export and import configurations from MediationZone into a working copy of the Version Control System. Configurations are stored in an XML format. Changes to the configurations can be diffed/merged using the tools provided by the Version Control System.

---

# Document 821: SNMP Collection UDRs - MediationZone Documentation 9.3 - InfoZone

**Source:** ratanon/mz93-documentation
**URL:** https://infozone.atlassian.net/wiki/spaces/MD93/pages/204643174/SNMP+Collection+UDRs
**Categories:** chunks_index.json

Open The SNMP Collection UDR types are designed to exchange data between the workflows, and can be viewed in the UDR Internal Format Browser . When an SNMP profile is saved, a UDR type is created to reflect the hierarchical structure of the loaded MIBs. These structures are populated by the SNMP Request agent from the SNMP responses it receives from requested network elements. Only fields that are selected in the agent configuration are populated. The generated hierarchical structure can be viewed in the UDR browser in a folder called snmp. This section contains the following sub-sections: SampleUDR and FlatSampleUDR SnmpRequestUDR SnmpTrapUDR

---

# Document 822: Using Passwords in External Reference - MediationZone Documentation 9.3 - InfoZone

**Source:** ratanon/mz93-documentation
**URL:** https://infozone.atlassian.net/wiki/spaces/MD93/pages/204998621/Using+Passwords+in+External+Reference
**Categories:** chunks_index.json

In the Database profile and for several different agents, you can use passwords from External Reference profiles. The password values must be represented by a string that has been encrypted with the mzsh encryptpassword command. When using the mzsh encryptpassword command you can use keys that have been generated using the Java standard tool keytool . The keys to be used are determined using aliases, and if no alias is used, the default key is used for the encryption. See the JDK product documentation for further information about using keytool in different scenarios. Note! You have to use the storetype JCEKS. If aliases are to be used, the full path and password to the keystore has to be indicated by including the Platform properties mz.cryptoservice.keystore.path and mz.cryptoservice.keystore.password in the Platform instance. See System Properties in the System Administration Guide for further information about these properties. The keystore must also contain keys for all the aliases you want to use. Note! The same keytool can be used for generating keys for RCP encryption. However, these keys are of a different type and cannot be used for External References. Example - Encrypting passwords with crypto service keystore keys This is an example of how passwords can be encrypted with crypto service keystore keys: Create a security key with the keytool: keytool -genseckey -alias myAlias -keyalg AES -keystore myKeystore.jks -keysize 128 -storepass myKeystorePassword -storetype JCEKS. Note! If you enter a -keysize that is larger than 128, you may get a message saying that JCE Unlimited Strength Jurisdiction Policy Files needs to be installed. See the Oracle product documentation for further information about this. The -storepass flag is optional. If you do not enter a -storepass you will be prompted for a password. -storetype JCEKS is mandatory. You will be prompted if you want to use the same password for the key as for the keystore and the system requires that the same password is used. Place the keystore in a suitable directory. Encrypt the password to the keystore using the mzsh encryptpassword command with the default key: mzsh mzadmin/<password> encryptpassword myKeystorePassword The encrypted password is returned. Set the Platform properties mz.cryptoservice.keystore.path and mz.cryptoservice.keystore.password : $ mzsh topo set topo://container:<platform container>/pico:platform/obj:config.properties '{ mz.cryptoservice.keystore.path="<suitable directory>/myKeystore.jks" mz.cryptoservice.keystore.password="<the encrypted password>" }' _ Encrypt the passwords with aliases that you want to use in your external references: mzsh mzadmin/<password> encryptpassword -a myAlias <passwordToEncrypt> Use the returned password string as a value in your External Reference source, i e file or environment variable.

---

# Document 823: System Overview - MediationZone Documentation 9.3 - InfoZone

**Source:** ratanon/mz93-documentation
**URL:** https://infozone.atlassian.net/wiki/spaces/MD93/pages/205815916/System+Overview
**Categories:** chunks_index.json

The MediationZone system architecture is designed to be completely distributed and scalable, capable of executing on various operating systems and hardware platforms. Logically, the MediationZone platform (the Platform) is layered into three different zones: Access Zone is the layer where users access the system through a graphical interface or command line interface to perform operations and maintenance taks. Control Zone hosts configurations and provides storage and a range of services that are essential to the system. Execution Zone is a scale-out layer that provides processing capacity in the system. This layer contains one or several Execution Contexts and Service Contexts, which are distributed over any number of servers. Execution Contexts are responsible for executing and supervising workflows. Service Contexts host services that workflows running in Execution Contexts can share. The system processes in the various zones are referred to as pico instances and can be of different types: Platform Execution Context (EC) Service Context (SC) Command Line Tool (mzsh) Desktop The Platform, ECs, and SCs run in "containers", that are installed on one or more hosts. Each installation is assigned a container name to identify it uniquely within a MediationZone system. One host, physical or virtual, may hold several containers, each one with a unique name and installed in separate home (MZHOME) directories. There are three types of containers: The Platform Container runs the Platform and optionally EC and SCs. The Platform is always included in a Platform Container installation. Execution Containers run ECs, and SCs. These pico instances are typically configured after the installation of the container. The UI Container runs the Desktop interface. You control the location of the ECs, and SCs via the System Topology Registry (STR), which is also used to set various system properties. For further information about STR, see System Topology Registry . The figure below illustrates the system architecture. Open MediationZone architecture This chapter includes the following sections: Access Zone Execution Zone Control Zone System Topology Registry Software Environment IPv6

---

# Document 824: HDFS Forwarding Agent Events - MediationZone Documentation 9.3 - InfoZone

**Source:** ratanon/mz93-documentation
**URL:** https://infozone.atlassian.net/wiki/spaces/MD93/pages/204739153/HDFS+Forwarding+Agent+Events
**Categories:** chunks_index.json

Agent Message Events An information message from the agent, stated according to the configuration done in the Event Notification Editor . For further information about the agent message event type, see Agent Event . Ready with file: name Reported along with the name of the target file when it has been successfully stored in the target directory. If an After Treatment Command is specified, the message also indicates that it has been executed. Debug Events There are no debug events for this agent.

---

# Document 825: Virtual Machine Tab - MediationZone Documentation 9.3 - InfoZone

**Source:** ratanon/mz93-documentation
**URL:** https://infozone.atlassian.net/wiki/spaces/MD93/pages/204676156/Virtual+Machine+Tab
**Categories:** chunks_index.json



---
**End of Part 36** - Continue to next part for more content.
