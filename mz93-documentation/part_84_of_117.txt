# RATANON/MZ93-DOCUMENTATION - Part 84/112

---
**Dataset:** ratanon/mz93-documentation
**Part:** 84 of 112
**GitHub:** https://github.com/ratan0n/docs/tree/main/mz93-documentation
**Size:** ~55.2 KB
---

The System Topology Registry (STR) provides a central interface for managing the Mediationzone topology, through manual configuration or scripting. Below are examples of tasks that can be performed in the STR: Creating and removing process configurations (pico instances). Updating container- and process attributes, e g system properties, JVM arguments, classpaths etc. Viewing configuration, status, and resource consumption of processes STR also brings the possibility to start and stop pico instances in any container via SSH, without the need for manually logging into each server host. The well-defined interface for managing the system topology and controlling processes, in combination with scripted installations of containers, facilitate deployment of MediationZone in highly automated environments. Managing Processes MediationZone processes can be managed from a central point via text editors, a UI, or from the command line. The data format used is HOCON (Human-Optimized Config Notation), a relaxed variant of JSON. Compared to JSON, this format is more oriented for human/manual editing and supports comments. The figure below illustrates configuration of an Execution Context in the System Administration GUI. Open Creating Execution Context (EC) in Pico Management UI. The same task can be performed from the command line or in a shell script as in the example below. $ mzsh topo set container:exec1/pico:ec2 ' { template:mz.standard-ec config { properties { httpd.port : 9092 } } }' Viewing Runtime Information The Pico Management UI can be used to view a list of the complete system topology and information about specific processes. Open Pico Management GUI - Runtime The runtime information can also be retrieved in strict JSON or HOCON format from the command line as in the example below. $ mzsh topo get --format data-only container:main1/pico:platform { "_execution" : { "service-members" : [], "workflows" : [] }, "_loc" : "topo://container:main1/pico:platform", "_name" : "platform", "_ref" : "topo://container:main1/pico:platform", "_ref-parts" : { "cell" : "default", "container" : "main1", "group" : "default", "pico" : "platform" }, "_status" : { "config" : { "hash" : "21449f8e619f18030012f448419bab46", "state" : "in-sync" }, "jvm" : { "stats" : { "cpu" : { "percent" : 0.7685199975967407, "time" : 60870025000 }, "gc" : { "count" : 25, "time" : 1535 }, "memory" : { "committed" : 634912768, "max" : 954728448, "used" : 135749504 }, "system" : { "open-files" : 414 } } }, ...} STR Replication Changes to the STR are instantly replicated by the Platform process, ensuring that all containers have consistent and valid information.

---

# Document 1971: Manage View - MediationZone Documentation 9.3 - InfoZone

**Source:** ratanon/mz93-documentation
**URL:** https://infozone.atlassian.net/wiki/spaces/MD93/pages/205030108
**Categories:** chunks_index.json

The Manage view contains options for Data Management , Tools, and Monitoring , and you open the view by clicking on the Manage button in the top button bar. When you click on an option, a new screen will open. You can use the Search field to search for a specific option. Open Manage view The following options are available. Data Management Data Management Option Description Aggregation Session Inspector In Aggregation Session Inspector you can view and edit existing aggregation sessions, see Aggregation Session Inspector . Archive Inspector You can use the Archive Inspector to locate files in an archive, see Archive Inspector . Data Hub With Data Hub you can store and query large amounts of data processed by the system, see Data Hub User's Guide Data Veracity You can use Data Veracity when UDRs fail validation and need to be manually handled before they can be successfully processed. With Data Veracity you can examine UDRs, mark them for deletion, force delete them, or update them, see Data Veracity . Duplicate Batch Inspector With the Duplicate Batch Inspector, you can view the metadata cache used for duplicate checking, see Duplicate Batch Agent . Duplicate UDR Inspector With the Duplicate UDR Inspector, you can view UDRs that have been identified as duplicates, see Duplicate UDR Inspector . PCC Buckets With PCC Buckets you can create and manage buckets based on subscriber information. With the PCC Buckets package, buckets can be created and used for usage counting, see PCC Buckets . PCC Extensions With PCC Extensions you can create your own data sets, in addition to the built-in data models for PCC, see PCC Extensions . PCC Policy Control You can use PCC Policy Control to manage PCC rules using the defined rules data model, see PCC Rules . PCC Routing Control With PCC Routing Control you can route and transform real-time data such as Diameter messages, see PCC Routing Control . PCC Usage Management With PCC Usage Management you can provision products in accordance with the defined PCC product sets, see PCC Buckets . Reference Data Management With Reference Data Management you can query and edit specific table sets in relational databases while schema permissions remain unaltered, see Reference Data Management User's Guide . Tools & Monitoring Option Description Access Controller In Access Controller you can define permissions rights for the users of the system, see Access Controller . Alarms and Events Alarms and Events is a monitoring tool that you can use to keep track of the various Alarms and Event Notifications configured in your workflows, see Alarm Detection and Event Notifications . Conditional Trace With Conditional Trace you can troubleshoot active instances, and set up trace filters on agents and UDRs in real-time workflow routes and Analysis agents for either a specific field value or a range of field values, see https://infozone.atlassian.net/wiki/spaces/MD93/pages/204676782 . EC Groups The EC Groups tool allows you to view and add EC Groups, see https://infozone.atlassian.net/wiki/spaces/MD93/pages/204671006 . Encrypt Password Encrypt Password allows you to encrypt any password and print out the result onto the text field, see https://infozone.atlassian.net/wiki/spaces/MD93/pages/204737275 . Execution Manager Execution Manager allows you to enable, activate, and monitor multiple workflow groups, see https://infozone.atlassian.net/wiki/spaces/MD93/pages/205030703 . Log Files With Log Files, you can access different types of log files, see https://infozone.atlassian.net/wiki/spaces/MD93/pages/205031026 . Log Filter In the Log Filter tool, you can edit log settings for the picos and update the logging dynamically, see https://infozone.atlassian.net/wiki/spaces/MD93/pages/314998785 . Python Manager With Python Manager you manage Python executables, see https://infozone.atlassian.net/wiki/spaces/MD93/pages/205030732 . System Exporter System Exporter enables you to export data from your system into a ZIP file, a specific directory, an MZ Package (MZP) file, or to Git, see https://infozone.atlassian.net/wiki/spaces/MD93/pages/204605469 . System Importer System Importer enables you to import data to your system, either from a ZIP file, a specific directory, an MZ Package (MZP), or from Git, see https://infozone.atlassian.net/wiki/spaces/MD93/pages/204998199 . System Log System Log stores events and errors that have been registered in the system. In addition, it also handles duplicate events within a time frame. The System Log tool allows you to browse and purge the stored log files, see https://infozone.atlassian.net/wiki/spaces/MD93/pages/204639211 . System Statistics System Statistics collects and consolidates execution information. System Statistics continuously monitors and logs the resource utilization of the different hardware nodes and can provide reports over a given time interval. The throughput of workflows can also be monitored using this mechanism. The statistical information can be viewed graphically over any period, and be printed. See https://infozone.atlassian.net/wiki/spaces/MD93/pages/312868905 . UDR File Editor The UDR File Editor allows you to view and edit the content of UDR files, see https://infozone.atlassian.net/wiki/spaces/MD93/pages/204737474 . Ultra Format Converter The Ultra Format Editor allows you to convert persisted UDRs into an updated UDR format, see https://infozone.atlassian.net/wiki/spaces/MD93/pages/204737474 .

---

# Document 1972: A TCP/IP Example - MediationZone Documentation 9.3 - InfoZone

**Source:** ratanon/mz93-documentation
**URL:** https://infozone.atlassian.net/wiki/spaces/MD93/pages/205654339/A+TCP+IP+Example
**Categories:** chunks_index.json

A workflow containing a TCP/IP collection agent can be set up to send responses back to the source from which the incoming data was received. This requires an APL agent (Analysis or Aggregation) to be part of the workflow. Open A TCP/IP workflow can be configured to send responses to the source To illustrate how such a workflow is defined, an example is given where an incoming UDR is validated, resulting in either the field anum or a sequence number being sent back as a reply message to the source. Depending on if one or several TCP/IP connections are allowed, the format of the reply message sent from the Analysis agent differs: Number of Connections Description Number of Connections Description Single Connection A bytearray is sent back as reply. Multiple Connections A UDR, extended with the built-in TCPIPUDR format. The reply message must be inserted in the response field (a bytearray ). Note! To keep the example as simple as possible, the valid records are not processed. Usually, no reply is sent back until the UDRs are fully validated and processed. The example aims to focus on the response handling only. Single TCP/IP Connection Clear the Allow Multiple Connections checkbox in the TCP/IP Collection agent to allow only one TCP/IP session at a time. If another attempt to create a connection is made while a connection already exists, the new connection is rejected. The TCP/IP Collection Agent To be able to send reply messages, Send Response must be selected in the configuration window of the agent. Add an Analysis agent to the workflow and connect it to the TCP/IP agent. Drag and drop in the opposite direction to create a response route in the workflow. Also, an Ultra format for decoding of incoming data must be defined. Note that no format has to be defined for the response - it will be sent as a bytearray from the Analysis agent. Open TCP/IP agent configuration The Analysis Agent The Analysis agent validates the incoming records and sends the response. If the field duration is less than or equal to zero, the UDR is discarded and the field anum , in form of a bytearray, is sent back as a response. All other UDRs are routed to the next agent in turn, and instead a sequence number is sent as a response. Note the use of the synchronized keyword. Updating a global variable within a real-time workflow must be done within a synchronized function to ensure consistency between threads. By default, a real-time workflow utilizes several threads. int seqNum; synchronized int createSeqNum() { seqNum = seqNum + 1; return seqNum; } consume { bytearray reply; if ( input.duration <= 0 ) { strToBA( reply, input.anum ); udrRoute( reply, "response" ); } else { strToBA( reply, (string)createSeqNum() ); udrRoute( reply, "response" ); udrRoute( input, "UDRs" ); } } Multiple TCP/IP Connections Select the Allow Multiple Connections checkbox in the TCP/IP Collection agent to allow several simultaneous TCP/IP sessions at a time. If an attempt to open a new connection is made when the maximum number of connections are already open, the new connection is refused. The TCP/IP Collection Agent To send reply messages, Send Response must be selected in the configuration window of the agent. An additional connection point will appear on the agent, to which you need to link an Analysis agent. Also, an Ultra format for the decoding of the incoming data must be defined. This format must contain the built-in TCPIP format. See the section below. Open TCP/IP agent configuration The Format Definition The incoming external format must be extended with the TCPIPUDR format. external asciiSEQ_ext sequential { ascii callId: terminated_by(":"); int seqNum: terminated_by(","); ascii anum: terminated_by(","); ascii bnum: terminated_by(","); ascii causeForOutput: terminated_by(","); int duration: terminated_by(0xA); }; internal TCP_Int : extends_class( "com.digitalroute.wfc.tcpipcoll.TCPIPUDR" ) { }; in_map TCP_InMap : external( asciiSEQ_ext ), internal( TCP_Int ), target_internal( ascii_TCP_TI ) { automatic; }; out_map ascii_TCP_outMap : external( asciiSEQ_ext ), internal( ascii_TCP_TI ) { automatic; }; decoder TCPData : in_map( TCP_InMap ); encoder TCPData : out_map( ascii_TCP_outMap ); The Analysis Agent The Analysis agent validates the incoming records and sends the response. If the field duration is less than or equal to zero, the UDR is discarded, the field anum is inserted into the response field, and the complete UDR is sent back as response. All other UDRs are routed to the next agent in turn and a sequence number is inserted into the response field before any routing takes place. Note the use of the synchronized keyword. Updating a global variable within a real-time workflow must be done within a synchronized function to ensure consistency between threads. By default, a real-time workflow utilizes several threads. int seqNum; synchronized int createSeqNum() { seqNum = seqNum + 1; return seqNum; } consume { bytearray reply; if ( input.duration <= 0 ) { strToBA( reply, input.anum ); input.response = reply; udrRoute( input, "response" ); } else { strToBA( reply, (string)createSeqNum() ); input.response = reply; udrRoute( input, "response" ); udrRoute( input, "UDRs" ); } }

---

# Document 1973: Python Processing Agent Configuration - Real-Time - MediationZone Documentation 9.3 - InfoZone

**Source:** ratanon/mz93-documentation
**URL:** https://infozone.atlassian.net/wiki/spaces/MD93/pages/204674145/Python+Processing+Agent+Configuration+-+Real-Time
**Categories:** chunks_index.json

The Python processing agent configuration consists of two tabs: General and MIM . General Tab The General tab consists of three sections: Python code for the consume block, input/output UDR types, and Interpreter configuration. Open The Python processing agent configuration - General tab Setting Description Setting Description Code Area This is the text area where you enter your code, see Python Writer's Guide for further information. The entered code will be color-coded depending on the code type, and for input assistance, a pop-up menu is available. Below the text area, there are line, column, and position indicators. See Python Code Editor Assistance . Input Types Enables selection of UDR Types. One or several UDR Types that the agent expects to receive may be selected. Set To Input Automatically selects the UDR Type distributed by the previous agent. Output Types Select which output types you want to have. Output Routes Enter the routes you want each output type to be sent out on. Interpreter select which Python Interpreter Profile you want to use. If no selection is made the interpreter that has been set as default in the Python Manager will be used. MIM Tab In the MIM tab, you can set the MIMs that you want the Python processing agent to publish. Open The Python processing agent configuration - MIM tab Parameter Description Parameter Description Assigned Select the type of MIM assigned. Only MIMs of the global type are available. Name Enter the MIM resource name. Type Select the data type of MIM resource.

---

# Document 1974: Couchbase Configuration - MediationZone Documentation 9.3 - InfoZone

**Source:** ratanon/mz93-documentation
**URL:** https://infozone.atlassian.net/wiki/spaces/MD93/pages/204613303/Couchbase+Configuration
**Categories:** chunks_index.json

After Couchbase has been installed, you can create Couchbase profiles to automatically generate buckets in the Couchbase cluster. In the Couchbase Web Console, you can also add more nodes to your cluster if you need to extend the database. Note! Created or updated Couchbase profiles that are used for PCC do not become effective until you restart the ECs. Couchbase Profiles A Couchbase profile is used to read and write bucket data in a Couchbase database. This profile can be accessed by workflows using Aggregation, Distributed Storage or PCC. As a client to Couchbase, the profile operates in synchronous mode. When sending a request to Couchbase, the profile expects a server response, indicating success or failure, before proceeding to send the next one in queue. To create a new Couchbase profile , click on the New Configuration button in the upper left part of the Desktop window, and then select Couchbase Profile from the menu. To open an existing Couchbase profile , double-click on the configuration in the Configuration Navigator , or right-click on the configuration, and then select Open Configuration(s)... . In a Couchbase profile , there are three tabs: Connectivity , Management , and Advanced. Note! To control Couchbase client management timeout as described in https://docs.couchbase.com/java-sdk/2.7/client-settings.html check Couchbase Profile . For information about how to add a server to the Couchbase Cluster, see the official Couchbase documentation: https://docs.couchbase.com/home/index.html

---

# Document 1975: JMS Collector Agent - MediationZone Documentation 9.3 - InfoZone

**Source:** ratanon/mz93-documentation
**URL:** https://infozone.atlassian.net/wiki/spaces/MD93/pages/204608150/JMS+Collector+Agent
**Categories:** chunks_index.json

The JMS collection agent sets up a subscription session to the JMS server destination that is specified in the JMS profile. For a list of JMS Message types supported by the collection agent see JMS UDRs . The message is inserted into the Request field of the JMSCycle UDR. Loading

---

# Document 1976: HDFS Collection Agent Events - MediationZone Documentation 9.3 - InfoZone

**Source:** ratanon/mz93-documentation
**URL:** https://infozone.atlassian.net/wiki/spaces/MD93/pages/204739140/HDFS+Collection+Agent+Events
**Categories:** chunks_index.json

Agent Message Events An information message from the agent, stated according to the configuration done in the Event Notification Editor . For further information about the agent message event type please refer to Agent Event . Ready with file: filename Reported along with the name of the source file that has been collected and inserted into the workflow. File cancelled: filename Reported along with the name of the current file, each time a Cancel Batch message is received. T his assumes the workflow is not aborted; refer to HDFS Collection Agent Transaction Behavior for further information. Debug Events There are no debug events for this agent.

---

# Document 1977: Python Code Editor Assistance - MediationZone Documentation 9.3 - InfoZone

**Source:** ratanon/mz93-documentation
**URL:** https://infozone.atlassian.net/wiki/spaces/MD93/pages/205653541
**Categories:** chunks_index.json

In the code area of the Python Module, the General tab of the Python collection and processing agents, and the API tab of the Python Connector agent, the different parts of the code are color coded according to type, for easier identification. When you right-click in the code area, a context sensitive popup menu appears, enabling easy access to the most common actions that you might want to perform. Code completion provides proposals when requested to help you write Python code. These features are described below. Syntax Highlighting The text is color coded according to the following definitions: Brown: Strings Blue: Functions Green: Types Purple: Keywords Orange: Comments Right-Click Menu The following options are available when you right-click on the code editor in a Python agent configuration: Open Text Editor right-click menu Option Description Option Description UDR Assistance Opens the UDR Internal Format Browser from which the UDR Fields may be inserted into the code area. MIM Assistance Opens the MIM Browser from which the available MIM Fields can be inserted into the code area.

---

# Document 1978: APL - PCC Runtime Support - MediationZone Documentation 9.3 - InfoZone

**Source:** ratanon/mz93-documentation
**URL:** https://infozone.atlassian.net/wiki/spaces/MD93/pages/204611740/APL+-+PCC+Runtime+Support
**Categories:** chunks_index.json

The runtime support is used for looking up the actual rules based on the references received with the mapper support. The runtime support functions include: pccCreate pccGetUdr pccGetUdrList pccCreate This function creates a data set object that can be used with the pccGetUdr and pccGetUdrList functions described below. any pccCreate ( string area ) Parameters Parameter Description Parameter Description area The name of the area which the function is operating against. Returns: A data set object that can be used with the pccGetUdr or pccGetUdrList functions. Example pccCreate("PROD"); will create a data set object that can be used with the pccGetUdr and pccGetUdrList functions against the PROD area. pccGetUdr Retrieves a specific UDR based on the stated UDR type and key. drudr pccGetUdr ( string typename, any key [, any dataset] ) Parameters Parameter Description Parameter Description typename The fully qualified typename of the requested UDR. key The reference to the requested UDR dataset The data set object that you want to use for retrieving the UDR. This field is optional, and if it is not used, the data set that was used last will be used for the retrieval. Returns: The matching UDR or null if no matching UDR was found. Example pccGetUdr("PCRF.Rules.Provisioning.Static_Rule", 333); will retrieve a UDR of the type PCRF.Rules.Provisioning.Static_Rule with the key 333 . pccGetUdrList Retrieves a list with all the UDRs with the stated UDR type. list <drudr> pccGetUdrList ( string typename [, any dataset] ) Parameters Parameter Description Parameter Description typename The fully qualified UDR typename of the requested UDRs. dataset The data set object that you want to use for retrieving the UDRs. This field is optional, and if it is not used, the data set that was used last will be used for the retrieval. Returns: A list containing all the UDRs of the requested type. Example list<drudr> rulesList = pccGetUdrList(ruleType); will return a list named rulesList with all the UDRs that have the type ruleType .

---

# Document 1979: 5G Profile - MediationZone Documentation 9.3 - InfoZone

**Source:** ratanon/mz93-documentation
**URL:** https://infozone.atlassian.net/wiki/spaces/MD93/pages/204671367
**Categories:** chunks_index.json

If you want to use 5G with HTTP/2 agents, you require a 5G profile configuration. You can select the profile that you configure in the HTTP/2 Server agent configuration. In the 5G profile configuration, enter the details required to register an NF (Network Function) instance in the NRF (NF Repository Function). Configuration The 5G profile consists of the following tabs: 1 General Tab 2 Advanced Parameters Tab General Tab Open 5G Profile - General tab Setting Description Setting Description 3GPP Version Version Select Select the version of 3GPP to apply to the 5G Profile. Note! 3GPP Release 15 is the current default version supported by MediationZone. Release 16 was added to support the handling of 3xx status codes. Release 17 is added to support the enhanced specifications and the new UDRs that are generated when coding with APLs. Enable Custom Specification Click this to use the custom version of the specification of NRF NFManagement Service. See Custom Specification Enabled for more information. Info! When enabling custom specification, all fields except for OpenAPI Profile and Enable Validation will be disabled. You need to use the Analysis agent or APL Code to create the NRFspecificationUDR that will contain all the values for the disabled fields. See Custom Specification Enabled for more information. Custom error handling for 5G during the startup can be configured at APL when the Route to APL option is enabled. See Route Error to APL for more information. OpenAPI Profile Select the OpenAPI profile for specification of NRF NFManagement Service. Enable Validation Validate the request for NF (Network Function) registration, heartbeat and de-registration against the OpenAPI schema provided from the OpenAPI profile. Configure Server Settings Path Enter the exact path to where the HTTP request will register, de-register and update the NF profile in the NRF. Example: /nnrf-nfm/v1/nf-instances/ Configure NF Settings NF Instance name Enter the name of the NF instance for the NF type that you want to use. This field supports parameterization using ${} syntax, see Appendix 1 - Profiles for more information on how parameterization works. NF type A list of various NF types is available for selection. The default is set to CHF (charging function). For more information on each NF type, refer to the specification in 3GPP TS 29.510, https://portal.3gpp.org/desktopmodules/Specifications/SpecificationDetails.aspx?specificationId=3345 . Heartbeat timer Enter the frequency (in seconds) for the NF registration to be updated in the NRF. NF Registration status Select the registration status that you want to have updated. The following status options are available: REGISTERED: This is to register your NF instance to the NRF UNDISCOVERABLE: This is to register your NF Instance without it being discovered by other NFs SUSPENDED: This is to temporary suspend the NF, so that it is unable to respond to any request FQDN Enter the Fully Qualified Domain Name (FQDN) for the NF instance. Support NRF Change Select this option to allow the NRF server to modify the heartbeat timer provided by the NRF client upon registration. IPv4 Address List You can add the IPv4 address(es) for the NF instance. IPv6 Address List You can add the IPv6 address(es) for the NF instance. Note! You must enter at least an FQDN, an IPv4 address or an IPv6 address, but you are not required to make an entry for all of these fields. In addition, you can enter any combination of the three fields that you require. Advanced Parameters Tab Open 5G Profile - Advanced parameters tab In this tab, you can add settings in a JSON configuration in accordance with 6.2.6.2.3 "Type: NFProfile" as defined the specification 3GPP TS 29.510, https://portal.3gpp.org/desktopmodules/Specifications/SpecificationDetails.aspx?specificationId=3345 . See the example below: Examples for Advanced Parameters Note! Values set in the Advanced Parameters tab will override those set in the General tab. Json configuration of advanced parameter { "nfProfileChangesSupportInd": true, "nfProfileChangesInd": true, "allowedPlmns": [ { "mcc":"262-01", "mnc":"302-720" } ], "allowedNfTypes": [ "PCF", "CHF" ], "allowedNfDomains": [ "www.domainname.com" ] } This field supports parameterization using ${} syntax. For more information on parameterization see Appendix 1 - Profiles . Parameterized Json Configuration of Advanced Parameter { "nfProfileChangesSupportInd": true, "nfProfileChangesInd": true, "allowedPlmns": [ { "mcc":"${5g.mcc}", "mnc":"${5g.mnc}" } ], "allowedNfTypes": [ "PCF", "CHF" ], "allowedNfDomains": [ "${5g.nfDomains}" ] } This example would result in three dynamic fields being generated and configurable per workflow: 5g - mcc 5g - mnc 5g - nfDomains Custom Specification Enabled When custom specification is enabled in 5G Profile, HTTP/2 Server agent will not perform registration of NF (Network Function) automatically during the startup of the workflow. The HTTP/2 Server agent will instead, wait to receive the NRFspecificationUDR in order to perform NF registration, heartbeat and de-registration. You can refer to the example below: Open An example workflow of HTTP/2 Server Agent with 5G Profile enabled and an Analysis Agent Example - HTTP/2 Server agent with 5G custom enabled The example workflow consists of HTTP/2 Server Agent with 5G Profile enabled and Analysis Agent to construct the NRFSpecificationUDR . When the workflow starts, the HTTP/2 Server Agent will route the NRFSpecificationUDR to the Analysis agent to construct the NRFSpecificationUDR as shown below. The constructed UDR is then routed back to the HTTP/2 Server Agent in order to perform the NF (Network Function) registration, heartbeat and de-registration. consume { if (instanceOf(input, NRFSpecificationUDR)) { nrf.NRFSpecificationUDR udr = udrCreate(nrf.NRFSpecificationUDR); udr.registerCycleUDR = constructRegUdr(); udr.heartbeatCycleUDR = constructHbUDR(); udr.deregisterCycleUDR = constructDeRegUDR(); udr.heartBeatFieldName = "heartBeatTimer"; udr.nfInstanceIdFieldName = "nfInstanceId"; udr.nfTypeFieldName = "nfType"; udr.nfProfileChangesSupportIndFieldName = "nfProfileChangesSupportInd"; udrRoute(udr); } } RequestCycle constructRegUdr() { // construct register UDR NFProfile nfUdr = udrCreate(NFProfile); nfUdr.nfInstanceId = "94d7f196-9d03-11eb-a8b3-0242ac130003"; nfUdr.heartBeatTimer = 5; nfUdr.fqdn = "domain.my"; nfUdr.nfType = "CHF"; nfUdr.nfStatus = "REGISTERED"; nfUdr.nfProfileChangesSupportInd = false; list<string> ipv4List = listCreate(string); listAdd(ipv4List, "10.60.10.111"); list<string> ipv6List = listCreate(string); listAdd(ipv6List, "2001:db8:85a3::8a2e:370:7334"); nfUdr.ipv4Addresses = ipv4List; nfUdr.ipv6Addresses = ipv6List; string jsonString = jsonEncodeUdr(nfUdr); bytearray ba; strToBA(ba, jsonString); http.RequestCycle regUDR = udrCreate(http.RequestCycle); map<string,list<string>> headersMap = mapCreate(string, list<string>); list<string> contentList = listCreate(string); listAdd(contentList, "application/json"); mapSet(headersMap, "Content-Type", contentList); regUDR.headers = headersMap; regUDR.method = "PUT"; regUDR.requestTimeout = 10000; regUDR.body = ba; regUDR.openAPIUDR = nfUdr; regUDR.path = "/nnrf-nfm/v1/nf-instances/94d7f196-9d03-11eb-a8b3-0242ac130003"; return regUDR; } RequestCycle constructHbUDR() { // construct heartbeat UDR PatchItem patchUDR = udrCreate(PatchItem); patchUDR.op = "replace"; patchUDR.path = "/nfstatus1"; patchUDR.value = "REGISTERED"; string jsonString = "[" + jsonEncodeUdr(patchUDR) + "]"; bytearray ba; strToBA(ba, jsonString); http.RequestCycle hbUDR = udrCreate(http.RequestCycle); map<string,list<string>> hbHeadersMap = mapCreate(string, list<string>); list<string> hbContentList = listCreate(string); listAdd(hbContentList, "application/json-patch+json"); mapSet(hbHeadersMap, "Content-Type", hbContentList); hbUDR.headers = hbHeadersMap; hbUDR.method = "PATCH"; hbUDR.requestTimeout = 10000; hbUDR.body = ba; hbUDR.openAPIUDR = patchUDR; hbUDR.path = "/nnrf-nfm/v1/nf-instances/94d7f196-9d03-11eb-a8b3-0242ac130003"; return hbUDR; } RequestCycle constructDeRegUDR() { // construct de-regsitration UDR http.RequestCycle udr = udrCreate(http.RequestCycle); udr.method = "DELETE"; udr.requestTimeout = 10000; udr.path = "/nnrf-nfm/v1/nf-instances/94d7f196-9d03-11eb-a8b3-0242ac130003"; return udr; }

---

# Document 1980: Aggregation Performance Tuning - MediationZone Documentation 9.3 - InfoZone

**Source:** ratanon/mz93-documentation
**URL:** https://infozone.atlassian.net/wiki/spaces/MD93/pages/204671965/Aggregation+Performance+Tuning
**Categories:** chunks_index.json

This section describes the various settings that are available for performance tuning of the Aggregation agent. The section contains the following subsections: Performance Tuning with Couchbase Storage Performance Tuning with File Storage Performance Tuning with Redis Storage

---

# Document 1981: APL Collection Strategy - MediationZone Documentation 9.3 - InfoZone

**Source:** ratanon/mz93-documentation
**URL:** https://infozone.atlassian.net/wiki/spaces/MD93/pages/205654949
**Categories:** chunks_index.json

APL Collection Strategy configurations are used on top of pre-defined collection strategies to customize how files are collected from the local file system. Prerequisites The reader of this document should be familiar with: Analysis Programming Language. For further information, see the APL Reference Guide . Configuration To open the configuration, go to Build  New Configuration and then select APL Collection Strategy from the menu. Open The APL Collection Strategy Configuration Setting Description Setting Description Base Collection Strategy From the drop-down list , select a pre-defined collection strategy. The Default Collection Strategy is the standard collection strategy that is used by default by the Disk and FTP agents. The available strategies are: Default Collection Strategy Control File Duplicate Filter Multi Directory TMO Full Collection Strategy Note! The Base Collection Strategy is the collection strategy that your APL Extension will be based on. When saving your new collection strategy, make sure to use a descriptive name since it will be added to the list of available strategies in the agent's configuration. The code that you see in the dialog is a default 'skeleton' set of function blocks that are already defined in the Base Collection Strategy . By adding APL code within these function blocks, you customize the way by which the collection is going to be handled by the workflow. initialize deinitialize prepareBaseDirList accept filterFiles preFileCollection postFileCollection begin commit rollback For more information about APL functions blocks and functions, see the APL Reference Guide . The FileInfo UDR Type The FileInfo UDR type includes the properties of the file to collect or a directory where files are stored. The FileInfo UDR type can be viewed in the UDR Internal Format Browser. To open the browser right-click in the editing area of an APL Editor and select UDR Assistance... . The browser opens. Open UDR Internal Format Browser - FileInfo UDR Type FileInfo UDR Fields The following fields are included in the FileInfo UDR: Field Description Field Description isDirectory(boolean) Set to True if FileInfo represents a directory. isFile(boolean) Set to True if FileInfo represents a file. name(string) The name of the file or directory. size(long) The size of the file or directory. timestamp(long) The timestamp for when the file or directory was last modified.

---

# Document 1982: Appendix 1 - Profiles - MediationZone Documentation 9.3 - InfoZone

**Source:** ratanon/mz93-documentation
**URL:** https://infozone.atlassian.net/wiki/spaces/MD93/pages/204639259
**Categories:** chunks_index.json

This appendix contains descriptions of the profiles that are not related to specific agents. Agent-specific profiles are described in the documentation of the respective agents. Parameterizable Profile Fields To make profiles reusable in an efficient way, some of them support a concept called Parameterizable Fields. Such fields makes it possible to have one configuration only, reusable both in development, test, and production systems. It also makes it easy to add support in CI/CD pipelines. For instructions on how to define basic parameters, refer to External Reference Profile . A parameterizable profile field can be used as a template and its value can be set per workflow. The parameter s ynt ax is ${category.name}. By using this syntax, a Dynamic Fields Tab of type string is created. The value of the field is set as a workflow parameter and the value will be replaced when the workflow is executed. Profile fields supporting parameterization are marked with a $(dollar sign) icon. Currently, the following profiles support use of parameterization: 5G Profile Couchbase Profile File System Profile Kafka Profile This chapter contains the following sections: 5G Profile Audit Profile Azure KeyVault Profile Couchbase Profile Database Profile Distributed Storage Profile Elasticsearch Profile External Reference Profile File System Profile Google Secret Manager Profile IPDR SP Template Profile Open API Profile Redis Profile Secrets Profile Security Profile Shared Table Profile

---

# Document 1983: System Log - MediationZone Documentation 9.3 - InfoZone

**Source:** ratanon/mz93-documentation
**URL:** https://infozone.atlassian.net/wiki/spaces/MD93/pages/204639211/System+Log
**Categories:** chunks_index.json

Events and errors encountered in the system are saved in the System Log. The System Log handles duplicate events within a time frame, and therefore every event and error has a first and last occurred date, as well as information on how many times it was repeated. You can select to filter out which events you want to see as well as delete selected events from the log. The System Log table will display a maximum of 500 000 entries. If you want to modify the maximum number of entries, add the Platform property mz.systemlog.maxresults to the platform.conf and modify the value, see Platform Properties . To open the System Log, go to Manage  Tools & Monitoring and then select System Log . Open The System Log If you have had the System Log open for a while, you can refresh the view by clicking on the Refresh button in the table action bar. System Log Table The System Log table displays the following options and values Column Description Column Description Open Selection Checkbox The selection check boxes can be used for selecting specific entries that you want to delete. If you select one or several check boxes, the table action bar will change to display a Clear and a Delete button. Last Occurred This column shows the date and time when the event last occurred. Severity This column shows the severity of the event: Info - An event with severity Info is an informative message, for example when a user logs in or a workflow is activated. Warning - An event with severity Warning is also an informative message but is considered to be slightly more serious than a regular information message, for example when a workflow sends data to ECS. Error - An error is logged when any part of the system fails, for example when a workflow aborts. If you display Event Details for an event with severity Error, you will see a stack trace that must always be included when contacting support. Fatal - Fatal is a severity that is never used by default, but may be used for user-defined agents. Type This column shows the event type: System Workflow User Message This column shows the message heading. If you display Event Details you will see the full message. First Occurred This column shows the date and time when the event first occurred. Repeated This column shows how many times this event has occurred. Area Indicates which part of the system the message originates from; user, system or workflow. Workflow/Agent The name of the workflow/agent from which the message originates. Message Area If an entry is selected from the list, further details about it is displayed in this area. Event Details If you click on the entry in the System Log table, you will see additional details about the event: Open Apart from the Last occurred, Message heading you will also see the following information: Information Description Information Description Creation date The date and time when the entry was registered. Origin The origin of the event, for example an IP address and port for a user event, or the host and port for a workflow event. Agent name Name of any agent involved. User name The user name of the user being the origin of the event. This information is only displayed for user events. Stack trace The full stack trace for errors. This information is only displayed for workflow events. Filter Open You can click on the Filter button to set filters for a more curated list of entries in the System Log. The Filter dialog will then open where you can configure your filter. Open System Log Filter An entry has to match all configured filter settings to be displayed in the System Log table. Item Description Item Description Severity The severity of the log entry; Info, Warning, Error, Fatal Type The affected entity. Date Range Within which period entries will be viewed. A few predefined options are available. If none are selected, all are considered. The default period is Today . The available options are: User-defined All Last hour Today Yesterday This week This month If you select User-defined , enter the Start date and time and End date and time . If neither are specified, all entries will match. Workflow Select to only view events relating to a selected workflow. All workflows for which entries have been registered are selectable in this drop-down-list. Only one workflow can be selected. Workflow Group Select to only view events relating to a selected workflow group. All workflow groups for which entries have been registered are selectable in this drop-down-list. Only one workflow group can be selected. Agent Select to only view events relating to a selected agent. All agents for which entries have been registered are selectable in this drop-down-list. Only one agent can be selected. Note! The System Log does not display agent events by default, in order for agent events to be presented in the System Log you have to configure agent events in an Event Notifications . Username Select to only view events relating to a selected user. All users for which entries have been registered are selectable in this drop-down-list. Only one user can be selected. Note! This filter will only apply to user events and not any other events with user name stated, and can therefore not be used for filtering out workflows created by specific users. Message Enter a free text search string to be matched by the messages in the entries you want to display. When you are finished, click OK to apply your filter settings. If you want to clear all filters, you can open the Filter dialog again and click on the Reset button. Deleting Entries You can delete either all entries in the System Log, or specific entries. To delete all entries, click on the Delete button in the table action bar. You will be prompted to confirm that you want to delete all entries. Click on the Delete button to confirm. If you want to only delete specific entries, select the check boxes for the entries you want to delete. The table action bar will change and display a Clear button and a Delete button. Click on the Clear button to clear all your selections, or on the Delete button if you want to delete selected entries. You will be prompted to confirm that you want to delete all entries. Click on the Delete button to confirm.

---

# Document 1984: HDFS Forwarding Agent MultiForwardingUDR Input - MediationZone Documentation 9.3 - InfoZone

**Source:** ratanon/mz93-documentation
**URL:** https://infozone.atlassian.net/wiki/spaces/MD93/pages/204739164/HDFS+Forwarding+Agent+MultiForwardingUDR+Input
**Categories:** chunks_index.json

When the agent is set to use MultiForwardingUDR input, it accepts input of the UDR type MultiForwardingUDR declared in the package FNT. The declaration follows: internal MultiForwardingUDR { // Entire file content byte[] content; // Target filename and directory FNTUDR fntSpecification; }; The content of the MultiForwardingUDR will be stored at the path that you have set in the fntSpecification field. Use the APL functions fntAddString and fntAddDirDelimiter to set the value of this field. For further information about these functions, see FNTUDR Functions in APL Reference Guide . When the files are received they are written to temp files in the DR_TMP_DIR directory situated in the root output folder. The files are moved to their final destination when an end batch message is received. A runtime error will occur if any of the fields have a null value or if the path is invalid on the target file system. A UDR of the type MultiForwardingUDR which has a target filename that is not identical to its precedent is saved in a new output file. Note After a target filename that is not identical to its precedent is saved, you cannot use the first filename again. For example: Saving filename B after saving filename A, prevents you from using A again. Instead, you should first save all the A filenames, then all the B filenames, and so forth. Non-existing directories will be created if the Create Non-Existing Directories check box under the Filename Template tab is selected. If not selected, a runtime error will occur if a previously unknown directory exists in the FNTUDR of an incoming MultiForwardingUDR . Every configuration option referring to bytearray input is ignored when MultiForwardingUDRs are expected. Example - APL code to send MultiForwardingUDRs This example shows the APL code used in an Analysis agent connected to a forwarding agent expecting input of type MultiForwardingUDRs . import ultra.FNT; MultiForwardingUDR createMultiForwardingUDR (string dir, string file, bytearray fileContent){ //Create the FNTUDR FNTUDR fntudr = udrCreate(FNTUDR); fntAddString(fntudr, dir); fntAddDirDelimiter(fntudr);//Add a directory fntAddString(fntudr, file);//Add a file MultiForwardingUDR multiForwardingUDR = udrCreate(MultiForwardingUDR); multiForwardingUDR.fntSpecification = fntudr; multiForwardingUDR.content = fileContent; return multiForwardingUDR; } consume { bytearray file1Content; strToBA (file1Content, "file nr 1 content"); bytearray file2Content; strToBA (file2Content, "file nr 2 content"); //Send MultiForwardingUDRs to the forwarding agent udrRoute(createMultiForwardingUDR ("dir1", "file1", file1Content)); udrRoute(createMultiForwardingUDR ("dir2", "file2", file2Content)); } The Analysis agent mentioned in this example sends two MultiForwardingUDRs to the forwarding agent. Two files with different contents are placed in two separate sub folders in the root directory. The Create Non-Existing Directories check box in the Filename Template tab in the configuration of the forwarding agent must be selected if the directories do not previously exist.

---

# Document 1985: Web Service Provider Agent - MediationZone Documentation 9.3 - InfoZone

**Source:** ratanon/mz93-documentation
**URL:** https://infozone.atlassian.net/wiki/spaces/MD93/pages/205002605/Web+Service+Provider+Agent
**Categories:** chunks_index.json

The Web Service Provider agent has a great resemblance to a server and allows Web Service requests to be collected and inserted into a workflow. When a request arrives at the Web Service Provider it will first decode and validate it into a pre-generated UDR type, WSCycle UDR. WSCycleUDR is then routed through the workflow with the param field set to the incoming message. If the client expects a response message the workflow is responsible for populating the response field with an appropriate answer message (through the udrCreate APL function). The WSCycleUDR must then be routed back to the Web Service Provider agent to transmit the answer. Note! Configurations made in the agent always override settings originating from the WSDL file. The section contains the following subsections: Web Service Provider Agent Configuration Web Service Provider Agent Input/Output Data, MIM and Events

---

# Document 1986: ECS Collection Agent Events - MediationZone Documentation 9.3 - InfoZone

**Source:** ratanon/mz93-documentation
**URL:** https://infozone.atlassian.net/wiki/spaces/MD93/pages/204738703/ECS+Collection+Agent+Events
**Categories:** chunks_index.json

Agent Message Events An information message from the agent, stated according to the configuration done in the Event Notification Editor. For further information about the agent message event type, see Agent Event . Ready with file: <filename> This event is logged for batch collection only, and is reported at end batch stating the name of the file currently processed. Ready with recovered file Reported when a file is recovered in case of a crash. Debug Events Debug messages are dispatched in debug mode. During execution, the messages are displayed in the Workflow Monitor. You can configure Event Notifications that are triggered when a debug message is dispatched. For further information about the debug event type, see Debug Event . The agent produces the following debug events: Start collecting This event is logged for UDR collection only, and is reported when collection from the ECS starts. Commit started This event is logged for UDR collection only, and is reported at end of batch when starting to commit changes to the database. Commit done, consumed <count> UDRs This event is logged for UDR collection only, and is reported at end of batch upon a successful commit.

---

# Document 1987: Inspection - MediationZone Documentation 9.3 - InfoZone

**Source:** ratanon/mz93-documentation
**URL:** https://infozone.atlassian.net/wiki/spaces/MD93/pages/204998019/Inspection
**Categories:** chunks_index.json

When workflows are executed, the agents may generate various kinds of data, such as logging errors into the System Log, or sending erroneous data to the Error Correction System (ECS), etc, and there are various Inspectors available where you can view such information. To open an Inspector, click on the Manage menu in Desktop and select the Inspector you want to open in the Data Management section. Note! The ECS Inspector and ECS Statistics are only available in Legacy Desktop The following Inspectors are available to analyze the data: Aggregation Session Inspector See Aggregation Session Inspector . Archive Inspector See Archive Inspector . Duplicate Batch Inspector See Duplicate Batch Inspector . Duplicate UDR Inspector See Duplicate UDR Inspector . ECS Inspector See ECS Inspector . ECS Statistics See ECS Statistics . Loading

---

# Document 1988: Control Zone and Execution Zone - MediationZone Documentation 9.3 - InfoZone

**Source:** ratanon/mz93-documentation
**URL:** https://infozone.atlassian.net/wiki/spaces/MD93/pages/205881511/Control+Zone+and+Execution+Zone
**Categories:** chunks_index.json

Refer to the System Administrator's Guide documentation for information about the administration of the Control Zone and Execution Zone.

---

# Document 1989: Radius Server Agent - MediationZone Documentation 9.3 - InfoZone

**Source:** ratanon/mz93-documentation
**URL:** https://infozone.atlassian.net/wiki/spaces/MD93/pages/205686720/Radius+Server+Agent
**Categories:** chunks_index.json

The Radius Server agent can receive accounting data (UDP packet) from multiple Network Access Servers (NAS). The Radius accounting data contains information about the last client that had logged in, the log-in time, the duration of the session etc. Other than collecting such data, the Radius Server agent may act as an extension to the NAS, creating accounting data itself. For instance, when receiving a packet containing a login request, it may reply with an accept or reject packet. The reply logic is handled through APL code (an Analysis or Aggregation node). Open Example Radius workflow Note the absence of a Decoder. For real-time workflows, field decoding is handled via APL commands. The Radius format is included when a Radius bundle is committed into the system. The format contains record identification information on the first level (code, identifier, length, authenticator and attributes) to be used by the Radius Server agent. Hence, the agent is responsible for recognizing the type of data, while the Analysis node does the actual decoding of the contents (the attributes). A UFDL format needs to be defined for this purpose. When activated, the agent will bind to the configured port and wait for incoming UDP packets from NASes. Each received UDP will be converted to a UDR and forwarded into the workflow. If fields are missing in a UDP, the agent will still create a UDR, filling in all found fields. If the data in the UDP is corrupt, or if data arrives from a host not present in the configuration window of the node, a message will be sent to the System Log and the data will be discarded. Since NASes cannot request historic data, the agent will lose all data that is delivered from the NAS while the agent is not executing. The Radius Server agent supports IPv4 and IPv6 environments. This section includes the following subsections: Radius Server Agent Preparations Radius Server Agent Configuration Radius Server Agent Input/Output Data and MIM Radius Server Agent Events Radius Server Agent with Supervision Service

---

# Document 1990: mzcli - configuration - MediationZone Documentation 9.3 - InfoZone

**Source:** ratanon/mz93-documentation
**URL:** https://infozone.atlassian.net/wiki/spaces/MD93/pages/547979405/mzcli+-+configuration
**Categories:** chunks_index.json

Usage configuration [-de <passphrase>] | [ -d ] | [ -e ] | [ -en <passphrase> ] | [ -l ] | [ -s ] | [-o] [-t <type>] [-n <name>] Options: -de, --decrypt Decrypt the configurations with passphrase Default: <empty string> -d, --disable Disable configurations. Default: false -e, --enable Enable configurations. Default: false -en, --encrypt Encrypt the configurations with passphrase Default: <empty string> -l, --list List configurations. Default: false -o, --locked Match only locked configurations. Default: false -n, --name Name to match configurations against. Default: .* -s, --status Status of configurations. Default: false -t, --type Type of configurations. This command enables you to handle your configurations in various ways, such as enabling, disabling, checking status, etc. Options Option Description Option Description [-de, --decrypt <passphrase>] Use this option to decrypt all configurations of the default configuration type, or configurations matching the regular expression stated with the -n option. You must enter the passphrase that you used to encrypt the configuration(s). [-d, --disable] Use this option to disable all enabled configurations of the default configuration type, or configurations matching the regular expression stated with the -n option and of the type stated with the -t option. The default value is false . [-e, --enable] Use this option to enable all disabled configurations of the default configuration type, or configurations matching the regular expression stated with the -n option and of the type stated with the -t option. The default value is false . [-en, --encrypt <passphrase>] Use this option to encrypt all configurations of the default configuration type, or configurations matching the regular expression stated with the -n option. You must enter a passphrase. [-l, --list] Use this option to list all configurations of the default type, or of the type stated with the -t option. The default value is false . [-o, --locked] Use this option to list only locked configurations. The default value is false . [-n, --name] Use this option to indicate which configurations you want to perform an action on. Only configurations matching the regular expression stated with the -n option will be affected. The default value is .* . [-s, --status] Use this option to display the status of all configurations of the default type, or configurations matching the regular expression stated with the -n option and of the type stated with the -t option. The default value is false . [-t, --type] Use this option to indicate the type of configuration you want to perform an action on. Only configurations matching the stated type will be affected. Note! Currently, Event Notification and Alarm Detection are the only type of configuration supported. When used in combination with - -decrypt or --encrypt , the -t option is ignored. Note! The options -d, -e, -l and -s are mutually exclusive, meaning that only one of the options will be applied even if you have stated several. Return Codes The different return codes for the configuration command are listed below: Code Description Code Description 0 Will be returned if the command was executed successfully. 1 Will be returned if the input could not be processed. 2 Will be returned if the input did not generate any action. 3 Will be returned if something unexpected happened. 4 Will be returned if one or more configurations were locked, or if the user does not have access to one or more of the configurations.

---

# Document 1991: SFTP Collection Agent Configuration - MediationZone Documentation 9.3 - InfoZone

**Source:** ratanon/mz93-documentation
**URL:** https://infozone.atlassian.net/wiki/spaces/MD93/pages/205001981/SFTP+Collection+Agent+Configuration
**Categories:** chunks_index.json



---
**End of Part 84** - Continue to next part for more content.
